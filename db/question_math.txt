QuestionKenntnis:
Can I use my powers for good?
qn_description:
I hesitate to ask this question, but I read a lot of the career advice from mathOverflow and math.stackexchange, and I couldn't find anything similar. 

Four years after the PhD, I am pretty sure that I am going to leave academia soon. I do enjoy teaching and research, but the alpha-maleness, massive egos and pressure to publish are really unappealing to me, and I have never felt that I had the mathematical power to prove interesting results. However, I am really having trouble thinking of anything else to do. Most people seem to think that the main careers open to mathematicians are in banking and finance. I really want to work in some field where I can use mathematics, but it is also important to me to feel like I am contributing something positive or at least not actively doing harm. For this reason, financial speculation is very unappealing to me, although I do find the underlying mathematics quite fascinating.

Here is my question: what careers which make a positive contribution to society
might be open to academic mathematicians who want to change careers?
AnswersKenntnis
AnswerKenntnis:
If you are in the US, there are several thousand institutions of higher learning, and at many of them there is very little "pressure to publish". At others, the "pressure to publish" can be met by publishing a textbook or some work of scholarship that does not require proofs of interesting (original) results. High schools also need qualified Mathematics teachers. Consider staying in academia, just moving to a different part of it, as an option for using your powers to do good. 

I suspect, but cannot be sure, that much of what I've written applies outside the US as well.
AnswerKenntnis:
Procedural world generation and AI in the field of games development needs people like You(!) to forward the state of the industry from the drivel we see today. It is as creative as it is technically challenging, and in my forays in this field (disclaimer: as someone generally mathematically inept), I have seen the use of a broad spectrum of mathematics and logic; to name just a few such applications:


Diffusion equations for chemical detection in AI (such as simulating a sense of smell and pulling AI entities along the gradients created by these equations toward their goals)
Radiosity algorithms using eg. Lambert's equations in realtime raycasting
Fluid dynamics using cellular automata
Graph theory for generating planar connected world graphs, including such aspects as finding and eliminating Kuratowski subgraphs
Combinatorics in evaluating corner cases for constructive solid geometry applications
Statistical modelling and analysis for game rules balancing
Minkowski sums in opening sufficiently broad paths for navigation during world generation
Spatial quantisation and subdivision as a general optimisation
Quaternions to RK4 integration to Delaunay's triangulations in physics and geometry
Combinatorics, probability theory and general statistics in projecting the emergent outcomes of complex systems
Probability theory in random number generation eg. Mersenne Twister
Formal grammars in narrative and physical object construction (eg. Lindemayer systems)
And more mathematics applicable to broader field of computer programming, such as analysing and reducing computational complexity.


This is a very haphazard and sparse collection of applications, so forgive me but my knowledge of the very existence of many of these areas has come from a game designer/developer's perspective. In any case, this list goes on ad infinitum for all practical purposes, considering that modelling worlds draws from every known field, from demographics to hydrodynamics to geomorphology to psychology to genetics to narratology... with mathematics being what all of these have in common.

The spectrum in game development is vast, because you are modelling the mechanics of worlds / universes, according to the processing contraints of the system(s) you are developing for -- this latter part is where the real challenge comes in, and a broad, sound understanding of mathematics becomes even more necessary to apply new optimisation tricks.

A sprinkling of some of my favourite places on the www, which may give you some insight into the breadth I'm talking about:


Infinity, generating galaxies from the top down.
Miguel Cepero's blog about his as yet unnamed, procedurally generated voxel-based world.
An interview with the author of Dwarf Fortress, describing how various aspects of the world were modelled (from history to geography to psychology).
A collection of pages on procedural generation of mazes (graph theory).
A video showing some emerging technologies in the virtual worlds arena.


I would speculate that it is far easier to be a trained mathematician and become a good programmer, than the reverse. In many ways I would rather be in your shoes, reading my post, than vice versa. Of course that's assuming that this is a convincing argument in terms of changing career direction!

If this does interest you even remotely, don't let what they say about games put you off. The line between games, traditional linear narratives, sandboxes for physical and AI experimentation, educational products ("serious games") and so on, is blurring at a rapidly accelerating rate. The vast majority of games, I would say all but less than 1%, are the same old rehashed tripe. But there is enormous potential for creativity, the more so for those with a strong mathematical background, as evidenced by some of the links above. I think there is something very positive in giving people new and inspiring spaces in which to play, relax and learn.



P.S. If my use of terms doesn't make sense, please correct me on every point, I joined this site to improve my mathematical knowledge and your criticism is welcome.
AnswerKenntnis:
Have you read the book 'Surely you're joking, Mr. Feynman?' The great physicist suffers a similar problem to what you describe - having worked on the atomic bomb, he felt 'burned out' and unable to do further physics. Somehow, he wasn't able to interest himself, and work with the same vigour as before.

He then took the approach not to work to any reasonable gain, but to enjoy physics! To enjoy messing around with it, calculating things of no use to anyone. And he found that suddenly, he had his hunger back.

Think about why you went into this profession in the first place. Surely you love maths? Well, enjoy it now, as you enjoyed it when you were a small child. And you never know, your work may  turn out to be useful (in Feynman's case, he won a noble prize for it).

And even if you choose to ignore everything else said, read the book. It's a great read.
AnswerKenntnis:
I found myself in a similar situation just over a decade ago: two years after PhD in mathematics, disenchanted with academia, and needing to make ends meet.

My own choice was to go into computing (specifically, I'm now a software engineer).  A mathematician of any stripe will find this field easy to pick up, and some of the skills gained in completing the PhD -- in particular, meticulousness, precision, and tenacity -- are of monumental import.

I've worked on software in several different fields: mechanical engineering (aerospace), nuclear energy, finance, and Child Protection Services, among others. My job satisfaction is very high; I only wish I'd gone into it earlier.

A final, more general note: your options are vast and wide, much broader than you'd expect.  I'd suggest looking into fields where the style of your mathematics is particularly applicable, and where you'd be both interested and happy. Software engineering has special attraction for me because (a) my area of math was combinatorics, and (b) I have a penchant for fixing problems and simplifying structural models.

Best of luck!
AnswerKenntnis:
You could go into operations research and work in the nonprofit/humanitarian sector.  While OR has traditionally been applied to problems in business and industry, the nonprofit and humanitarian world has started to use it more and more in recent years.  There are even interesting research problems being generated because the constraints and objectives in the nonprofit world don't always boil down to the same kinds of mathematics that constraints and objectives in the business world do.

INFORMS (the Institute for Operations Research and the Management Sciences) has been promoting this lately under the slogan "Doing Good with Good OR."  A recent issue of the INFORMS journal Interfaces was devoted to humanitarian applications of OR; check it out to get some ideas for ways to use your powers for good.  Or do a search on "Doing Good with Good OR" for more ideas.
AnswerKenntnis:
A lot of responses to this question are more upbeat than I think is warranted.  Many answers give detailed lists of uses of mathematics in a way that suggests the writer has no experience actually hiring people out of academia to meet those needs.  There is an awful lot of "fields X, Y, and Z need people to do math, so you can probably get a job doing that."  The irony is that this attitude is most common within academia.  Most people who will assume that a math PhD with no job experience outside of academia is good for something, to the point of paying them to work on an applied problem, are in academia--- in bioengineering, machine learning, and other fields that people have recommended.  The point I would underline here is that these people work in universities and if you want to get into these areas, you will have to stay in academia, at least a little.

The experience of a researcher at a university in some applied area is very different from the experience of a professor of pure mathematics.  For example there are often fewer teaching duties (e.g. lab supervision, instead of teaching large classes--- or no teaching duties at all).  And there are more options for sources of outside funding--- unlike in most of math, where if you don't get a grant from a government agency that funds math, you aren't getting a grant.  But there will still be publishing papers, and you will still spend the majority of your time with people who share their social characteristics more with other academics than they do with the general population.

Academia isn't the only culture with negative aspects.  If you look for a private sector job, you will find that most people--- even in very technical companies--- are not open to hiring people with no private sector experience and no personal connections for non-entry-level jobs.  And they aren't open to hiring PhDs for entry level jobs (you are "overqualified").  At many companies, it's not "we do a lot of mathy stuff, so math PhDs can help a lot," but "we do a lot of real world stuff here, and anybody who spends decades buried in textbooks won't know anything about that."  For example, unless you have an easily documented and publicized history of programming (e.g. contributions to open source projects, or reasonably self-contained projects that you can make public and stick on a personal website), most companies will not give you a second look for any software engineering job.  Even if you've done a ton of programming, you will never get a chance to show it, because most companies will not call a math PhD back on the off chance they can do something useful.  Say what you will about academia, but if you apply to an academic research group whose work has some mathematical flavor, they are much more likely to actually give you a chance.

Someone linked a talk by Cathy O'Neil in another answer.  It contains good advice, but recall that this was a talk given at MIT.  Cathy O'Neil has a PhD from Harvard and research experience at MIT.  Her first work post-academia was at D. E. Shaw.  It is reasonable to assume that she does not have any experience with the obstacles that confront the average academic who wants to transition into something else.  She writes: "being really [flipping] good at math is considered a superpower by the people outside. This is because you can do stuff with your math that they actually donΓÇÖt know how to do, no matter how much time they spend trying."  These are the words of someone who has had a very atypical experience in transitioning from academia to the private sector (granted, given the audience of the talk, it is reasonable to assume that most of the audience will be atypical also).  People coming out of academia who are not coming from the absolute top schools, with the connections that often come from that, are generally not greeted as superheroes by the private sector.  (I want to make clear: I'm not criticizing Cathy here, or suggesting that she hasn't worked hard to get where she is.  It's just a lot harder to do what she has done than you might think, reading only her words and not considering the context.)

I would say: if you want to get a mathy job, unless you have a documented history of things that are of immediate relevance to the private sector, or professionally useful personal connections in the outside world--- stay in academia, but switch fields to an applied area (lots of good suggestions have been given here).  After a few years, you may have connections that can help you transition to a mathy job outside of academia, or at least a broader resume that people might be more inclined to take seriously.  I don't mean to be negative here--- you probably should be taken seriously as you are now.  But outside of academia, in my view, the odds are that you won't.
AnswerKenntnis:
Don't write off the finance industry. If you are confident you can avoid your own self-corruption there is no need to think you can't have an amazing impact on the world by working in finance.

There are many areas of finance that add tremendous stability to society and are a good thing (for example, insurance). Mathematicians are able to provide the models and techniques that mean these things can be fair and sustainable as a business.

The finance industry will teach you what things are worth investing in and what things are a waste of time and money. Lots of firms and organisations are incredibly wasteful and stunted in potential because they do not know how best to organise their money. Someone smart like you can learn important skills to take elsewhere to solve these problems. As a mathematician you'll enter straight away into one of the more lucrative verticals of the banking sector. Give yourself ten years to make as much wealth as possible then leave. You'll have the experience and capital to set up a business/charity you believe in.
AnswerKenntnis:
I've seen people in pure math who wanted to switch fields while saving the world get postdocs in biostatistics or bioinformatics. This was a few years ago when these fields were especially 
"hot" but I would guess it's still true. There were many expanding labs and research groups and they would often take people switching from other fields. If you go into these fields, epecially bioinformatics, you may end out doing a lot of programming, so be sure this is something you'd be comfortable with.

Another option would be to get a masters degree, or even go for a second PhD if you can stand it. But I don't think you should have to go this far. 

If you are into programming you could try working for a company that does mathematical software, as KCd suggested.
AnswerKenntnis:
The difficulty here is that "a positive contribution to society" turns out to be quite a subjective thing. So even if you feel other people might know what you mean, there's lots of space for confusion and disagreement.

I can tell you what I did with my maths (across the UK / NW Europe). I've tried to make a positive contribution to society, by my own standards. Your mileage may vary.

I've designed photovoltaic systems. I've been an urban transport planner and modeller. I've been an energy analyst, and created models for local, national and international clean-energy supply and demand. My work has cut across engineering, physics, politics, economics, sociology, psychology, urban design and architecture.

There are still plenty of gaps in all these fields; for example, for clean-energy modelling, it would be very useful to have a simulation package that could produce plausible patterns of insolation, rainfall and wind, at continental scale, and that which reproduced real-world temporal and spatial correlations, at the level of minutes to years.

Note that you're unlikely to use PhD-level maths in many places at all: there's a trade-off between depth of maths used, and number of options open to you.

Good luck.
AnswerKenntnis:
Consider a career working for a publisher of technical books. Like Springer or Birkhauser. Be a force for good mathematics!

Years ago just after I finished my PhD I spent a week as a taxi driver (I don't recommend this career choice) -- technically I was helping with a conference and shuttling participants around. One of the people I met (the wife of the principal speaker) was a publisher working for Birkhauser. I mentioned that I still hadn't found "the job" and she suggested coming to work for her. They are always in need of someone with the ability to edit/correct/deal with mathematically technical texts. I didn't take her up on the offer, but have thought about it at times. The idea of sitting around reading and discussing math texts all day sounds...well...like goofing around on math.stackexchange.com :)

My second suggestion (this one's probably already been suggested) is join the Peace Corps for a few years. I met a "semi-retired" mathematician last year who joined the Peace Corps and went off to Africa (for an adventure). You would probably end up training math teachers in a foreign country.
AnswerKenntnis:
Original Answer: 

I am surprised no one has suggested you could start collaborating with the scientists working on the  Azimuth Project. I was initiated by the renowed mathematical physicist John Baez. He recently stopped working on $n$-categories and their applications in physics to start "... help saving our beleaguered planet". He now works at the Centre for Quantum Technologies in Singapore (this is their website).

The azimuth project focusses on tackling the various environmental problems we are currently facing, including, but not limited to: global warming, extinction, deforestation, ocean acidification, dead zones, the water crisis and peak oil. 

Everything is more elaborately and carefully explained in the links I provided you with and the links within the websites to which the links will direct you. 

I believe this project is an overwhelmingly noble initiative and in my opinion, you would certainly use your powers for "good" if you started working on it. 

Added on the seventh of April, 2014: 

Recently, I discovered "The Ocean Cleanup" project. For a sustainability competition, Boyan Slat came up with a design for an ocean cleanup array that can help getting rid of a lot of plastic in the sea. The device consists of anchored network of floating booms and processing platforms that could be dispatched to garbage patches around the world. From inhabitat:  


  Instead of moving through the ocean, the array would span the radius of a garbage patch, acting as a giant funnel. The angle of the booms would force plastic in the direction of the platforms, where it would be separated from plankton, filtered and stored for recycling.


According to the organisation's (yup, the design is now being fleshed out by a whole organisation of students, postdocs and professors from the TU Delft, aided by volunteers) website, 
they're still looking for: 


Hydrodynamic/Fluid dynamics modellers
Advanced Computational Modellers 
Physical Oceanographers 
Biologists and Remote Sensing experts 


For more information: their website is over here. You can also view Boyan's TEDx Talk.
AnswerKenntnis:
there are a set of skills required for 'data scientists' that drawn mainly from math topics like graph theory and statistics. I'm not sure if this fits your ethos requirements though. You'll have to figure it out by yourself.

more reading: http://www.technologyreview.com/blog/mimssbits/27201/#.TpW-IJsr2so
AnswerKenntnis:
You may want to consider moving to a country where there is a lack of trained mathematicians. I'm sure that many of these countries have the problem of their best minds being drawn away by exciting overseas opportunties. The universities in these countries are probably less focused on research and more focused on the pragmatic task of upskilling their workers.
AnswerKenntnis:
I also hesitate to give this answer but here it goes. 

You do not have to work in the most obvious jobs to help the society. As a mathematician you must be fully aware of the fact that many useless looking abstract mathematical tools turned out to be extremely useful in practice only later. 

Besides how do you know that education is helping the society where we have an increasing evidence that our educational system is very wrong. So in reality, you might be doing the exact opposite what you wish initially i.e. making people love math and make them suffer by a pursuing a degree among those mean and arrogant alpha-males (Exaggeration police was here! But you can see this,this and especially this for the fun of it). 

Moreover, you might do more good if you really love your subject and create a use of it. Many concepts like Street-Fighting Mathematics and Freakonomics showed that the academia is missing something that is truly crucial for its self-sustained dignity. The relevance. 

By relevance, I don't mean that poem starting with math is pure, would you know that it is relevant from the start. I know what R&D departments do, because I worked for quite some time in one particular industry. Hence, I know how to measure how much of my work will be complete fun and useless (for the time being) and how much of it will spin-off to something that would be good for a product. Same holds for the academia, you can't expect every single person to publish and turn everything upside down with one 3-page article. Some people don't want to publish anyway. Some people love to get their hands dirty and work on applied math problems which most of them are not even publishable. Some even go into private companies and carry on their stuff applied to a special (and possibly boring but, hey who cares) practical problem (Not to mention the Google's PageRank).

Long story short, you would better off if you follow nobody's instincts but yours. Try to materialize your career plan with the given limited resources and surplus of happiness that it provides. Sounds clich├⌐ but it became a clich├⌐, in the first place, for a reason. By itself, it is a damn hard problem. So you might work on it as a mathematician starting from the Lagrangian :P
AnswerKenntnis:
Why not apply your math skills to Machine Learning or AI?  The IT industry is starving for people like this.  Check out www.ml-class.org as just one example Stanford is doing to help bring more ML to the industry.  It's right up a mathmatics background alley!
AnswerKenntnis:
Your main assets are your ability to learn new topics and analyze complex problems quantitatively. These can be applied to any number of fields, some of which were mentioned above.

Try by searching for job openings as an algorithm developer and similar titles. Often requirements will include a Ph.D. in mathematics or a related field. Such jobs are often exploratory and include writing a prototype using either mathematical utilities such as Matlab, Mathematica or R, or programming languages such as Perl, Phyton, C. These prototypes either serve as an internal research tool or as a starting point for distributed software components. 

Indeed, machine learning is often used and it would be a good idea to familiarize yourself with the approach and even gain some hands on experience, e.g, via the online course mentioned above by @Mech.
AnswerKenntnis:
I skimmed through the answers and didn't see this mentioned already, but have you considered working for an entity involved in making mathematical education resources available online?  There's a huge gap between what current technology could allow us to do in mathematics education and what is currently being done.  One could argue that mathematics education will likely be very, very different ten to twenty years from now.  One site that has recieved a lot of attention and funding is Khan Academy, but I am sure there are lot more initiatives taking place around the world.

Imagine a world where the same group of mathematicians no longer spend each semester giving the same (often uninspired) lectures on college algebra and introductory calculus, because high quality lectures and supporting material are freely available online.  Instead, classroom time is used to give individual attention to each student's current state of progress, and research mathematicians spend more of their teaching time supervising undergraduate research projects instead of explaining the perils of dividing by zero to students who are busily texting their friends their plans for Friday night.  When you're done having this nice dream, go out and find a job where you can help make this a reality! :)
AnswerKenntnis:
You might want to look into holography related fields, which are mathematical complexity bound, but have the potential to change a great deal of how we interact with the world.

Beyond TV and Movies, computer generated holograms have uses in everything from medical imagery, geographic data representation and remote visualization.  We are at our core visually driven creatures, and so having an enhanced way of visualizing data, whether real or artificially generated, has a huge impact on our ability to comprehend and react to the world around us.  Dare I say it, but the ability to present data more dynamically is a world changer.

There are companies out there investing in the technology needed to make mass market holographic devices, and with good reason: We quite literally have all the technology required to do holography, and the only thing preventing holographic visualization from becoming the norm is the ability to do the math efficiently.
AnswerKenntnis:
I really appreciate that you are asking such a question. I suggest looking into non profits, and using an organization like Data Without Borders for guidence:
http://datawithoutborders.cc/
AnswerKenntnis:
Use your skills to help improving cryptographic algorithms in projects such as Tor, BitTorrent and Bitcoin.
AnswerKenntnis:
Being an actuary is a good job, always ranked as one of the top jobs based on things such as salary and stress level.  If you find the right company, you can work 40 hours a week and get paid a lot of money, while working on something that is necessary to culture (car insurance, for example).  As someone who is good at math, you could pass 2 or 3 exams in a few months.  You wouldn't want to do more than that until after you start a job, because companies don't want to pay someone with no experience a huge extra amount of money.  If you have much experience with probability, you could probably pass the first one with very little study, possibly none at all depending on how much experience you have.
AnswerKenntnis:
I am currently a PhD student in robotics and AI, and it seems to me that the field is thirsty for good mathematicians, to counterbalance the vast majority of heuristic-minded engineers (like myself). In fact, the main reason why I am a part of this community is because my work often leads to interesting mathematical systems that are beyond my ability to analyse (e.g. this one, why not use the opportunity to advertise my own question? :-)).

I find the field very appealing and I can see it being used as a force for good, such as in medicine and healthcare, personal care, search and rescue, and the like. Of course, there is always the argument that what you contribute to could eventually be used in military technology, but I guess that makes you as guilty as the person who invented the knife is for all the stabbings that happen. That being said, I have made a decision never to work directly on military applications.

In this way you could remain in academia, but I'm fairly sure that you would have an easier time publishing, because the mathematics involved will be simpler that what you are dealing with at the moment. At the same time, you will get to meet lots of interesting people of both genders (less alpha-maleness), as the field is probably one of the most inter-disciplinary around. Apart from the obvious engineers and computer scientists, you get psychologists, linguists, biologists, philosophers (for robot ethics), and people from pretty much every other science that you can think of.

I wish you the best of luck in whatever you decide to do!
AnswerKenntnis:
I'm not sure these areas have been mentioned already.

I would outline two areas that are beneficial for the society and interesting for mathematicians: cancer research and computer virus propagation. They are closer than one might think, applying tools from probability theory such as Markov chains, stochastic processes, limiting distributions, equilibrium states, optimization, etc.

You will be able to help a lot of people and maybe even save lives.
AnswerKenntnis:
Cathy O'Neil gave a talk at MIT entitled "Math in Business" last week; she summarizes that talk in this blog post. There may be some ideas here.
AnswerKenntnis:
Google? Microsoft Research? Some funky startup?
QuestionKenntnis:
A "simple" 3rd grade problem...or is it?
qn_description:
So this is supposed to be really simple, and it's taken from the following picture:



Text-only:


  It took Marie 10 minutes to saw a board into 2 pieces. If she works just as fast, how long will it take for her to saw another board into
  3 pieces?


I don't understand what's wrong with this question.  I think the student answered the question wrong, yet my friend insists the student got the question right.

I feel like I'm missing something critical here. What am I getting wrong here?
AnswersKenntnis
AnswerKenntnis:
Haha! The student probably has a more reasonable interpretation of the question.

Of course, cutting one thing into two pieces requires only one cut! Cutting something into three pieces requires two cuts!  


  -------------------------------  0 cuts/1 piece/0 minutes 
  ------------|------------------  1 cut/2 pieces/10 minutes 
  ------|------------|-----------  2 cuts/3 pieces/20 minutes 


This is a variation of the "fence post" problem: how many posts do you need to build a 100 foot long fence with 10 foot sections between the posts?  

Answer:  11  You have to draw the problem to get it...See below, and count the posts!

|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----| 
0-----10----20----30----40----50----60----70----80----90---100
AnswerKenntnis:
Well, the information is incomplete, so they're both right and wrong. Since the question is for $3^{rd}$ graders the correct answer should be $20$ minutes ($2$ cuts $\times$ $10$ min), though the teacher is right if you do cut it like this (first red, then green):



The problem is that the question doesn't say anything about how you have to cut it, so the blue cut would have been good enough too. That cut should only have taken a few seconds.
AnswerKenntnis:
The student was correct: 

Sawing a board into two pieces requires exactly one cut to be made. Sawing the board into three pieces requires exactly two cuts...

Hence, if it took $\bf 10$ minutes to make one cut, then cutting a board twice, at the same pace, would take $\;2 \times 10 = \bf 20$ minutes.

The instructor should receive tutoring from the student, I'm afraid!
AnswerKenntnis:
You can actually do it in ten minutes but your saw must look like this:

|     |
|     |
|     |
|     |      <- cutting edges
|     |
|     |
+--+--+
   |         <- handle
   |


:-)
AnswerKenntnis:
Another correct answer would be 10 minutes.  One could infer, "If she works just as fast," that "work" is the complete amount of time to do the job.
AnswerKenntnis:
Let P : pieces 

Let m : minutes

Let C : cuts

Let t : time per slice = 10

$$C(m) = m/t , \{m| m < Life(Marie)\}, \{C < length(board)\}$$

$$P(C(m)) = floor(C(m)) +1 , \{m| m < Life(Marie)\}$$

You're right that clearly isn't a simple grade 3 problem, but the answer is still 20.
$$P(C(20)) = floor(C(20)) + 1 = floor(20/10)+1 =floor(2) + 1 = 2 + 1 = 3\ pieces $$
AnswerKenntnis:
The topologists among us may perhaps enjoy the following defense of the teacher's answer: if the board is in the shape of a ring, it will take two cuts to get two pieces, and three cuts to get 3 pieces.
AnswerKenntnis:
The student answered the question the most correct way possible. First it is stated that Marie spends 10 minutes on sawing a board into two pieces. And then the student must answer how long it will take to saw another board into three pieces.

So we are not talking about chopping off pieces from an undefined source. We are talking about splitting a board.

However, it's poorly phrased because it's not explained how the board must be cut. It can be cut in infinite ways. Also, we don't know if the two boards are identical, so we must rely on assumptions here.
AnswerKenntnis:
The teacher would be correct if the question was "... to cut two pieces from the end of a board ...", implying more strongly that the pieces were being cut so as to leave another remaining piece.

I don't think that a reasonable person would interpret the question in that way, though.
AnswerKenntnis:
One part of what the teacher suggests is possible. Four pieces can be obtained in twenty minutes, because this takes only two cuts: cut it in two, then parallel the pieces and cut again, such that the saw goes through both at the same time. (The assumption is that the extra energy doesn't take more time, just more effort per stroke: not realistic, but let's go with it).

The mistake is interpolating between the two possibilities. If two pieces takes ten minutes, and four can be had in twenty, it does not follow that three pieces can be had in fifteen. However, six pieces can be had in thirty minutes which averages out to three in fifteen.

Suppose two workers are put on the job, and suppose it is somehow possible for them to divide a cut between themselves by attacking it from opposite sides without hindering each other, so they can meet in the middle in five minutes and complete the cut.  They can execute this at the beginning to make one board into two. Then they double up the board, and each makes a ten minute double cut through both boards: six pieces in fifteen minutes, so basically three pieces per worker per fifteen minutes.

So if we think about just a one-off job carried out by a single person with a saw, then the student is right. However, if we were talking about productivity over multiple pieces, and possibly with multiple workers, then the teacher would also be right; the problem is, nothing of the sort is suggested in the way the question is posed.
AnswerKenntnis:
The student is absolutely correct (as Twiceler has correctly shown). 

The time taken to cut a board into $2$ pieces (that is $1$ cut) : $10$ minutes
Therefore, The time taken to cut a board into $3$ pieces (that is $2$ cuts) : $20$ minutes

The question may have different weird interpretations as I am happy commented:


  Time taken to cut it into one piece = $0$ minutes
  So Time taken to cut it into $3$ piece s= $0 * 3$ minutes = $0$ minutes.


So $0$ can be an answer. but it is illogical just like the teacher's answer
and as Keltari said 


  Another correct answer would be 10 minutes. One could infer, "If she works just as fast," that "work" is the complete amount of time to do the job.  -Keltari


This is logical but you can be sure that this is not waht the question meant.

but the student has chosen the most relevant one. The teacher's interpretation is mathematically incorrect. 
The teacher may have put the question for the students to have an idea of Arithmetic Progression and may have thought that the students will just answer the question without thinking hard. In many a schools, at low grades children are thought that real numbers consists of all the numbers. Only later in higher grades do they learn that complex numbers also exist. (I learned just like that.) So the question was put as a question on A.P. thinking that the students may not be capable of solving the answer the correct way.

Or as Jared rightly commented:


  This is simultaneously wonderful and sad. Wonderful for the student who was level-headed enough to answer this question correctly, and sad that this teacher's mistake could be representative of the quality of elementary school math education. ΓÇô Jared 


Whatever may be the reason, there is no doubt that the student has been accurate in answering the question properly and that the teacher's answer is illogical.
AnswerKenntnis:
The answer will have to be 20. If it takes 'Marie' 10 minutes to cut the board into two pieces then that means it has taken her 10 minutes to make that chop. 

Three pieces would require two chops therefore the teacher is wrong:

2 * 10 = 20
AnswerKenntnis:
Teaching children, you have to be fair to them: 


Think as they do.
Third graders are budding topologists, just very far from graduation.
Children are honest and direct in their assessments - it would not likely occur to them to "cut into 3 pieces of equal length" because that was not in the question. Nether would they likely think of any of the alternative cuts offered here in the various answers --- precisely because:
People (especially children) tend to be very visual. DUH there is a picture of the saw cutting the board. The board IS a board, not a paper cut out, not a piece of rectangular plywood; and the way the saw is positioned very strongly implies the next cut would be made in a similar fashion. Honestly, how many of you looked at that picture and almost unconsciously imagined moving the saw to the right (or maybe to the left) of the current cut ? I did - and I bet the children would too ... because:
Children are hands on.


When I read the problem, I thought the test grader just muffed it misreading the scoring sheet.  Wow - I guess I'm childish :-P
AnswerKenntnis:
There is a similar problem that needs an argument quite analogous to what the student seems to have used:


  A clock takes 12 seconds to strike 4 o'clock, how long will it take to strike 8 o'clock?


The interpretation is that the time is spent between the strikes, so the answer is 28 seconds instead of 24.
AnswerKenntnis:
I would think of it this way: how long would it take to cut it in to 1 piece... 0 minutes because it is already in one piece. The model is: time = cuts x 10. As 1 cut = 10 minutes.
AnswerKenntnis:
Considering they show a drawing of the piece of wood on the problem itself, the assumption is the cut would be made in the same way, hence the student was right to start with.
AnswerKenntnis:
Well, i have something else in my mind.I know it is not that practical still i want to share my views about the question.

Assuming the board is of 1 meter long and we have to cut it into 3 pieces of equal length i.e. finally each of the pieces should be length of 1/3 meter long (see the picture given in the question). So we have to make two cuts at length 1/3 and at length 2/3. Now note that after cutting it first time(which will take 10 minutes), we will have two piece. One is of 1/3 meter long and the other portion is of 2/3 meter long.Now we have to make a cut to the last portion(which is of 2/3 meter long) and make it in two pieces. 

Now the interesting part comes. If we assume the board has a uniform resistance against the saw, then after losing its one third end, board will lose its resistance uniformly (assuming resistance depends on length proportionally). In that case, it will take  another $10*(2/3)=6.67$ minutes to get another two pieces. 

hence  we need total $16.67$ minutes.

I know it is not practical, still...
AnswerKenntnis:
Quite a random question. The answer would depend on where and how the cuts are made. 

e.g. Let's say the $2$ blocks are identical (assumption on my part) each of $10$cm $\times$ $5$cm $\times$ $1$cm
Let's say first block is cut lengthwise, i.e. into 2 blocks of 10cmx5cmx0.5cm. This means it took 10 mts to cut through and area of $10\times5 = 50cm^2$

Now let's look at the second block. Cut along width to create 2 blocks each of 5cmx5cmx1cm. Then you take one of these and cut off along the thickness to create two pieces 5cmx2.5cmx1cm. In this case you have just gone through an area of 5x1+5x1 = $10cm^2$ so it should only take 2mts.

Of course, if this was a question in a $3^{rd}$ grade exam, none of the above is relevant. The way the question is written, the answer could be 20 (if you are cutting pieces off a long piece of wood as the diagram indicates) or 15 (if you cut a block into half and then use the second cut to cut one of the halves into half). 

+++++++++++ | +++++++++++ | +++++++++++
+++++++++++ | +++++++++++ | +++++++++++
+++++++++++ | +++++++++++ | +++++++++++
+++++++++++ | +++++++++++ | +++++++++++
+++++++++++ | +++++++++++ | +++++++++++
Answer 20

++++++++++ | +++++++++++++++++
++++++++++ | +++++++++++++++++
------------------| +++++++++++++++++
++++++++++ | +++++++++++++++++
++++++++++ | +++++++++++++++++
Answer 15  

That being said, it is a terribly poorly framed question.
AnswerKenntnis:
Sawing once takes 10 minutes and obtains 2 pieces.
So, since we obtain 3 pieces when we saw twice, it takes $2 \cdot 10 = 20$ minutes.
AnswerKenntnis:
Perhaps if it was "can marie saw the board into 3 pieces in 10 minutes?" then it would be correct. Maybe it was a misprint.
QuestionKenntnis:
What was the first bit of mathematics that made you realize that math is beautiful? (For children's book)
qn_description:
I'm a children's book writer and illustrator, and I want to to create a book for young readers that exposes the beauty of Mathematics. I recently read Paul Lockhart's essay "The Mathematician's Lament," and found that I, too, lament the uninspiring quality of my elementary math education.

I want to make a book that discredits the notion that math is merely a series of calculations, and inspires a sense of awe and genuine curiosity in young readers.

However, I myself am mathematically unsophisticated.


  What was the first bit of mathematics that made you realize that math is beautiful?


For the purposes of this children's book, accessible answers would be appreciated.
AnswersKenntnis
AnswerKenntnis:
This wasn't the first, but it's definitely awesome:



This is a proof of the Pythagorean Theorem, and it uses no words!
AnswerKenntnis:
For me it was the Times Table of 9.

We are usually forced to memorize the multiplication tables in school. I remember looking at the table for 9, and seeing that the digit in ten's place increased by one, while the digit in the one's place decreased by one.

After this, I realized that I could always add 10 and subtract 1 to get the next result. For a 7 year old, this was the greatest discovery ever made.

And that your hands could give you the answer immediately: 7 x 9 = hold down your 7th finger, leaves 6 fingers on left of held down finger, and 3 on right: 63.. works all the way up to 9*10, beautiful.
AnswerKenntnis:
Whether this is 'simple' enough is debatable... the method to generate the Mandelbrot set is likely to be far too complicated for the book in question, but the mathematical expression that's at its heart couldn't be much simpler.

$z_{n+1} = {z_n}^2 + c$

After implementing the Mandelbrot set I learned about the Buddhabrot, which is basically a way of rendering the stages of the Mandelbrot algorithm, and after some considerable processing time I had a render:



I then tweaked my input parameters to 'zoom in' on a particular area, and when I saw the result my jaw hit the floor. This is when I saw the true beauty in mathematics beyond 'nice' results. Again, it's probably too advanced for your book because of the steps involved in creating the visual, but maybe it'd make for a nice final hurrah to inspire further exploration? It still boggles my mind to see such amazing results from something so simple.
AnswerKenntnis:
I found it completely amazing that the angles in a triangle always added up to 180 degrees.  No matter how you drew a triangle, you could measure the angles with a protractor and they always add up to about 180 degrees, like magic.  Even more amazing when I realized it wasn't some rule of thumb or approximation, but true in some deeper sense for the ideal, platonic triangle.
AnswerKenntnis:
I remember being very pleased at an early age, perhaps five or six, by the following bits of calculator tinkering, among others:


12345679 ├ù $n$ ├ù 9 = nnnnnnnnn.
The cyclic behavior of the decimal expansions of $\frac  n7$. For example, $4\times 0.142857\ldots  = 0.571428\ldots$.
The reciprocity of digit patterns in numbers and their reciprocals.  For example, $\frac12 = 0.5$ and $\frac15 = 0.2$; $\frac14 = 0.25$ and $\frac 1{2.5} = 0.4$. This is the earliest pattern I can remember observing completely on my own. Similarly, I enjoyed that the decimal expansions of $\frac1{2^n}$ (0.5, 0.25, 0.125ΓÇª) look like powers of 5.
The attraction of the map $x\mapsto \sqrt x$ to 1, regardless of the (positive) starting point. I liked that numbers greater than 1 were attracted downwards, and numbers less than 1 were attracted upwards. 


When I got a little older, I loved that I could find an $n$th-degree polynomial to pass through  $n+1$ arbitrarily chosen points, and that if I made up the points knowing the polynomial ahead of time, the method would magically produce the polynomial I had used in the first place. I spent hours doing this.

I also spent hours graphing functions, and observing the way the shapes changed as I varied the parameters. I accumulated a looseleaf binder full of these graphs, which i still have.

As a teenager, I was thrilled to observe that although the number "2 in a pentagon"
in the SteinhausΓÇôMoser notation is far too enormous to calculate, it is a trivial matter to observe that its decimal expansion ends with a 6.

I realize that your book wants to discredit the notion that math is merely a series of calculations, but I have always been fascinated by calculation, and I sometimes think, as the authors of Concrete Mathematics say in the introduction, that we do not always give enough attention to matters of technique. Calculation is interesting, for theoretical and practical reasons, and a lot of very deep mathematics arises from the desire to calculate.
AnswerKenntnis:
I used to love naughty 37.

37 x 3 = 111;

37 x 6 = 222;

37 x 9 = 333;

37 x 12 = 444;

37 x 15 = 555;

37 x 18 = 666;

37 x 21 = 777;

37 x 24 = 888;

37 x 27 = 999;
AnswerKenntnis:
Adding to LaceySnrΓÇÖs answer, IΓÇÖd like to mention fractals in general. While fractals will probably count as a higher application of maths, they are very often very visually beautiful. So you could easily show a picture of a fractal and explain that there is just a simple formula behind it all.






Some more examples:


Animated Barnsley Fern (Press a)
Animated IFS Tree (Press a)
Tom BeddardΓÇÖs Fractal Lab
Exploring the Infinite: Short part of a presentation by Tom Beddard about his 3D fractal software
AnswerKenntnis:
First "math thing" that just blew my mind is identity
$$
e^{i\pi} = -1
$$
namely the fact that two independently discovered transcendent numbers and imaginary one so simply and elegantly bound.
AnswerKenntnis:
This isn't what did it for me, but it's fairly simple and quite nice: 

$$0.9999999999\ldots =1$$
AnswerKenntnis:
The number of pennies stacked in a triangle (1,3,6,10,...) is along one diagonal line of Pascal's Triangle.  The number of spheres stacked in a tetrahedron (1,4,10,20,...) is the line next to it.  The next line is the number of hyperspheres in a pentachoron.  



I was about 10 and living in a hotel and home sick from school, stacking up pennies and "red hots" in pyramids, etc.  I made a table of these numbers.  Noticing the simple addition rule in the table, I extrapolated to the 4th, 5th, dimensions.  Later when I learned of Pascal's triangle that moment was probably my biggest joy of mathematics, realizing I'd run into that years before.
AnswerKenntnis:
My son loved this when he was little - patterns everywhere:
AnswerKenntnis:
As a child, the Fibonacci numbers $F_n$ defined by the recurrence $$F_1 = 1, \quad F_2 = 1, \quad F_{n+2} = F_{n+1} + F_n$$
were very fascinating to me. It was fun to compute them
$$F_3 = F_2 + F_1 = 1 + 1 = 2\\F_4 = F_3 + F_2 = 2 + 1 = 3\\F_5 = F_4 + F_3 = 3 + 2 = 5\\F_6 = F_5 + F_4 = 5 + 3 = 8\\\vdots$$
and to collect the results in tables
$$\begin{array}{c|cccccccccc}n & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \cdots \\ \hline F_n & 1 & 1 & 2 & 3 & 5 & 8 & 13 & 21 & 34 & 55 & \cdots\end{array}$$
At some point, I asked myself the question: To compute $F_{10}$, do I really have to compute all the Fibonacci numbers up to $F_9$ beforehand? So I tried to figure out some formula where you can plug in $n$, do some basic arithmetics, and get $F_n$ as a result.
I've spent a lot of time on this. However no matter how hard I tried, I didn't succeed.

After a while I found the closed form
$$F_n = \frac{1}{\sqrt{5}} \left(\left(\frac{1 + \sqrt{5}}2\right)^{\!n} - \left(\frac{1 - \sqrt{5}}{2}\right)^{\!n}\right)
$$
in some book. I was paralysed.

How can it happen that an easy recurrence formula can only be described by such a complex expression? Where do the square roots come from, and why does the expression still always evaluate to an integer in the end? And, most importantly: How on earth can one find such a formula??
AnswerKenntnis:
Here is my favorite classic illustrating the power and beauty of mathematical argument. Consider the question:


  Question: Can an irrational number raised to an irrational number be rational?
  
  Answer: One of the classic answer goes as follows. Consider the number $x=\sqrt{2}^\sqrt{2}$. If $x$ is rational, we are done. If $x$ is irrational, then consider $x^{\sqrt2}$, which is $2$ and now we are done.
AnswerKenntnis:
When I was a kid my parents explained basic arithmetic to me. After thinking for a while I told them that multiplying is difficult because you need to remember if $a \cdot b$ means $a+a+\ldots + a$ ($b$ times) or $b + b + \ldots + b$ ($a$ times). I was truly amazed by their answer.
AnswerKenntnis:
For me, it was the discovery that the sum of the digits in all multiples of three are themselves multiples of three, and you can recursively sum them to get to 3, 6, or 9 (i.e. an 'easy' multiple of three)

E.g.

The sum of the digits in $13845$ is $21$,

The sum of the digits in $21$ is $3$



Edit: Should probably add that what made this useful to me was that numbers that are not multiples of three do not have this pattern.
AnswerKenntnis:
The fact that you can always divide something by two. That is an amazing discovery my dad tells I made as a toddler.

I think that ever since I remember abstract mathematics was a fascination of mine, even before I knew what it is (because it was obvious school mathematics wasn't that).

Another fact I stumbled upon as a teenager and fascinated me was that if you hold a magnifying glass over a ruled paper the parallel lines bend, and eventually meet at the edge of the glass. That, in a nutshell, is a non-Euclidean geometry.
AnswerKenntnis:
When I was a child, I spent the whole summer at a camping in the coast of Catalonia. There I was always around my grandfather. He himself had no proper education and never finished school. Nevertheless he liked to read books on his own, about many things, grammar, the french language, mechanics, mathematics... I remember he taught me many things. He was the first to explain me, as I fell asleep in his arms, under the starry night, that the Earth was a ball, and that there were people underneath the ground where we stood, on the other side of the planet, who were standing upside down without falling, because we were all attracted to the center of the ball. I did not understand, at that moment, how was that possible. But I trusted him and knew that there were many things I did not understand about the world.

One particular thing related to mathematics that he told me and that got me thinking, making myself questions and reaching the boundaries of my mind, was that one frog could try to jump her way across a puddle (we also went together to catch frogs), jump first to the half of it, then to the half of the remaining half and so on, and that after an infinite number of jumps she would arrive at the other shore.

This was, I think, one of the first things that made me feel that the world or that reality itself was infinitely bigger, more complex and more beautiful that anything we could understand or even begin to grasp. I guess this sense of real magic is what makes me have a special love for mathematics.
AnswerKenntnis:
I don't remember what the first beautiful piece of math I encountered was, but here are a couple of candidates:


Proof that the square root of 2 is irrational
Euclid's proof that there are infinitely many prime numbers
AnswerKenntnis:
(Copy from http://mathforum.org/library/drmath/view/57919.html)

There is a well known story about Karl Friedrich Gauss when he was in
elementary school.  His teacher got mad at the class and told them to
add the numbers 1 to 100 and give him the answer by the end of the 
class. About 30 seconds later Gauss gave him the answer.  

The other kids were adding the numbers like this:

$$
1 + 2 + 3 + ... + 99 + 100 = ?
$$

But Gauss rearranged the numbers to add them like this:

$$
     (1 + 100) + (2 + 99) + (3 + 98) + ... + (50 + 51) = ?
$$

If you notice every pair of numbers adds up to 101.  There are 50 
pairs of numbers, so the answer is 
$$
50 * 101 = 5050
$$  Of course Gauss 
came up with the answer about 20 times faster than the other kids.

In general to find the sum of all the numbers from 1 to n:

$$
1 + 2 + 3 + 4 + ... + n = (1 + n) * \bigg(\frac{n}2\bigg)
$$
That is "1 plus n quantity times n divided by 2".
AnswerKenntnis:
I always thought cycles in decimal fractions were magic, until I realized I can easily create whichever cycle I wanted:


${1\over9} = 0.111...$  
${12\over99} = 0.12\ 12\ 12...$
${1234\over9999} = 0.1234\ 1234...$


I failed a number theory exam because the professor did not know this trick and said I needed to prove it.
AnswerKenntnis:
Who remembers magic squares? Those sparked my interest in mathematics.
AnswerKenntnis:
Here are some things that I found interesting back when I was in junior high school. I hope they are not too advanced for young children:


Archimedes' method for computing areas and volumes (which is really cool).
The "limit" card magic. Take 27 cards from an ordinary deck of playing cards. Invite your audience to pick one of them, without telling the choice. Deal the 27 cards into three stacks, say $A, B$ and $C$, each containing 9 cards. The deal order is $A\to B\to C\to A\to B\to\cdots\to C$. Ask the audience which stack contains the chosen card. Collect the three stacks into one deck, where the stack containing the chosen card is placed in the middle. Repeat this deal-and-ask procedure twice more (so, thrice in total). Now the chosen card is the middle one in the stack as told by the audience.
The remainder of a whole number, when divided by $3$, is the remainder of the sum of its digits when divided by $3$.
The cyclic decimal expansion you get when a whole number is divided by $7$.
$1+2+\ldots+n=\frac{n(n+1)}2$.
$$
n\left\{
\begin{array}{ccccc}
\bullet&\color{red}\bullet&\color{red}\bullet&\color{red}\bullet&\color{red}\bullet\\
\bullet&\bullet&\color{red}\bullet&\color{red}\bullet&\color{red}\bullet\\
\bullet&\bullet&\bullet&\color{red}\bullet&\color{red}\bullet\\
\bullet&\bullet&\bullet&\bullet&\color{red}\bullet\\
\end{array}\right.
$$
(Actually $1^2+2^2+\ldots+n^2=\frac{n(n+1)(2n+1)}6$ is even more interesting, but its proof is certainly too advanced for most young children.)
The (slanted) cross section of a cone has a symmetric shape (an ellipse). (Provided that the cross section does not cut into the base of the cone, of course.) This is rather inobvious to me because I thought the slant will break symmetry.
AnswerKenntnis:
The game of Nim and it's solution are pretty cool.  The proof might be a bit difficult, but I think kids would love to learn a game like that and how to beat their parents at it.  There's a lot of other fun mathematical games like that too.  But I think the first thing I learned that turned me towards mathematics was the existence of multiple infinities, and things like Hilbert's infinite hotel.
AnswerKenntnis:
I always had a peripheral understanding that there was something more to maths than working out how your change or divvying up sweets with your siblings. But the day I really, truly understood was when I learned about $\pi$.

$\pi$ was magical to me. For one thing, it's a funny-looking Greek letter with a funny-sounding name. But, more captivatingly, it introduced me to an epiphany: that somewhere, on some level, the fundamental structure of reality itself could be understood through mathematics.

Let's assume your childen understand what a circle is, and how to measure things with a measuring tape. Introduce them to circumference and diameter. Give them a table with three columnsΓÇöcircumference, diameter and "the secret of circles"ΓÇöand a big tape measure. Tell them to go out and measure as many circles as they can find: plates, car tires, stop signs, plant pots, lines on a basketball courtΓÇª anything so long as it's circular. Let them loose.

Later, once they're done measuring everything in the neighbourhood, hand them a calculator and tell them to go through each of their circles and divide the circumference by the diameter, and write the number they get in the mystery third column. Tell them that a pattern will start to appear, and they need to see if they can spot it.

Once they're done, you can explain to them that the reason the first couple of numbers is the same is because there's a number, a magical number, that tells us a secret about every circle in the universeΓÇöfrom rings we wear on our fingers to the sun and moon in the sky and the whole planet Earth. No matter how big or how small, how grand or how humble, every single circle is a bit more than three times bigger around than it is from one side to the other. This number is so special that it has its own name, pi, and its own special letter, $\pi$. It's not three and it's not fourΓÇöit's somewhere just after three, and we can't write down exactly where because it goes on forever. Luckily, we only really need to know the first few numbers most of the time, so we can use this magical number whenever we need it.

The sense of revelation that came from knowing that every circle in the universe is connected by this strange, special number stayed with me for a long time, and is at least partly responsible for my love of mathematics in later life.
AnswerKenntnis:
The Golden Ratio

It was presented to me like this:  There exists a number that you can square, subtract itself, and you'll get 1.  Or, you can inverse the number, add 1, and you'll get the number back.  What a beautiful number, I thought.  Of course, I later realized the number was just a solution to:

$$x^2 - x - 1 = 0.$$

However, I was really impressed when later I learned this number also shows up in nature in the patterns of plant growth.  Wow!  Who would have thought?
AnswerKenntnis:
It was probably not the first thing that made me realize that math is beautiful, but it was something that amazed me the most and still does to this day: The fact that the Mandelbrot set is not only infinite - in a way that eg. the Koch snowflake is infinite - but that it is infinitely complex, the complexity never ends, you can zoom it forever and you will never find exactly the same patterns, the information that is contained in it is infinite and yet it is described by such a simple formula.

It made me wonder whether math was discovered or created, whether things like the Mandelbrot set existed independently from their discovery or not, whether the infinitely complex pictures existed if they were never seen etc.

I remember the sleepless nights in elementary school when I was writing programs to explore the Mandelbrot set, to find nice looking colors, to animate it - impossible to do live at that time so I had to learn how to script some animation program that I had, wait an hour to realize that I had the colors wrong, change one number, wait another hour, rinse and repeat.

I didn't know about complex numbers at that time. I only knew that I was looking at something most amazing in the world and just couldn't stop exploring. Fractals became my obsession and were probably one of the reasons why I started programming more seriously.

I was fascinated by the fact that I could zoom it so much that it was like finding some proton on the face of Earth and zooming it to the size of a planet, and then looking at that planet-sized proton with an electron microscope. I could print what I found and I knew that no one in the Universe has ever seen it before me and no one will ever be able to find it even after looking on my printout - the scale was so amazing.

I remember how I got scared when I eventually saw large pixels in my Mandelbrot set! Finally I realized that I hit the limits of the floating point number precision on my 386 but I knew that the complexity of the Mandelbrot set was there, somewhere, even if I couldn't see it with my computer at that time.

Those are some of my favorite pictures that I posted to Wikipedia:

Cool Mandelbrot:



Calm Mandelbrot:



Hot Mandelbrot:



You can download them from Wikipedia.

One of those pictures was magnified 248,034,982,258 times - probably the Cool Mandelbrot but I'm not sure because strangely all of them have the same description on Wikimedia Commons (something had to go wrong when they were copied from Wikipedia to Wikimedia Commons).

I would be honored if you'd like to use those pictures in your book. If you need higher resolution pictures or more information about them then I might be able to find something in some very very old backups.

Good luck with the book!
AnswerKenntnis:
http://en.wikipedia.org/wiki/Donald_in_Mathmagic_Land

Disney, as it was long time ago.
AnswerKenntnis:
Everybody loves Fractals. I think this one - The Dragon Curve - is particularly easy to explain, and it is very surprising and aesthetically pleasing:


Here's a video I've seen which explains how it comes about:
The Dragon Curve from Numberphile
AnswerKenntnis:
Realising why Zero is not Nothing: And Understanding Numbers

I first understood the difference between zero and none when thinking about thermometer readings. If you had a ton of thermometers scattered around the world, and you collected their readings periodically and put them in a database, what would you do if any thermometer was broken? If you just put a zero reading, you'll screw up your averages, but if you put a null value, you can handle broken thermometers easily.

That made me realise what a number is.
AnswerKenntnis:
That the roots of $z^n-1 = 0$ start to form a circle as $n$ increases. It starts out with the simple solution, the quadratic which you've already seen, then the complex plane comes in for $z^3$ and all of a sudden it's like "Hey! Those form circle!"
QuestionKenntnis:
Visually stunning math concepts which are easy to explain
qn_description:
Since I'm not that good at (as I like to call it) 'die-hard-mathematics', I've always liked concepts like the golden ratio or the dragon curve, which are easy to understand and explain, but are mathematically beautiful at the same time.

Do you know of any other concepts like these?
AnswersKenntnis
AnswerKenntnis:
I think if you look at this animation and think about it long enough, you'll understand:


Why circles and right-angle triangles and angles are all related
Why sine is opposite over hypotenuse and so on
Why cosine is simply sine but offset by $\pi/2$ radians
AnswerKenntnis:
My favorite: tell someone that $$\sum_{n=1}^{\infty}\frac{1}{2^n}=1$$ and they probably won't believe you. However, show them the below:



and suddenly what had been obscure is now obvious.
AnswerKenntnis:
Here is a classic: the sum of the first $n$ positive odd numbers $= n^2$.



We also see that the sum of the first $n$ positive even numbers $= n(n+1)$ (excluding $0$), by adding a column to the left.
AnswerKenntnis:
A well-known visual to explain $(a+b)^2 = a^2+2ab+b^2$:
AnswerKenntnis:
This visualisation of the Fourier Transform was very enlightening for me:



The author, LucasVB, has a whole gallery of similar visualisations at his Wikipedia gallery and his tumblr blog.
AnswerKenntnis:
The sum of the exterior angles of any convex polygon will always add up to $360^\circ$. 



This can be viewed as a zooming out process, as illustrate by the animation below:
AnswerKenntnis:
When I understood Fourier series visually-
AnswerKenntnis:
This is similar to Aky's answer, but includes a second drawing (and no math.)

To me the second drawing is key to understanding why the $\mathrm c^2$ area is equal to the sum of $\mathrm a^2+\mathrm b^2$.
AnswerKenntnis:
When I look up "area of a rhombus" on Google images, I find plenty of disappointing images like this one:



which show the formula, but fail to show why the formula works. That's why I really appreciate this image instead:



which, with a little bit of careful thought, illustrates why the product of the diagonals equals twice the area of the rhombus. 

EDIT: Some have mentioned in comments that that second diagram is more complicated than it needs to be. Something like this would work as well:



My main objective is to offer students something that encourages them to think about why a formula works, not just what numbers to plug into an equation to get an answer. 



As a side note, the following story is not exactly "visually stunning," but it put an indelible imprint on my mind, and affected the way I teach today. A very gifted Jr. High math teacher was teaching us about volume. I suppose just every about school system has a place in the curriculum where students are required learn how to calculate the volume of a pyramid. Sadly, most teachers probably accomplish this by simply writing the formula on the board, and assigning a few plug-and-chug homework problems. 



No wonder that, when I ask my college students if they can tell me the formula for the volume of a pyramid, fewer than 5% can. 

Instead, building upon lessons from earlier that week, our math teacher began the lesson by saying:


  We've learned how to calculate the area of a prism: we simply multiply the area of the base times the height. That's easy. But what if we don't have a prism? What if we have a pyramid?


At this point, she rummaged through her box of math props, and pulled out a clear plastic cube, and a clear plastic pyramid. She continued by putting the pyramid atop the cube, and then dropping the pyramid, point-side down inside the cube:


She continued: 


  These have the same base, and they are the same height. How many of these pyramids do you suppose would fit in this cube? Two? Two-and-a-half? Three? 


Then she picked one student from the front row, and instructed him to walk them down the hallway:


  Go down to the water fountain, and fill this pyramid up with water, and tell us how many it takes to fill up the cube.


The class sat in silence for about a full minute or so, until he walked back in the room. She asked him to give his report. 


  "Three," he said.
  
  She pressed him, giving him a hard look. "Exactly three?"
  
  "Exactly three," he affirmed. 
  
  Then, she looked around the room:
  
  "Who here can tell me the formula I use to get the volume of a pyramid?" she asked.
  
  One girl raised her hand: "One-third the base times the height?"


I've never forgotten that formula, because, instead of having it told to us, we were asked to derive it. Not only have I remembered the formula, I can even tell you the name of boy who went to the water fountain, and the girl who told us all the formula (David and Jill). 



Given the upvoted comment, If high school math just used a fraction of the resources here, we'd have way more mathematicians, I hope you don't mind me sharing this story here. Powerful visuals can happen even in the imagination. I never got to see that cube filling up with water, but everything else in the story I vividly remember.

Incidentally, this same teacher introduced us to the concept of pi by asking us to find something circular in our house (ΓÇ£like a plate or a coffee canΓÇ¥), measuring the circumference and the diameter, and dividing the one number by the other. I can still see her studying the data on the chalkboard the next day ΓÇô all 20 or so numbers just a smidgeon over 3 ΓÇô marveling how, even though we all probably measured differently-sized circles, the answers were coming out remarkably similar, ΓÇ£as if maybe that ratio is some kind of constant or something...ΓÇ¥
AnswerKenntnis:
A visual explanation of Taylor series:

$f(0)+\frac {f'(0)}{1!} x+ \frac{f''(0)}{2!} x^2+\frac{f^{(3)}(0)}{3!}x^3+ \cdots$

or

$f(a)+\frac {f'(a)}{1!} (x-a)+ \frac{f''(a)}{2!} (x-a)^2+\frac{f^{(3)}(a)}{3!}(x-a)^3+ \cdots$



When you think about it, its quite beautiful that as you add each term it wraps around the curve.
AnswerKenntnis:
This is a neat little proof that the area of a circle is $\pi r^2$, which I was first taught aged about 12 and it has stuck with me ever since. The circle is subdivided into equal pieces, then rearranged. As the number of pieces gets smaller, the resulting shape gets closer and closer to a rectangle. It is obvious that the short side of this rectangle has length $r$, and a little thought will show that the two long sides each have a length half the circumference, or $\pi r$, giving an area for the rectangle of $\pi r^2$.

This can also be done physically by taking a paper circle and actually cutting it up and rearranging the pieces. This exercise also offers some introduction to (infinite) sequences.
AnswerKenntnis:
Simple,visual proof of the Pythagoras Theorem. Originally from Pythagorean Theorem Proof Without Words 6.
AnswerKenntnis:
While attending an Abstract Algebra course I was given the assignment to write out the multiplication table modulo n. I forgot to do the homework until just before class, but it was so easy to write the program I was able to print the result between classes.

The circular patterns in the tables fascinated me, and compelled me to replace the numbers with colors. The result is a beautiful illustration showing the emergence of primes and symmetry of multiplication.

The colors were chosen to start blue at 1 (cold) and fade to red at n (hot). White is used for zero (frozen), because it communicates the most information about prime factorization.

The interactive version can be found here: http://arapaho.nsuok.edu/~deckar01/Zvis.html

Multiplication of the integers modulo 15:



Multiplication of the integers modulo 512:
AnswerKenntnis:
Similarly to eykanal's answer, although demonstrating some interesting facts about medians and geometry as well. It demonstrates that $\displaystyle\sum_{n = 1}^{\infty}\frac{1}{2^n} = 1$:
AnswerKenntnis:
This is a visual explanation that a circle's perimeter is equal to $2r*\pi$.  

In this image the wheel's diameter is 1. After the perimeter is rolled down we can see that its length equals to $\pi$ amount of wheels.



Source
AnswerKenntnis:
As I was in school, a supply teacher brought a scale to lesson:



He gave us several weights that were labeled and about 4 weights without labels (lets call them $A, B, C, D$). Then he told us we should find out the weight of the unlabeled weights. $A$ was very easy as there was a weight $E$ with weight($A$) = weight($E$).
I think at least two of them had the same weight and we could only get them into balance with a combination of the labeled weights. The last one was harder. We had to put a labeled weight on the side of the last one to get the weight.

Then he told us how this can be solved on paper without having the weights. So he introduced us to the concept of equations. That was a truly amazing day. Such an important concept explained with a neat way.
AnswerKenntnis:
Fractal art. Here's an example: "Mandelbrot Island".



Now that I think about it, fractals in general are quite beautiful. Here's a close-up of the Mandelbrot set:
AnswerKenntnis:
Topology needs to be represented here, specifically knot theory.  The following picture is from the wikipedia page about Seifert Surfaces and was contributed by Accelerometer. Every link (or knot) is the boundary of a smooth orientable surface in 3-space.  This fact is attributed to Herbert Seifert, since he was the first to give an algorithm for constructing them.  The surface we are looking at is bounded by Borromean rings.
AnswerKenntnis:
Simple answer for "what is a radian":



Logarithmic spiral and scale:
AnswerKenntnis:
How about a line integral of a scalar field by http://1ucasvb.tumblr.com:
AnswerKenntnis:
Fourier transform of the light intensity due to a diffraction pattern caused by light going through 8 pinholes and interfering on a wall, for different choices of parameter:















The best thing about them is, they satisfy periodic boundary conditions, and so you can pick one of them and set it as a desktop background by tiling it, resulting in a far more spectacular image than just the single unit cells posted above! 

The images seem to be a vast interconnected network of lines once you tile them, but in fact the entire picture is actually just a single circle, which has been aliased into a tiling cell thousands of times. 

Here is a video of the first couple thosand patterns:
http://www.youtube.com/watch?v=1UVbUWuyNmk

Here is the Mathematica code used to generate and save the images. There are two parameters that are adjustable: mag is the magnification and must be an integer, with 1 generating 600 by 600 images, 2 generating 1200 by 1200 images, etc. i is a parameter which can be any real number between 0 and ~1000, with values between 0 and 500 being typical (most of the preceding images used i values between 200 and 300). By varying i, thousands of unique diagrams can be created. Small values of i create simple patterns (low degree of aliasing), and large values generate complex patterns (high degree of aliasing).

$HistoryLength = 0;
p = {x, y, L};
nnn = 8;
q = 2.0 Table[{Cos[2 \[Pi] j/nnn], Sin[2 \[Pi] j/nnn], 0}, {j, nnn}];
k = ConstantArray[I, nnn];
n[x_] := Sqrt[x.x];
conjugate[expr_] := expr /. Complex[x_, y_] -> x - I y;
a = Table[k[[i]]/n[p - q[[i]]], {i, nnn}];
\[Gamma] = Table[Exp[-I \[Omega] n[p - q[[i]]]/c], {i, nnn}];
expr = \[Gamma].a /. {L -> 0.1, c -> 1, \[Omega] -> 100};
ff = Compile[{{x, _Real}, {y, _Real}}, Evaluate[expr], 
   CompilationTarget -> "C", RuntimeAttributes -> {Listable}];
i = 250;
mag = 1;
d = 6 i mag;
\[Delta] = 0.02 i;
nn = Floor[Length[Range[-d, d, \[Delta]]]/2];
A = Compile[{{x, _Integer}, {y, _Integer}}, Exp[I (x + y)], 
    CompilationTarget -> "C", RuntimeAttributes -> {Listable}] @@ 
   Transpose[
    Outer[List, Range[Length[Range[-d, d, \[Delta]]]], 
     Range[Length[Range[-d, d, \[Delta]]]]], {2, 3, 1}];
SaveImage = 
  Export[CharacterRange["a", "z"][[RandomInteger[{1, 26}, 20]]] <> 
     ".PNG", #] &;
{#, SaveImage@#} &@
 Image[RotateRight[
   Abs[Fourier[
     1 A mag i/
      nnn ff @@ 
       Transpose[
        Outer[List, Range[-d, d, \[Delta]], 
         Range[-d, d, \[Delta]]], {2, 3, 1}]]], {nn, nn}], 
  Magnification -> 1]
AnswerKenntnis:
I do not know if this meets your criteria of "visually stunning", but nonetheless - 

I like this proof of Pythagoras' Theorem (image taken from www.wisfaq.nl):



The key to understanding this is to realize that the inner quadrilateral must be a square - the sides are equal in length (obviously) and each of its angles is $90^{\circ}$ because the two angles on either side sum to $90^{\circ}$, and the sum of the three angles is $180^{\circ}$. The area of this square is $c^2$. 

The outer square's area is $(a + b)^2$, which is $c^2$ plus  $2 a b$ which is the total area of the four triangles, each of area $\frac{1}{2} a b$.

$(a + b)^2 = c^2 + 2 a b$

$a^2 + b^2 + 2 a b = c^2 + 2 a b$

$a^2 + b^2 = c^2$, which is Pythagoras' theorem.
AnswerKenntnis:
Here's a GIF that I made that demonstrates Phi (golden number)
AnswerKenntnis:
The magnetic pendulum:



An iron pendulum is suspended above a flat surface, with three magnets on it. The magnets are colored red, yellow and blue. 

We hold the pendulum above a random point of the surface and let it go, holding our finger on the starting point. After some swinging this way and that, under the attractions of the magnets and gravity, it will come to rest over one of the magnets. We color the starting point (under our finger) with the color of the magnet.

Repeating this for every point on the surface, we get the image shown above.
AnswerKenntnis:
Steven Wittens presents quite a few math concepts in his talk Making things with math. His slides can be found from his own website.

For example bezier curves visually:

 



He has also created MathBox.js which powers his amazing visualisations in the slides.
AnswerKenntnis:
Take a look at this great example of Fourier series visualisations written in js.
AnswerKenntnis:
Here is a very insightful waterproof demonstration of the Pythagorean theorem, and there is a video here http://www.youtube.com/watch?v=CAkMUdeB06o
AnswerKenntnis:
This is from betterexplained.com, it's a really cool website with lots of intuitive explanations of maths concepts. This helped me understand pythagoras' theorem. Actually my go-to website for intuitive explanations of concepts.



These are similar triangles
This diagram also makes something very clear:

Area (Big) = Area (Medium) + Area (Small)
Makes sense, right? The smaller triangles were cut from the big one, so the areas must add up. And the kicker: because the triangles are similar, they have the same area equation.

Let's call the long side c (5), the middle side b (4), and the small side a (3). Our area equation for these triangles is:

Area = F * hypotenuse^2

where F is some area factor (6/25 or .24 in this case; the exact number doesn't matter). Now let's play with the equation:

Area (Big) = Area (Medium) + Area (Small)

F c^2 = F b^2 + F a^2

Divide by F on both sides and you get:

c^2 = b^2 + a^2

Which is our famous theorem! You knew it was true, but now you know why

This explains the product rule.
AnswerKenntnis:
A theorem that I find extraordinarily beautiful and intuitive to understand is Gauss' Theroma Egregium, which basically says that the Gaussian curvature of a surface is an intrinsic property of the surface. Implications of this theorem are immediate, starting from the equivalence of developable surfaces and the 2D euclidean plane, to the impossibility of mapping the globe to an atlas. Wikipedia also provides the common pizza eating strategy of gently bending the slice to stiffen it along its length, as a realization
AnswerKenntnis:
It's not exactly stunning, but it is interesting and visual and simple enough for an elementary school child:

There are only 5 platonic solids.

Numberphile has a great video explaining it:  https://www.youtube.com/watch?v=gVzu1_12FUc

In short, the reason is that there are only enough space for 3, 4, or 5 equilateral triangles at a corner; only enough space for 3 squares at a corner; and only enough space for 3 pentagons at a corner; and not even enough space for 3 hexagons at a corner, so there are only 5.



Although I guess it was stunning enough for the ancient Greeks to decide that they were the geometric basis of the five elements of the universe: earth, fire, wind, water, aether.
QuestionKenntnis:
Splitting a sandwich and not feeling deceived
qn_description:
This is a problem that has haunted me for more than a decade. Not all the time - but from time to time, and always on windy or rainy days, it suddenly reappears in my mind, stares at me for half an hour to an hour, and then just grins at me, and whispers whole day: "You will never solve me..."

Please save me from this torturer.

Here it is:

Let's say there are two people and a sandwich. They want to share the sandwich, but they don't trust each other. However, they found the way how both of them will have a lunch without feeling deceived: One of them will cut the sandwich in two halves, and another will choose which half will be his. Fair, right?



The problem is:

Is there such mechanism for three people and a sandwich?



EDIT: This was roller-coaster for me. Now, it turns out that there are at least two books devoted exclusively on this problem and its variations:

Fair Division

Cake Cutting Algorithms





I was yesterday in a coffee shop, in a small company. We ordered coffee and some chocolate cakes. As I was cutting my cake for my first bite, I felt sweat on my forehead. Would  some of my buddies just interrupt me and say: Stop! You are not cutting the cake in a fair manner! My hands started shaking in fear of that. But, no, nothing happened. Fortunately.
AnswersKenntnis
AnswerKenntnis:
Just for the record, here's the SelfridgeΓÇôConway discrete procedure mentioned in the comments. The Wikipedia article also contains some commentary on why it works.


  Suppose we have three players P1, P2 and P3. Where the procedure gives a criterion for a decision it means that criterion gives an optimum choice for the player.
  
  
  P1 divides the cake into three pieces he considers of equal size.
  Let's call A the largest piece according to P2.
  P2 cuts off a bit of A to make it the same size as the second largest. Now A is divided into: 
  
  the trimmed piece A1 
  the trimmings A2. 
  
  
  
  Leave the trimmings A2 to one side. If P2 thinks that the two largest parts are equal, then each player chooses a part in this order: P3, P2 and finally P1.
  
  4 . P3 chooses a piece among A1 and the two other pieces.
  
  5 . P2 chooses a piece with the limitation that if P3 didn't choose A1, P2 must choose it.
  
  6 . P1 chooses the last piece leaving just the trimmings A2 to be divided.
  
  Now, the cake minus the trimmings A2 has been divided in an envy free manner. The trimmed piece A1 has been chosen by either P2 or P3. Let's call the player who chose it  PA and the other one Player PB. 
  
  
  PB cuts A2 into three equal pieces.
  PA chooses a piece of A2 - we name it A21.
  P1 chooses a piece of A2 - we name it A22.
  PB chooses the last remaining piece of A2 - we name it A23.
AnswerKenntnis:
For more than two, the moving knife is a nice solution.  Somebody takes a knife and moves it slowly across the sandwich.  Any player may say "cut".  At that moment, the sandwich is cut and the piece given to the one who said "cut".  As he has said that is an acceptable piece, he believes he has at least $\frac 1n$ of the sandwich.  The rest have asserted (by not saying "cut") that is it at most $\frac 1n$ of the sandwich, so the average available is now at least their share.  Recurse.
AnswerKenntnis:
For dividing a cake to $n$ people, there is an algorithm that guarantees that:


Each of the $n$ people gets a piece that he considers at least as good as each of the other pieces (i.e., the division is envy free);
All pieces are connected (actually, all pieces are rectangles).


This algorithm was invented by Forest Simmons and published by Francis Su at 1999.

The only problem with this algorithm is that its runtime is not bounded, i.e., it might take forever (As proved by Stromquist at 2008, no bounded algorithm can find an envy-free division when we want the pieces to be connected).

But, you can stop at any time and get a division that is approximately envy free.
AnswerKenntnis:
Here's a variation on the accepted answer.  

A cuts the sandwich into 3 parts
If B thinks the top 2 pieces are equal
  C chooses a piece
  B chooses a piece
  A gets the remaining piece
Else
  B re-balances the 2 biggest pieces.
  C chooses a piece
  If only one of B's re-balanced pieces remain
    B gets that piece
    A gets the remaining piece
  else
    A chooses a piece
    B gets the remaining piece


Summary:


A will get one of their original "equal" pieces or more, and is thus happy. 
B will get one of the pieces they adjusted, and are thus happy.
C will get first choice, and is thus happy.
Although each person should get at least a third in their mind, this doesn't qualify as an envy-free solution.  For example, if B re-balances two pieces and C chooses the piece B increased, then A would envy C because he got more than 1/3 in A's mind.  However, A still gets 1/3 in their mind.  


I think you can generalize this pattern for $N$ people.  Simplified, you give up your place in the picking order if you rebalance, but the trade-off is that you are guaranteed to get a piece you rebalanced or a bigger one.  Here's a first take at the priority rules for the picking procedure, though I'm not sure it handles all cases:  


If N people each have N pieces they rebalanced remaining, the first person who rebalanced from that group gets to choose from their rebalanced pieces.  For example, if there is one piece left from the pieces you re-balanced, you get that piece.
If you did not re-balance, the highest number gets to pick first
If you did rebalance, the lowest cutter gets to pick first


Also, here's an example of how it would work for 4 people:

A cuts the sandwich into 4 equal pieces
If B thinks the top 3 pieces are equal:
  If C thinks the top 2 pieces are equal:
    D chooses a piece
    C chooses a piece
    B chooses a piece
    A gets the last piece
  Else:
    C rebalances the top 2 pieces
    D chooses a piece
    If only one of C's rebalanced pieces remain:
      C gets the other rebalanced piece
      B chooses a piece
      A gets the last piece
    Else:
      B chooses a piece
      If only one of C's rebalanced pieces remain
        C gets the other rebalanced piece
        A gets the remaining piece
      Else
        A chooses
        C gets the remaining piece
Else:
  B rebalances the top 3 pieces
  If C thinks the top 2 pieces are equal:
    D chooses a piece
    C chooses a piece
    If only one of B's rebalanced pieces remain:
      B takes that piece
      A gets the final piece
    Else:
      A chooses a piece
      B gets the final piece
  Else:
    C rebalances the top 2 pieces
    D chooses a piece
    If only one of C's rebalanced pieces remain:
      C gets that piece
      If only one of B's rebalanced pieces remain:
        B gets that piece
        A gets the last piece
      Else:
        A chooses a piece
        B gets the other piece
    Else if only 2 pieces rebalanced by both C & B are left:
      B chooses one of the rebalanced pieces
      C gets the other one
      A gets the last piece
    Else:
      A chooses a piece
      If only one of C's rebalanced pieces remain:
        C gets that piece
        B gets the final piece
      Else:
        B gets to choose
        C gets the final piece
AnswerKenntnis:
According to Wikipedia, the Brams-Taylor procedure is


  the first finite procedure to produce an envy-free division of an infinitely divisible good among any positive integer number of players.


A nice discussion about it can be found here.
AnswerKenntnis:
Okay, so this is just a small comment about the "general science'' behind all these. You can understand a sandwich as a measure space with $n$ given measures. Also, these measures are non-atomic, otherwise you can not solve the problem even for two people. These measures generate a vector measure on the ``sandwich''. Now you can apply Lyapunov theorem and say, that the range of this measure is closed and convex. But the points $(1,1,...,1)$ and $(0,0,...,0)$ lie in the range, thus the point $(1/n,..., 1/n)$ does. This means, that there is a piece of sandwich such that each person thinks that it is exactly $1/n$ of the whole sandwich. Now you can give it to anyone and repeat the procedure. Cool thing is that you will divide the sandwich in such a way that each person will think, that the sandwich is divided into equal parts. So one can solve the problem in the following form "There is a way to divide a sandwich such that each person thinks that no one have more sandwich than him". I have no idea how to make an explicit algorithm for that one.
AnswerKenntnis:
Complete EDIT (too lazy to formulate mathematically): Imagine X as a sandwich just for simplicity. The first person cuts X into thirds "horizontally" and they have to cut across the whole sandwich in a straight line with each cut. The second person cuts each third into thirds by cutting the sandwich "vertically" with each cut going through all of the original thirds in a straight line. Now there are 9 pieces. Third player picks one piece and then first person picks, then second and third again in a circle.... This operation with the horizontal and vertical constraints (and having to go right across the sandwich) should avoid anyone feeling deceived.
AnswerKenntnis:
From http://senseis.xmp.net/?YouCutIChoose

"An interesting solution is outlined in "Mutiny on the H.M.S. Bounty", called the Who-shall-have-this Method. Say there are 'N' people to divide between, they choose from amongst themselves two people - A and B. 'A' stands where 'B' cannot observe him, and divides the cake. B then points to someone and that someone comes to claim his share of the cake. B may at any time point to A or to himself, but since he never can see which segment of cake he's giving out, and since B and A are both chosen by the crowd, there is virtually no opportunity for intentional collusion.

This method still won't guarantee everyone a satisfactory cut of the cake, but it gives 'A' the correct motivation, since only by dividing the cake evenly can he hope to get a large piece for himself. "
AnswerKenntnis:
This was covered in the first class I ever TAed in graduate school. Naturally, the reaction of most of the students was, "why don't they just eat the cake?"

Person A cuts it into two pieces she views as "of equal value." Person B then chooses her favorite half. A and B then each divide their halves into thirds that they views as "of equal value." Person C then chooses her 1 favorite piece from A and one favorite piece from B. This ensures a fair (but not envy-free) division.
AnswerKenntnis:
Nobody said it has to be a discrete process. Just blend the sandwich into infinitestimally small pieces, everyone eats small pieces until they ate a third of the mess. Lucky person gets to lick the blades.
AnswerKenntnis:
The "one person cuts, the other chooses" algorithm generalises to any number of people, but the generalisation is (a) not envy-free; (b) vulnerable to collusion in a subset of at least two of the participants. It does work for cases where one or more participants want a piece of size $ < \frac{1}{n}$, but it splits their share unfairly among the remaining participants.

The participants sit in a circle. Person 0 cuts a portion from the cake. (They don't cut the cake all the way through, but just cut one slice from it.) The resulting portion is offered to person 1. If he accepts it, he takes it and is removed from the circle; otherwise, it's offered to person 2, and so on around the circle. If no one takes it, the portion is returned to person 0, who must take it and is removed from the circle.

This procedure is repeated with the remaining participants (starting with person 1 if they're still present, otherwise person 2), until there is only one person left. This person gets the left-over slice of cake which has never been offered to anyone.

It's clearly very gameable, but if the participants are basically honest, it works well. At least it runs in bounded time and delivers connected portions. Its main practical problem is that one participant can cut a slice that's much too large, advantaging one participant at the expense of all the others. But unlike the "one person cuts all slices" method, the resentment gets to be spread among all the participants who slice, not just focused on one person.
AnswerKenntnis:
Okay, I've got a weird idea that I think might work.

Viewed from above, the sandwich is a square, right? Since a square is technically a disc in $L_1$ space, I think you can use the pizza theorem to cut it into 12 pieces and divide it evenly with way less work than Selfridge-Conway.

I think this should work because 12 divides into 4 (a pizza theorem requirement) but also divides into 3. I started with the following image from Wikipedia:



My algorithm was, first divide the pizza along the cardinal directions. Then, enumerating over each such section, color each first wedge, second wedge, third wedge, and fourth wedge (modulo 3) black. Offset that sequence by 1, and repeat twice more. Here is the result:

I have a feeling that this is at least a good approximation. The color permutation might not be so simple, though--the claim is that there exists such a permutation for any set of cuts that satisfy the requirements of the theorem.

edit: I'm more confident about this one.

The algorithm for this one is much more intuitive:


Observe that there are 3 "opposite pairs" of slices of each color.
Select one opposite pair of each color, and recolor it.




The claim is that each pair of opposites is a third of half of the pizza sandwich.
AnswerKenntnis:
Call the players A, B, C:

A cuts the sandwich in two pieces, and calls it "one third" and "two thirds". B can either 


accept the "one third" or 
choose to cut the "two thirds" in two halves.


In the first case, C gets to cut the "two thirds", and A will choose one of the two halves.

In the second case, C chooses one of the two halves, B gets the other half, and A gets the "one third" he cut at the beginning.

I think it's the easiest possible solution, assuming the players are honest.
AnswerKenntnis:
Divide the sandwich into three portions and weigh each one on a digital scale. Adjust until the portions are the same. If equal distribution of condiments is a point of contention, the sandwich must be pureed prior to portioning. No one said it had to taste good.
AnswerKenntnis:
It's simple: one person divides the sandwich into 3 pieces, and that person is the last one to choose (the other two can decide using odds and evens, for instance). The dividing person will not want to make no piece larger than another, because he/she would obviously be left with the smaller one.
AnswerKenntnis:
This may be silly, but I think it's fairly straightforward for as many people as you want. If you have $n$ people, order person number $1$ to cut the sandwich into $n$ pieces. All the other $n-1$ people then pick their own piece. The person who was cutting gets the piece that was left. If he cut all pieces equally, he will have $1/n$ of the sandwich. If any one piece was bigger, this means one piece had to be smaller, and the smaller piece will not get selected, so the cutter has motivation to cut equally.
AnswerKenntnis:
I think I have a more practical solution than the one selected:


A cuts the cake in three.  
B cuts each piece in three. 
C cuts each piece in three.


We now have 27 pieces, each takes one piece in the same order they have cut the cake then reverse the sequence: ABC-CBA-ABC-CBA-...

No matter how A and B cut the cake, C can make sure that every piece is very close to the same size AND it is his best interest to do so. Similarly B, by cutting each piece properly in 3 equal parts, minimizes C's ability to screw up. 

A has least incentive to cut fairly, but his cuts have the least influence on the final outcome. He can however set a baseline: if his cuts are fair, no screw-up can be bigger than one third of the cake. 



The assumption here is that none of them is capable of making perfect cuts, but that the errors will cancel themselves out. The important issue is to make it in their best interest to attempt the fairest cuts possible. 

By reverting the picking order on each turn, A & C will alternatively chose the biggest remaining piece and B will get the medium piece of each set, so even if there is a discrepancy in the portion sizes the picking order should minimize its impact. 

There is also another aspect which is that the greater the number of portions of somewhat similar size, the harder it becomes for each person to keep track of the total amount of cake gotten. With 1 piece each, it's fairly easy for each one to compare portions. But if each person must chose 9 pieces, it's a lot harder to compare the total volume gotten by each.
AnswerKenntnis:
It might help what is in the sandwitch. If it's a BLT for example then one of the people might be a vegetarian, but might feel cheated if the other gets more tomato. On the otherhand the bacon will be up for grabs. The lettuce is a wild card of course if they all want it.

I think what you have to do is negotiate sandwitch parts with the others. Perhaps one person will be happy letting the other eat all the bacon if they can eat all the tomato and lettuce. Perhaps one is gluten intolerant so they don't mind the 3rd person having all the bread. The other alternative is for each person to bring their own sandwitches. We had a similar problem like this at work once with pizza and we basically decided not to eat shared pizza anymore.
AnswerKenntnis:
Here's my solution...

Let's say it's a pizza and there are 3 people, but it would work for other items or numbers of people.

The pizza is divided into 3 pieces. It's assumed that the pieces are cut into equal sizes, but it's not important... because the "value" of a piece may not be solely dependent on it's size. For example, a smaller piece may have more of a particular topping, or it may be more/less burned, or thicker/thinner, etc.

Each person identifies the piece they want. If each piece is chosen, then everyone is happy... we're done.

Otherwise, each person "bids" an amount of money they are willing to pay for the piece they want. The piece with the highest bid is set aside for that person.

Bidding continues for the remaining pieces until the last piece (and 1 person) is left. 

Everyone pays the amount that they bid, and the last person pays an amount that is the average of all the bids, less the amount that the highest bid exceeded the average (which could be $0 or even less, but that should not be typical).

From this money, the pizza is paid for, and the remaining money is divided equally among all the people.

In the case where the money collected is not enough to pay for the pizza, then everyone pays an equal amount to cover the shortage. Also in this case, you should consider 1: choose another place for your pizza, 2: choose different people to share pizza with.
AnswerKenntnis:
I think I might have an algorithm that 
a) Is fair
b) Can be generalized for n players
c) Only uses a bounded number of cuts (a different bound for each n)

odds are that I am wrong =P



The procedure for 3 players:


P1 divides the cake in 3 parts
P2 and P3 choose each a 'smallest piece', such that they dont want part of it.


2.1 If P2 and P3 agree,then they take the 2 pieces they like, and divide each amongst themselves. P3 gets the remaining

2.2 If P2 and P3 disagree, we have:
   P2 'likes' two pieces
   P3 'likes' two pieces
   P1 will be assumed to like the two pieces that are not liked by both P2 and P3
   Now, each piece has 2 people that like it. These 2 divide the piece amongst themselves 

P1 is happy (if he divided correctly): he either got 1 piece, or half of 2 pieces

P2 and P3 are happy: they each got half of the two pieces they think are bigger



The procedure for n (using the procedure for n-1)


P1 divides in N
Each P2, ..., PN chooses a piece they dislike (and therefore, n-1 they like). They get a 'stake' in each piece they like. 
P1 gets 'stakes' in pieces such that each piece is 'divided'  in n-1 stakes
recurse: each piece is divided amonsgt the people with stakes on them. If P1 has more then 1 stake, he can 'play as many players' in the division. As far as I can tell, that is not a problem
AnswerKenntnis:
Hmm, if you cut it into an approximate 3rd and 2/3rds portions, then the cutter would get a slice that both other people think is about 1/3rd.  To attempt to subvert this, player A could cheat and make 2 equal halves.  In the real world, such a player would never get invited to party games again.  ;)  But let's just say that then one of the other players would have to divide each half into 1/6th and 1/3rd slices.  Repeat ad nauseum?

If you can 'uncut' the sandwich, then it's easier:  Just keep having a different player cut the sandwich until the other 2 agree.  This is similar to the moving-knife solution but where the cut is not done unless all 3 agree, in actual practice since 'uncutting' really means just not cutting yet.

Once you get the bigger piece being roughly 2/3rds, then you can apply the normal 2-person method.  To go to 4 people, vote in pairs?  You could also apply this idea with 1/4th & 3/4ths slices.  This is generalizable to 5,...,dozens of people.
AnswerKenntnis:
Person 1 cut out a 1/3 piece.

Person 2 and 3 decide what piece they want.

If they pick different pieces, the 1/3 piece is given, and other play the 2 people game with the 2/3 piece and players 1.

If they both pick the 2/3 piece, player 1 receives the 1/3 piece and they play the 2 people game with the 2/3 piece.

If they both pick the 1/3 piece, person 2 cut off a part of the 1/3 piece, that part is then added to the 2/3 piece. Person 3 decide if he takes the remaining 1/3 piece, or plays the 2 people game with player 1.



If you do not want to cut the sandwich in more than 3 pieces, go as follow:

Person 1 cut out his piece (1/3);

Person 2 cut out his piece (1/3);

Person 3 can now switch with person 1 or 2 or keep the remaining piece himself.
AnswerKenntnis:
Take the sandwich and divide it into 4 even squares, take 1 of the squares and cut it evenly into 3  rectangular pieces. Everyone now gets a big square and a small rectangular piece.
QuestionKenntnis:
Why can you turn clothing right-side-out?
qn_description:
My nephew was folding laundry, and turning the occasional shirt right-side-out. I showed him a  "trick" where I turned it right-side-out by pulling the whole thing through a sleeve instead of the bottom or collar of the shirt. He thought it was really cool (kids are easily amused, and so am I).

So he learned that you can turn a shirt or pants right-side-out by pulling the material through any hole, not just certain ones. I told him that even if there was a rip in the shirt, you could use that to turn it inside-out or right-side-out, and he was fascinated by this and asked "why?"

I don't really know the answer to this. Why is this the case? What if the sleeves of a long-sleeve shirt were sewn together at the cuff, creating a continuous tube from one sleeve to the other? Would you still be able to turn it right-side-out? Why? What properties must a garment have so that it can be turned inside-out and right-side-out?

Sorry if this is a lame question, but I've always wondered. I wouldn't even know what to google for, so that is why I am asking here.

If you know the answer to this, could you please put it into layman's terms?

Update: Wow, I really appreciate all the participation. This is a really pleasant community and I have learned a lot here. It seems that the answer is that you need at least one puncture in the garment through which to push or pull the fabric. It appears that you can have certain handles, although it's not usually practical with clothing due to necessary stretching.

Accepted (a while ago actually -- sorry for not updating sooner) Dan's answer because among the answers that I understand, it is the highest ranked by this community.
AnswersKenntnis
AnswerKenntnis:
Everything I'm wearing is a topological sphere with holes (t-shirts have 4, pants 3, shoes and socks 1) in which cases any hole works.  Instead of a long-sleeve shirt with the arms sewn together, consider a pair of pants with legs sewn together to form a topological torus with a hole (so if you were to wear them your feet would be touching and it would be impossible to put your shoes on).  This pair of pants has two parameters which are roughly constant, the circumference of the leg and the total length of the two legs.  When it is turned inside out through the waist, these parameters swap roles, so you will have a tube about the length of a pant leg with an opening on each end, the same as if you had turned one leg inside-out and pushed the other leg through it prior to sewing.  I think this would be possible to do with real toroidal clothing as long as it is thin enough, because the process doesn't require any stretching.
AnswerKenntnis:
First, a warning.  I suspect this response is likely not going to be immediately comprehensible.  There is a formal set-up for your question, there are tools available to understand what's going on.  They're not particularly light tools, but they exist and they're worthy of being mentioned.  Before I write down the main theorem, let me set-up some terminology.  The tools belong to a subject called manifold theory and algebraic topology.  The names of the tools I'm going to use are called things like: the isotopy extension theorem, fibre-bundles, fibrations and homotopy-groups.

You have a surface $\Sigma$, it's your shirt or whatever else you're interested in, some surface in 3-dimensional space.  Surfaces have automorphism groups, let me call it $Aut(\Sigma)$.  These are, say, all the self-homeomorphisms or diffeomorphisms of the surface.   And surfaces can sit in space.  A way of putting a surface in space is called an embedding.  Let's call all the embeddings of the surface $Emb(\Sigma, \mathbb R^3)$.  $Emb(\Sigma, \mathbb R^3)$ is a set, but in the subject of topology these sets have a natural topology as well.  We think of them as a space where "nearby" embeddings are almost the same, except for maybe a little wiggle here or there.  The topology on the set of embeddings is called the compact-open topology (see Wikipedia, for details on most of these definitions). 

Okay, so now there's some formal nonsense.  Look at the quotient space $Emb(\Sigma, \mathbb R^3)/Aut(\Sigma)$.  You can think of this as all ways $\Sigma$ can sit in space, but without any labelling -- the surface has no parametrization.  So it's the space of all subspaces of $\mathbb R^3$ that just happen to be homeomorphic to your surface. 

Richard Palais has a really nice theorem that puts this all into a pleasant context.  The preamble is we need to think of everything as living in the world of smooth manifolds -- smooth embeddings, $Aut(\Sigma)$ is the diffeomorphism group of the surface, etc. 

There are two locally-trivial fibre bundles (or something more easy to prove -- Serre fibrations), this is the "global" isotopy-extension theorem:

$$Diff(\mathbb R^3, \Sigma) \to Diff(\mathbb R^3) \to Emb(\Sigma, \mathbb R^3)/Aut(\Sigma)$$

$$Diff(\mathbb R^3 fix \Sigma) \to Diff(\mathbb R^3, \Sigma) \to Aut(\Sigma)$$

here $Diff(\mathbb R^3)$ indicates diffeomorphisms of $\mathbb R^3$ that are the identity outside of a sufficiently large ball, say.  

So the Palais theorem, together with the homotopy long exact sequence of a fibration, is giving you a language that allows you to translate between automorphisms of your surface, and motions of the surface in space. 

It's a theorem of Jean Cerf's that $Diff(\mathbb R^3)$ is connected. A little diagram chase says that an automorphism of a surface can be realized by a motion of that surface in 3-space if and only if that automorphism of the surface extends to an automorphism of 3-space.  For closed surfaces, the Jordan-Brouwer separation theorem gives you an obstruction to turning your surface inside-out.  But for non-closed surfaces you're out of tools.  

To figure out if you can realize an automorphism as a motion, you literally have to try to extend it "by hands".  This is a very general phenomena -- you have one manifold sitting in another, but rarely does an automorphism of the submanifold extend to the ambient manifold.  You see this phenomena happening in various other branches of mathematics as well -- an automorphism of a subgroup does not always extend to the ambient group, etc. 

So you try your luck and try to build the extension yourself.  In some vague sense that's a formal analogy between the visceral mystery of turning the surface inside-out and a kind of formalized mathematical problem, but of a fundamentally analogous feel. 

We're looking for automorphisms that reverse orientation. For an arbitrary surface with boundary in 3-space, it's not clear if you can turn the surface inside out.  This is because the surface might be knotted. Unknotted surfaces are examples like your t-shirt.  Let's try to cook up something that can't be turned inside-out. 

The automorphism group of a 3-times punctured sphere has 12 path-components (12 elements up to isotopy).  There are 6 elements that preserve orientation, and 6 that reverse.  In particular the orientation-reversing automorphisms reverse the orientation of all the boundary circles.  So if you could come up with a knotted pair-of-pants (3-times punctured surface) so that its boundary circles did not admit a symmetry that reversed the orientations of all three circles simultaneously, you'd be done. 

Maybe this doesn't seem like a reduction to you, but it is. 

For example, there are things called non-invertible knots: 

http://en.wikipedia.org/wiki/Invertible_knot

So how do we cook up a knotted pair-of-pants from that? 

Here's the idea.  The non-invertible knot in the link above is sometimes called $8_{17}$.  Here is another picture of it:

http://katlas.org/wiki/8_17

Here is a variant on that. 



Interpret this image as a ribbon of paper that has three boundary circles.  One boundary circle is unknotted.  One is $8_{17}$.  The other is some other knot. 

It turns out that other knot isn't trivial, nor is it $8_{17}$.  

So why can't this knotted pair of pants be turned inside-out?  Well, the three knots are distinct, and $8_{17}$ can't be reversed. 

The reason why I know the other knot isn't $8_{17}$?  It's a hyperbolic knot and it has a different ($4.40083...$) hyperbolic volume than $8_{17}$ ($10.9859...$). 

FYI: in some sense this is one of the simplest surfaces with non-trivial boundary that can't be turned inside-out.  All discs can be turned inside-out.  Similarly, all annuli (regardless of how they're knotted) can be turned inside-out. So for genus zero surfaces, 3 boundary components is the least you can have if you're looking for a surface that can't be turned inside-out.

edited to correct for Jason's comment.

comment added later: I suggest if you purchase a garment of this form you return it to the manufacturer.
AnswerKenntnis:
I'm going to try to give a lighter-flavoured version of my previous answer.  I'd rather not edit the previous one anymore so here goes another response.  I want to make clear, this response is to you, not your 10-year-old nephew.  How you translate this response to any person depends more on you and that person than anything else. 

Take a look at the Wikipedia page for diffeomorphism. In particular,the lead image 

When I look at that image I see the standard Cartesian coordinate grid, but deformed a little. 



There's a "big theorem" in a subject called Manifold Theory and it's name is the "Isotopy Extension Theorem".  Moreover, it has a lot to do with these kinds of pictures. 

The isotopy extension theorem is roughly this construction: say you have some rubber, and it's sitting in a medium of liquid epoxy that's near-set.  Moreover, imagine the epoxy to be multi-coloured.  So when you move the rubber bit around in the epoxy, the epoxy will "track" the rubber object.  If your epoxy had a happy-face coloured into it originally, after you move the rubber, you'll see a deformed happy-face.  




So you get images that look a lot like mixed paint.  Stir various blotches of paint, and the paint gets distorted.  The more you stir, the more it mixes and it gets harder and harder to see the original image.  The important thing is that the mixed paint is something of a "record" of how you moved your rubber object.  And if your motion of the rubber object returns it to its initial position, there is a function

$$ f : X \to X $$

where $X$ is all positions outside your rubber object.  Given $x \in X$ you can ask where the particle of paint at position $x$ went after the mixing, and call that position $F(x)$. 

All my talk about fibre bundles and homotopy-groups in the previous response was a "high level" encoding of the above idea.  An intermediate step in the formalization of this idea is the solution of an ordinary differential equation, and that differential equation is essentially the "paint-mixing idea" above, in case you want to look at this subject in more detail later. 

So what does this mean?  A motion of an object from an initial position back to the initial position gives you an idea of how to "mix paint" outside the object.  Or said another way, it gives you an Automorphism of the complement, in our case that's a 1-1, continuous bijective function between 3-dimensional space without the garment and itself. 

You may find it odd but mathematicians have been studying "paint mixing" in all kinds of mathematical objects, including "the space outside of garments" and far more bizarre objects for well over 100 years.  This is the subject of dynamical systems.  "Garment complements" are a very special case, as these are subsets of 3-dimensional euclidean space and so they're 3-manifolds.  Over the past 40 years our understanding of 3-manifolds has changed and seriously altered our understanding of things.  To give you a sense for what this understanding is, let's start with the basics.  3-manifolds are things that on small scales look just like "standard" 3-dimensional Euclidean space.   So 3-manifolds are an instance of "the flat earth problem".  Think about the idea that maybe the earth is like a flat sheet of paper that goes on forever.  Some people (apparently) believed this at some point. And superficially, as an idea, it's got some things going for it.  The evidence that the earth isn't flat requires some build-up. 



Anyhow, so 3-manifolds are the next step.  Maybe all space isn't flat in some sense.  That's a tricky concept to make sense of as space isn't "in" anything -- basically by definition whatever space is in we'd call space, no?  Strangely, it's not this simple.  A guy named Gauss discovered that there is a way to make sense of space being non-flat without space sitting in something larger. Meaning curvature is a relative thing, not something judged by some exterior absolute standard.  This idea was a revelation and spawned the idea of an abstract manifold.  To summarize the notion, here is a little thought experiment. 

Imagine a rocket with a rope attached to its tail, the other end of the rope fixed to the earth.  The rocket takes off and goes straight away from the earth.  Years later, the rocket returns from some other direction, and we grab both loose ends of the rope and pull.  We pull and pull, and soon the rope is tight.  And the rope doesn't move, it's taught. as if it was stuck on something.  But the rope isn't touching anything except your hands.  Of course you can't see all the rope at one time as the rope is tracing out the (very long) path of the rocket. But if you climb along the rope, after years you can verify: it's finite length, it's not touching anything except where it's pinned-down on the earth.  And it can't be pulled in.  

This is what a topologist might call a hole in the universe.  We have abstract conceptions of these types of objects ("holes in the universe") but by their nature they're not terribly easy to visualize -- not impossible either, but it takes practice and some training.

In the 1970's by the work of many mathematicians we started to achieve an understanding of what we expected 3-manifolds to be like.  In particular we had procedures to construct them all, and a rough idea of how many varieties of them there should be.  The conjectural description of them was called the geometrization conjecture. It was a revelation in its day, since it implied that many of our traditional notions of geometry from studying surfaces in 3-dimensional space translate to the description of all 3-dimensional manifolds.   The geometriztion conjecture was recently proven in 2002. 

The upshot of this theory is that in some sense 3-dimensional manifolds "crystalize" and break apart in certain standard ways.  This forces any kind of dynamics on a 3-manifold (like "paint mixing outside of a garment") to respect that crystalization. 

So how do I find a garment you can't turn inside-out?  I manufacture one so that its exterior crystalizes in a way I understand.  In particular I find a complement that won't allow for this kind of turning inside-out.  The fact that these things exist is rather delicate and takes work to see.  So it's not particularly easy to explain the proof.  But that's the essential idea. 

Edit: To say a tad more, there is a certain way in which this "crystalization" can be extremely beautiful.  One of the simplest types of crystalizations happens when you're dealing with a finite-volume hyperbolic manifold.  This happens more often than you might imagine -- and it's the key idea working in the example in my previous response.  The decomposition in this case is very special as there's something called the "Epstein-Penner decomposition" which gives a canonical way to cut the complement into convex polytopes.  Things like tetrahedra, octahedra, icosahedra, etc, very standard objects.  So understanding the dynamics of "garments" frequently gets turned into (ie the problem "reduces to") the understanding of the geometry of convex polytopes -- the kind of things Euclid was very comfortable with.  In particular there's software called "SnapPea" which allows for rather easy computations of these things. 




Images taken from Morwen Thistlethwaite's webpage.  These are images of the closely-related notion of a "Dirichlet domain". 

Here is an image of the Dirichlet domain for the complement of $8_{17}$, the key idea in the construction of my previous post.



Technically, this in the Poincare model for hyperbolic space, which gives it the jagged/curvy appearance.
AnswerKenntnis:
The wikipedia page for the torus has a very nice animation of a punctured torus turning inside out.  In just the same way, if you stitch together the two cuffs of a pair of pants together you can turn the result inside out.  You have to attach the cuffs in the simplest way, without knotting, to get a torus with a hole, not a Klein bottle with a hole.

As Ryan says, it is not possible to turn every piece of clothing inside out,  However such "bad" pieces of clothing have to be knotted in some fashion.  Here is an example, perhaps a bit simpler than Ryan's, that avoids hyperbolic geometry :).  Take a pair of pants, tie the legs in an overhand knot, and stitch together the cuffs to get a knotted punctured torus.  The knot in this case is a trefoil knot.  

I'll call this piece of clothing $S$.  The proof I know that $S$ cannot be turned inside out uses some ideas from low-dimensional topology. Notice that the curve of stitches compresses (bounds a disk $D$) in the inner direction.  If you could turn $S$ inside out then that motion of $S$ would also give a motion of the disk $D$.  Thus the motion sends the curve of stitches to some curve on $S$ (still not parallel to the boundary!) that compresses in the outer direction.  But since the trefoil is not the unknot there is no such curve.
AnswerKenntnis:
I can at least answer the question about the rip, and point you to some terms to look up.  What you are looking at is not geometry as it is usually understood but topology (particularly of surfaces with boundary), which informally is the study of properties of things that are invariant under deformation.  It is often said that a topologist can't tell a coffee mug from a doughnut (it is possible to deform one into the other) and this is the attitude you should take towards questions of this kind.

From this perspective, a rip is the same thing as the bottom of the shirt is the same thing as a sleeve: you can deform each of them into the other, so topologically they're the same thing.  (Imagine making the rip bigger, or squashing a long sleeve into a short sleeve.)  They are all just examples of what topologists call punctures.    

I don't know the answer to your general question, but one property a surface must have to be able to be turned inside out is that it must be orientable; in other words, it must have an inside and an outside to begin with!  Surfaces such as the M├╢bius strip famously don't have this property, so it doesn't even make sense to ask about whether it's possible to turn such things inside-out or not.  (And some non-orientable surfaces can't even be realized in three dimensions...)

Orientable surfaces happen to have a particularly simple description: they are all topologically just spheres with some handles sewn on and with some punctures.  To turn them inside out, at least one puncture is necessary, and if you can turn one handle inside-out then you can presumably turn all of them inside-out.  If what I said in the comments is wrong and you can't turn handles inside-out, then a necessary and sufficient condition is that there is at least one puncture and no handles.
AnswerKenntnis:
A shirt with no hole, or all holes sealed is homeomorphic to a sphere.

A shirt with holes is homeomorphic to a sphere with punctures.

Now you intuitively see that a rubber sphere with punctures can be turned inside out by continuous motion, whereas a perfect sphere cannot.

To understand why, let's concentrate on 2-dimentional plane, taking a circle instead of a sphere. It can be proven that any continuous deformation that inverts the circle will make it cross itself. However if the circle has 'holes', or gaps, then it topologically is equivalent to one or more line segments, which can all be inverted in place without touching each other (appropriate scaling may be necessary).

Similar feature holds for a sphere too. Hence you cannot turn a shirt inside out if all the holes are sealed, but you can do it even if you have one hole (and provided that the shirt is flexible enough to go through that hole if the hole is small).
QuestionKenntnis:
Is $\frac{dy}{dx}$ not a ratio?
qn_description:
In the book Thomas's Calculus (11th edition) it is mentioned (Section 3.8 pg 225) that the derivative $\frac{dy}{dx}$ is not a ratio. Couldn't it be interpreted as a ratio, because according to the formula $dy = f'(x)dx$ we are able to plug in values for $dx$ and calculate a $dy$ (differential). Then if we rearrange we get $\frac{dy}{dx}$ which could be seen as a ratio. 

I wonder if the author say this because $dx$ is an independent variable, and $dy$ is a dependent variable, for $\frac{dy}{dx}$ to be a ratio both variables need to be independent.. maybe?
AnswersKenntnis
AnswerKenntnis:
Historically, when Leibniz conceived of the notation, $\frac{dy}{dx}$ was supposed to be a quotient: it was the quotient of the "infinitesimal change in $y$ produced by the change in $x$" divided by the "infinitesimal change in $x$". 

However, the formulation of calculus with infinitesimals in the usual setting of the real numbers leads to a lot of problems. For one thing, infinitesimals can't exist in the usual setting of real numbers! Because the real numbers satisfy an important property, called the Archimedean Property: given any positive real number $\epsilon\gt 0$, no matter how small, and given any positive real number $M\gt 0$, no matter how big, there exists a natural number $n$ such that $n\epsilon\gt M$. But an "infinitesimal" $\xi$ is supposed to be so small that no matter how many times you add it to itself, it never gets to $1$, contradicting the Archimedean Property. Other problems: Leibniz defined the tangent to the graph of $y=f(x)$ at $x=a$ by saying "Take the point $(a,f(a))$; then add an infinitesimal amount to $a$, $a+dx$, and take the point $(a+dx,f(a+dx))$, and draw the line through those two points." But if they are two different points on the graph, then it's not a tangent, and if it's just one point, then you can't define the line because you just have one point. That's just two of the problems with infinitesimals. (See below where it says "However...", though.)

So Calculus was essentially rewritten from the ground up in the following 200 years to avoid these problems, and you are seeing the results of that rewriting (that's where limits came from, for instance). Because of that rewriting, the derivative is no longer a quotient, now it's a limit:
$$\lim_{h\to0 }\frac{f(x+h)-f(x)}{h}.$$
And because we cannot express this limit-of-a-quotient as a-quotient-of-the-limits (both numerator and denominator go to zero), then the derivative is not a quotient.

However, Leibniz's notation is very suggestive and very useful; even though derivatives are not really quotients, in many ways they behave as if they were quotients. So we have the Chain Rule:
$$\frac{dy}{dx} = \frac{dy}{du}\;\frac{du}{dx}$$
which looks very natural if you think of the derivatives as "fractions". You have the Inverse Function theorem, which tells you that
$$\frac{dx}{dy} = \frac{1}{\quad\frac{dy}{dx}\quad},$$
which is again almost "obvious" if you think of the derivatives as fractions. So, because the notation is so nice and so suggestive, we keep the notation even though the notation no longer represents an actual quotient, it now represents a single limit.  In fact, Leibniz's notation is so good, so superior to the prime notation and to Newton's notation, that England fell behind all of Europe for centuries in mathematics and science because, due to the fight between Newton's and Leibniz's camp over who had invented Calculus and who stole it from whom (consensus is that they each discovered it independently), England's scientific establishment decided to ignore what was being done in Europe with Leibniz notation and stuck to Newton's... and got stuck in the mud in large part because of it.

(Differentials are part of this same issue: originally, $dy$ and $dx$ really did mean the same thing as those symbols do in $\frac{dy}{dx}$, but that leads to all sorts of logical problems, so they no longer mean the same thing, even though they behave as if they did.)

So, even though we write $\frac{dy}{dx}$ as if it were a fraction, and many computations look like we are working with it like a fraction, it isn't really a fraction (it just plays one on television). 

However... There is a way of getting around the logical difficulties with infinitesimals; this is called nonstandard analysis. It's pretty difficult to explain how one sets it up, but you can think of it as creating two classes of real numbers: the ones you are familiar with, that satisfy things like the Archimedean Property, the Supremum Property, and so on, and then you add another, separate class of real numbers that includes infinitesimals and a bunch of other things. If you do that, then you can, if you are careful, define derivatives exactly like Leibniz, in terms of infinitesimals and actual quotients; if you do that, then all the rules of Calculus that make use of $\frac{dy}{dx}$ as if it were a fraction are justified because, in that setting, it is a fraction. Still, one has to be careful because you have to keep infinitesimals and regular real numbers separate and not let them get confused, or you can run into some serious problems.
AnswerKenntnis:
Just to add some variety to the list of answers, I'm going to go against the grain here and say that you can, in an albeit silly way, interpret $dy/dx$ as a ratio of real numbers.

For every (differentiable) function $f$, we can define a function $df(x; dx)$ of two real variables $x$ and $dx$ via $$df(x; dx) = f'(x)\,dx.$$
Here, $dx$ is just a real number, and no more.  (In particular, it is not a differential 1-form, nor an infinitesimal.)  So, when $dx \neq 0$, we can write:
$$\frac{df(x;dx)}{dx} = f'(x).$$



All of this, however, should come with a few remarks.

It is clear that these notations above do not constitute a definition of the derivative of $f$.  Indeed, we needed to know what the derivative $f'$ meant before defining the function $df$.  So in some sense, it's just a clever choice of notation.

But if it's just a trick of notation, why do I mention it at all?  The reason is that in higher dimensions, the function $df(x;dx)$ actually becomes the focus of study, in part because it contains information about all the partial derivatives.

To be more concrete, for multivariable functions $f\colon R^n \to R$, we can define a function $df(x;dx)$ of two n-dimensional variables $x, dx \in R^n$ via
$$df(x;dx) = df(x_1,\ldots,x_n; dx_1, \ldots, dx_n) = \frac{\partial f}{\partial x_1}dx_1 + \ldots + \frac{\partial f}{\partial x_n}dx_n.$$

Notice that this map $df$ is linear in the variable $dx$.  That is, we can write:
$$df(x;dx) = (\frac{\partial f}{\partial x_1}, \ldots, \frac{\partial f}{\partial x_n})
\begin{pmatrix}
 dx_1 \\
 \vdots \\
 dx_n \\
\end{pmatrix}
= A(dx),$$
where $A$ is the $1\times n$ row matrix of partial derivatives.

In other words, the function $df(x;dx)$ can be thought of as a linear function of $dx$, whose matrix has variable coefficients (depending on $x$).

So for the $1$-dimensional case, what is really going on is a trick of dimension.  That is, we have the variable $1\times1$ matrix ($f'(x)$) acting on the vector $dx \in R^1$ -- and it just so happens that vectors in $R^1$ can be identified with scalars, and so can be divided.

Finally, I should mention that, as long as we are thinking of $dx$ as a real number, mathematicians multiply and divide by $dx$ all the time -- it's just that they'll usually use another notation.  The letter "$h$" is often used in this context, so we usually write $$f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h},$$
rather than, say,
$$f'(x) = \lim_{dx \to 0} \frac{f(x+dx) - f(x)}{dx}.$$
My guess is that the main aversion to writing $dx$ is that it conflicts with our notation for differential $1$-forms.

EDIT: Just to be even more technical, and at the risk of being confusing to some, we really shouldn't even be regarding $dx$ as an element of $R^n$, but rather as an element of the tangent space $T_xR^n$.  Again, it just so happens that we have a canonical identification between $T_xR^n$ and $R^n$ which makes all of the above okay, but I like distinction between tangent space and euclidean space because it highlights the different roles played by $x \in R^n$ and $dx \in T_xR^n$.
AnswerKenntnis:
My favorite "counterexample" to the derivative acting like a ratio: the implicit differentiation formula for two variables.  We have $$\frac{dy}{dx} = -\frac{\partial F/\partial x}{\partial F/\partial y} $$

The formula is almost what you would expect, except for that pesky minus sign.

See http://en.wikipedia.org/wiki/Implicit_differentiation#Formula_for_two_variables for the rigorous definition of this formula.
AnswerKenntnis:
It is best to think of "d/dx" as an operator which takes the derivative, with respect to x, of whatever expression follows.
AnswerKenntnis:
Typically, the $\frac{dy}{dx}$ notation is used to denote the derivative, which is defined as the limit we all know and love (see Arturo Magidin's answer). However, when working with differentials, one can interpret $\frac{dy}{dx}$ as a  genuine ratio of two fixed quantities. 

Draw a graph of some smooth function $f$ and its tangent line at $x=a$. Starting from the point $(a, f(a))$, move $dx$ units right along the tangent line (not along the graph of $f$). Let $dy$ be the corresponding change in $y$. 

So, we moved $dx$ units right, $dy$ units up, and stayed on the tangent line. Therefore the slope of the tangent line is exactly $\frac{dy}{dx}$. However, the slope of the tangent at $x=a$ is also given by $f'(a)$, hence the equation

$$\frac{dy}{dx} = f'(a)$$

holds when $dy$ and $dx$ are interpreted as fixed, finite changes in the two variables $x$ and $y$. In this context, we are not taking a limit on the left hand side of this equation, and $\frac{dy}{dx}$ is a genuine ratio of two fixed quantities. This is why we can then write $dy = f'(a) dx$.
AnswerKenntnis:
The notation $dy/dx$ - in elementary calculus - is simply that: notation to denote the derivative of, in this case, $y$ w.r.t. $x$. (In this case $f'(x)$ is another notation to express essentially the same thing, i.e. $df(x)/dx$ where $f(x)$ signifies the function $f$ w.r.t. the dependent variable $x$. According to what you've written above, $f(x)$ is the function which takes values in the target space  $y$).

Furthermore, by definition, $dy/dx$ at a specific point $x_0$ within the domain $x$ is the real number $L$, if it exists. Otherwise, if no such number exists, then the function $f(x)$ does not have a derivative at the point in question, (i.e. in our case $x_0$).

For further information you can read the Wikipedia article: http://en.wikipedia.org/wiki/Derivative
AnswerKenntnis:
It is not a ratio, just as $dx$ is not a product.
AnswerKenntnis:
To supplement Arturo Magidin's fine answer, I would note that in Leibniz's mathematics, if $y=x^2$ then $\frac{dy}{dx}$ would be "equal" to $2x$, but the meaning of "equality" to Leibniz was not the same as it is to us.  He emphasized repeatedly (for example in his 1695 response to Nieuwentijt) that he was working with a generalized notion of equality "up to" a negligible term. Also, Leibniz used several different pieces of notation for "equality".  One of them was the symbol "$\,{}_{\ulcorner\!\urcorner}\,$". To emphasize the point, one could write $$y=x^2\quad \rightarrow \quad \frac{dy}{dx}\,{}_{\ulcorner\!\urcorner}\,2x$$ where $\frac{dy}{dx}$ is literally a ratio. When one expresses Leibniz's insight in this fashion, one is less tempted to commit an ahistorical error of accusing him of having committed a logical inaccuracy.

In more detail, $\frac{dy}{dx}$ is a true ratio in the following sense.  We choose an infinitesimal $\Delta x$, and consider the corresponding $y$-increment $\Delta y = f(x+\Delta x)-f(x)$. The ratio $\frac{\Delta y}{\Delta x}$ is then infinitely close to the derivative $f'(x)$. We then set $dx=\Delta x$ and $dy=f'(x)dx$ so that $f'(x)=\frac{dy}{dx}$ by definition. One of the advantages of this approach is that one obtains an elegant proof of chain rule $\frac{dy}{dx}=\frac{dy}{du}\frac{du}{dx}$ by applying the standard part function to the equality $\frac{\Delta y}{\Delta x}=\frac{\Delta y}{\Delta u}\frac{\Delta u}{\Delta x}$.

In the real-based approach to the calculus, there are no infinitesimals and therefore it is impossible to interpret $\frac{dy}{dx}$ as a true ratio. Therefore claims to that effect have to be relativized modulo anti-infinitesimal foundational commitments.

Note 1. I recently noticed that Leibniz's $\,{}_{\ulcorner\!\urcorner}\,$ notation occurs several times in Margaret Baron's book The origins of infinitesimal calculus, starting on page 282. It's well worth a look.
AnswerKenntnis:
$\frac{dy}{dx}$ is not a ratio - it is a symbol used to represent a limit.
AnswerKenntnis:
In most formulations, $\frac{dx}{dy}$ can not be interpreted as a ratio, as $dx$ and $dy$ do not actually exist in them. An exception to this is shown in this book. How it works, as Arturo said, is we allow infinitesimals. It is well formulated, and I prefer it to limit notions, as this is how it was invented. Its just that they weren't able to formulate it correctly back then. I will give a slightly simplified example. Let us say you are differentiating $y=x^2$. Now let $dx$ be a miscellaneous infinitesimals (it is the same no matter which you choose if your function is differentiate-able at that point.) $$dy=(x+dx)^2-x^2$$
$$dy=2x*dx+dx^2$$
Now when we take the ratio, it is:
$$\frac{dx}{dy}=2x+dx$$

(Note:Actually,$\frac{\Delta x}{\Delta y}$ is what we found in the beginning, and $dy$ is defined so that $\frac{dy}{dx}$ is $\frac{\Delta x}{\Delta y}$ rounded to the nearest real.)
AnswerKenntnis:
Of course it is a ratio. 

$dy$ and $dx$ are differentials. Thus they act on tangent vectors, not on points. That is, they are functions on the tangent manifold that are linear on each fiber. On the tangent manifold the ratio of the two differentials $dy/dx$ is just a ratio of two functions and is constant on every fiber (except being ill defined on the zero section) Therefore it descends to a well defined function on the base manifold. We refer to that function as the derivative.

As pointed out in the original question many calculus one books these days even try to define differentials loosely and at least informally point out that for differentials $dy = f'(x) dx$ (Note that both sides of this equation act on vectors, not on points). Both $dy$ and $dx$ are perfectly well defined functions on vectors and their ratio is therefore a perfectly meaningful function on vectors. Since it is constant on fibers (minus the zero section), then that well defined ratio descends to a function on the original space.

At worst one could object that the ratio $dy/dx$ is not defined on the zero section.
AnswerKenntnis:
$\dfrac{dy}{dx}$ is definitely not a ratio - it is the limit (if it exists) of a ratio. This is Leibniz's notation of the derivative (c. 1670) which prevailed to the one of Newton $\dot{y}(x)$. 

Still, many Engineers and even Applied Mathematician use it as a ratio. The most common such use is when they solve ODEs of the form
$$
\frac{dy}{dx}=f(x)g(y),
$$
writing the above as
$$f(x)\,dx=\frac{dy}{g(y)},
$$
and then integrating. 

Apparently this is not Mathematics, it is a symbolic calculus, which often leads to the right solution, but not always. For example
applying this method to the IVP
$$
\frac{dy}{dx}=y+1, \quad y(0)=-1,\qquad (\star)
$$ 
we get, for some constant $c$,
$$
\ln (y+1)=\int\frac{dy}{y+1} = \int dx = x+c,
$$
equivalently
$$
y(x)=\mathrm{e}^{x+c}-1.
$$
Note that it is impossible to incorporate the initial condition $y(0)=-1$, as $\mathrm{e}^{x+c}$ never vanishes. By the way, the solution of $(\star)$ is $y(x)\equiv -1$.

In my opinion, Calculus should be taught rigorously, with $\delta$'s and $\varepsilon$'s. Once these are well understood, then one can use such symbolic calculus, provided that he/she is convinced under which restrictions it is indeed permitted.
AnswerKenntnis:
It may be of interest to record Russell's views of the matter:

Leibniz's belief tbat the Calculus had philosophical importance is now known to be erroneous: there are no infinitesimals in it, and dx and dy are not numerator and denominator of a fraction. (Russell, RECENT WORK ON THE PHILOSOPHY OF LEIBNIZ. Mind, 1903).
AnswerKenntnis:
Assuming you're happy with $dy/dx$, when it becomes $\ldots dy$  and $\ldots dx$ it means that it follows that what precedes $dy$ in terms of $y$ is equal to what precedes $dx$ in terms of $x$.

"in terms of" = "with reference to".

That is, if "$a \frac{dy}{dx} = b$", then it follows that "$a$ with reference to $y$ = $b$ with reference to $x$".  If the equation has all the terms with $y$ on the left and all with $x$ on the right, then you've got to a good place to continue.

The phrase "it follows that" means you haven't really moved $dx$ as in algebra. It now has a different meaning which is also true.
AnswerKenntnis:
I realize this is an old post, but I think its worth while to point on that in the so-called Quantum Calculus $\frac{dy}{dx}$ $is$ a ratio.  The subject $starts$ off immediately by saying this is a ratio, by defining differentials and then calling derivatives a ratio of differentials:

The $q-$differential is defined as 

$$d_q f(x) = f(qx) - f(x)$$

and the $h-$differential as
$$d_h f(x) = f(x+h) - f(x)$$

It follows that $d_q x = (q-1)x$ and $d_h x = h$. 

From here, we go on to define the $q-$derivative and $h-$derivative, respectively:

$$D_q f(x) = \frac{d_q f(x)}{d_q x} = \frac{f(qx) - f(x)}{(q-1)x}$$

$$D_h f(x) = \frac{d_h f(x)}{d_q x} = \frac{f(x+h) - f(x)}{h}$$

Notice that 

$$\lim_{q \to 1} D_q f(x) = \lim_{h\to 0} D_h f(x) = \frac{df(x)}{x} \neq \text{a ratio}$$
AnswerKenntnis:
Aanything that can be said in mathematics can be said in at least 3 different ways...all things about derivation/derivatives depend on the meaning that is attached to the word:TANGENT.
It is agreed that the derivative is the "gradient function" for tangents (at a point); and spatially (geometrically) the gradient of a tangent  is the "ratio" ( "fraction" would be better ) of the y-distance to the x-distance.
Similar obscurities occur when "spatial and algebraic" are notationally confused.. some pepople take the word "vector" to mean a track!
QuestionKenntnis:
Is this Batman equation for real?
qn_description:
HardOCP has an image with an equation which apparently draws the Batman logo.  Is this for real?
AnswersKenntnis
AnswerKenntnis:
As Willie Wong observed, including an expression of the form $\displaystyle \frac{|\alpha|}{\alpha}$ is a way of ensuring that $\alpha > 0$. (As $\sqrt{|\alpha|/\alpha}$ is $1$ if $\alpha > 0$ and non-real if $\alpha < 0$.)



The ellipse $\displaystyle \left( \frac{x}{7} \right)^{2} + \left( \frac{y}{3} \right)^{2} - 1 = 0$ looks like this:



So the curve $\left( \frac{x}{7} \right)^{2}\sqrt{\frac{\left| \left| x \right|-3 \right|}{\left| x \right|-3}} + \left( \frac{y}{3} \right)^{2}\sqrt{\frac{\left| y+3\frac{\sqrt{33}}{7} \right|}{y+3\frac{\sqrt{33}}{7}}} - 1 = 0$ is the above ellipse, in the region where $|x|>3$ and $y > -3\sqrt{33}/7$:



That's the first factor. 



The second factor is quite ingeniously done. The curve $\left| \frac{x}{2} \right|\; -\; \frac{\left( 3\sqrt{33}-7 \right)}{112}x^{2}\; -\; 3\; +\; \sqrt{1-\left( \left| \left| x \right|-2 \right|-1 \right)^{2}}-y=0$ looks like:



This is got by adding $y = \left| \frac{x}{2} \right| - \frac{\left( 3\sqrt{33}-7 \right)}{112}x^{2} - 3$, a parabola on the positive-x side, reflected:



and $y = \sqrt{1-\left( \left| \left| x \right|-2 \right|-1 \right)^{2}}$, the upper halves of the four circles $\left( \left| \left| x \right|-2 \right|-1 \right)^2 + y^2 = 1$:





The third factor $9\sqrt{\frac{\left( \left| \left( 1-\left| x \right| \right)\left( \left| x \right|-.75 \right) \right| \right)}{\left( 1-\left| x \right| \right)\left( \left| x \right|-.75 \right)}}\; -\; 8\left| x \right|\; -\; y\; =\; 0$ is just the pair of lines y = 9 - 8|x|:



truncated to the region $0.75 < |x| < 1$.



Similarly, the fourth factor $3\left| x \right|\; +\; .75\sqrt{\left( \frac{\left| \left( .75-\left| x \right| \right)\left( \left| x \right|-.5 \right) \right|}{\left( .75-\left| x \right| \right)\left( \left| x \right|-.5 \right)} \right)}\; -\; y\; =\; 0$ is the pair of lines $y = 3|x| + 0.75$:



truncated to the region $0.5 < |x| < 0.75$.



The fifth factor $2.25\sqrt{\frac{\left| \left( .5-x \right)\left( x+.5 \right) \right|}{\left( .5-x \right)\left( x+.5 \right)}}\; -\; y\; =\; 0$ is the line $y = 2.25$ truncated to $-0.5 < x < 0.5$.



Finally, $\frac{6\sqrt{10}}{7}\; +\; \left( 1.5\; -\; .5\left| x \right| \right)\; -\; \frac{\left( 6\sqrt{10} \right)}{14}\sqrt{4-\left( \left| x \right|-1 \right)^{2}}\; -\; y\; =\; 0$ looks like:



so the sixth factor $\frac{6\sqrt{10}}{7}\; +\; \left( 1.5\; -\; .5\left| x \right| \right)\sqrt{\frac{\left| \left| x \right|-1 \right|}{\left| x \right|-1}}\; -\; \frac{\left( 6\sqrt{10} \right)}{14}\sqrt{4-\left( \left| x \right|-1 \right)^{2}}\; -\; y\; =\; 0$ looks like





As a product of factors is $0$ iff any one of them is $0$, multiplying these six factors puts the curves together, giving: (the software, Grapher.app, chokes a bit on the third factor, and entirely on the fourth)
AnswerKenntnis:
You may be able to see more easily the correspondences between the equations and the graph through the following graph which is from the link I got after a curious search on Google:
AnswerKenntnis:
Here's what I got from the equation using Maple...
AnswerKenntnis:
Looking at the equation, it looks like it contains terms of the form 
$$ \sqrt{\frac{| |x| - 1 |}{|x| - 1}} $$
which evaluates to
$$\begin{cases} 1 & |x| > 1\\ i & |x| < 1\end{cases} $$

Since any non-zero real number $y$ cannot be equal to a purely imaginary non-zero number, the presence of that term is a way of writing a piece-wise defined function as a single expression. My guess is that if you try to plot this in $\mathbb{C}^2$ instead of $\mathbb{R}^2$ you will get all kinds of awful.
AnswerKenntnis:
In fact, the five linear pieces that consist the "head" (corresponding to the third, fourth, and fifth pieces in Shreevatsa's answer) can be expressed in a less complicated manner, like so:

$$y=\frac{\sqrt{\mathrm{sign}(1-|x|)}}{2}\left(3\left(\left|x-\frac12\right|+\left|x+\frac12\right|+6\right)-11\left(\left|x-\frac34\right|+\left|x+\frac34\right|\right)\right)$$

This can be derived by noting that the functions

$$\begin{cases}f(x)&\text{if }x<c\\g(x)&\text{if }c<x\end{cases}$$

and $f(x)+(g(x)-f(x))U(x-c)$ (where $U(x)$ is the unit step function) are equivalent, and using the "relation"

$$U(x)=\frac{x+|x|}{2x}$$



Note that the elliptic sections (both ends of the "wings", corresponding to the first piece in Shreevatsa's answer) were cut along the lines $y=-\frac37\left((2\sqrt{10}+\sqrt{33})|x|-8\sqrt{10}-3\sqrt{33}\right)$, so the elliptic potion can alternatively be expressed as

$$\left(\left(\frac{x}{7}\right)^2+\left(\frac{y}{3}\right)^2-1\right)\sqrt{\mathrm{sign}\left(y+\frac37\left((2\sqrt{10}+\sqrt{33})|x|-8\sqrt{10}-3\sqrt{33}\right)\right)}=0$$



Theoretically, since all you have are arcs of linear and quadratic curves, the chimera can be expressed parametrically using rational B-splines, but I'll leave that for someone else to explore...
AnswerKenntnis:
The following is what I got from the equations using MATLAB:




Here is the M-File (thanks to this link):

clf; clc; clear all; 
syms x y

eq1 = ((x/7)^2*sqrt(abs(abs(x)-3)/(abs(x)-3))+(y/3)^2*sqrt(abs(y+3/7*sqrt(33))/(y+3/7*sqrt(33)))-1);
eq2 = (abs(x/2)-((3*sqrt(33)-7)/112)*x^2-3+sqrt(1-(abs(abs(x)-2)-1)^2)-y);
eq3 = (9*sqrt(abs((abs(x)-1)*(abs(x)-.75))/((1-abs(x))*(abs(x)-.75)))-8*abs(x)-y);
eq4 = (3*abs(x)+.75*sqrt(abs((abs(x)-.75)*(abs(x)-.5))/((.75-abs(x))*(abs(x)-.5)))-y);
eq5 = (2.25*sqrt(abs((x-.5)*(x+.5))/((.5-x)*(.5+x)))-y);
eq6 = (6*sqrt(10)/7+(1.5-.5*abs(x))*sqrt(abs(abs(x)-1)/(abs(x)-1))-(6*sqrt(10)/14)*sqrt(4-(abs(x)-1)^2)-y);


axes('Xlim', [-7.25 7.25], 'Ylim', [-5 5]);
hold on

ezplot(eq1,[-8 8 -3*sqrt(33)/7 6-4*sqrt(33)/7]);
ezplot(eq2,[-4 4]);
ezplot(eq3,[-1 -0.75 -5 5]);
ezplot(eq3,[0.75 1 -5 5]);
ezplot(eq4,[-0.75 0.75 2.25 5]);
ezplot(eq5,[-0.5 0.5 -5 5]);
ezplot(eq6,[-3 -1 -5 5]);
ezplot(eq6,[1 3 -5 5]);
colormap([0 0 1])

title('Batman');
xlabel('');
ylabel('');
hold off
AnswerKenntnis:
Since people (not from this site, but still...) keep bugging me, and I am unable to edit my previous answer, here's Mathematica code for plotting this monster:

Plot[{With[{w = 3*Sqrt[1 - (x/7)^2], l = (6/7)*Sqrt[10] + (3 + x)/2 - (3/7)*Sqrt[10]*Sqrt[4 - (x + 1)^2], h = (1/2)*(3*(Abs[x - 1/2] + Abs[x + 1/2] + 6) - 11*(Abs[x - 3/4] + Abs[x + 3/4])), r = (6/7)*Sqrt[10] + (3 - x)/2 - (3/7)*Sqrt[10]*Sqrt[4 - (x - 1)^2]}, w + (l - w)*UnitStep[x + 3] + (h - l)*UnitStep[x + 1] + (r - h)*UnitStep[x - 1] + (w - r)*UnitStep[x - 3]], (1/2)*(3*Sqrt[1 - (x/7)^2] + Sqrt[1 - (Abs[Abs[x] - 2] - 1)^2] + Abs[x/2] - ((3*Sqrt[33] - 7)/112)*x^2 - 3)*((x + 4)/Abs[x + 4] - (x - 4)/Abs[x - 4]) - 3*Sqrt[1 - (x/7)^2]}, {x, -7, 7}, AspectRatio -> Automatic, Axes -> None, Frame -> True, PlotStyle -> GrayLevel[0]]

This should work even for versions that do not have the Piecewise[] construct. Enjoy. :P
AnswerKenntnis:
Here's the equations typed out if you want save time with writing it yourself.

(x/7)^2*SQRT(ABS(ABS(x)-3)/(ABS(x)-3))+(y/3)^2\*SQRT(ABS(y+3*SQRT(33)/7)/(y+3*SQRT(33)/7))-1=0
ABS(x/2)-((3*SQRT(33)-7)/112)*x^2-3+SQRT(1-(ABS(ABS(x)-2)-1)^2)-y=0
9*SQRT(ABS((ABS(x)-1)*(ABS(x)-0.75))/((1-ABS(x))*(ABS(x)-0.75)))-8*ABS(x)-y=0
3*ABS(x)+0.75*SQRT(ABS((ABS(x)-0.75)*(ABS(x)-0.5))/((0.75-ABS(x))*(ABS(x)-0.5)))-y=0
2.25*SQRT(ABS((x-0.5)*(x+0.5))/((0.5-x)*(0.5+x)))-y=0
(6*SQRT(10))/7+(1.5-0.5*ABS(x))*SQRT(ABS(ABS(x)-1)/(ABS(x)-1))-((6*SQRT(10))/14)*SQRT(4-(ABS(x)-1)^2)-y=0


Also: http://pastebin.com/x9T3DSDp
AnswerKenntnis:
The 'Batman equation' above relies on an artifact of the plotting software used which blithely ignores the fact that the value $\sqrt{\frac{|x|}{x}}$ is undefined when $x=0$. Indeed, since weΓÇÖre dealing with real numbers, this value is really only defined when $x>0$. It seems a little ΓÇÿsneakyΓÇÖ to rely on the solver to ignore complex values and also to conveniently ignore undefined values.

A nicer solution would be one that is unequivocally defined everywhere (in the real, as opposed to complex, world). Furthermore, a nice solution would be ΓÇÿrobustΓÇÖ in that small variations (such as those arising from, say, roundoff) would perturb the solution slightly (as opposed to eliminating large chunks).

Try the following in Maxima (actually wxmaxima) which is free. The resulting plot is not quite as nice as the plot above (the lines around the head donΓÇÖt have that nice ΓÇÿstraight lineΓÇÖ look), but seems more ΓÇÿlegitimateΓÇÖ to me (in that any reasonable solver should plot a similar shape). Please excuse the code mess.

/* [wxMaxima batch file version 1] [ DO NOT EDIT BY HAND! ]*/
/* [ Created with wxMaxima version 0.8.5 ] */

/* [wxMaxima: input   start ] */
load(draw);
/* [wxMaxima: input   end   ] */

/* [wxMaxima: input   start ] */
f(a,b,x,y):=a*x^2+b*y^2;
/* [wxMaxima: input   end   ] */

/* [wxMaxima: input   start ] */
c1:sqrt(26);
/* [wxMaxima: input   end   ] */

/* [wxMaxima: input   start ] */
draw2d(implicit(
f(1/36,1/9,x,y)
+max(0,2-f(1.5,1,x+3,y+2.7))
+max(0,2-f(1.5,1,x-3,y+2.7))
+max(0,2-f(1.9,1/1.7,(5*(x+1)+(y+3.5))/c1,(-(x+1)+5*(y+3.5))/c1))
+max(0,2-f(1.9,1/1.7,(5*(x-1)-(y+3.5))/c1,((x-1)+5*(y+3.5))/c1))
+max(0,2-((1.1*(x-2))^4-(y-2.1)))
+max(0,2-((1.1*(x+2))^4-(y-2.1)))
+max(0,2-((1.5*x)^8-(y-3.5)))
-1,
x,-6,6,y,-4,4));
/* [wxMaxima: input   end   ] */

/* Maxima can't load/batch files which end with a comment! */
"Created with wxMaxima"$


The resulting plot is:


(Note that this is, more or less, a copy of the entry I made on http://blog.makezine.com.)
AnswerKenntnis:
Sorry but this is not the answer but too long for a comment:
Probably the easiest verification is to type the equation on Google you'l be surprised :
The easiest way is to Google :2 sqrt(-abs(abs(x)-1)abs(3-abs(x))/((abs(x)-1)(3-abs(x))))(1+abs(abs(x)-3)/(abs(x)-3))sqrt(1-(x/7)^2)+(5+0.97(abs(x-.5)+abs(x+.5))-3(abs(x-.75)+abs(x+.75)))(1+abs(1-abs(x))/(1-abs(x))),-3sqrt(1-(x/7)^2)sqrt(abs(abs(x)-4)/(abs(x)-4)),abs(x/2)-0.0913722(x^2)-3+sqrt(1-(abs(abs(x)-2)-1)^2),(2.71052+(1.5-.5abs(x))-1.35526sqrt(4-(abs(x)-1)^2))sqrt(abs(abs(x)-1)/(abs(x)-1))+0.9
QuestionKenntnis:
How to study math to really understand it and have a healthy lifestyle with free time?
qn_description:
Here's my problem. I'm studying math and when I really work hard, I think I understand things very good, but that comes at a big cost: in the last few years, I've had practically zero physical exercise, I've gained 30 kg, I've spent countless hours studying at night, constantly had sleep deprivation, I've lost my social life, and I got health problems. My grades are quite good, but I feel as though I'm wasting my life.

I love mathematics when it's done my way, but that's hardly ever. I would very much like my career to be centered around mathematics (topology, algebra or something similar). I want to really understand things and I want the proofs to be done in a (reasonably) rigorous way. I've been accused of being a formalist before, but I don't consider myself one at all. However, I am a perfectionist, I admit. For comparison, the answers of Theo, Arturo, Jim Belk, Mariano, etc. are absolutely rigorous enough for me. From my experience, 80% or more mathematics in our school is done in a sketchy, "hmm, probably true" kind of way (just like reading cooking recipes), which bugs the hell out of me. Most classmates adapt to it. I for some reason can't. I don't understand things until I understand them (almost) completely. They learn "how one should do things", but less often do they ask themselves WHY is this correct. I have two friend physicists, who have the exact same problem. One is at the doctorate level, constantly frustrated, while the other abandoned physics altogether after getting a diploma. Apart from one 8, he had a perfect record, only 10s. He said that he doesn't feel he understands physics well enough. From my experience, ALL his classmates understand less than he does, they just go with the flow and accept certain statements as true.

Also, my problem is having weak memory. I forget a lot. Having to study a different subject each day is killing me. If it were up to me, I'd change the way lectures are done. We'd study only ONE subject for a month or two, then have the exams, and the next month or two the next subject. Mixing it up has a terrible effect: I forget things, because I constantly change the topic. That's why I'm always behind schedual. For example, in the second year, during the school year, I understood almost nothing of multivariable calculus, because I had to simultaneously study abstract algebra, topology, computer programming, etc, and couldn't keep up. But then, I devoted the whole three months of summer and got through all 330 pages of theory, understood it very good, including all the proofs ( which I was forgetting along the way), got a 9/10 grade, and had absolutely no vacations (stayed at home), no free time, no sport, no nothing. It was complete crap.


should I not read the proofs at all?
should I try less hard, get worse grades and understanding, and 'have a life'?
abandon the idea of doing math for a living?
how can I spot the important/illustrative proofs, without studying them completely (it often happens, that I 'get the whole point' only after I've understood the whole proof)


I'm not gifted/bright at all, I'm completely average with a bad memory, but I do have interest in math, good grades, and a horrible lifestyle for the last few years. This question is directed at people who have a career doing mathematics. How did you manage to study everything on time, AND sufficiently rigorous, that you were able to understand it?

ADDITIONS:

I often tend to be the only one to find serious issues in the proofs, in the formulations of theorems, and also in the worked out exercises at classes. Everyone else either understands everything/most, or doesn't understand and also doesn't care for possible issues. Often do I find holes in the proofs and that hypotheses are missing in the theorem. When I present them to the professor, he says that I'm right, and says that I'm very precise. How is this precise, when the theorem doesn't hold in it's current state. Are we even supposed to understand proofs. Are the proofs actually really just sketches? How on earth is one then supposed to be able to discover mathematical truths? Is the study of mathematics just one big joke and you're not supposed to take it too seriously?

NOTE:

I have a bunch of sports I like and used to do. Also, I had a perfectly good social life before, so you don't need to give advice regarding that. I don't socialize and do sport because digesting proofs and trying to understand the ideas behind it all eats up all my time. If I go hiking, it will take away 2 days, 1 to actually walk + 1 to rest and regenerate. If I go train MMA, I won't be focused for the whole day. I can't just switch from boxing to diagram chasing in a moment. Also, I can't just study for half an hour. The way I study is I open the book, search up what I already know but forgot from the previous day, and then go from theorem to theorem, from proof to proof, correcting mistakes, adding clarifications, etc. etc. Also, I have a bad habit of having difficulty starting things, but when I do start 'my engine', I have difficulty stopping, especially if it's going good. That's why I unintentionally spend an hour or two before studying just doing the most irrelevant stuff, just to avoid study. This happens especially when I've had more math than I can shove down my throat, I have mental preparations to begin studying. But when my engine does start and studying goes well (proven a lot, understood a lot), it's hard for me to stop, so I often stay late at night, up to 4 a.m., 5 a.m., 6 a.m. When the day of the exam arrives, I don't go to sleep at all, and the night and day are reversed. I go to sleep at 13h, and wake at 21h... I know it's not good but I can't seem to break this habit. If I'm useless through the whole day, I feel a need (guilty conscience) to do at least smth. useful before I go to sleep. I know this isn't supposed to happen if one loves mathematics, but when it's 'forced upon you' what and how much and in what amount of time you have to study, you start being put off by math. It stops being enjoyment/fun and becomes hard work that just needs to be done.
AnswersKenntnis
AnswerKenntnis:
In my view the central question that you should ask yourself is what is the end goal of your studies. As an example, American college life as depicted in film is hedonistic and certainly not centered on actual studies. Your example is the complete opposite - you describe yourself as an ascetic devoted to scholarship.

Many people consider it important to lead a balanced life. If such a person were confronted with your situation, they might look for some compromise, for example investing fewer time on studies in return for lower grades. If things don't work out, they might consider opting out of the entire enterprise. Your viewpoint might be different - for you the most important dimension is intellectual growth, and you are ready to sacrifice all for its sake.

It has been mentioned in another answer that leading a healthy lifestyle might contribute to your studies. People tend to "burn out" if they work too hard. I have known such people, and they had to periodically "cool off" in some far-off place. On the contrary, non-curricular activities can be invigorating and refreshing.

Another, similar aspect is that of "being busy". Some people find that by multitasking they become more productive in each of their individual "fronts". But that style of life is not for every one.

Returning to my original point, what do you expect to accomplish by being successful in school? Are you aiming at an academic career? Professional career? In North America higher education has become a rite of passage, which many graduates find very problematic for the cost it incurs. For them the issue is often economical - education is expensive in North America.

You might find out that having completed your studies, you must turn your life to some very different track. You may come to realize that you have wasted some best years of your life by studying hard to the exclusion of everything else, an effort which would eventually lead you nowhere. This is the worst-case scenario.

More concretely, I suggest that you plan ahead and consider whether the cost is worth it. That requires both an earnest assessment of your own worth, and some speculation of the future job market. You should also estimate how important you are going to consider these present studies in your future - both from the economical and the "cultural" perspective.

This all might sound discouraging, but your situation as your describe it is quite miserable. Not only are you not satisfied with it, but it also looks problematic for an outside observer. However, I suspect that you're exaggerating, viewing the situation from a romantic, heroic perspective. It's best therefore to talk to people who know you personally.

Even better, talk to people who're older than you and in the next stage of "life". They have a wider perspective on your situation, which they of their acquaintances have just still vividly recall. However, even their recommendations must be taken with a grain of salt, since their present worries are only part of the larger picture, the all-encompassing "life".



Finally, a few words more pertinent to the subject at hand.

First, learning strategy. I think the best way to learn is to solve challenging exercises. The advice given here, trying to "reconstruct" the textbook before reading it, seems very time consuming, and in my view, concentrating the effort at the wrong place

The same goes for memorizing theorems - sometimes one can only really "understand" the proof of a theorem by studying a more advanced topic. Even the researcher who originally came out with the proof probably didn't "really" understand it until a larger perspective was developed.

Memorizing theorems is not your choice but rather a necessity. I always disliked regurgitation and it is regrettable that this is forced unto you. I'm glad that my school would instead give us actual problems to solve - that's much closer to research anyway. Since you have to go through this lamentable process, try to come up with a method of memorization which has other benefits as well - perhaps aim at a better understanding of "what is going on" rather than the actual steps themselves. This is an important skill.

Second, one of the answers suggests trying to deduce as many theorems as possible as the "mathematical" thing that ought to be done after seeing a definition. I would suggest rather the opposite - first find out what the definition entails, and then try to understand why the concept was defined in the first place, and why in that particular way.

It is common in mathematics to start studying a subject with a long list of "important definitions", which have no import at all at that stage. You will have understood the subject when you can explain where these definitions are coming from, what objects they describe; and when you can "feel" these objects intuitively. This is a far cry from being able to deduce some facts that follow more-or-less directly from the definitions.
AnswerKenntnis:
Let me tell you that the only thing that I have been doing for the last four years of my life is mathematics. I have enjoyed the experience thoroughly but I have also had points where I was somewhat unsure as to how to approach my learning. I think that there is no one rule that works for everyone; however, let me answer some of your questions. I hope that I can help:


  Question: How to study mathematics the
  right way?
  
  Answer: I think that the best way to
  study mathematics is as follows. Let
  us assume that you have already chosen
  a mathematics book on a subject that
  you are really interested to learn.
  When you read the book, aim to
  actively think about the subject
  matter in different ways. For example,
  if a definition is presented, spend at
  least 30 minutes to think about the
  definition. If you are studying a book
  on linear algebra and the definition
  of a "nilpotent operator" is
  presented, you should try to discover
  some basic properties about nilpotent
  operators on your own without reading
  further. This can be difficult at
  first but ultimately an ability to do
  this effectively with as many
  definitions as possible is important
  in research mathematics.
  
  Let us take the following example in
  elementary group theory. The author
  presents the definition of a maximal
  subgroup of a finite group $G$: a
  subgroup $M$ of $G$ is said to be a
  maximal subgroup if $M$ is a proper
  subgroup of $G$ and if there are no
  proper subgroups of $G$ strictly
  containing $M$. You should try to take
  the following steps:
  
  (1) Find examples of maximal subgroups
  in finite groups and begin with the
  most trivial examples! For example,
  the trivial group can have no maximal
  subgroup. If you understand this, you
  have grasped one point of the
  definition. The next step is to
  consider the simplest cyclic groups.
  What are the maximal subgroup(s) of
  the cyclic group of order 2? What are
  the maximal subgroup(s) of the cyclic
  group of order 4? Think about basic
  examples such as this one. When you
  are ready, try to formulate a general
  theorem on your own which concerns
  maximal subgroups of a cyclic group of
  order $n$. You should arrive at the
  theorem that a subgroup $H$ of a
  cyclic group $G$ is maximal if and
  only if the number
  $\frac{\left|G\right|}{\left|H\right|}$
  is prime. 
  
  Continue to find other examples of
  maximal subgroups in a finite group.
  The next step is to consider the Klein
  4-group and the permutation groups of
  low orders. I hope at this point you
  are really fascinated by the concept
  of a maximal subgroup. At first, the
  definition might seem like something
  arbitrary; however, now that you have
  thought about it, you have started to
  gain a sense of "ownership" over the
  definition.
  
  (2) It is now time to formulate and
  prove some theorems about maximal
  subgroups. Again, think of the
  easiest examples. One thing that can be discouraging for a beginner is
  to not be able to answer a question
  that looks easy over a long period of
  time. What is a good example of an
  easy theorem? You can study those
  finite groups which have exactly one
  maximal subgroup. What can you deduce
  about such a group? If you find that
  you are stuck, try to work back to the
  examples of maximal subgroups that you
  devised earlier. In fact, this
  question can be answered quite
  satisfactorily; a finite group with a
  unique maximal subgroup is cyclic of
  prime power order.
  
  (3) The next step is to conjecture
  some more properties about maximal
  subgroups based on the examples you
  devised in (1). For example, you
  worked out that if $H$ is a maximal
  subgroup of a finite cyclic group $G$,
  then
  $\frac{\left|G\right|}{\left|H\right|}$
  is a prime number. Is this true for
  all groups $G$? Can you think of
  groups $G$ for which this is true? 
  
  Notice how one can deconstruct a
  simple definition to arrive at a host
  of interesting questions? This is what
  a mathematician does all the time and
  is a very important skill. It might
  seem difficult at first but doing this
  will make mathematics all the more
  exciting and will give you a sense of
  "ownership" over the content. You
  worked out this piece of mathematics.
  This is the way I learn mathematics
  and I can tell you with confidence
  that if you practice this, it will
  soon become the norm.
  
  What do you do after you look at the
  definition and have thought about it
  extensively? You continue reading the
  text. There is a good chance that you
  will notice the author stating some of
  the results that you discovered on
  your own. With luck, there will be
  results that the author has not
  stated. If this is the case, it could
  be a good idea to ask (on this
  website, for example) about the
  originality of the result. 
  
  However, you will encounter theorems
  concerning the definitions that you
  simply did not think about. You should
  resist the temptation to see the
  proofs of these theorems and rather
  you should try to prove these theorems
  on your own. Think about the theorem
  for at least a few hours before giving
  up. Note that theorems with quite
  short proofs can require highly
  original ideas and therefore you
  should not pressure yourself to prove
  the theorem in a small amount of time.
  
  At first, you will take a long time to
  prove some theorems. There will be
  routine theorems and these should be
  proven fairly quickly. But there will
  also be difficult theorems. As you
  become experienced, your thinking will
  be faster and these theorems will come
  more easily to you. However, you
  should not expect this to be the case
  initially. 
  
  For example, you might encounter the
  following theorem in linear algebra:
  if $N$ is a nilpotent linear
  transformation from a vector space $V$
  to itself and if the dimension of $V$
  is $n$, then $N^n=0$. Working out how
  to prove this theorem on your own is a
  very valuable and rewarding
  experience. If you have not seen it
  already, I suggest that you try to
  prove it. It is not too difficult,
  however.
  
  Question: How to avoid forgetting mathematics?
  
  Answer: I used to forget mathematics too when I learnt it. I
  have talked to various mathematicians
  about this and they have said exactly
  the same thing. The point is that you
  just have to accept from the start
  that you will forget what you learn.
  However, there are ways to ensure that
  you keep this to a minimum. 
  
  For example, the best way to not worry
  too much about forgetting mathematics
  is to work out the mathematics on your
  own. For example, consider the steps
  that I suggested in the previous
  question. Even if you do this, you can
  still forget the mathematics,
  especially if the result in question
  was fairly easy to prove. (Note,
  however, that if the result is hard to
  prove, and you spend, let us assume,
  10 hours to prove it, then you will
  probably never forget it for the rest
  of your life.) 
  
  The best method to take is to write
  down all the mathematics that you
  learn. Take copious notes. For
  example, when I read Walter Rudin's
  "Real and Complex Analysis" last year,
  I took down 3 entire books of notes.
  In fact, I wrote down 600 pages of
  mathematics when I only read 315
  pages!
  
  Write down every definition, every
  theorem, and every proof. The
  definitions and theorems should be
  produced verbatim from the book since
  it is important to ensure that
  your understanding of the rigor is
  correct. However, the proofs should be
  written in your own words.
  
  Question: How to have a healthy lifestyle?
  
  Answer: I am afraid I really do not have a good answer for this. In
  the four years that I have been
  studying mathematics, I have certainly
  not done anything else. Therefore, I
  cannot really give advice on how to
  manage one's time. If you are a
  serious student in mathematics, you
  will find yourself spending virtually
  your entire day doing the subject.
  This is inevitable. For example, I set
  myself goals every day of how much
  mathematics I wish to do and usually I
  end up doing mathematics non-stop.
  Nonetheless, I really enjoy this and I
  would not wish to have it any other
  way. 
  
  But I can offer one small piece of
  advice: try to wake up early, let us
  assume, at 6:00 AM. However, do ensure
  that you sleep for at least 8 hours;
  therefore, go to bed at 9:00 PM. Sleep
  is one of the most important points
  when it comes to studying. Over many
  years of doing mathematics, I have
  found that I am most productive and
  energetic before 12:00. If you can
  finish off most of your work before
  12:00, then you will be in a really
  good position to do well each day.
  Also, try to avoid eating big meals.
  Big meals often cause you to lose your
  concentration and this can, in turn,
  lead to several wasted hours. 
  
  I think the most important point when
  you set out to achieve any goal in
  your life is to take it day by day,
  hour by hour, even minute by minute.
  Often you can complicate goals too
  much by thinking of what you would
  like to do over the next 1 year or
  even one month. If you work hard each
  and every day and set realistic goals,
  then anything should be possible.


I hope that I have helped! (I hope that my usage of bold text is not considered offensive; I simply used it to highlight some of the key points in my answer.)

Disclaimer (Dec. 25, 2013): This answer was written when I was 16 years old and does not necessarily represent my current views of mathematics. (Some points, e.g., "write down all of the mathematics you learn" is not something I would recommend to anyone today.) But I leave my answer here because I think it is overall reasonable advice and has clearly been useful to many people as is evidenced by the 77 upvotes.
AnswerKenntnis:
Most people probably won't like this answer, but mathematics is a field where there's an unstable separation between those of genius caliber understanding and those who are just able to get by through dogged hard work. Way too many people want to do proofs and aesthetically pleasing artful mathematics for a career who are in the dogged-hard-work category. I am speaking as someone who has worked myself to death over the past 3 years to hack it in an Ivy League Ph.D. program in applied mathematics. Next to my peers, the only advantage I have is that I am able to work much harder, and to some extent I am much better at writing software. In terms of mathematical prowess, they all dominate me.

If, as you admit, you are average with a bad memory (aside from your obviously above average tolerance for difficult technical work), then you need to consider that an actual career in pure mathematics is not right for you. I want to be careful to avoid other-optimizing so please take my advice with a grain of salt. It may not be right for you, and surely all of the other commenters have insightful advice as well. But one thing that I think will never work for you is to just "try to exercise, eat right, and have a balanced life." Whatever others say, this will not happen for a pure mathematician who has really good taste in the aesthetic beauty of results, unless that mathematician really is at the genius level.

You have a limited talent supply and a limited time budget. Your personal forecast that you'll enjoy a career in abstract mathematics is almost surely incorrect; you seem to undervalue important things like salary, competitiveness for tenure, geographic preferences, etc. 

For example, I have a close friend who studied very pure aspects of cryptographic number theory. He did two post-docs and earned practically no money at all, sacrificed personal relationships to try to get tenure track faculty positions, and ultimately found no jobs doing pure math. He took a job as a programmer for a company that makes cryptographic software. He thought that at least some of his time would go to researching new asbtract ideas in cryptography, but it turned out not to be true. Instead, he writes Java programs most of the time, learns about new applied cryptographic research, and writes very little (though he still dabbles in research in personal time and is, in my view, far more educated about cryptographic research than most people who currently publish in that field).

Is he unhappy in this situation? No! Actually, he discovered that to do software design properly, virtually everything is all about understanding the right abstraction, the right data encapsulation, the right design pattern, and this not only has great mathematical aesthetic value, but also delivers a better product to a client. After acclimating to professional software development, he now sees all sorts of parallels between his former work coming up with abstract math ideas and his current job coming up with abstract software solutions. His skills set now has a far higher economic demand, he isn't pressured to compete for tenured positions, and he's able to keep a very healthy work/life balance because of his company's regular work schedule.

I would say that, just as so many small businesses fail, far too many bright-eyed grad students see themselves as the next Godel, gung-ho for tenured positions and "living the life of the mind." They are especially prone to do what you are doing and to let the rest of their lives deteriorate in the hopes of being able to pursue what they currently (probably mistakenly) think is their own preference for abstract beauty that can only be satiated (also a mistake) by generalized math. Many more of these people should own up to the fact that they are not talented enough, and that universities that have to dedicate an ever slimming number of resources to hiring the best tenured faculty shouldn't really hire them.

Here are a few links to consider:


The Disposable Academic
Why post-docs are replacing principle investigators


The economics also matter. Tenure is greatly diminishing in many parts of academia, and math faculty are especially notorious because pure math doesn't bring in grant money the way applied projects do. With the advent of online courses and open courseware, and sites like Stack Exchange, the need for highly specialized math teachers is diminishing at the university level. You should expect competition for tenured jobs to tighten, and that if you want a tenured job you'll have to go anywhere that offers them, even if this is a small regional university that is nowhere near any major city, has no real cultural atmosphere, and doesn't attract gifted students. It would be a big mistake to fail to take this into account.

My advice to you is this. Think hard about what it is specifically that you enjoy about mathematics. If you like the abstractions and geometrical thinking that are often part of advanced analysis and topology, then there are many applied mathematics / applied physics / engineering career routes that will offer you the chance to explore math questions, but will also put that geometrical abstraction ability to work writing software to solve actual problems. Your familiarity with pure mathematics may give you a career edge if you switch to a field like this. You might be situated to compete more effectively for grants and faculty jobs if that is what you want, and to the extent that you master programming skills, you'll have marketable skills to get different jobs if the need arises.

If you prefer the more abstract thinking that often accompanies algebra and number theory (that is, if you are a "problem solver" type of pure mathematician according to Timothy Gowers' definition (see here for my take on that if interested)), then I think you will find a lot to enjoy about software design. You may be better served by focusing on abstract problems in computer science and software engineering.

If you read a good math history book (e.g. Stillwell), you'll notice that (a) most good abstract math begins by being some sort of ad hoc, "it's probably true but I can't see the details" intuition anyway and it only gets refined later; and (b) most awesome stuff invented in mathematics was not invented by people who thought that mathematics was the way they needed to earn a living. People have been driving themselves mad over solving math problems for millennia, staying up late into the night, leading destructive romantic lives, falling into ill health. If you really love math, you'll never be happy doing it in the half-assed way that a healthy work-life balance requires, and very few people are truly capable of sustaining a career like that. Most ultimately stop trying hard on the math part and become dissatisfied with their careers.

Earning a living by being a pure mathematician is a very modern concept that arose largely because of the implications of Lebesgue integration in analysis and computability theory in computer science. And now that we have enough of a handle on those fields and their subsequent children, there just isn't enough stuff to support a lot of career mathematicians. Almost surely, significant mathematical advances in the next 50 years are going to come from highly intelligent, dedicated hobbyists, who solve problems at places like Stack Exchange or polymath.

And there's no reason why you can't find some niche problems that you like to work on, do so in your free time, and meanwhile have a fulfilling and economically sensible career that affords you a more comfortable life. For as obviously smart as you are, it would not be wise to fail to consider this sort of thing in your youth. Many more math students should do so as well. 

In fact, the really egregiously unfair underfunding of students and inflation of post-doc positions largely comes about because naive youngsters who think they will automatically get tenure if they just try hard, and who think that nerdy love for aesthetic science is a good thing to base a career choice on, seem to unquestioningly accept underpaid and under-insured academic positions with no question. Trust me, you don't want to just be another one of those folks.
AnswerKenntnis:
Regarding the "and have a healthy lifestyle" thing.  Well, you also have to learn when to stop.  

Sometimes you figure out you don't understand something and you don't have time right then to understand it.  Try to "box" that as much as possible.  Figure out the general form of the kind of thing you don't understand.  How does it function?  What context is this idea used in?  What kinds of "inputs" does it have?  Does something appear as if by magic?  What?  Have you ever seen anything like that before?  If you keep these vague ideas in mind, you may very well figure it out in your sleep, in a conversation with someone, maybe weeks later, maybe years.  It depends on the particular thing. 

Sometimes you don't understand something because that thing is complete nonsense.  Profs sometimes say nonsense -- they're human beings and make mistakes.   Books make mistakes.   I remember spending a lot of time trying to complete a proof for a homework problem and everything I tried failed.  An hour before the homework was due I was talking with someone else in class.  He showed me an example he cooked up to demonstrate the theorem and I reinterpreted it as an example that disproved the theorem.   These things happen.  Similarly, plenty of textbooks have subtle "lazy" errors in them.  If you're not particularly confident in yourself you may spend hours being frustrated on such a problem.  Talk with people.
AnswerKenntnis:
Some very basic non mathematical advice and I'm sorry if I sound like your mother.  If you feel like your memory is bad and you're not finding enough time to socialise, perhaps you're not finding enough time to eat well.  Eating plenty of fresh fruit, fresh vegetables, fresh fish, olive oil and cereals will give your body the building blocks to do its best .  Oily fish in particular are known to be good for the brain.  http://www.newscientist.com/article/mg20827801.300-mental-muscle-six-ways-to-boost-your-brain.html

I find that the time I spend cooking / washing up is pleasurable mentally relaxing down time during which some of my best ideas come.  Perhaps you could combine this with a social aspect and invite people round to tea if you're cooking something nice.  Avoid the alcohol that usually goes with these situations if you're intending to get back to work after.
AnswerKenntnis:
On studying math:

Your time on this rock is finite, the amount of mathematical knowledge is infinite. You must choose wisely about what you want to spend your time learning. Decide if you want to be a "jack of all, master of none" or "a master of one, jack of none" type. 

Personally, I'd rather know a lot about everything than everything about one thing, thus I'd say don't waste your time learning every single detail. Appreciate the high level material, move on to the next field until you run out of fields. Then, work your way down to lower level material as your time allows.

Your learning doesn't stop once you complete your degree(s). Learn to pace yourself.

On the healthy lifestyle side of things:

The mind can only be as sharp as the body. Make the time to exercise, eat right and get enough sleep. You will find that you think more clearly, you retain information more effectively and that you are happier.

Balance is critically important. You get but one life to live and there is far more to it than mathematics. Take the time to explore other interests, discover new ones and become more well rounded. The greater your overall knowledge, the better you will be at math.

Live life. Socialize, fall in love, run a marathon, get into a fight, go to the ballet, paint a masterpiece, go fishing, explore the world; do the things that make you more than just a mathematician, do the things that make you a person.
AnswerKenntnis:
I can see that this question is a couple of month old, but I would like to add some remarks:

1) Most research mathematicians have a better memory and are quicker than what you describe. There are notable exceptions, but you have to understand that it will be hard to compete. You will always have to work harder than most of your peers. If it takes you three times as long to correct exams, then this time will be missing from your research even though you might be just as talented for actual research. On the other hand, don't trust your fellow students when they just say that they understand things and are quick. In many places, it is cool to claim to have aced the exam with little study time. In the long run, you might overtake some of the people who know how to learn just for an exam.

2) Of your peer group, a very small percentage will become researchers. There is no point in comparing yourself to people who efficiently pass the exams if you want to become a researcher. Seek out good, ambitious students and socialise with them. If they are quicker and have a better memory than you, then ask them what is wrong with Lemma 3.4 whose proof seems somehow strange to you. There is no point in finding all stupid errors yourself. Ask your peers, ask your professors, ask here. You are wasting time if it takes you three hours to find out that the professor wrote "c" instead of "e".

3) If you concentrate too much on details, you have to train summaries. Can you explain to a very talented beginner student what they will learn in linear algebra and analysis? In 10 sentences? In a couple of minutes? In a couple of hours? Without paper?
When I need a result from a lecture that I heard as a student 15 years ago, I don't need to remember the conditions in the theorem. I need to realize that this theorem is probably applicable to my problem, in which lecture or book I saw it and then I can look it up to check whether there was some technical condition I forgot.
To do so, I have to remember the gist of the theorem and the proof, not the details.
Also, if you don't understand something during learning, preliminarily accept the result, continue and return to the result later, don't brood on one thing indefinitely.

4) Usually, the gist is something professors like to hear during an oral exam. They will check the details here or there, but they don't need to hear the gritty details all the time. Are you sure that you are acutally speaking at the expected level of detail during your oral exams? Or are you just assuming that the professor wants to hear all details and start right away at the epsilon level? Have you ever tried to sit in on other students exams?

5) Seek out younger students and help them preparing for their exams (or answer questions here). Helping others is the best method to keep your acquired knowledge fresh. This will not be wasted time.

6) You should absolutely not sacrifice your physical and mental health. Sleep, food, exercice, social life and hobbies are important and should not be neglected for an extended time period.
Is it not possible to just take fewer lectures per semester? Who will care later if it takes you a year longer to finish?
Something has to give, and it seems to me that the easiest thing for you is to just spread the work over more time. (And yes, I do realise that even without tuition there are high opportunity costs, but you seem to need more time now.)
AnswerKenntnis:
Being in good physical shape, makes your head clearer.
Besides, you only need one hour of exercise a day to keep in decent shape.
Do some multitasking! Walking and thinking can be done at the same time,
you train your memory, AND your stamina. 

Solving math problems in your head is a good mental exercise.
AnswerKenntnis:
I am an undergraduate at an American university going through almost exactly what you're describing... the lack of sleep, lack of social life, weak memory for proofs, and a perfectionist insistence that mathematics be presented "my way."  Like I say, I'm currently going through this, so I can't offer any answers.  I do, however, have some suggestions from experience.



Recently I found myself in the unfortunate situation of having to memorize many proofs the day before an exam.  Suddenly, it no longer mattered if I knew only a few proofs in great detail.  What I needed was to know all of the proofs, but only in enough detail to warrant sufficient partial credit.  To do this, I skimmed the proofs in my textbook one by one, writing little summaries of each in my own words.

My point is that this (for me) was a very effective method of grasping the big ideas of the proofs without getting hung up on the details.  In writing my own summaries, I was also able to boil down entire proofs to a couple of sentences, which then served as mnemonics for memorization.

But as for the questions you actually asked...

Should you skip reading the proofs?  Ideally, you'd read and understand all of them, but if you're crunched for time (as you seem to be), then you have to be efficient.  Ryan Budney is right: you have to learn when to stop.  Learn what you think is relevant to doing well in the class.  Then, when the course is over, you can take the time to understand the details or less-important proofs or whatever you want, should you so desire.

Should you try less hard, get worse grades, but "have a life"?  I don't think anyone can answer that but you, I'm afraid.

I will say, though, that efficiency really matters, and that you might be able to find ways to balance academics with a social life if you look for them.  You know, somehow we're all pretty efficient when exam time comes around, managing to cram large amounts of information in a very short amount of time.  We have no choice but to be efficient.  So while I'm not saying that you should treat every day like it's the day before an exam, I do think that you can find ways of increasing efficiency if you look for them.



I should point out that all of this is meant to be practical advice rather than sage advice.  For sage advice, I also recommend Terrence Tao's career advice, as well as talking to your professors and advisers.

Finally, I should mention that it is my understanding that -- although I am by no means a professional mathematician just yet -- that at the end of the day, discipline and hard work matters just as much as natural talent, if not more.

So if you're worried about being able to produce research-level math, then my advice would be to stop worrying about it.  If you haven't actually tried your hand at research yet, then there's no reason to worry yourself about it prematurely.  At least, this is what my adviser told me when I presented him with these concerns last year, and really, it's been some of the best advice I've ever received.
AnswerKenntnis:
I think Terence Tao's Career advice can answer your question. I would strongly recommend you to read it.

Edit: And also Kevin Houston's How to Think Like a Mathematician: A Companion to Undergraduate Mathematics.
AnswerKenntnis:
If you choose to study mathematics so hard, as you describe it, then it means that you should like it, and I guess you do. Still, saying that it eats up all your time worries me. Math should be a pleasure; at least that's how it is for me. Math shouldn't take all your time, because your brain needs to rest for you to process things more easily. Here are a few tips:


when studying, choose a degree of detail or depth you wish to go through. Do not work out all the proofs from a book, when studying it. Choose what really interests you and what you need for your course. Usually a course does not cover an entire book, and for getting good grades you don't need to now way more than what has been taught in the course. Some things will get clear only with time and experience; you will learn them for the exam, but you'll understand the whole picture in a larger period of time, maybe years.
learn to relax everyday. Maybe I'm a lazy type, but I always find time for a walk, a bike ride, for playing the piano, for watching a movie. For example, I relax when solving problems on this site, or on my own, problems which do not have anything to do with what I'm studying at the moment. Take at least 8 hours of sleep per night. When relaxing you leave the brain a chance to put all the things in order. Many mathematicians had revealing ideas while doing ordinary things. A walk in the park can help you understand a key point in a proof, or a solution to a problem might pop up when doing some sport or some chores around the house (it happened to me more than once; the funniest one was that I solved a problem given to a team selection test for the IMO in my head, without any pen and paper while cutting the grass in the field with my father and grandfather). 
usually you can focus better if you have a better goal than 'finishing the book'. For example, take an article in the field you're studying (maybe a teacher can help you with that) and try and understand that article in detail. Study only the theorems and proofs which are related to that. Mathematics has developed enormously in the past years. Trying to keep the pace with everything is impossible. Focusing on a narrower scope is usually easier, and in research this is really needed.
do not ever worry about memorizing everything. You will forget many things no matter how many times you learn them, but the essential thing to do is to remember where to look for the things you forgot. For example: theorem X with examples and counterexamples is presented in book Y, subject Z can be found in the book T, and so on. Try and split your proofs into steps you can remember. Do not memorize calculations. Remember only key points, and trust yourself that you can fill in the blanks.
find time to spend with friends or colleagues. Having someone to share an idea with, even a mathematical one, can be of great help. 
find someone you can tutor ( at highschool or university level, in a lower year ). This can be of great help financially and you'll notice how good you understand things when you try and explain them to someone who doesn't know them at all. This has been of great help to me.


Good luck.
AnswerKenntnis:
I suggest transferring to a program where you can make your interests coincide as much as possible with the things you're required to study.  

Mid-way through my 1st year as an undergraduate I stumbled upon the honours mathematics program at the University of Alberta and I was pretty much hooked.  The honours program emphasized rigor, understanding, technique, visualization, precision, basically just a really solid foundation. 

In my 2nd year as an undergraduate I had a (required) rather unfortunate introductory differential equations course where it was all crank-the-formula.  Proofs and ideas were nowhere to be seen.   That course was quite frustrating for me -- it seemed like such a waste of an opportunity to start connecting the various threads we had been developing in analysis, linear algebra, algebra and so on. 

I found as an undergraduate I usually had plenty of time to do everything I was required to do.  There were moments when I got in situations that were close to being over my head but it all worked out for the best.  If you never push yourself too hard you'll never know what "too hard" is.  So it's a good thing to discover. I think it helps when the things you have to do are the things you want to do.  If they're not, you can end up wasting time being bored out of your skull.   It's a good lesson to learn how to accomplish boring things, but hopefully there's not too many of them in your undergraduate education!
AnswerKenntnis:
This answer will attempt to only address the first part of your question.  When I was doing undergrad work, I gained a lot of weight since my main way of doing my homework was just sitting down and eating chips or something while putting my nose to the grindstone.  This, in combination with needing to constantly study, was really bad for my body and also caused some anxiety problems down the line.  Around my 4th year, I started making daily to-do lists which included little bits and pieces of things which were not math-y: I found short (10-15 minute) exercise videos on youtube that I knew I had time to commit to, and I did that "100 Push up Challenge" which you can probably find via google (I didn't quite get there, but I had a lot of fun along the way!).  

To this day, I set aside time for at least 20 minutes of exercise each night (you'd be surprised at how focused you are afterwards) and I feel significantly better, physically.  Once you've been doing it for a month or so, it just becomes natural.  

As far as the social problem, different people do different things.  I ride my bike to school, so I joined a cyclist group.  I also found a number of other social clubs in the city (Chicago at the time) that did things I liked.  I was surprised at the number of people just looking for other people to talk to, and not all of it was science-y!  

It may be the case that this does not work for you, but I wanted to share my experience just in case someone found it even a little bit helpful.
AnswerKenntnis:
I was (and am still to an extent) going through much a similar phase some time back. I am not particularly good in all the main subject areas of mathematics and am precise about details myself and there occur times when it all sorts to overwhelm me a little. At such times I either indulge in fun-maths, and just try to prove results for fun which attract me, no matter how much time it takes, or how trivial they seem. This keeps me attached to mathematics while also relaxing me. Also I take time out daily for non-mathematical activities because if I dont, too much mental activity invariably gives me a headache.

I think doing maths is much like playing music. It is hard work, but occasionally you can play whatever tunes relax you. All said and done, I think it is important to remember why exactly we do maths: because it is fun! 

Added after seeing the comment:

I see. I can sort of relate to my graduate days with that. I got through them somehow with a lot of angst, and what I learnt from that was this: Its important that you study the proper way and that proper way is unique to everyone. In my second semester I remember really struggling through Complex Analysis by Ahlfors (I still am a little apprehensive towards it) and the reason was that that book was not geared towards my way of studying, and there was no time to painstakingly give arguments for everything "assumed to be clear" in the book. Later on, I read another book on Complex Analysis(Brown & Churchill) and what I know of the subject is largely due to that. This is because the second book was more geared to my internal understanding process then Ahlfors. Perhaps you too will go a lot of quicker with the grades if you read from books that appeal to you intuitively and not from prescribed ones.
AnswerKenntnis:
You might consider distinguishing the understanding of mathematics from the requirements of your classes. If you need to memorize a proof for a test, in order to remain in school, then do it... but don't confuse it with understanding, or with working out proofs for yourself. You might find that breaking a proof into the parts you do understand and the parts you don't understand will simplify the process of coping with the proof.

Who knows? Maybe having memorized a proof you don't understand, you'll find that you can think about it while you're doing something else, and perhaps understand it in a flash of insight.
AnswerKenntnis:
A friend send a link to this post and I find it very interesting. One thing that is particularly interesting is your conviction that you do not have a talent. How do you know if you have a talent or not? What is talent anyway? Why are you so sure that your peers who get a proof faster or remember it longer have more talent than you? 

It is very difficult to explain what mathematical talent is. Most math problems that are worth solving and most theorems that are worth proving take years to solve and proof, so speed or memory will not come so handy while solving or proving these theorems. I believe most humans have enough memory to store all the necessary information in order to work on worthwhile problems for few years (they have enough time to do that). Speed in a three or four year project is hardly ever useful (of course there are notable exceptions but in average I would say this is irrelevant). What actually comes much more handy is diligence, which you seem to have. If you can stay with a problem after few months of failure then you have the right qualities, I think. 

One thing people bring up often is imagination. This you can never know if you have or not until you actually start working on problems. You can learn a language quickly but after doing that you may never become a poet. The undergrad math, in fact most math taught in standard classes, is just developing a language which some people learn faster than others and some remember more than others, but what will they do with it isn't something that is taught in those classes. 

I would say that mathematical talent is in fact this imagination. To say someone is mathematically gifted is just to say that the person sees more mathematical connections and relations among mathematical objects than most people. A mathematically gifted person has a strong intuition about which line of thought will lead to beautiful new theories and new discoveries. Good memory and speed of performing mathematical computations and logical operations is often mistaken for mathematical talent. It is of course a talent, a very useful one, but I wouldn't call it a mathematical talent. 

At any rate, you seem to be far away from a kind of place in your life where you can actually figure out if you are mathematically gifted or not. You can speed up your journey towards getting there by singing up for research projects rather than taking math courses, which are the most deceiving indicators of mathematical talent. You can also take reading courses and sign up for more higher level, like graduate level, courses. There are also summer research programs that you can sign up for. 

As for healthy life style, I don't know. I actually think about math when I do my exercise. That is the great thing about the profession but you have to teach things to yourself. For instance, you can teach yourself to think about math when you are doing routine daily things like washing the dishes. But it took me a while to get to this kind of state of mind, as a college student I had an unhealthy life style as well and didn't exercise much thinking its waste of time. But its not! You can teach yourself to think about math while doing it and also it is a way to rejuvenate yourself and deal with the stress. 

The social life part is hard. As a research mathematician you do need significant amount of time to yourself. I doubt that there are research mathematicians out there with huge social circles. But with some effort you can have enough people around you and these people, in most cases I know, are usually very interesting, intelligent and motivating people. 

As to how to learn math, well, you never know. We all I guess put a lot of emphasize on learning the proofs and the details of it but when we go a higher level we realize that we didn't really understand the proof. So in a sense its actually a pointless activity to really learn the proof of a theorem you have seen first time. Probably doing some kind of circular thing where you learn things and as you go on you come back to earlier things and you re-learn them is better. 

But what is more important I think is for you to figure out why you want to learn these proofs so well. There are many more proofs to learn and you will not know all of them by heart ever. In fact what is it that you want to gain out of math?  Its best to concentrate on finding what area of math you like and learning that subject with a good professor in a circular fashion where the subject gets more and more sophisticated and important ideas that have been left behind get revisited from time to time. 

In short, there is nothing to be afraid of and I am sure you will figure these things out for yourself.
AnswerKenntnis:
Set your priorities.  Get a calendar.  Put exercise in it for a half hour 3 times a week.  This is better than nothing.  Don't do anything that's going to absolutely wear you out.  Schedule time to hang out with people.  Schedule other priorities like sleep.  Then, whatever time is left over, which would probably be quite a bit still, do math.  If you still feel the same way, schedule more exercise/sleep/hang out time/whatever.

Lots of people forget math.  I wanted to study algebra stuff.  I had Real Analysis 1 and 2 (graduate level) one year and spent so much time on those that I had no time for algebra.  I couldn't remember the algebra stuff that was actually important.  The real analysis isn't even important to me.  I should have prioritized better and spent less time on real analysis and more time on algebraic stuff.

I spent so much time away from my family that year also, which was terrible.  I now basically work 8-5 and go home.  And, maybe Saturday I work for a few hours.  Sometimes, I try to get in some more work.  But, my family is more important than this math so I don't care if it takes longer to graduate or I don't do quite as well.
AnswerKenntnis:
Something could be useful when Special Force Soldiers are trained, named Devil Training.

It seems the good reasons are related to transcend extreme limit of capacity to quickly extend the comfort-zone and equipped with massively difficult practices in very complicated environments NOT easy ones.

Some parts the same as good mathematical training, one could absorb both broad and important knowledge quickly, and move on quickly, intensively practices to be done in advanced and complicated 'environment' to train both elementary and advanced skills at the same time. Never stay in easy level but just move on even if some skills/knowledge are not absorbed well, since it'll be better as we go further. There's only a fine line between Wisdom and Foolish, wise persons absorb and move on fast with playing around with knowledge like a swimming fish and keep on deepening the understanding; while fool persons only suffer from the pain passively and repeat everything mechanically without thinking.

While some parts are apparently opposite, in Military Training it's obey the orders, no question asked, but in mathematics(natural science) it's break the orders, endlessly ask questions. Plus some passion, curiosity, self-automatic willingness to explore and some luck, it can generate a very beautiful road in mathematical world.
AnswerKenntnis:
I know there is one fellow here that wants to discourage you from doing your mathematics... He is absolutely right, graduate school is very difficult, post-docs are a nightmare... What is disturbing is that he tries to set you up for a comfortable life... Perhaps this is not what you want. One thing I know for sure is that any human being is "the captain of his soul". If you want to do something, and if you don't give-up you will get there. Nothing worth doing comes easily. This is why there is such a competition for professions such as mathematician or cook. Because the people that want to do it absolutely love it and for them there is nothing better they could be doing. Yes, you will not be paid well, yes some idiot is going to ride a better car than you. The ultimate question however is, if you want to follow your passion to the very final destination where it leads you, perhaps to the abyss, or if you want to never try, and be pushed around by every kinds of people that will tell what they think life is and how they think life should be lived. I know you don't listen to these people anyway because you question even mathematical objects, you ask "why?" which is all you need, coupled with a practical life-approach, for a career in mathematics. I didn't listen either. The same people told me I would get nowhere, that mathematics is too competitive, that there is no room for me there.

On the practical level, it is not normal for mathematics to cause a gain of weight; there could be external factors you should look into. Also mathematics should not cause a loss of social life, perhaps your friends were not the best fit for you? 

Concerning academia, inform yourself about the practical means of staying and surviving in academia. You will need a game-plan and a well thought-off strategy always present for the next 3-5 years at every moment in your career until tenure-track. Otherwise you might end up with no job. The most important "currency" in academia are publications, their quantity and their quality. You should incorporate these in your plan very soon. Prestige of the academic institution and of the professors that you've worked with is important in the early beginnings. Look at successful mathematicians (adjust to the level where you want to be in 10 years but always try to do slightly better than they did), their papers, their career progression, etc. to get an idea what is necessary. I wish you the best of luck, no matter what you decide is the correct choice for you.
AnswerKenntnis:
For the weight gain part: Read some Arthur De Vany's writings, and check out his diet. People eat constantly and expect not to gain any weight. De Vany suggests, some days, after a healthy, big breakfast it's okay not to eat anything, and going to sleep hungry. "Going to sleep hungry" part gets big objections from people, but our bodies have not evolved from their hunter gatherer structure just yet. When humans hunted, they could go days without eating much. Our metabolism is geared towards feasting (overeating) after a good catch, and going around hungry until that catch. Constant eating is not our way. Try this and you will happier, your body when it is hungry will be relieved even, because there will be one less thing it needs to work on. On days when you are not eating (after breakfast), it is also advised  to set that day aside for physical activity, walking, etc. (yes, while hungry), but your mind will rest in the meantime.
AnswerKenntnis:
"Also, my problem is having weak memory. I forget a lot."

Have you tried using a flashcards program? There is a program where you can add questions. If you answered a question correctly, the program will ask you the question again in 2 days. If you answer correctly in 2 days, it will ask you again in 4 days. After that, the interval will grow to 8, 16, and so on. I found it helpful. You can also set a custom interval. The program accepts mathematical symbols.

Also, don't add EVERYTHING you want to remember to the program. You'll remember a lot of things anyway. The trick is to figure out which ones you need to add.



Regarding how you can lose the temptation of doing math all the time, I'd like to mention the concept of marginal utility. The marginal utility of anything (say, an ounce of water) is how much acquiring one additional unit benefits you. If you're dehydrated, the marginal utility of an ounce of water is very high. As you drink more and more water, its marginal utility diminishes. The same thing happens with mathematical knowledge. Even if you've been consuming new math for years and are anxious to get more of it, there will be a point where its marginal utility will diminish, and you'll be able to focus on other things easily. You just don't know yet what that point is, and maybe you won't reach it even in years, but based on my experience, I expect that you'll reach it at some point.
AnswerKenntnis:
The agony regarding "How to study maths?" is not as real as posed. Before going for study a topic one should devote some ten percent duration in making strategy how to complete the Chapter. Never take any thing granted in Math. Do not rely on the proof of a theorem given in the books with too many "clearlys". Do not rely on Professor's authority. They are rarely ideal to follow. Simply try to discover your own proof, putting every definition, and previous results before your eyes written on a broad sheet of paper. Never rely on memory regarding definition or statement of a complicated theorem when using somewhere. They mostly deceives a novice. Simply see it without shame. In this way you will enjoy and form a habit of proving anything on its own. Only in emergency read some parts of the proof. Do not go mad for solving Problems. They are rarely challenging for a student who has gone through the procedure I have described in completing a Chapter. Preserve the "proofs discovered by you" for future need. 
You will be amazed to observe after studying this way you are becoming bold everyday. Even then, if you fall into trouble, you should devote more time in making your prerequisite vibrant. Abandon the idea of abandoning maths. Only fortunate people spend their life in Maths. Young people do not as much need exercise as old. Your priority is Math, not anything else. If you leave the table without completing the work, you will have to spend double time in recapitulating the next time you sit. In this way you will be a great looser in the long run. So leave the study table only after completing the task at hand.
AnswerKenntnis:
As a CPA who is now returning to school to take a Masters in Computer Science (and thereby a few math courses along the way), I can indirectly relate with your problem; however, I do believe my perspective is relevant and may very well be of help to you.

I was like you in my undergraduate studies in accounting.  I literally spent every waking moment of my day during the last two years of my studies - seven days a week - preparing for my classes.  Like yourself, I am driven by the "why"; not just the "how".  It also holds true in the business arena that the majority of students do not ask why a solution is true; they merely accept that it is true and memorize the steps to work out the corresponding solution.

Unlike you, I do not consider myself only marginally talented or mediocre at best; and, in fact, I encourage you to truly consider an earlier poster's comment who challenged your self-deprecating opinion by saying you may indeed be talented and to therefore not prematurely make this judgment concerning yourself.  Proverbially: How can I build a house if I do not believe I am able too?  It would not be a waste of time to consider how your internalized belief about yourself may be significantly affecting A) your academic performance, and B) your level of personal anxiety.  Please take this to heart.

Having now made such statements, I would also like to say that from a practical point of view I totally "get" where you are right now.  You want tomorrow's perspective, today, and thereby to make sure you do not make a foolish choice today that will cost you tomorrow.  My advice is to follow the deepest passion of your heart today and trust "tomorrow" to work out the other details.  

For example, if doing mathematics is truly the supreme passion of your life, then commit yourself to this path irrespective of whether you become a tenured professor or instead find yourself in some area of applied mathematics ... or even software development.  Everyone must do their best and strive for the highest achievement.  You will always be happiest striving to do your very best while at the same time following the deepest passion of the heart.

Of course, there is more to life than "X" (e.g., mathematics, in your case), so we must also nurture the other parts of our being.  Even our base desires teach us this in their insistence every twenty-four hours to feed, rest, clean and relieve.  And how about our, higher, emotional and spiritual needs?  Is it mere vanity to seek humanity (companionship)?  As with the assumptions inherent in mathematics, our carnal and psychological desires also provide self-evident assumptions to aid in the building process of our existence.  Listen to yours and act accordingly, but understand that not every house is of the same shape, size, and symmetry; therefore, you may require very little, or very much, of such "y" variables while solving the "x" factor of your life.
QuestionKenntnis:
Mathematical difference between white and black notes in a piano
qn_description:
The division of the chromatic scale in 7 natural notes (white keys in a piano) and 5 accidental ones (black) seems a bit arbitrary to me.

Apparently, adjacent notes in a piano (including white or black) are always separated by a semitone. Why the distinction, then? Why not just have scales with 12 notes? (apparently there's a musical scale called Swara that does just that)

I've asked several musician friends, but they lack the math preparation for giving me a valid answer. "Notes are like that because they are like that".

I need some mathematician with musical knowledge (or a musician with mathematical knowledge) to help me out with this.

Mathematically, is there any difference between white and black notes, or do we make the distinction just for historical reasons?
AnswersKenntnis
AnswerKenntnis:
The first thing you have to understand is that notes are not uniquely defined.  Everything depends on what tuning you use.  I'll assume we're talking about equal temperament here.  In equal temperament, a half-step is the same as a frequency ratio of $\sqrt[12]{2}$; that way, twelve half-steps makes up an octave.  Why twelve?

At the end of the day, what we want out of our musical frequencies are nice ratios of small lintegers.  For example, a perfect fifth is supposed to correspond to a frequency ratio of $3 : 2$, or $1.5 : 1$, but in equal temperament it doesn't; instead, it corresponds to a ratio of $2^{ \frac{7}{12} } : 1 \approx 1.498 : 1$.  As you can see, this is not a fifth; however, it is quite close.

Similarly, a perfect fourth is supposed to correspond to a frequency ratio of $4 : 3$, or $1.333... : 1$, but in equal temperament it corresponds to a ratio of $2^{ \frac{5}{12} } : 1 \approx 1.335 : 1$.  Again, this is not a perfect fourth, but is quite close.

And so on.  What's going on here is a massively convenient mathematical coincidence: several of the powers of $\sqrt[12]{2}$ happen to be good approximations to ratios of small integers, and there are enough of these to play Western music.  

Here's how this coincidence works.  You get the white keys from $C$ using (part of) the circle of fifths.  Start with $C$ and go up a fifth to get $G$, then $D$, then $A$, then $E$, then $B$.  Then go down a fifth to get $F$.  These are the "neighbors" of $C$ in the circle of fifths.  You get the black keys from here using the rest of the circle of fifths.  After you've gone up a "perfect" perfect fifth twelve times, you get a frequency ratio of $3^{12} : 2^{12} \approx 129.7 : 1$.  This happens to be rather close to $2^7 : 1$, or seven octaves!  And if we replace $3 : 2$ by $2^{ \frac{7}{12} } : 1$, then we get exactly seven octaves.  In other words, the reason you can afford to identify these intervals is because $3^{12}$ happens to be rather close to $2^{19}$.  Said another way, 

$$\log_2 3 \approx \frac{19}{12}$$

happens to be a good rational approximation, and this is the main basis of equal temperament.  (The other main coincidence here is that $\log_2 \frac{5}{4} \approx \frac{4}{12}$; this is what allows us to squeeze major thirds into equal temperament as well.)

It is a fundamental fact of music that $\log_2 3$ is irrational, so it is impossible for any kind of equal temperament to have "perfect" perfect fifths regardless of how many notes you use.  However, you can write down good rational approximations by looking at the continued fraction of $\log_2 3$ and writing down convergents, and these will correspond to equal-tempered scales with more notes.  

Of course, you can use other types of temperament, such as well temperament; if you stick to $12$ notes (which not everybody does!), you will be forced to make some intervals sound better and some intervals sound worse.  In particular, if you don't use equal temperament then different keys sound different.  This is a major reason many Western composers composed in different keys; during their time, this actually made a difference.  As a result when you're playing certain sufficiently old pieces you aren't actually playing them as they were intended to be heard - you're using the wrong tuning.



Edit:  I suppose it is also good to say something about why we care about frequency ratios which are ratios of small integers.  This has to do with the physics of sound, and I'm not particularly knowledgeable here, but this is my understanding of the situation.

You probably know that sound is a wave.  More precisely, sound is a longitudinal wave carried by air molecules.  You might think that there is a simple equation for the sound created by a single note, perhaps $\sin 2\pi f t$ if the corresponding tone has frequency $f$.  Actually this only occurs for tones which are produced electronically; any tone you produce in nature carries with it overtones and has a Fourier series

$$\sum \left( a_n \sin 2 \pi n f t + b_n \cos 2 \pi n f t \right)$$

where the coefficients $a_n, b_n$ determine the timbre of the sound; this is why different instruments sound different even when they play the same notes, and has to do with the physics of vibration, which I don't understand too well.  So any tone which you hear at frequency $f$ almost certainly also has components at frequency $2f, 3f, 4f, ...$.  

If you play two notes of frequencies $f, f'$ together, then the resulting sound corresponds to what you get when you add their Fourier series.  Now it's not hard to see that if $\frac{f}{f'}$ is a ratio of small integers, then many (but not all) of the overtones will match in frequency with each other; the result sounds a more complex note with certain overtones.  Otherwise, you get dissonance as you hear both types of overtones simultaneously and their frequencies will be similar, but not similar enough.  



Edit:  You should probably check out David Benson's "Music: A Mathematical Offering", the book Rahul Narain recommended in the comments for the full story.  There was a lot I didn't know, and I'm only in the introduction!
AnswerKenntnis:
The first answer is great, so I'll try to approach the question from another angle.

First, there are several different scales, and different cultures use different ones.  It depends on the mathematics of the instruments as much as on cultural factors. Our scale has a very long history that can be traced to the ancient Greeks and Pythagoras in particular.  They noticed (by hearing) that stringed instruments could produce different notes by adjusting the length of the string, and that some combinations sounded better.

The Greeks had a lot of interest in mathemathics, and it seemed "right" for them to search for "perfect" combinationsΓÇöperfect meaning that they should be expressed in terms of fractions of small integer numbers.  They noticed that if you double or halve the string length, you get the same note (the concept of an octave); other fractions, such as 2/3, 3/4, also produced "harmonic" combinations. That's also the reason why some combinations sound better, as it can be explained by physics. When you combine several sine waves, you hear several different notes that are the result of the interference betwen the original waves. Some combinations sound better while others produce what we call "disonance". 

So, in theory, you can start from an arbitrary frequency (or note) and build a scale of "harmonic" notes using these ratios (I'm using quotes because the term harmonic has a very specific meaning in music, and I'm talking in broad and imprecise terms). The major and minor scales of Western music can be approximately derived from this scheme. Both scales (major and minor) have 7 notes. The white keys in the piano correspond to the major scale, starting from the C note.

Now, if you get the C note and use the "perfect" fractions, you'll get the "true" C major scale. And that's where the fun begins. 

If you take any note in the C major scale, you can treat that note as the start of another scale. Take for instance the fifth of C (it's the G), and build a new major scale, now starting from G instead of C. You'll get another seven notes. Some of them are also on the scale of C; others are very close, but not exactly equal; and some fall in the middle of the notes in the scale of C. 

If you repeat this exercise with all notes, you'll end up building 12 different scales. The problem is that the interval is not regular, and there are some imprecisions. You need to retune the instrument if you want to have the perfect scale.

The concept of "chromatic" scale (with 12 notes, equaly spaced) was invented to solve this "problem". The chromatic scale is a mathematical approximation, that is close enough for MOST people (but not all). People with "perfect" ear can listen the imperfections. In the chromatic scale, notes are evenly spaced using the twelfth root of two. It's a geometric progression, that matches with good precision all possible major and minor scales. The invention of the chromatic scale allows players to play music in arbitrary scales without retuning the instrumentΓÇöyou only need to adjust the scale by "offsetting" a fixed number of positions, or semitones, from the base one of the original scale.

All in all, that's just convention, and a bit of luck. The white keys are an "historical accident", being the keys of the major scale of C. The other ones are needed to allow for transposition. Also bear in mind that (1) the keys need to have a minimum width to allow for a single finger, and (2) if you didn't have the black keys, the octave would be too wide for "normal" hands to play. So the scheme with a few intermediate keys is needed anyway, and the chromatic scale that we use is at least as good (or better) as any other possible scale.
AnswerKenntnis:
The answers given are pretty good from a musical, mathematical, and socialogical / historical reason.  But they miss the fundamental reason why there are 12 notes in a western scale (or 5 notes in an eastern pentatonic, etc.), and why it's those particular 12 notes (or 5).

Qiaochu almost nailed it by pointing out that we like notes which are simple integer ratios.  But why?  The fundamental reason stems from the physics of common early instruments -- flutes (including the human voice) and plucked strings -- and from the physics of the tympanum in the ear.

As Qiaochu noted, sound is not composed of a single sine wave frequency but rather a sum of many sine waves.  The "note" we hear is the frequency of the primary (loudest) wave coming from these instruments.  But frequencies exist in that wave as well, albeit largely masked by the primary.  These are known informally as harmonics or overtones.

The first several harmonics of flutes and plucked strings are similar and very straightforward:  If the primary is normalized to frequency 1, then the second loudest harmonic is typically 1/2 (an octave above), the third is usually 1/3 (an octave and a fifth above), the fourth is usually 1/4 (two octaves), the fifth is usually 1/5 (two octaves and a major third), and the sixth is usually 1/6 (two octaves and a fifth).  If the primary note is C1, these translate roughly into C2, G3, C4, E4, and G4.  If the harmonics continued in this way -- and they don't always -- various other notes appear.

This matters because if you want to play TWO instruments together, you'd like their harmonics to coincide even if they're playing different notes.  Otherwise the excess of harmonics sounds bad to the ear.  In the worst case, very close but not entirely overlapping harmonics create "beats" -- seeming alternating loud and soft periods of time -- which are irritating to listen to and tough on the ear.

To get harmonics to coincide in multiple instruments or even successive notes, you have to pick notes for them to play where their harmonics have a strong overlap.  For example, this is also why the major fourth is useful even though it doesn't often appear early.  It's because if one instrument is playing C, if the other instrument is playing major fourth but lower by an octave, they'll overlap nicely.

I believe these note selections (guaranteeing harmonics in harmony, so to speak) influenced the evolution of scale choices -- especially the pentatonic, that is, the black notes), and the division of the octave into 12 pieces. 

One early instrument which is totally out of whack from this is the bell.  Bells and gongs can be tuned to have a variety of harmonics, but the most common ones -- foundry bells -- have a very loud, unusual third harmonic: minor third or E flat.  It is so loud and incongruous that they sound terrible, even disturbing, when played along with strings, flutes, voices, etc.  In fact, entire musical pieces have to be written specially for carillons (large multibell instruments) in order to guarantee proper overlap of harmonics.  Generally this means that the entire piece has to be written in fully diminished chords.  Major chords sound among the worst because of the clash between the major third in the chord and the minor third coming from the root's loud third harmonic.
AnswerKenntnis:
The math of frequency relationships here is sound (pun intended) but they don't help explain the white vs black key piano layout.

Here's the historical imperitive thay led to this layout for "Western Music".

First consider the major triad: root + third + fifth notes of the "diatonic scale".
They follow the harmonic series:
1 - root
2 - octave (doubling of root frequency)
3 - fifth (triple of the root - 3:2 relationship to the octave)
4 - double octave (4x)
5 - 10th (double octave of a third)
6 - octave fifth

These are notes a static length of tubing can produce by blowing into it: the bugle.

Combinations of these notes create frequencies that make choirs sound heaven-ly.
The frequencies align and blend into pure complex vibraations that are the sum and
the differencies (harmonic overtones) of these relationships.

Choirs can tune themselves dynamically to create these frequency alignments that
are percieved as being perfectly consonant. Upbeat western music focus on the 3 major
chords found in the diatonic scale:
1+3+5 root major chord - white keys C - E - G
4+6+1 4th chord - white keys F - A - C
5+7+2 5th chord - whote keys G - B - D

The basics of western folk music are the 1 - 4 - 5 sequences of chords.
Learn C, F and G on a guitar and you can play the bulk of the classic Country 
song book.

Put the notes of these chords into a scale and you get that row of 7 white keys:
C - D - E - F - G - A - B (repeat until you can't hear it).

So, they western scale is based upon frequency relationships that make combinations
of notes "ring" in consonance in it's purest form... like the Gregorian Chants of
the Roman Church.

So, a basic "western keyboard" could be made from just these 7 notes repeated across the frequency spectrum. Look at the layout of a Greek Lyre (a harp) and that's what you
will find. A sequence following the diatonic scale which sounds pleasant if you just strum across the strings due to the tuning of even multiples (adjusted by octaves).

OK... now adding the black keys is a compromise of tuning specific notes so that you can build these 1+3+5 chords from any starting point and thus play a song adjusted up or down to any starting point. The piano will never achieve that sonic mathematical glimpse into the "music of the spheres" that the self-adjusting choir can to make a chord mathematically perfect in alignment but it's the "keyboard" for the modern composer... the effective "musical qwerty" that a composer or a pianist begins to visualize chord "shapes" as hand positions.

With a lot of practice a pianist can pre-visualize sound in terms of finger and hand movements much like a solid touch typist starts to set words and sentences as a sequence of movements.

The addition of the black keys was called a "Well Tempered" tuning and Bach was one of the first composers to create whole bodies of compositions that worked through the Major and Minor keys of the 12 scales that you noticed intially when inspecting the keyboard.

If you look into other musical cultures you will find a different approaches to standardizing sound relationships that do not focus on the 1 - 4 - 5 chords.
This music to a culturally trained western ear is less predicatable in nature and
that lack of predictablility can make the music frustrating or exciting... music "speaks" to us in terms of pure sensory inputs that can move, excite, bore or confuse us.

So, the piano keyboard is designed to be the perfect delivery system for an individual to produce the range of complexity that western music has achieved.

The modern keyboard synthesizers are now able to produce the full range of the western orchestra in terms of "instruments" and I'm hoping someone create one that micro-adjusts notes based upon the surrounding context... shifting a note up or down slightly from the "well tempered" compromise to the pitch that makes a chord "ring" and
produce the upper harmonic overtones that make a great orchestra truly "heavenly".

Maybe it's already been done.
AnswerKenntnis:
The math in this thread is awesome, but I'm not sure it addresses the original question about the "difference between white and black notes".

The other responses in this thread provide enough math to understand that each octave can be more-or-less naturally divided into twelve semitones. The Western music tradition further evolved to be based around what's called the "diatonic scale". 

A musical scale is a sequence of pitches within one octave; scales can be defined by the number of semitones between each successive note.

For example, the Whole Tone Scale consists entirely of whole tones; it has six distinct pitches, each of which is two semitones higher than the last. So you might represent it with the string '222222' ΓÇö that is, take a note, then the note 2 semitones higher, then the note 2 semitones higher, etc., until the last "2" takes you to the note an octave above where you started.

The Diatonic Scale that Western music is based around could likewise be represented by the string '2212221'.

If you start with a C on a keyboard and go up, you'll see that the white keys conform to that pattern of semitones. That, generally, is why the black keys are in that particular pattern.

Of course, you can start a scale on any pitch, not just C. That's why the "same" diatonic scale in a different key will involve a unique set of sharps and flats.

Now, the Diatonic Scale can also be represented by '2212221' shifted to the left or right any number of times. For example, '2122212', '1222122', etc. are also Diatonic; these are called the "modes" of the Diatonic scale. Each Diatonic mode can be played on only the white keys of the piano by starting on a different pitch.

2212221 is called the Ionian mode (this is also generically called the Major scale), and can be played on the white keys starting with C.

2122212 is the Dorian mode and can be played on the white keys starting with D.

1222122 is the Phrygian mode, starting on E.

2221221 is the Lydian mode, starting on F.

2212212 is the Mixolydian mode, starting on G.

2122122 is the Aeolian mode (the Minor scale), starting on A.

1221222 is the (awesome) Locrian mode, starting on B.

Each mode has its own unique "sound", which (in my opinion, at least) derives precisely from the different placement of the semitones within each scale.

And of course there are scrillions of non-Diatonic scales that have nothing whatsoever to do with how the modern keyboard came to be.

EDIT to add a shorter, less implicit answer: The white keys alone can be used to play the set of diatonic scales listed above; the black keys are "different" because they are the remaining chromatic pitches not used in that set of diatonic scales.
AnswerKenntnis:
Mathematically, is there any difference between white and black notes, or do we make the distinction just for historical reasons?


There is no mathematical difference between the white and black notes. Adjacent notes on modern piano keyboards are typically tuned 1/12 of an octave apart. Quiaochu explains this most completely, but what it boils down to is that there is no difference.

We haven't always and don't today always use equal temperament on keyboard instruments but even then the difference between white and black notes would be arbitrary.

The distinction is for historical and cultural reasons. There is a cool picture here showing Nicholas Farber's Organ (1361), which used an 8 + 4 layout rather than the modern 7 + 5 layout we see today. http://en.wikipedia.org/wiki/Musical_keyboard#Size_and_historical_variation

There are examples of instruments in use today that use a chromatic keyboard with no differentiation between the "white" and the "black" notes. See the Bayan and the Bandoneon accordion type instruments.

At the New England Conservatory in the classroom where they teach a class on quarter tones, they keep two pianos tuned a quarter tone off from each other. In that case, a full 24-note chromatic quarter tone octave must be played alternating notes on the two pianos.

This is only the beginning of this particular rabbit hole.
AnswerKenntnis:
Note also that many cultures use a pentatonic scale. This would correspond to playing only the notes CDEGA. As explained in Qiaochu's answer, we want notes that are in small rational intervals, and particularly notes that are in small rational intervals from the tonic. Exactly which set of notes is chosen varies from culture to culture, with Western music using the 7 white keys, but many other cultures only using the 5 pentatonics.
AnswerKenntnis:
Just to let you see that other tunings are possible and thus other keyboards:

http://www.kylegann.com/tuning.html
AnswerKenntnis:
To add to this thread, you can understand why certain notes sound good/bad together by looking at trig sum/product formulas, e.g.:

cos(a) + cos(b) = 2 * cos(a - b) * cos(a + b)

What this means is that when you add two tones/frequencies 'a' and 'b', it is equivalent to taking one wave of frequency 'a + b' and modulating its amplitude with another of frequency 'a - b'. The frequency 'a + b' will be a faster vibration, and the frequency 'a - b' will be a slower vibration.

When the two original frequencies are close (e.g. A = 440Hz and A# = 466Hz), the 'a - b' component will be heard as an unpleasant low frequency beating (here, 26Hz).

When the two original frequencies are integer ratios of each other (e.g. 3/2, 4/3) as in chords, then the resulting 'a + b' and 'a - b' frequencies will also be integer ratios of each other. The resulting wave will be simple and sounds harmonious. This is why integer ratios of notes are so important in music.

It helps to plot sums of sines graphically to see this in action.
AnswerKenntnis:
Start at F and go up a fifth (to C).



(In a keyboard with 12-key octaves, that's 7 steps.) Repeat that process (through the circle of fifths). You'll hit all the white keys and then all the black keys  -- F, C, G, D, A, E, B, F#, C#, G#, D#, A# -- note, these keys are usually represented with flats). So it turns out if you're splitting tones on 3 : 2 (fifth) or 4 : 3 (fourth), the least common multiple is twelve. In practice, the 3 : 2 is similar enough that it gives a sort of 'secure' or content feeling. The 4 : 3 gives a slightly edgier feeling but one which is somewhat counterposed perfectly against this secure feeling. So a fourth + a fifth will give you an octave. So why we want all twelve keys is that we're saying that we want the fifth (dominant) and the fourth (subdominant) to come together and make a whole. This is sort of mirrored with the fact that the first 7/12 of the circle of fifths form the basis and the second 5/12 are 'overlayed' on top (with black keys).
AnswerKenntnis:
If you only had a repetitive series of keys on your piano it would be a bit difficult to visually get some reference points. I think this is the main reason wh
AnswerKenntnis:
Check out this paper which is about the regular 12-gon and music theory.  It will help you answer this question, as well as many others that are similar to it.
AnswerKenntnis:
Other responses do a good job of explaining the 12-note chromatic scale. From those 12 tones, if one starts to build a series of tones starting on a single note and going up the circle of fifths, there are two natural stopping points where you have a complete-sounding scale that spans the octaves and has relatively equal spacing between the notes with no gaps: five notes, which gives whole-step and minor-third intervals; and seven notes, which gives whole-step and half-step intervals. These two scales (pentatonic and heptatonic) correspond to the spacing of the black keys and white keys on the keyboard.  They are mirror images of each other around the circle of fifths. So the two colors of notes are not "different," but rather a natural division into two symmetrical sclaes built from going opposite directions around the circle of fifths.

In the standard tuning system C is "privileged" because it is (essentially) the note where we start building the circle of fifths to create these two scales.
AnswerKenntnis:
The "circle of fifths" is a by product of the preference for diatonic scales.
If you layout the chromatic (12-tone) scale without the white and raised black arrangement you'd use the same logic to describe a "circle of sevenths" (counting
upo semitones from C to G).

So, the arrangement makes solid sense when applied to the human hand. We need to be able to span interesting distances with the "octave" interval be very useful for most pianists
as a basic required for anyone older that 10-12. Some pianists can span 10ths with relative ease but they are in the minority. The piano music of Rachmaninoff is riddled with these massive but musically sonorus intervals. The are the major third expanded to
the pure natural interval (10 keys apart) of the "bugle" overtone series.

I can reach the 10th's on the white to white instances but the black to white (Bb to D for example) are beyond me. And doing them quickly and accurately is the mark of true mastery of the instrument... it's like being able to dunk: genetics help and no amount of effort can help a small handed pianist.
AnswerKenntnis:
I'm no musician, but as far as I know, audio waves are felt only then "round/sound", iff they repeat faster than a specific frequency. That frequency is probably that of our brain waves: being awake and in a non-meditating state, that is faster than like 18 or more Hz; neither can you shiver faster nor hear lower frequencies than your brain waves.

Audio waves have a length of $$\mathrm{lcm}\{m,n\}·2\pi$$ if they are of the shape $$a_1·\sin(m·2\pi·t+s_1)+a_2·\sin(n·2\pi·t+s_2)$$. The notes double their frequency each octave; therefore they have a logarithmic scale and not a linear. Good violin and harp players can play all fitting ("sound" sounding) combination of frequencies, but instruments with keys lack the variety.

(Qiaochu Yuan did answer faster than me, while I was on the phone. Seems to be more complete than I could have answered. I have nothing to add.)
AnswerKenntnis:
I agree with the theory that the distinction between the notes is used for visual aid and reference points. In addition to that, it was meant to be treated as a vertically rising instrument as if you were to go up a ladder of sorts and those accidentals ( in the case of C, the black notes) are the grips to reach to the next level. As we would refer to them as leading notes. There is also another reason why there are that many notes. Almost all scales are a variation of the major scale or aeolian mode. This scale is designed to have a certain number of tones and semitones to give it the feel of a major scale. If there were too many tones or too many semitones it would not be the same because it will produce too much dissonance or invariably consonance. That is why there is a standard tuning for pianos i.e. A440. If the interval in vibration were to be changed it would not be the same because if the vibrations aren't in sync, the resonation will be totally off. That is why there can be only soo many notes on a piano and make sense to the human ear. Other tunings are possible but the same effect is made that the intervals are kept in a strict way to keep harmony. So, getting back to your question Mathematically, yes there is a reason for that specific order of white keys and black keys. Most of its relation deals with the mode theory of 12 notes and the circle of fifths where if you were to expand the notes on the piano it will form a perfect circle in diminished chords of C as the cardinal points. If you were to go in fifths in a clockwise direction the circle will be C g d A e b F#/Gb d#/db Ab Eb Bb F where when compressed into one octave it turns out with 7 natural notes and 5 accidentals
AnswerKenntnis:
I think in a tiny tiny nutshell... the reason for the 12-division is because a very practical solution for Western music, and the layout of black/white "evolved" into this form because it lacked re-engineering.

There is no particularly "mathemagical" thing about it. In other words... square two: it's an arbitrary choice.

If you're looking for something that uses 12-divided octave as a practical solution and is engineered for facility, check out the layout of the Russian Bayan (accordion). It's pretty awesome.

As for something that is engineered for facility but does not divide the octave into 12 parts, your common fretless string instruments are good examples.

Again, all I've said has been mentioned above. Just beware of the overtly "mathemagical" ones, they don't say much about the music but rather put it in a fancy straightjacket.
AnswerKenntnis:
If you really want to know all about it then you should read 'On the sensation of tone' by Helmholtz.
AnswerKenntnis:
One day I shall do a serious study of this!  there is truth in all these answers, the white notes give us our do-re-mi (major scale) starting on C, this scale has a mixture of tones and semitones, and dictate where the black notes should go and how many we need.  The re-tuning to equal temperament is a fudge, and if you were to analyse a tuned keyboard, not all semitones are equally spaced.  Other intervals are also compromised, so a major third in one key may have notes further apart than one in a different key.  Composers have long been aware of this, and aware that the key they select for a composition can make a significant difference to the "mood" (that is after you have selected major or minor).  

Classical Indian Music uses a system of scales (ragas).  There are several hundred of these, and they will be fitted to specific moods, times of day, types of occasion etc. These are not random variations from any Western scale, and have nothing to do with the keyboards we commonly use.  

Our keyboard system is just for keyboards - a string instrument may not play exactly the same pitch as a piano for a given note (unless it is an open string), because they will tend to use something closer to the original pythagorean scale.

PS I am a working musician with a bachelors degree in maths!
AnswerKenntnis:
A somewhat grapical representation of what Carlos Ribeiro was talking about.

"If you take any note in the C major scale, you can treat that note as the start of another scale. Take for instance the fifth of C (it's the G), and build a new major scale, now starting from G instead of C. You'll get another seven notes. Some of them are also on teh scale of C; others are very close, but not exactly equal; and some fall in the middle of the notes in the scale of C. "

Note the semi-tone interval EF and BC on the C scale.
When trying to reproduce the same scale starting at D, we run into a problem.
Alphabetically, the third note should be a F, but F is a semitone too low for that spot. In order to maintain the same sounding scale, we need to introduce a NEW note, called F#.


C - D - E F - G - A - B C  (C scale)
D - E - F#G - A - B - C#D  (D scale)
E - F#-G#A - B - C#- D#E  (E scale)
F - G - AA#- C - D - E F  (F scale)  
etc.
Note that in actual writing of music the A-A# would be written as A-Bb so that the 'A' line of the staff wouldn't be ambiguous.
QuestionKenntnis:
My son's Sum of Some is beautiful! But what is the proof or explanation?
qn_description:
My youngest son is in $6$th grade. He likes to play with numbers. Today he showed me his latest finding. I call it his "Sum of Some" because he adds up some selected numbers from a series of numbers, and the sum equals a later number in that same series. I have translated his finding into this equation.
$$(100\times2^n)+(10\times2^{n+1})+2^{n+3}=2^{n+7}$$ 

Why is this so? What is the proof or explanation? Is it true for any $n$?

His own presentation of his finding:

Every one of these numbers is two times the number before it.
$1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192$.
I pick any one of them, times $100$. Then I add the next one, times $10$. Then I skip the next one. Then I add the one after that.
If I then skip three ones and read the fourth, that one equals my sum!
AnswersKenntnis
AnswerKenntnis:
It works because the number 

$$
128
$$
has two special properties: it is a power of $2$, and every digit is a power of $2$.  This means that we can write it in two separate ways: 

\begin{align}
128&=2^7\\
128&=100\times2^0+10\times2^1+1\times2^3
\end{align}

Multiplying both sides by $2^n$ then gives:

$$
2^{n+7}=(100\times2^n)+(10\times2^{n+1})+2^{n+3}
$$



Edit: others have done a better job of generalizing this, but I feel I should point out another obvious related sequence.  

$128$ is not the only power of $2$ whose digits are all powers of $2$ (or $0$).  For instance: 

$$
1024 = 2^{10}
$$

So another, similar kind of relation is given by:

$$
2^{n+10} = (1000\times2^n)+(10\times2^{n+1})+2^{n+2}
$$

In your son's notation, that becomes:

Every one of these numbers is two times the number before it.
$1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192$.
I pick any one of them, times $1000$.  Then I add the next one, times $10$.  Then I add the next one.
If I then skip seven (!) ones and read the eighth, that one equals my sum!

See if he likes that one.
AnswerKenntnis:
Factor out the $2^n$ and you get: $2^n (100+20+8) = 2^n 128 = 2^{n+7}$ since $2^7 = 128$
AnswerKenntnis:
Here is another formula similar to your son's, using powers of $5$:

$$1000000\cdot5^n+100000\cdot5^{n+1}+10000\cdot5^{n+2}+1000\cdot5^{n+3}+100\cdot5^{n+4}+5^{n+6}=5^{n+9}$$

We can derive identities of a similar form more generally.  Consider any $m$th degree polynomial $f(x)\in\mathbb{Z}[x]$ of the following form

$$f(x)=a_0+a_1x+\ldots+a_{m-1}x^{m-1}-x^m$$

Notice that all rational roots of $f(x)$ are integers.  Suppose $f$ has a rational root $k$.  Then we have the following equality:

$$\begin{align}k^{n+m}&=k^nk^m\\&=k^n(a_0+a_1k+a_2k^2+\ldots+a_{m-1}k^{m-1})\\&=a_0k^n+a_1k^{n+1}+a_2k^{n+2}+\ldots+a_{m-1}k^{n+m-1}\end{align}$$

Your son's formula involves the $7$th degree polynomial $f(x)=100+10x+x^3-x^7$ and the root $k=2$.  Above I've used the polynomial $f(x)=10^6+10^5x+10^4x^2+10^3x^3+10^2x^4+x^6-x^9$ and the root $k=5$.

Here are other examples for $k=3$.  Consider the polynomials $f(x)=3+8x+80x^3-x^7,$ $g(x)=2130+10x+x^3-x^7$, and $h(x)=99+687x+x^3-x^7$, and notice that $f(3)=g(3)=h(3)=0$.  These give us the following identities:

$$3\cdot3^n+8\cdot 3^{n+1}+80\cdot3^{n+3}=3^{n+7}\\2130\cdot3^n+10\cdot3^{n+1}+3^{n+3}=3^{n+7}\\99\cdot3^n+687\cdot3^{n+1}+3^{n+3}=3^{n+7}$$

Try using this method to find identities for other values of $k$ (including negative integers!).
AnswerKenntnis:
A proof which, unlike all other suggestions, doesn't require power as a prerequisite.

This is what your son noticed by himself by looking at the first occurences in the sequence:

1 ├ù 100 + 2 ├ù 10 + 8 = 128

Now, let him remark that he can multiply everything by 2 without affecting the equality:

2 ├ù (1 ├ù 100 + 2 ├ù 10 + 8) = 2 ├ù 128

Assuming that he understands that the doubling distributes over the sum, he will obtain:

2 ├ù 1 ├ù 100 + 2 ├ù 2 ├ù 10 + 2 ├ù 8 = 2 ├ù 128

Then remark that when you double any pick you obtain of course the next pick in the sequence:

2 ├ù 100 + 4 ├ù 10 + 16 = 256

Repeat. Multiply both sides by two, distribute and double every pick again, and you obtain one more equality:

4 ├ù 100 + 8 ├ù 10 +  32 = 512

Repeat.

Now he should be pretty much convinced that his statement holds for any pick.
(Of course it could be a good opportunity to introduce recurrence!)
AnswerKenntnis:
You may obverse that whenever in any geometric progression $a_n=\lambda^na_0$, one term satisfies a linear recurrence ($a_n=c_0a_0+c_1a_1+\cdots+c_{n-1}a_{n-1}$, where some coefficients $c_i$ may be zero and the corresponding terms dropped), then every further term of the sequence satisfies the same recurrence: $a_{i+n}=c_0a_i+c_1a_{i+1}+\cdots+c_{n-1}a_{i+n-1}$. This is because the relation has simply been multiplied by $\lambda^i$. Even every term in another geometric progression with ratio$~\lambda$ will satisfy the recurrence.

What make the example especially attractive is that the nonzero coefficients are all powers of$~10$, which makes the linear combination easy to compute; this is related to the fact that all (nonzero) digits of $2^7=128$ themselves occur as powers of $2$. The same phenomenon happens for $2^{10}=1024$: take $1000$ times some power of$~2$, add $10~$times the next power of two, and once the one after that; the result is present again $8~$places further in the same progression. (For the digits of $2^{11}=2048$ you basically get the same relation.)
AnswerKenntnis:
Nice discovery, truly impressive for a boy.
The answers have already show the justification, I just wanted to display three examples of the property, probably this corresponds to how it was discovered:

    1 . .        4 . .          1 6 . .    
  +   2 .      +   8 .        +   3 2 .    
        8          3 2            1 2 8    
    -----       ------         --------    
    1 2 8        5 1 2          2 0 4 8
AnswerKenntnis:
A way of beginning understanding it is for example:

Take any number in the series, multiply by $30$, add the next one. You get the one that is five to the right of where you started.

Because multiplying by $30$ then adding the next one is the same as just multiplying by $32$. Which is the same as multiplying by $2$ five times.
AnswerKenntnis:
One could just manipulate the left-hand-side to be multiples of $2^{n+2}$ $:$
$${5^2} \times {2^{n + 2}} + 5 \times {2^{n + 2}} + 2 \times {2^{n + 2}}$$

Factoring,
$${2^5}{2^{n + 2}}$$
 And therefore, the Right Hand Side $$2^{n+7}$$ q.e.d.
AnswerKenntnis:
Proof by Induction. 
Base case for $n = 1$ is $100 \cdot 2^1 + 10 \cdot 2^2 + 2^4 = 200 + 40 + 16 = 256 = 2^8 = 2^{1+7}$. 
Now to prove that it is true for $n+1$, given it is true for $n$. 
$f(n+1) = 100 \cdot 2^{n+1} + 10 \cdot 2^{n+2} + 2^{n+4}$ $= 2 \cdot (100 \cdot 2^n + 10 \cdot 2^{n+1} + 2^{n+3})$ $= 2 \cdot 2^{n+7} = 2^{(n+1)+7}$.
AnswerKenntnis:
Here's my non-mathematical answer:


It works for elements $1, 2, 4$ and $8$ of your series (whose values are $1, 2, 8$ and $128$): $1 \times 100 + 2 \times 10 + 8 = 128$
If you start anywhere else (say, at term $16$, whose value is $\,\,32768$), then you can just divide all those terms by $32768$ to have the same expression as in step 1.


So I think any expression involving a series of terms in the $2^n$ series would work.
QuestionKenntnis:
What are imaginary numbers?
qn_description:
At school I really struggled to understand the concept of imaginary numbers.  My teacher told us that an imaginary number is a number which has something to do with the square root of -1.  When I tried to calculate the square root of -1 on my calculator, it gave me an error.  To this day I do not understand imaginary numbers.  It makes no sense to me at all.  Is there someone here who totally gets it and can explain it?

Why is the concept even useful?
AnswersKenntnis
AnswerKenntnis:
Let's go through some questions in order and see where it takes us. [Or skip to the bit about complex numbers below if you can't be bothered.]

What are natural numbers?

It took quite some evolution, but humans are blessed by their ability to notice that there is a similarity between the situations of having three apples in your hand and having three eggs in your hand. Or, indeed, three twigs or three babies or three spots. Or even three knocks at the door. And we generalise all of these situations by calling it 'three'; same goes for the other natural numbers. This is not the construction we usually take in maths, but it's how we learn what numbers are.


  Natural numbers are what allow us to count a finite collection of things. We call this set of numbers $\mathbb{N}$.


What are integers?

Once we've learnt how to measure quantity, it doesn't take us long before we need to measure change, or relative quantity. If I'm holding three apples and you take away two, I now have 'two fewer' apples than I had before; but if you gave me two apples I'd have 'two more'. We want to measure these changes on the same scale (rather than the separate scales of 'more' and 'less'), and we do this by introducing negative natural numbers: the net increase in apples is $-2$.


  We get the integers from the naturals by allowing ourselves to take numbers away: $\mathbb{Z}$ is the closure of $\mathbb{N}$ under the operation $-$.


What are rational numbers?

My friend and I are pretty hungry at this point but since you came along and stole two of my apples I only have one left. Out of mutual respect we decide we should each have the same quantity of apple, and so we cut it down the middle. We call the quantity of apple we each get 'a half', or $\frac{1}{2}$. The net change in apple after I give my friend his half is $-\frac{1}{2}$.


  We get the rationals from the integers by allowing ourselves to divide integers by positive integers [or, equivalently, by nonzero integers]: $\mathbb{Q}$ is (sort of) the closure of $\mathbb{Z}$ under the operation $\div$.


What are real numbers?

I find some more apples and put them in a pie, which I cook in a circular dish. One of my friends decides to get smart, and asks for a slice of the pie whose curved edge has the same length as its straight edges (i.e. arc length of the circular segment is equal to its radius). I decide to honour his request, and using our newfangled rational numbers I try to work out how many such slices I could cut. But I can't quite get there: it's somewhere between $6$ and $7$; somewhere between $\frac{43}{7}$ and $\frac{44}{7}$; somewhere between $\frac{709}{113}$ and $\frac{710}{113}$; and so on, but no matter how accurate I try and make the fractions, I never quite get there. So I decide to call this number $2\pi$ (or $\tau$?) and move on with my life.


  The reals turn the rationals into a continuum, filling the holes which can be approximated to arbitrary degrees of accuracy but never actually reached: $\mathbb{R}$ is the completion of $\mathbb{Q}$.


What are complex numbers? [Finally!]

Our real numbers prove to be quite useful. If I want to make a pie which is twice as big as my last one but still circular then I'll use a dish whose radius is $\sqrt{2}$ times bigger. If I decide this isn't enough and I want to make it thrice as big again then I'll use a dish whose radius is $\sqrt{3}$ times as big as the last. But it turns out that to get this dish I could have made the original one thrice as big and then that one twice as big; the order in which I increase the size of the dish has no effect on what I end up with. And I could have done it in one go, making it six times as big by using a dish whose radius is $\sqrt{6}$ times as big. This leads to my discovery of the fact that multiplication corresponds to scaling $-$ they obey the same rules. (Multiplication by negative numbers responds to scaling and then flipping.)

But I can also spin a pie around. Rotating it by one angle and then another has the same effect as rotating it by the second angle and then the first $-$ the order in which I carry out the rotations has no effect on what I end up with, just like with scaling. Does this mean we can model rotation with some kind of multiplication, where multiplication of these new numbers corresponds to addition of the angles? If I could, then I'd be able to rotate a point on the pie by performing a sequence of multiplications. I notice that if I rotate my pie by $90^{\circ}$ four times then it ends up how it was, so I'll declare this $90^{\circ}$ rotation to be multiplication by '$i$' and see what happens. We've seen that $i^4=1$, and with our funky real numbers we know that $i^4=(i^2)^2$ and so $i^2 = \pm 1$. But $i^2 \ne 1$ since rotating twice doesn't leave the pie how it was $-$ it's facing the wrong way; so in fact $i^2=-1$. This then also obeys the rules for multiplication by negative real numbers.

Upon further experimentation with spinning pies around we discover that defining $i$ in this way leads to numbers (formed by adding and multiplying real numbers with this new '$i$' beast) which, under multiplication, do indeed correspond to combined scalings and rotations in a 'number plane', which contains our previously held 'number line'. What's more, they can be multiplied, divided and rooted as we please. It then has the fun consequence that any polynomial with coefficients of this kind has as many roots as its degree; what fun!


  The complex numbers allow us to consider scalings and rotations as two instances of the same thing; and by ensuring that negative reals have square roots, we get something where every (non-constant) polynomial equation can be solved: $\mathbb{C}$ is the algebraic closure of $\mathbb{R}$.


[Final edit ever: It occurs to me that I never mentioned anything to do with anything 'imaginary', since I presumed that Sachin really wanted to know about the complex numbers as a whole. But for the sake of completeness: the imaginary numbers are precisely the real multiples of $i$ $-$ you scale the pie and rotate it by $90^{\circ}$ in either direction. They are the rotations/scalings which, when performed twice, leave the pie facing backwards; that is, they are the numbers which square to give negative real numbers.]

What next?

I've been asked in the comments to mention quaternions and octonions. These go (even further) beyond what the question is asking, so I won't dwell on them, but the idea is: my friends and I are actually aliens from a multi-dimensional world and simply aren't satisfied with a measly $2$-dimensional number system. By extending the principles from our so-called complex numbers we get systems which include copies of $\mathbb{C}$ and act in many ways like numbers, but now (unless we restrict ourselves to one of the copies of $\mathbb{C}$) the order in which we carry out our weird multi-dimensional symmetries does matter. But, with them, we can do lots of science.

I have also completely omitted any mention of ordinal numbers, because they fork off in a different direction straight after the naturals. We get some very exciting stuff out of these, but we don't find $\mathbb{C}$ because it doesn't have any natural order relation on it.

Historical note

The above succession of stages is not a historical account of how numbers of different types are discovered. I don't claim to know an awful lot about the history of mathematics, but I know enough to know that the concept of a number evolved in different ways in different cultures, likely due to practical implications. In particular, it is very unlikely that complex numbers were devised geometrically as rotations-and-scalings $-$ the needs of the time were algebraic and people were throwing away (perfectly valid) equations because they didn't think $\sqrt{-1}$ could exist. Their geometric properties were discovered soon after.

However, this is roughly the sequence in which these number sets are (usually) constructed in ZF set theory and we have a nice sequence of inclusions
$$1 \hookrightarrow \mathbb{N} \hookrightarrow \mathbb{Z} \hookrightarrow \mathbb{Q} \hookrightarrow \mathbb{R} \hookrightarrow \mathbb{C}$$

Stuff to read


The other answers to this question give very insightful ways of getting $\mathbb{C}$ from $\mathbb{R}$ in different ways, and discussing how and why complex numbers are useful $-$ there's only so much use to spinning pies around.
A Visual, Intuitive Guide to Imaginary Numbers $-$ thanks go to Joe, in the comments, for pointing this out to me.
Some older questions, e.g. here and here, have some brilliant answers.


I'd be glad to know of more such resources; feel free to post any in the comments.
AnswerKenntnis:
You ask why imaginary numbers are useful. As with most extensions of number systems, historically such generalizations were invented because they help to simplify certain phenomena in existing number systems. For example, negative numbers and fractions permit one to state in a single general form the quadratic equation and its solution (older solutions bifurcated into many cases, avoiding negative numbers and fractions). One of the primary reasons motivating the invention of complex numbers is that they serve to linearize what would otherwise be nonlinear phenomena - thus greatly simplifying many problems. Here are some examples. 

Consider the problem of representing integers as sums of squares $\rm\: n = x^2 + y^2$. Early solutions to this and related problems employed a complicated arithmetic of binary quadratic forms. Such arithmetic was quite intricate and often very nonintuitive, e.g. even the proof of associativity of composition of such forms was a tour de brute force, occupying pages of unmotivated computations in Gauss' Disq. Arith. But this quadratic arithmetic of binary quadratic forms can be linearized. Indeed, by factorization $\rm\: x^2 + y^2 = (x+y{\it i})(x-y{\it i}),$ which allows us to view sums of squares as norms of Gaussian integers $\rm\:x+y{\it i},\ \ x,y\in \Bbb Z.\:$ But just like the rational integers $\Bbb Z,$ these "imaginary" integers have a Euclidean algorithm, so enjoy unique factorization into primes. By considering all the possible factorizations of $\rm\:n\:$ in the Gaussian integers we obtain all the possible representations of $\rm\:n\:$ as a sum of squares. In a similar way, "rational, real" arithmetic of integral quadratic forms becomes much simpler by passing to the "irrational" and/or "imaginary" arithmetic of quadratic number fields. This line of research led to the discovery of ideals and modules, fundamental linear structures at the heart of modern number theory and algebra.

Thus, by factorizing completely over $\Bbb C$, we have reduced the complicated nonlinear arithmetic of binary quadratic forms to the simpler, linear arithmetic of Gaussian integers, i.e. to the more familiar arithmetical structure of a unique factorization domain (in fact a Euclidean domain).  Analogous linearization serves to simplify many problems. For example, when integrating or summing  rational functions (quotients of polynomials), by factoring denominators over $\Bbb C$ (vs. $\Bbb R)$ and taking partial fraction decompositions, the denominators are at worst powers of linear (vs. quadratic) polynomials - which greatly simplifies matters. More generally, when solving constant coefficient differential or difference equations (recurrences), by factoring their characteristic (operator) polynomials over $\Bbb C,$ we reduce to solutions of linear (vs. quadratic) differential or difference equations. In the same way, there are many real problems (over $\Bbb R)$ whose simplest solutions are obtained by an imaginary detours (over $\Bbb C).$  Perhaps readers will mention more such problems in the comments.
AnswerKenntnis:
I went to school for electrical engineering (7 years total) and we used imaginary numbers all over the place.

Even with all that schooling, this is probably the clearest explanation of imaginary numbers I've seen:

http://betterexplained.com/articles/a-visual-intuitive-guide-to-imaginary-numbers/

HTH.
AnswerKenntnis:
Well, as you know there's no real number whose square is negative. But now imagine numbers which are. Let's call them imaginary. Now what properties would such numbers have? Well, there would be for example a number whose square is $-1$. Let's call that number the imaginary unit and give it the name $\mathrm i$. Now if we multiply this number with some real number, that is, use $r\mathrm i$, we get a number whose square is $(\mathrm ir)^2 = \mathrm i^2r^2 = -r^2$. Since all positive numbers can be written as $r^2$, we get that all negative numbers can be written as $(\mathrm ir)^2$. Thus the products $\mathrm ir$ are our imaginary numbers. We also see that $(-\mathrm i)^2 = (-1)^2\mathrm i^2 = -1$, so there are actually two numbers whose square is $-1$ (which makes sense because, after all, there are also two numbers whose square is $1$, namely $1$ and $-1$).

OK, but what happens if we add a real number and one of out imaginary numbers. Well, now things get complex. We get general complex numbers.

OK, but how do we know that we've not just made some nonsense, similar to the nonsense that we get when we invent a number $o$ so that $0o=1$? Well to see that, we recognize that all complex numbers are of the form $x+\mathrm iy$ with real numbers $x$ and $y$, and thus the pair $(x,y)$ completely specifies a complex number. Therefore now we re-derive the complex numbers as pairs of real numbers, but now using proper mathematical instruments so we know for sure that whatever we do is well defined. Since doing that we arrive at the very same structure which we just had derived in a quite informal way, we know that the complex numbers are a sound mathematical structure.

OK, now that we have invented the imaginary and complex numbers, are they useful for something? Well, indeed they are. For example, several mathematical statements are much easier in complex numbers than in real numbers. For example, with complex numbers, every polynomial can be written in the form $a(x-x_1)(x-x_2)\cdots(x-x_n)$. With real numbers, this is impossible for polynomials having for example factors of the form $(x^2+1)$. Moreover, we have the very useful relation $\mathrm e^{\mathrm i\phi} = \cos\phi + \mathrm i\sin\phi$. So forget about complicated addition theorems for sine and cosine. Just rewrite your formula in complex exponentials and enjoy the simple relation $\mathrm e^{\mathrm i(\alpha+\beta)}=\mathrm e^{\mathrm i\alpha}\mathrm e^{\mathrm i\beta}$.

Finally, if you want to do quantum physics (and almost all modern physics is quantum physics) you'll find that you have to use complex numbers.
AnswerKenntnis:
The term "imaginary" is somewhat disingenuous. It's a real concept, with real (at least theoretical) application, just like all the "real" numbers.

Think back to that algebra class. You were asked to solve a polynomial equation; that is, find all the values of X for which the entire equation evaluates to zero. You learned to do this by polynomial factoring, simplifying the equation into a series of first-power terms, and then it was easy to see that if any one of those terms evaluated to zero, then everything else, no matter its value, was multiplied by zero, producing zero.

You tried this on a few quadratic equations. Sometimes you got one answer (because the equation was $y=ax^2$ and so the only possible answer was zero), sometimes you got two (when the equation boiled down to $y= (x\pm n)(x \pm m)$, and so when $x=-m$ or $x=-n$ the equation was zero), and a couple of times, you got no answers at all (usually, an equation that breaks down to $y=(x+n)(x+m)$ doesn't evaluate to zero at $x=-m$ or $x=-n$).

In your algebra class, you're told this just happens sometimes, and the only way to make sure any factored term $(x\pm k)$ represents a real root is to plug in $-k$ for $x$ and solve. But, this is math. Mathematicians like things to be perfect, and don't like these "rules of thumb", where a method works sometimes but it's really just a "hint" of where to look. So, mathematicians looked for another solution.

This leads us to application of the quadratic formula: for $ax^2 + bx + c = 0$, $x=\dfrac{-b \pm \sqrt{b^2-4ac}}{2a}$. This formula is quite literally the solution of the general form of the equation for x, and can be derived algebraically. We can now plug in the coefficients, and find the values of $x$ where $ax^2 + bx + c=0$. Notice the square root; we're first taught, simply, that if $b^2-4ac$ is ever negative, then the roots you'd get by factoring the equation won't work, and thus the equation has no real roots. $b^2-4ac$ is called the determinant for this reason. 

But, the fact that $b^2-4ac$ can be negative remains a thorn in our side; we want to solve this equation. It's sitting right in front of us. If the determinant were positive, we would have solved it already. It's that pesky negative that's the problem.

Well, what if there was something we could do, that conforms to the rules of basic algebra, to get rid of the negative? Well, $-m = m*-1$, so what if we took our term that, for the sake of argument, evaluated to $-36$, and made it $36*-1$? Now, because $\sqrt{mn} = \sqrt{m}\sqrt{n}$, $\sqrt{-36} = \sqrt{36}\sqrt{-1} = 6\sqrt{-1}$. We've simplified the expression by removing what we can't express as a real number from what we can. 

Now to clean up that last little bit. $\sqrt{-1}$ is a common term whenever the determinant is negative, so let's abstract it behind a constant, like we do $\pi$ and $e$, to make things a little cleaner. $\sqrt{-1} = i$. Now, we can define some properties of $i$, particularly a curious thing that happens as you raise its power:

$$i^2 = \sqrt{-1}^2 = -1$$
$$i^3 = i^2*i = -i$$
$$i^4 = i^2*i^2 = -1*-1 = 1$$
$$i^5 = i^4*i = i$$

We see that $i^n$ transitions through four values infinitely as its power $n$ increases, and also that this transition crosses into and then out of the real numbers. Seems almost... circadian, rotational. As Clive N's answer so elegantly explains it, that's what imaginary numbers represent; a "rotation" of the graph through another plane, where the graph DOES cross the $x$-axis. Now, it's not actually really a circular rotation onto a new linear z-plane. Complex numbers have a real part, as you'd see by solving the quadratic equation for a polynomial with imaginary roots. We typically visualize these values in their own 2-dimensional plane, the complex plane. A quadratic equation with imaginary roots can thus be thought of as a graph in four dimensions; three real, one imaginary.

Now, we call $i$ and any product of a real number and $i$ "imaginary", because what $i$ represents doesn't have an analog in our "everyday world". You can't hold $i$ objects in your hand. You can't measure anything and get $i$ inches or centimeters or Smoots as your result. You can't plug any number of natural numbers together, stick a decimal point in somewhere and end up with $i$. $i$ simply is.



As far as having use outside "ivory tower" math disciplines, a big one is in economics; many economies of scale can be described as a function of functions of the number of units produced, with a cost term and a revenue term (the difference being profit or loss), each of these in turn defined by a function of the per-unit sale price or cost and the number produced. This all generally simplifies to a quadratic equation, solvable by the quadratic formula. If the roots are imaginary, so are the breakeven points (and your expected profits).

Another good one is in visualizations of complex numbers, and of their interactions when multiplied. The first one I was exposed to is a well-known series set, produced by taking an arbitrary complex number, squaring it ($(a+bi)^2 = (a+bi)(a+bi) = a^2 + 2abi + b^2i^2 = a^2-b^2 + 2abi$), and then adding back its original value. Repeated to infinity with this number, the series either converges to zero or diverges to infinity (with a few starting numbers exhibiting periodicity; they'll jump around infinitely between a finite number of points much like $i$ itself does). The set of all complex numbers for which the series does not diverge is the Mandelbrot set or M-set, and while the area of the graph is finite, its perimeter is infinite, making the graph of this set a fractal (one of the most highly-studied, in fact). 

The Mandelbrot set can in turn be defined as the set of all complex numbers $c$ for which the Julia set $J(f)$ of $f(z)=z^2 + c \to z$ is connected. A Julia set exists for every complex polynomial function, but usually the most interesting and useful sets are the ones for values of $c$ that belong to the M-set; Julia fractals are produced much the same way as the M-set (by repeated iteration of the function to determine if a starting $z$ converges or diverges), but $c$ is constant for all points of the set instead of being the original point being tested. You can define Julia sets with all sorts of fractal shapes. These fractals, more accurately the iterative evaluation behind them, are used for pseudorandom number generation, computer graphics (the sets can be plotted in 3-d to create landscapes, or they can be used in shaders to define complex reflective properties of things like insect shells/wings), etc.
AnswerKenntnis:
This question has already been answered quite thoroughly, but I just want to add that generally speaking, besides the whole numbers, none of the numbers we use "exist" in the real world.  The only reason we have adopted extensions to the whole numbers to the natural, integer, rational, real, and complex sets in turn is because these extensions make problems solvable when thinking abstractly.  At the end of the day, everything relates back to the whole numbers, however.

Most people use all of the sets except for complex numbers in very commonplace, everyday situations, which is why we've come to view everything up to the real numbers as being fairly intuitive, at least at first glance. (When you dig under the surface, everything gets a great deal more subtle, which is why there are people who study primarily numbers, who we call number theorists.  But that's a whole other story.)

It's important to note that this progression isn't the only way to extend the whole numbers.  There are hundreds of different arithmetics that have been designed, many not even based on the whole numbers.  It's just that the usual extension applies to so many situations that come up commonly.  (People who study universal algebra study the ways in which different possible math systems are alike and different.  But that's a whole other story as well.)

Complex numbers have taken their place as the normal extension to the reals because they are so useful when dealing with polynomials, which happen to arise in a massive number of mathematical situations.  They also allow the exponential function and the trigonometric functions to be viewed as special cases of the same thing, through Euler's Formula, which enables all sorts of great algebra tricks.  Specifically, these sorts of functions pop up constantly when using either Taylor or Fourier series to simplify the process of working on problems with tricky transcendental functions.  Complex numbers make dealing with these representations a breeze (relatively).

There are even further extensions.  If instead of worrying about how to take the square root of -1, you worry about what happens past infinity, the real numbers can alternatively be expanded in several jumps to include hyperreals, superreals, and surreals.  None of these systems have caught on, though, because we have alternative ways of dealing with the infinite and infinitesimal quantities in calculus that people find more powerful/convenient.

You can also zip on past complex numbers to Quaternions, and octonions on top of that.  Vectors generalize all of the above.  They aren't often though of as numbers, but are similar in that they generalize the concept of a property of an object having a mathematical value.  Matrixes generalize vectors, and tensors generalize matrixes.  

As you climb this ladder, you gain more and more mathematical power, but you start to lose properties that we expect of whole numbers.  For complex numbers, order (greater than/less than) begins to become ambiguous.  We generally don't think of vectors as "numbers" because we want all operations on vectors to work regardless of dimension, and most of the arithmetic operations don't really generalize.  With matrixes, the commutative property goes out the window, and things start to get really weird, especially when the matrixes aren't square.  And so forth.

All of this to say that numbers are best viewed as machinery.  Different number systems are really only used to the extent which they make a given math situation or problem easier to think about.  If you're an engineer, complex numbers do this in many, many situations, which justifies their added...complexity.  If you're not an engineer, they're definitely worth understanding, but you may not find uses for them on a daily basis.
AnswerKenntnis:
Complex numbers are just a handy way to handle two dimensional points and move them around. The key to it is understanding that i × i = −1 is just a simple by-product of moving these points around.

Real numbers correspond to numbers on a line (one dimension), which is usually how they are represented: a single axis where each number has a position.
Operations on these real numbers have been defined to apply the two most basic transformations:


Translation (addition)

Move a point by a given amount.
Scaling (multiplication)

Move a point by an amount related to its value, e.g., two times further than it was.


Now, for a number of situations, you need to handle elements that are not on a line, but on a planeΓÇöyou are now in two dimensions. When working in two dimensions, you need to know where you are horizontally and vertically, which you usually represent with two numbers. For instance, (3, 2) is ΓÇ£3 to the right, 2 upΓÇ¥. Complex numbers are designed to manipulate these elements with dimensions with ΓÇ£simpleΓÇ¥ mathematics.

We define i as being the vertical unit. 2i is ΓÇ£2 upΓÇ¥, −4i is ΓÇ£4 downΓÇ¥, and 3 + 2i is ΓÇ£3 to the right and 2 upΓÇ¥. We still can use translation and scaling like in the one-dimension case, but we would like to add something: rotation. How do I turn ΓÇ£2 to the rightΓÇ¥ into ΓÇ£2 upΓÇ¥?

The solution comes with multiplying by i. If 1 is ΓÇ£1 to the rightΓÇ¥ and 1 × i is ΓÇ£1 upΓÇ¥, then it means that multiplying by i is simply rotating by 90 degrees with point 0 as a center, counter-clockwise. 2 × i = 2i means ΓÇ£2 to the rightΓÇ¥ multiplied by i gives ΓÇ£2 upΓÇ¥.

And this is where it gets interesting: rotating the point ΓÇ£1 to the rightΓÇ¥ by 90 degrees gives ΓÇ£1 upΓÇ¥. Rotating it again by 90 degrees gives ΓÇ£1 leftΓÇ¥. This means that multiplying 1 twice by i gives −1.

We have 1 × i × i = −1, and since i × i = −1, i is by definition the square root of −1.
AnswerKenntnis:
I think of i as just a symbol to represent an operation 


      √-1


When we want the square root of -1, just represent the whole statement with a symbol without evaluating it. This avoids the necessity of trying to explain it further, we don't need to map the answer to some real world concept, it's just a saved operation. We also know that the square root has the following property: 


      √x √x = x


No matter what the x. i.e. 


      √-1 √-1 = -1


Numbers are useful to me when they represent concepts in the real world. I don't map i to anything in the real world but with this ability to represent the operation, I can now manipulate it in algebraic expressions to ultimately get back to non-imaginary numbers that I do find useful. http://en.wikipedia.org/wiki/Euler%27s_formula
AnswerKenntnis:
This argument is a loose argument for the sake of simplicity and because I know little about the subject. However, I think it may be good for non-mathematicians. 

The simplistic view is to note that imaginary numbers (or Complex Numbers) are numbers that are defined by humans to describe quantities different from the numbers we use in our day-to-day life (unless you are a scientist). They have certain rules that are somewhat different than those we use to calculate with non-complex numbers. Hence, the subjects of (Complex Variables and Complex Analysis). 

In mathematics, this is not strange. There are concepts that may look surprising until you study them carefully. For example, in Binary Numbers $1+1=10$. This result does not make any sense unless you understand and realize that the result is valid in the Binary System, domain or framework. 

Personally, I thought about this before I read your question, and found that the problem comprehending such concepts could arise when you think about a concept outside its framework (or domain) and try to rationalize the results using our every day concepts. 

For example trying to evaluate the $\sqrt{-1}$ on a regular calculator with no setting for Imaginary Arithmetic (the proper name is probably Complex Arithmetic). The calculator has to be set to the correct mode (or framework) to give a correct result. In fact, the software in your calculator should have given you a decent error message (or better yet the result of $i$ with a warning note).

Again, the same thing will happen if you are using your calculator in Binary mode to add $1+1$, you will not get the familiar $2$.

Many other examples can be driven around the same concept.

I hope this helps.
AnswerKenntnis:
I'm surprised that, as far as I can see, no one has mentioned Paul Nahin's book "An imaginary tale : the story of ΓêÜ-1", pub: Princeton University Press ISBN 0-691-12798-0. It is a historical account of how  ΓêÜ-1 became a necessary mathematical tool, and is written in an easy to read conversational style. I keep re-reading parts of it, like going over old ground again with a friend.

Two reviews give contrasting opinions: the first very favourable http://plus.maths.org/content/imaginary-tale; the second giving a long list of (alleged -- I haven't checked them independently) inaccuracies and omissions: http://www.ams.org/notices/199910/rev-blank.pdf
AnswerKenntnis:
Check it out, I just learned this very recently:

Define the set of all ordered pairs $(x, y)$, call it $\mathbb{C}$, the set of complex numbers. We call $x$ the real part, and y the imaginary part.
Now define multiplication like this:

$(x, y) \cdot (a,b) = (xa-yb, xb+ya) $

Now I'm not sure what that's supposed to be but observe:

$(0, 1)^2 = (0,1) \cdot(0,1)= (0-1, 0+0) = (-1, 0)$

Since the second number in the ordered pair is the imaginary part, (0,1) corresponds to $0+1\cdot i =i$. (In fact all complex numbers $(x, y)$ correspond to $x+yi$ ).

So I have just shown you how defining multiplication that way results in $i^2 = -1$.

But that multiplication isn't the multiplication I'm familiar with!, you say.
Well guess what:

$a\cdot b = (a, 0) \cdot (b, 0) = (ab-0,0+0) = (ab, 0) = ab $

Yes it is!

So what I get from this is that essentially someone said: "What if there was a number that could be squared to get -1", and there you have it!

In fact, once you define addition like this:

$(a, b) + (x, y) = (a+b, x+y)$

I'm pretty sure you'll find this new system of complex numbers, $\mathbb{C}$, to be compatible with the old set of real numbers, $\mathbb{R}$ .
AnswerKenntnis:
One answer for why imaginary (and complex) numbers are useful is that they provide solutions to polynomial equations. (The square root of -1 part comes from trying to solve the equation $x^2 = -1$, which has no real number solutions.) The Fundamental Theorem of Algebra states that any polynomial equation with real (or even complex!) coefficients has solutions in the complex number system. 

The theorem doesn't always seem very powerful, because a lot of times we discard all non-real solutions. But, this isn't always the case. Linear (ordinary) differential equations can be solved by first solving an associated polynomial equation. The complex solutions to the polynomial equation end up influencing the solution to the differential equation.
AnswerKenntnis:
This is probably not helpful for someone first learning about imaginary numbers, but my personal motivation for complex numbers is so that every linear transformation over the reals can be decomposed into a direct sum of shift plus scaling operators, ie. the Jordan normal form exists.

If you work with matrices/linear operators over the reals for long enough, this is something that "feels" like it should be true - like some sort of linear algebra version of the pigeonhole principle - but it doesn't quite work over the reals because of rotation matrices. On the other hand, rotation is "like" a scaling because if you apply a rotation twice, it's the same as rotating twice as much once, so one feels this shouldn't really be an obstruction.

In any case, complex numbers are exactly the number system you need to ensure Jordan normal form exists, where rotations are scalings of complex eigenvectors by a complex number.
AnswerKenntnis:
I just think of imaginary numbers as a definition. In the "real world" you cannot take the square root of $ΓêÆ1$ (which is what is happening with your calculator). However, we just define some "number", call it $i$, such that $i^2=ΓêÆ1$, add it to our number system and see what happens. So when you study imaginary numbers, you are just "seeing what happens".

One can then write every number as $a+ib$ where $a,b\in\mathbb{R}$ ($a$ and $b$ are real numbers) and $i^2=ΓêÆ1$. In his comment, ivan is taking this pair $(a,b)$ and pointing out that this pair defines a point on a plane (so, like, a piece of paper, as when you draw a graph). This is the way that people often view imaginary numbers - as points on the plane (and the plane is the Complex Plane, or an Argand diagram).
AnswerKenntnis:
Imaginary numbers can also be thought of as a simple hack mathematicians use when they want to keep units separate.

Need a result with more than one component? make it a multiple of something that won't resolve. Pretty handy.
AnswerKenntnis:
@  I just want to add that generally speaking, besides the whole numbers, none of the numbers we use "exist" in the real world.

@ Sachin Kainth
Hmmm. The question you ask is a deep one. The answer is far from easy. The quote above from one of the earlier answers is not right. I am not sure that "whole numbers" do "exist in the real world", let alone that "real numbers" do, or that complex numbers, quaternions or octonions don't.

The relationship between maths and the real world is extremely mysterious. It goes straight into the classic "God is a Mathematician" statement. I do not remotely have time to go into it properly here. Whole books have been written about it. Some better than others.

One viewpoint is simply to ignore questions of "reality" or relationship to the "real world" and say that complex numbers are exceedingly useful. Another approach is to go down the Clifford Algebra route, originally pioneered by William Clifford (1845-79) at my old college (Trinity, Cambridge) and which has recently seen an explosion of interest by theoretical physicists led perhaps by Stephen Gull at the Cavendish. Roger Penrose (Oxford) is also interesting on the subject of complex numbers.

But all that stuff requires some math sophistication to understand. An important prior question is "real numbers" or even fractions. There are many deeply puzzling and paradoxical questions about them. I suspect you have not been exposed to them.

Looking for someone who "totally gets it" is likely to be a vain hope. If you find them, let me know!
AnswerKenntnis:
Imaginary numbers were invented to make calculations easier. Everyone knows the quadratic formula; when Cardano was working on the formula for cubics (known as Cardano's formula), he found out that it was extremely hard to write down a formula unless you out down some symbol as a placeholder for $\sqrt{-1}$, which you manipulate like a number and which always cancelled out in the end. So he left it in. He was embarrassed by it, and called it imaginary, but the formula worked. Mathematicians later found out that imaginary numbers made a lot of formulas easier, like finding a formula for $\sin(3x)$, and so they found consistent rules for them. Ever since then, they've kept making formulas easier.
AnswerKenntnis:
It's an extension field . . . but since you probably don't know that, the terminology is horrible!  Just think of imaginary numbers as the completion of real numbers so that you can find solutions to the equation

$x^2 + 1 = 0.$

If you set $i = \sqrt{-1}$, then $i$ and $-i$ are solutions to this polynomial.  There are no 'real solutions'.  

It is known that any univariate system of degree $n$ has exactly $n$ solutions in the complex plane.  This can be generalized further to multivariate square systems in that the max number of solutions is the multiplication of the largest degree of each function.

For example,

$x_1^3 + x_1*x_2 + 4 = 0$
$x_1^2*x_2 + x_1 + x_2 - 2 = 0$

has (at most) $3*4 = 12$.  This is known as Bezout's Theorem and is a result of classical algebraic geometry.  Letting $i = \sqrt{-1}$ is necessary to find all the solutions (and it is possible to find these solutions numerically, up to an arbitrary choice of precision).
QuestionKenntnis:
Do complex numbers really exist?
qn_description:
Complex numbers involve the square root of negative one, and most non-mathematicians find it hard to accept that such a number is meaningful. In contrast, they feel that real numbers have an obvious and intuitive meaning. What's the best way to explain to a non-mathematician that complex numbers are necessary and meaningful, in the same way that real numbers are?

This is not a Platonic question about the reality of mathematics, or whether abstractions are as real as physical entities, but an attempt to bridge a comprehension gap that many people experience when encountering complex numbers for the first time. The wording, although provocative, is deliberately designed to match the way that many people do in fact ask this question.
AnswersKenntnis
AnswerKenntnis:
There are a few good answers to this question, depending on the audience. I've used all of these on occasion.

A way to solve polynomials

We came up with equations like x - 5 = 0, what is x?, and the naturals solved them (easily). Then we asked, "wait, what about x + 5 = 0?" So we invented negative numbers. Then we asked "wait, what about 2x = 1?" So we invented rational numbers. Then we asked "wait, what about x^2 = 2?" so we invented irrational numbers.

Finally, we asked, "wait, what about x^2 = -1?" This is the only question that was left, so we decided to invent the "imaginary" numbers to solve it. All the other numbers, at some point, didn't exist and didn't seem "real", but now they're fine. Now that we have imaginary numbers, we can solve every polynomial, so it makes sense that that's the last place to stop.

Pairs of numbers

This explanation goes the route of redefinition. Tell the listener to forget everything he or she knows about imaginary numbers. You're defining a new number system, only now there are always pairs of numbers. Why? For fun. Then go through explaining how addition/multiplication work. Try and find a good "realistic" use of pairs of numbers (many exist).

Then, show that in this system,  (0,1) * (0,1) = (-1,0), in other words, we've defined a new system, under which it makes sense to say that sqrt(-1) = i, when i=(0,1). And that's really all there is to imaginary numbers: a definition of a new number system, which makes sense to use in most places. And under that system, there is an answer to sqrt(-1).

The historical explanation

Explain the history of the imaginary numbers. Showing that mathematicians also fought against them for a long time helps people understand the mathematical process, i.e., that it's all definitions in the end.

I'm a little rusty, but I think there were certain equations that kept having parts of them which used sqrt(-1), and the mathematicians kept  throwing out the equations since there is no such thing.

Then, one mathematician decided to just "roll with it", and kept working, and found out that all those square roots cancelled each other out.

Amazingly, the answer that was left was the correct answer (he was working on finding roots of polynomials, I think). Which lead him to think that there was a valid reason to use sqrt(-1), even if it took a long time to understand it.
AnswerKenntnis:
The concept of mathematical numbers and "existing" is a tricky one.  What actually "exists"?

Do negative numbers exist?  Of course they do not.  You can't have a negative number of apples.

Yet, the beauty of negative numbers is that when we define them (rigorously), then all of a sudden we can use them to solve problems we were never ever able to solve before, or we can solve them in a much simpler way.

Imagine trying to do simple physics without the idea of negative numbers!

But are they "real"?  Do they "exist"?  No, they don't.  But they are just tools that help us solve real life problems.

To go back to your question about complex numbers, I would say that the idea that they exist or not has no bearing on whether they are actually useful in solving the problems of every day life, or making them many, many, many times more easy to solve.

The math that makes your computer run involves the tool that is complex numbers, for instance.
AnswerKenntnis:
No number does "really exist" the way trees or atoms exist.
In physics people however have found use for complex numbers just as they have found use for real numbers.
AnswerKenntnis:
One need only consult the history of algebra to find many informal
discussions on the existence and consistence of complex numbers. 
Any informal attempt to justify the existence of $\mathbb C$ 
will face  the same obstacles that existed in earlier times. Namely, the lack of any rigorous (set-theoretic) foundation makes it difficult to be precise - both syntactically and semantically. Nowadays the set-theoretic foundation of algebraic structures 
is so subconscious that is is easy to overlook just how much power it provides 
for such purposes. But this oversight is easily remedied. One need only consult
some of the older literature where even leading mathematicians struggled
immensely to rigorously define complex numbers. For example, see the
quote below by Cauchy and Hankel's scathing critique - which is guaranteed 
to make your jaw drop! (Below is an excerpt from my post on the notion 
of formal polynomial rings and their quotients).

A major accomplishment of the set-theoretical definition of 
algebraic structures was to eliminate imprecise syntax and semantics. 
By eliminating the syntactic polynomial term $\rm\ a+b\cdot x+c\cdot x^2\ \ $ 
in favor of its set-theoretic semantic reduction 
$\rm\:(a,b,c,0,0,\ldots)\:$, there can no longer be any doubt about the precise denotation of the symbols $\rm\: x,\; +,\;\cdot\:,$ or about their equality, since, by set theory definition, tuples are equal iff their components are equal. Similarly for complex numbers  $\rm\:a + b\cdot i\:$ 
vs. their set-theoretic pair reduction $\rm\:(a,b)\:$ discovered by Hamilton. 
Before Hamilton gave this semantic reduction of $\mathbb C$ to pairs 
of reals, prior syntactic constructions (e.g. by Cauchy) as 
formal expressions or terms $\rm\:a+b\cdot i\:$ were subject to heavy criticism regarding 
the precise denotation of their constituent symbols, e.g. 
precisely what is the meaning of the symbols $\rm\;i, +, = \;$ ? 
In modern language, Cauchy's construction of $\mathbb C$ is simply the 
the quotient ring $\rm\:\mathbb R[x]/(x^2+1)\:,\ $ which he described essentially 
as real polynomial expressions modulo $\rm\:x^2+1\:$. However, in Cauchy's time 
mathematics lacked the necessary (set-theory) foundations to 
rigorously define the syntactic expressions comprising the
polynomial ring term algebra $\rm\mathbb R[x]$, and its quotient ring of
congruence classes $\rm\:(mod\ x^2+1)\:$. The best that Cauchy could 
do was to attempt to describe the constructions in terms of 
imprecise natural (human) language, e.g, in 1821 Cauchy wrote: 


  In analysis, we call a symbolic expression any combination of 
  symbols or algebraic signs which means nothing by itself but 
  which one attributes a value different from the one it should 
  naturally be [...] Similarly, we call symbolic equations those 
  that, taken literally and interpreted according to conventions 
  generally established, are inaccurate or have no meaning, but 
  from which can be deduced accurate results, by changing and 
  altering, according to fixed rules, the equations or symbols 
  within [...] Among the symbolic expressions and equations 
  whose theory is of considerable importance in analysis, one 
  distinguishes especially those that have been called imaginary. $\quad$ -- Cauchy, Cours d'analyse,1821, S.7.1


While nowadays, using set theory, we can rigorously interpret such "symbolic expressions" 
as terms of formal languages or term algebras, it was far too 
imprecise in Cauchy's time to have any hope of making sense 
to his colleagues, e.g. Hankel replied scathingly: 


  If one were to give a critique of this reasoning, we can not 
  actually see where to start. There must be something "which 
  means nothing," or "which is assigned a different value than 
  it should naturally be" something that has "no sense" or is 
  "incorrect", coupled with another similar kind, producing 
  something real. There must be "algebraic signs" - are these 
  signs for quantities or what? as a sign must designate something 
  - combined with each other in a way that has "a meaning." I do 
  not think I'm exaggerating in calling this an unintelligible 
  play on words, ill-becoming of mathematics, which is proud 
  and rightly proud of the clarity and evidence of its concepts. $\quad$-- Hankel


Thus it comes as no surprise that Hamilton's elimination 
of such "meaningless" symbols - in favor of pairs of reals - 
served as a major step forward in placing such numbers on a 
foundation more amenable to his contemporaries. 
Although there was not yet any theory of sets in which to 
rigorously axiomatize the notion of pairs, they were far easier 
to accept naively - esp. given the already known closely 
associated geometric interpretation of complex numbers. 
Hamilton introduced pairs as 'couples' in 1837 [1]: 


  p. 6: The author acknowledges with pleasure that he agrees with 
  M. Cauchy, in considering every (so-called) Imaginary Equation 
  as a symbolic representation of two separate Real Equations: 
  but he differs from that excellent mathematician in his method 
  generally, and especially in not introducing the sign  sqrt(-1) 
  until he has provided for it, by his  Theory of Couples, 
  a possible and real meaning, as a symbol of the couple (0,1) 
  
  p. 111:  But because Mr. Graves employed, in his reasoning, the 
  usual principles respecting about Imaginary Quantities, and 
  was content to prove the symbolical necessity without showing 
  the interpretation, or inner meaning, of his formulae, the 
  present Theory of Couples is published to make manifest that 
  hidden meaning: and to show, by this remarkable instance, that 
  expressions which seem according to common views to be merely 
  symbolical, and quite incapable of being interpreted, may pass 
  into the world of thoughts, and acquire reality and significance, 
  if Algebra be viewed as not a mere Art or Language, but as the 
  Science of Pure Time.  $\quad$ -- Hamilton, 1837


Not until the much later development of set-theory was it explicitly realized 
that ordered pairs and, more generally, n-tuples, serve a fundamental foundational role, providing the raw materials necessary to construct composite (sum/product) structures - the raw materials required for the above constructions of polynomial rings and their quotients.
Indeed, as Akihiro Kanamori wrote on p. 289 (17) of 
his very interesting paper [2] on the history of set theory: 


  In 1897 Peano explicitly formulated the ordered pair using 
  $\rm\:(x, y)\:$ and moreover raised the two main points about the 
  ordered pair: First, equation 18 of his Definitions stated 
  the instrumental property which is all that is required of 
  the ordered pair: 
  
  $$\rm (x,y) = (a,b) \ \ \iff \ \ x = a \ \ and\ \ y = b $$
  
  Second, he broached the possibility of reducibility, writing: 
  "The idea of a pair is fundamental, i.e., we do not know how 
  to express it using the preceding symbols." 


Once set-theory was fully developed one had the raw materials 
(syntax and semantics) to provide rigorous constructions of 
algebraic structures and precise languages for term algebras. The polynomial ring $\rm\:R[x]\:$ is nowadays just a special case of much more general constructions of free algebras. Such equationally axiomatized algebras and their genesis via so-called 'universal mapping properties'  are topics discussed at length in any course on Universal Algebra - 
e.g. see Bergman [3] for a particularly lucid presentation. 

[1] William Rowan Hamilton. Theory of conjugate functions, or algebraic couples; with a preliminary and elementary essay on algebra as the science of pure time
Trans. Royal Irish Academy, v.17, part 1 (1837), pp. 293-422.)
http://www.maths.tcd.ie/pub/HistMath/People/Hamilton/PureTime/PureTime.pdf

[2] Akihiro Kanamori. The Empty Set, the Singleton, and the Ordered Pair
The Bulletin of Symbolic Logic, Vol. 9, No. 3. (Sep., 2003), pp. 273-298.
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.95.9839
PS  http://www.math.ucla.edu/~asl/bsl/0903/0903-001.ps
PDF http://ifile.it/b20c48j  

[3] George M. Bergman. An Invitation to General Algebra and Universal Constructions.
PS  http://math.berkeley.edu/~gbergman/245/
PDF http://ifile.it/yquj5w1
AnswerKenntnis:
In my opinion, the most natural way to view complex number is as a class of maps from the plane to itself. Specifically, lets define $(R, \theta)$ to be the map which multiplies every point in the plane by the number $R$, and then rotates it by the angle $\theta$. We may call these maps "dilations with rotations."

Such maps can be added and composed (multiplied) in the obvious way, and its not hard to work out that the sum and product of two such mappings is another dilation with rotation.

We can also identify the real number $x$ with the map $(x,0)$, i.e. the map which multiplies every point in the plane by $x$.  Then we see that these maps have the magical property that $-1$ has a square root! Namely, if $P$ is the mapping $(1,\pi/2)$ (i.e. rotate every point by angle $\pi/2$), then applying $P$ twice is the same as multiplying every number by $-1$, i.e. $P^2=-1$! 

As should be obvious by now, these maps are just complex numbers in disguise. 

Unsurprisingly, they are 
singularly useful for solving polynomial equations. Indeed, the real number $x'$ is a root of the polynomial equations $a_0 x^n + a_1 x^{n-1} + \cdots + a_n =0$ if and only if the mapping $(x',0)$ satisfies the same equation. So viewing polynomial equations over the set of these mappings loses no solutions, while at the same time giving us additional freedom to do operations such as taking the square roots of negative numbers.
AnswerKenntnis:
Even though quite a few people have already contributed towards answering your question, I would like to offer some thoughts of mine that may help you.

I am not going to give you ways of showing that complex numbers are necessary and meaningful, rather an idea about why I think people find them meaningless and how this can be resolved.

I am prompted by the part of your question that says: "...most non-mathematicians find it hard to accept that such a number is meaningful. In contrast, they feel that real numbers have an obvious and intuitive meaning." I have thought about this a lot in the past and have come to the conclusion that the problem in finding complex numbers meaningful lies in the meaning we have attached to the number systems "preceding" them in the hierachical chain: $\mathbb{N}, \mathbb{Z}, \mathbb{Q}, \mathbb{R}$. The meaning we have attached is that of quantity! Numbers all the way up to and including the reals are scalar quantities: We use them for distance, area, volume, weight, speed, intensity and so on. However, when you get to the complex numbers all that has to go away. There is no such thing as $2 + 3i$ kilogrammes or $-4i$ dollars or $1-5i$ centimetres... Yet we ask the learner to call them numbers!

So, the learner is faced with an apparent contradiction in terms: They are asked to think of these strange entities as numbers while at the same time these new additions to the realm don't behave as the numbers of old. And you should take into account that the older numbers have been around for a long time. That's where I think the problem lies. 

To circumvent this, I think that what one needs to do is explain to the learner that - from now on - numbers are going to take on a much wider role than before: They are going to be used not only to denote quantities, but also to denote directions, which is precisely what complex numbers do on the two-dimensional plane. Every complex number can be represented by a vector and this automatically suggests a direction. The "older" meaning is not lost, since a complex number has a modulus in addition to its real and imaginary parts and these three are quantities. 

Of course, one might say "But real numbers denote directions as well: +1 denotes a unit displacement to the right of 0 along the x-axis while -1 denotes a displacement to the left". This is indeed true, however, I sincerely doubt that the untrained mind of a learner, who encounters complex numbers for the first time, will delve in that direction. And, if it does, then that's fine, because it shows that the direction concept was already lurking in the number hierarchy ever since negative integers were introduced!!

I hope all this is of help to you.
AnswerKenntnis:
To the degree that anything actually "exists" in math, yes complex number exist.

Once you accept that groups, rings and fields exist, and that isomorphism of rings makes sense, complex numbers can be recognized as (isomorphic to) the subring (which happens to be a field) of the ring of 2 by 2 real matrices.

Generators of this subring are the matrices


 |1  0|
 |0  1|


and


 |0 -1|
 |1  0|


which correspond to 1 and i in the normal notation of complex numbers.

As people tend to accept that matrices exist, this may be a convincing argument. ;-)
AnswerKenntnis:
You may be interested to read the MathOverflow question "Demystifying Complex Numbers," here. A teacher is asking how to motivate complex numbers to students taking complex analysis.
AnswerKenntnis:
Quantum mechanics, and hence physics and everything around us, fundamentally involves complex numbers.
AnswerKenntnis:
I'll start by pointing out that a whole host of things that people think of as 'real' are on shakier ground than imaginary numbers. Given that quantum mechanics predicts a fundamental limit to how granular reality is, the whole concept of real numbers is on very shakey ground, yet people accept those as fine. I'd therefore suggest that it is merely a case of familiarity - people are less familiar with complex numbers than with some other mathematical constructs.

As for an actual existence outside the realms of pure maths... your best bet is to look at quantum mechanics again. This area has some fascinating results that are only possible through the use of imaginary numbers. Incidentally, fundamental particles are the place in nature that gave a 'physicality' to negative numbers (the charge of an electron is negative) well after they were accepted as normal by most people.
AnswerKenntnis:
Here is an example of a physical quantity which comes naturally as a complex number.

The impedance between two nodes of a linear electrical circuit working in alternate current, which is the analogous of the resistance of a resistor and is also measured in Ohms, is a complex quantity. For instance, the impedance of an (ideal) capacitor is imaginary.
AnswerKenntnis:
Yes, as much as any number "exists". (We could say a mathematical "object" exists if it models something empirical.)

Here's a way to visualize a vector "pointing" in the $i$ direction.  If electrical power is traveling 100% efficiently from power generator to your home, then it's pointing in the direction $\langle 1 \rangle$ (or flip-flopping $\langle 1 \rangle$ and $\langle -1 \rangle$ for A/C).  If the power points in the direction of $\langle \sqrt{-1} \rangle$ then the wire will heat up but transmit no useful electricity.
AnswerKenntnis:
I think some confusion comes from calling the numbers that only have imaginary part "imaginary numbers". I believe if mathematicians had other name to give to them (but I am really not thinking on a better name), there would be less confusion.
AnswerKenntnis:
Are real numbers "real"?  It's not even computationally possible to compare two real numbers for equality!

Interestingly enough, it is shown in Abstract Algebra courses that the idea of complex numbers arises naturally from the idea of real numbers - you could not say, for instance, that the real numbers are valid but the complex numbers aren't (whatever your definition of valid is...)
AnswerKenntnis:
As phrased, your question invites a philosophical answer but you said that's not what you want. One way to approach this question is to ask if complex numbers correspond to anything in the real world. What can you count or measure with them?

As far as I can tell, complex numbers are most directly useful for measuring things that rotate or oscillate. They're used by electrical engineers because voltages and currents can oscillate, and could be used for measuring springs or pendulums, or for anything that behaves like a wave. There are not that many situations in day-to-day life where you'd use complex numbers, but they're used extensively in physics because waves and oscillations show up everywhere.
AnswerKenntnis:
Complex numbers are the final step in a sequence of increasingly "unreal" extensions to the number system that humans have found it necessary to add over the centuries in order to express significant numerical concepts.

The first such "unreal number" was zero, back in the mists of time. It seems obvious to us now, but it must have seemed strange at first. How can the number of sheep I have be zero, when I don't actually have any sheep?

Negative numbers are the next most obvious addition to the family of numbers. But what does it mean to have -2 apples? If I have 3 apples and you have 5, it's convenient to be able to say that I have -2 more apples than you. Even so, during the middle ages many mathematicians were very uncomfortable with the idea of negative numbers and tried to arrange their equations so that they didn't occur.

Rationals (fractions) seem real enough, since I'm happy to have 2/5 of a pizza. However, this is not the number of pizzas that I have, just a ratio between 0 and 1 pizzas, and so is further removed from the concept of counting.

More significant philosophical problems problems arose when irrational numbers were first discovered by the classical Greeks. They were astonished when Euclid (or one of his predecessors) proved that the diagonal of a unit square could not be represented by ratio of two integers. This was such an outrageous idea to them that they called these numbers "irrational". However, they couldn't easily deny their existence since they have a direct geometric representation.

Irrational numbers were first understood as the solutions to algebraic equations such as x^2 = 2 but this still doesn't cover all the possible numbers that we need. For example, the ratio of a circle's diameter to its circumference is ╧Ç and so has a direct geometric representation. However, in 1882 ╧Ç was proved to be transcendental, meaning that it can't be defined as the solution to a specific algebraic equation. This begins to seem a lot less "real", especially when you consider that there are many important transcendental numbers that, unlike ╧Ç, don't have a geometric interpretation.

There are of course many algebraic equations that don't have a solution even among the irrational numbers, and in some ways there's no reason why they should. However, when 16th century mathematicians like Gerolamo Cardano began working on solutions to cubic equations they found that the square roots of negative numbers began cropping up very naturally in their procedures, even though the solutions themselves were purely real. This eventually led people to explore the arithmetic of complex numbers and they were surprised to find that it produced a consistent and beautiful theory.

However, complex numbers don't have such an intuitively obvious geometrical meaning as the numbers that came before. They are typically represented graphically as points in the 2D plane, and the rules of addition and multiplication are equivalent to certain operations on lengths and angles, but those operations aren't driven by geometrical necessity in quite the way that squares and circles are. Even so, complex numbers are a perfect representation for various physical phenomena such as the state of particles in quantum mechanics and the behaviour of varying currents in electrical circuits. They are also very useful for reducing the cost of computation in 3D computer graphics.

The really special thing about complex numbers, though, is that they are the end of this journey that has been going on for millenia. There is no need to invent further number systems to provide solutions to problems expressed in terms of complex numbers because now every non-contradictory equation, algebraic or transcendental, has a solution within the complex numbers. They are a self-sufficient, consistent system.

Physicists have been breaking matter down into smaller and smaller particles over the years. Molecules, atoms, nuclei, protons, quarks. When will the process stop? For several decades it was felt that quarks could be the final, indivisible particle. However, new theoretical frameworks such as string theory are suggesting that there may be more fundamental entities than quarks. Because physics ultimately relies on experimental verification, we can never be sure that there aren't going to be more steps in the sequence.

In mathematics, however, we can prove things for all time. Complex numbers are the final step in the sequence, the numbers that we have been reaching for since before the beginning of recorded history. Every other number system is just a subset of the complex numbers, just a part of the true picture. Complex numbers are the real thing.
AnswerKenntnis:
The argument isn't worth having, as you disagree about what it means for something to 'exist'. There are many interesting mathematical objects which don't have an obvious physical counterpart. What does it mean for the Monster group to exist?
AnswerKenntnis:
There are geometric interpretations of imaginary numbers where they are thought of as parallelograms with a front and back, or oriented parallelograms. That interpretation requires geometric algebra but only uses real numbers. 

Here is a link:
http://en.wikipedia.org/wiki/Geometric_algebra#Complex_numbers

That doesn't have any pictures so it is admittedly not intuitive, but the answer is yes. Whether you think of imaginary numbers as square root of negative 1 or as parallelogram with a front and back, they exist.
AnswerKenntnis:
I usually say: "Believe it or not, electricity and radio waves actually do behave like complex numbers. You don't see that in high school, but electric and electronics engineers do."
AnswerKenntnis:
I have just discovered this web page and your question.  This is probably a late response.

A lot of people think that at some point someone came along and simply asserted "yes there is a square root of -1 after all" and called it 'i'. That's a common misconception, and, unfortunately, seems to be what is often "taught" in "high schools" in the US.

The set of Real Numbers that you are used to is an example of what mathematicians call a "field". That means you can add, subtract, multiply, and divide according to familiar properties. The field C contains the Reals: it is just the two-dimensional plane endowed with a very natural addition (vectors) and a really cool multiplication, which takes a little effort to understand.

A complex number is just a point on the plane, an ordered pair. The absolute value of a complex number is its distance to the origin, and let's call its "angle" the angle it forms with the positive x-axis. The Real numbers are just the x-axis, and "i" is just (0,1). So the real number 1 is (1,0) and -1 is (-1,0). Then multiplying complex numbers multiplies their absolute values and adds the angles. That's why (0,1) times itself is -1 = (-1,0). 90 degrees plus 90 degrees = 180 degrees.

There is essentially no other way to imbed R (the reals) in a field in which all numbers have square roots. If you want to be technical, any other such field is isomorphic to C. Furthermore, there is no way to make any higher R^n (R^3 = space for example) into a field in a natural way. The quaternions are a way to make R^4 into a division ring, close but not a field.

So, in short, the field of complex numbers is extremely real and concrete.

Last March Steven Strogatz wrote a column about C = the field of complex numbers in the New York Times. You might enjoy this exchange of emails I had with someone a few months later, after Strogatz's article appeared in the New York Times.

http://home.bway.net/lewis/Complex.htm
AnswerKenntnis:
The question you and your students are asking is whether the concept deserves to exist, i.e., is it really a useful concept? The best answer to offer non-mathematical people is that it is at the heart of many, many applications which are perhaps simpler to understand with this abstraction. You can draw historical parallels, for example to surds (such as $\sqrt2$), which were thought not to exist from the ancient Greek rational-geometric constructive perspective. But at the least, I think, you must point out the beauty and utility of Euler's formula
$$
e^{i\theta}=\cos\theta+i\sin\theta
$$
(connecting them to trigonometry)
and of the complex plane.
Perhaps DeMoivre's formula
$$
\left(\cos\theta+i\sin\theta\right)^n=
\cos{n\theta}+i\sin{n\theta}
$$
provides a nice example of a considerable
simplification realized through complex numbers.
Then, you should mention some of the multifarious
connections that could come to mind, both
applications (such as to alternating current & fluid dynamics)
and mathematical extensions and related areas:
vectors, quaternions, octonions,
complex (!), Fourier & Harmonic analysis,
Lie Groups, cyclotomic polynomials,
analytic number theory, etc.

Above all, one should mention that they have deep connections to algebra (e.g., its fundamental theorem) and by extension, to linear algebra and differential equations (?), two of the most useful areas of mathematics. And don't hesitate to use pretty pictures.

There is also some debate over, and well should there be room for, different fundamental viewpoints on what mathematics is and how it should be conducted. And one should probably also include here some perspectives more historically associated with statistics, such as pragmatism. With this in mind, one should have some tolerance for, or at least understanding of, non-mathematicians' continued skepticism regarding mathematical concepts, since the proof of a concept's utility is contingent on sufficient experience with it and, even within the field of mathematics, there are revisions and simplifications and room for alternative approaches.
AnswerKenntnis:
We will will first consider the most common definition of i, as the square root of -1. When you first hear this, it sounds crazy. 0 squared is 0; a positive times a positive is positive and a negative times a negative is positive too. So there doesn't actually appear to be any number that we can square to get -1.

A mathematician would collectively term 0, negative numbers and positive numbers as the real numbers. They would also define the term complex numbers as a group of numbers that includes these real numbers. So while we have shown that no real number can square to get -1, we haven't even defined complex numbers at this point, so we can't rule out that one might have this property.

At this point, it makes sense to ask what does a mathematician mean by a number? It certainly isn't what most people associate it with - as an abstract representation some kind of real world quantity. We need to understand that it isn't uncommon for one word to have different meanings for different groups of people - after all words mean whatever we make them mean. Most people only need to real world quantities, so they find it convenient to call those numbers. On the other hand, mathematicians explore a variety of different number systems. Indeed some, such as complex numbers, are useful for solving problems that are actually about real numbers.

So mathematicians define i as a number that obeys most of the normal algebraic laws. They also defined i*i to equal -1. From this we can derive all of the standard results about complex numbers.

As for whether they are real - it depends on what you want to know. Obviously, they don't correspond to quantities of physical objects. On the other hand, complex numbers can useful for representing resistance in an electric circuit. Ultimately, they are an idea and while ideas don't exist physically, saying they don't exist at all is inaccurate.
AnswerKenntnis:
Even natural numbers are abstract notions. Through abstract constructions the complex numbers can be demonstrated. So asking whether complex numbers is something like asking whether the natural numbers exist, whether the real numbers exist, or not. They are all things in the abstract domain of thought.

If you want to reconcile it with your physical intuition, try the following. I suppose that your mental picture of the real numbers is by associating a line to it. Similarly, you can associate a plane to the set of complex numbers. Points are complex numbers. The real numbers will be the x-axis and imaginary numbers would be the y-axis. Addition is straightforward to visualize. For visualizing multiplication, write a complex number in the form $re^{i\theta}$. Then multiplication is a combination of stretching by a magnitude of $r$ and rotation by an angle of $\theta$. I hope this helps you in mental visualization.

In electrical networks, complex numbers are very good for analysis of alternating current networks. If some current has an imaginary component, it means that the current is leading or lagging the voltage by some "phase difference", or "angle". A resistance having imaginary components mean that it has capacitance or inductance. Only the "real" parts contribute to energy loss. But for imepdance calculations you have to consider capacitance and inductance too. A similar analysis can be made for every kind of control systems. So complex number are all very much there in nature and all sorts of engineering problems. I cannot stress their importance enough.
AnswerKenntnis:
Here is a possible line of reasoning.

Say, we start with natural numbers, $\mathbb{N}$, then add $0$, making them the whole numbers $\mathbb{N}_0$, then add negative numbers, making them integers $\mathbb{Z}$, then expand them to rationals $\mathbb{Q}$, and finally to reals $\mathbb{R}$. In some respect, we keep filling up the line, till there are no gaps left. 

Now the question: why do we call them "numbers"? What are the properties we expect from some object so we can call it a number. In fact, just a few: addition and multiplication must be defined for all of them, and we want these operations to be commutative and associative.  The distributive law of multiplication over addition must hold. It's nice to have a notion of ordering, so we can say $a \lt b$, and multiplication by some positive number must be compatible with that notion: if $a \lt b$ and $x$ is positive, then $ax \lt bx$. Those are the minimal requirements, met by $\mathbb{N}$. As we expand our numbering system, we get more and more useful properties, and the structure (both algebraic and topological) gets more complicated: from semigroup in case of $\mathbb{N}$ to complete ordered field in case of $\mathbb{R}$, but those basic ones always hold. 

Now, the next step in our "quest for expanding our system" would be to look at $\mathbb{R}^2$, $\mathbb{R}^3$ etc. In general, the objects ("points") populating the space $\mathbb{R}^n$ are called "vectors" and they differ from numbers in one important respect: we can't define vector multiplication so it meets our requirements for numbers (commutativity, associativity and having multiplication distributed over addition). So we don't treat vectors in $\mathbb{R}^n$ as the numbers, in particular, we don't think of them as atomic objects, but rather in terms of the components or coordinates.

There's one important exception, however: i is $\mathbb{R}^2$. In fact we can define multiplication of two objects (points, vectors) in $\mathbb{R}^2$ so it meets all our requirements and we can call these objects "numbers". To be precise, all except one: the ordering. Multiplication we define is no longer compatible with the ordering. So we agree that probably not having that feature isn't such a big deal. Once we introduced multiplication, we end up with complete field (but not ordered field) of entities which we have a right to call the numbers. So we call them the complex numbers and designate them as $\mathbb{C}$. There are some similarities between $\mathbb{R}^2$ and $\mathbb{C}$, but there are also some difference, the most important one being the fact that multiplication is defined so $\mathbb{C}$ is a field rather than vector space. In fact we can treat the elements of $\mathbb{C}$ as the scalars and use them to build a vector space, a complex matrices, etc. Well, this is roughly, why we can call complex numbers "numbers". They exhibit the same behavior (except for ordering) as the numbers we're familiar with do. One of my favorite examples: when we define the derivative in vector analysis, the formulas look quite different from those we got used in Calculus. But when we define the derivative for complex-valued functions, the formula is exactly the same, because multiplication and hence division) is defined. 

Now, why complex numbers are important is a different question. What I wanted to focus is the fact that we have a right to call them "numbers". But, just like we can think of rational numbers as a special case of reals, and when move from reals to rationals, we loose the important property of completeness, we can think of real numbers as a special case of complex numbers, and when we move from complex to reals we loose some nice properties as well. In many respects, studying complex numbers helps us to better understand real numbers. 

As a sidenote, again, when we move from $\mathbb{R}$ to $\mathbb{C}$, we loose the ordering. Complex numbers form a complete field, but this is not an ordered field. (There is only one complete ordered field, up to isomorphism.) Now suppose we want to explore $\mathbb{R}^n$ further. That's the next best? $\mathbb{R}^4$. We can define multiplication of objects (vectors) in $\mathbb{R}^4$ which is associative, but - alas - not commutative. It's kind of hard to think of numbers whose multiplication is not commutative. So we no longer call them (quaternions, $\mathbb{H}$) numbers. Finally, the next interesting space is $\mathbb{R}^8$, where we still can define multiplication, but it is no longer associative (in addition to being non-commutative). It's really hard to deal with something which is not associative, and certainly it's hard to think of those entities as numbers.
AnswerKenntnis:
Re: "What's the best way to explain to a non-mathematician that complex numbers are necessary and meaningful, in the same way that real numbers are?"

I am a non-mathematician...so fully qualified to answer this question...


first explain imaginary numbers
then explain that complex numbers are simply numbers that use imaginary numbers
then tell 'em about how they are applied in weather forecasting
bang!....I geddit


I got all this from an amazing radio show :

"In Our Time - Imaginary Numbers" 

Melvyn Bragg and his guests discuss imaginary numbers - important mathematical phenomena which provide us with useful tools for understanding the world.
AnswerKenntnis:
Ordered pairs exist.
If you define an operation on something that exists, the thing 'with the operation' exists.
Certain operations can be defined on ordered pairs
Complex numbers are ordered pairs with those operations defined on them.
Γê┤ Complex numbers exist.
AnswerKenntnis:
Since nobody has talked about Caspar Wessel I will, mainly because of this:


  In 1799, Wessel was the first person to describe the geometrical interpretation of complex numbers as points in the complex plane.


As you can read from previous answers, all numbers are mathematical abstraction. $1$ is not even defined in the real world, it is an abstraction to quantify what surrounds us. To every object we have, we define it's "unity": one potato is the whole elipsoidal tuber. But then if we cut it in half we'd say we have "half" a potato. We're representing a concrete object with the abstract notion of unity, but the number $1$ itself is our first numerical abstraction. What makes it so awfully mundane is that we are very used to unity. And, thus, we march steadily to $2$, $3$, $\dots$, to get what we name the "natural" numbers: $\mathbb{N}$. They are those who naturally arise in our day to day life, which we use to count and order, among other uses. 

Now, as you would probably imagine, we move onto integers. But as you are now doubtfull about the notion of complex numbers, many mathematicians were too about the negatives! They thought they were "impossible" and didn't considered them numbers:


  Prior to the concept of negative numbers, negative solutions to problems were considered "false" and equations requiring negative solutions were described as absurd.
  
  Although the first set of rules for dealing with negative numbers was stated in the 7th century by the Indian mathematician Brahmagupta, it is surprising that in 1758 the British mathematician Francis Maseres was claiming that negative numbers
  "... darken the very whole doctrines of the equations and make dark of the things which are in their nature excessively obvious and simple" .


So much for the "simple" integers, $\mathbb{Z}$. We can go on to the rational numbers $\mathbb{Q}$, the irrationals, and the real numbers $\mathbb{R}$, but let me focus on Wessels' genius. He named his paper "On the Analytical Representation of Direction; An Attempt." and began with

"This present attempt deals with the question, how may be represet direction analytically; that is, how shall we express right lines so that in a single equation involving one unknow line and others known, both the length and the direction of the unknown line may be expressed." 

He gives two propostition which seem to him "undeniable":


"...changes in direction which can be effected by algebraic operations shall be indicated by their signs."
"...direction is not a subject for algebra except in so far as it can be changed by algebraic operations." 


He then explains how sum and substraction should be defined (he basically defines vector addition and substractino) and what he's aiming in this exposition, among other remarks. But here's the interesting part, after he defines multiplication:


  "...so that the angle of the product (...) becomes equal to the sum of the direction angles of the factors."
  
  "Let $+1$ designate the positive rectilinear unit and $+\epsilon$ a certain other unit perpendicular to the positive unit and having the same origin; then the direction angle of $+1$ will be equal to $0º$, that of $-1$ to $180º$, that of $+\epsilon$ to $90º$ and that of $-\epsilon$ to $-90º$ or $270º$. By the rule that the direction angle of the product shal equal to sum of the angles of the factors, we have: $(+1)(+1)=+1$;$(+1)(-1)=-1$;$(-1)(-1)=+1$;$(+1)(+\epsilon)=+\epsilon$;$(+1)(-\epsilon)=-\epsilon$;$(-1)(+\epsilon)=-\epsilon$;$(-1)(-\epsilon)=+\epsilon$;$(+\epsilon)(+\epsilon)=-1$;$(+\epsilon)(-\epsilon)=+1$;$(-\epsilon)(-\epsilon)=-1$. 
  From this it is seen that $\epsilon$ is equal to  $\sqrt{-1}$ (...)"


He then, after some reasoning and trignometrical though gives the know representation:


  "In agreement with 1 and 6, the radius which begins at the center and diverges from the absolute or positive unit by angle $v$ is equal to $\cos v + \epsilon \sin v$. 


But what is most amazing is that he then gives a great ending to his paper!


  Without knowing the angle which the indirect line $1+x$ makes with the absolute value, we may find, if the length of $x$ is less than $1$, the power ${\left( {1 + x} \right)^m} = 1 + \dfrac{{mx}}{1} + \dfrac{m}{1}\dfrac{{m - 1}}{2}{x^2} + \operatorname{etc}.$ If this series is arranged according to the powers of $m$, it has the same value and is changed into the form 
  $$1 + \frac{{ml}}{1} + \frac{{{m^2}{l^2}}}{1\cdot2} + \frac{{{m^3}{l^3}}}{{1 \cdot 2 \cdot 3}} + \operatorname{etc}.$$
  where
  $$l = x - \frac{{{x^2}}}{2} + \frac{{{x^3}}}{3} - \frac{{{x^4}}}{4} + etc.$$
  and is a sum of a direct [horizontal] and a perpendicular line. If we call the direct line $a$ and the perpendicular $b\sqrt{-1}$ then $b$ is the smallest measure of the angle which $1+x$ makes with $+1$. If we set
  $$1 + \frac{1}{1} + \frac{1}{{1 \cdot 2}} + \frac{1}{{1 \cdot 2 \cdot 3}} + \operatorname{etc}. = e$$ then $${\left( {1 + x} \right)^m}$$ (...) may be represented by ${e^{ma + mb\sqrt { - 1} }}$ (...)"


So in trying to give direction an analytical representation Caspar Wessel has given the most important rules to represent complex numbers as lines in the plane, and made them be meaningfull for us.

I hope you enjoyed this as much as I did when I read it. If you want, I can give you the whole article, which is amazingly interesting.
AnswerKenntnis:
There is a lovely way of motivating the "existence" of the complex numbers just by using a little calculus on the real numbers. I found this in Visual Complex Analysis, and it tickled me, so I thought I'd share it here, despite the lateness of the answer.

If $r_1,...,r_n$ are real numbers, define:

$$f(x)= \frac{1}{(x-r_1)(x-r_2)...(x-r_n)}$$

When $a\notin \{r_1,...,,r_n\}$ we can find the Taylor series around $a$:

$$\sum_{k=0}^\infty \frac{f^{(k)}(a)}{k!}(x-a)^k$$

The question is, for what (real) $x$ does this series converge to $f(x)$?

As it turns out, if we let $R=\min_{k} |a-r_k|$, then if $|x-a|<R$ this series converges to $f(x)$ and if $|x-a|>R$, then it doesn't converge.

So, in a sense, the $r_i$ "block" the ability of the Taylor series to converge around them.

Now, what about the Taylor series for $g(x)=\frac{1}{x^2+1}$?

Given an $a$, this function has no "real" blockages - it is defined on all of $\mathbb R$ - but the Taylor series for $g(x)$ around $a$ has a similar $R$ value, and that $R$ value is $\sqrt{1+a^2}$, a value that can be computed entirely with real number calculations.

That then looks like there is some geometric obstruction to the Taylor series, an obstruction not on the real line, but a unit distance away from the real line in a perpendicular direction away from $0$.  It "looks like" an "imaginary" root of $x^2+1=0$.
AnswerKenntnis:
It may help to think of negative numbers as something other than "negative."

The concept that helped me was to think of -1 as the opposite of 1.

If the context was distance, for example, and I had a value of 1, then I went one unit in a direction.  If, on the other hand, I had a value of -1, then I'm traveling in the opposite direction of 1.

In calculus and series work, it will become more clear that this is a terminology problem most people have.  So whether you're dealing with space-time or voltages or something else, the negative symbol is just a relative thing, not an absolute value.  In other words, don't think of -5 as negative 5 but as something opposite of something else...
AnswerKenntnis:
A number of answerers have answered by asking the question of whether the real numbers exist.

There are lots of physical examples that a person can give to a lay-person of real numbers, including fractions, zero and negative numbers. Vector addition all by itself provides plenty of examples. For instance, most anyone can develop an intuition for the idea that if a vector pointing north has a positive component, then it can be combined with a vector pointing south, and that the south-pointing vector intuitively and usefully can be assigned a negative component.

So the question is, are there intuitive physical examples of imaginary numbers. I've never seen one! For example, I'd like anyone to show me something even resembling or approximating a stick of length 2i, that when lined up perpendicularly with another stick of length 2i outlines a region with area -4. Given this, lay people have a point when they deny complex numbers exist.

Two advanced comments on this:

(1) A lovely and non-obvious fact about sqrt(-1) is that once you have introduced it and called it "i" you don't have to introduce a pile of other numbers. For example, the sqrt(i) = 1 / sqrt(2) + i / sqrt(2). Imaginary numbers would be a lot less compelling to mathematicians if introducing them immediately led to a bunch of other quantities having to be hypothesized and named.

(2) Quantum mechanics makes heavy use of imaginary numbers. Unlike in electrical engineering, it isn't just a convenience. At the end of the day, in electrical engineering, after having solved a difficult problem, you'll never actually go measure an imaginary voltage or current. The solution to electrical engineering problems always involves "throwing away" the imaginary part of the answer, even though it makes the legwork a lot simpler when coming to an answer. In quantum mechanics, you don't throw the complex part of the wave function away. You work with it at every step of the way, until at the end, you use it's norm-squared. This turns a complex "probability amplitude" into a "probability density."

So you might say that quantum mechanics provides an example of the "existence" of complex numbers. However, the problem with this example is that quantum mechanics remains difficult to intuit even for the most experienced physicists. "I think I can safely say that nobody understands quantum mechanics." http://en.wikiquote.org/wiki/Richard_Feynman
QuestionKenntnis:
My sister absolutely refuses to learn math
qn_description:
My 13-year-old sister has a problem which, given the way math is currently taught, I doubt is anything but all too common. She has a low grade in her math course and only ever attempts to memorize formulas and tricks, but never actually learn any of the reasoning behind the math. Cross multiplication is the perfect example. 

She knows that from

$\frac{3}{5}=\frac{x}{10}$

.. she can "cross multiply" to get

$30 = 5x$ 

.. and from there get $x=6$. She has absolutely no idea what any of this means, however. She's simply memorized a pattern and is applying that pattern to a recognizable arrangement of numbers. 

Given the incremental nature of math, her performance has gotten worse as her lack of understanding has compounded. She'll occasionally ask me for help, but is always upset that I won't simply give her the answer to the problem at hand or the "formula" for what she's trying to do. As I ask questions to test her understanding of something, she begins to randomly guess numbers either out of thin air or numbers that I'd mentioned in my explanations, but she doesn't appear to be actually thinking about the problem and considering the answer. After about an hour, she begins to claim she's tired, can no longer focus, and that we're spending too much time on a single problem and that she has more to do.

The inspiration for my finally posting this question and reaching out to the mathematics community came from the homework she had today. She wanted to know how to find the circumference of a circle. After a few questions I had determined that she had no idea what the radius, diameter, or circumference of a circle even were. She even attempted to guess "area" at one point. After relating circumference to the circumnavigation she had learned about, radius to the rays of a sun, and diameter to meaning two (even though this isn't the proper etymology of diameter), she was at least able to label the parts of a circle. Instead of giving her the $c=\pi d$ formula she wanted so badly, I wanted her to understand that $\pi$ represented the amount of times the diameter "fits" into the circumference and that this is the relation between the parts of the circle. I measured as accurately as possible the perimeter and diameter of the mouth of a cup I had and showed her that dividing the numbers produced approximately pi. This unfortunately didn't provide the "ohhh" response I was looking for, which signified that she didn't intuitively understand division. So I tried with a much simpler example. Our conversation went something like:

"The circumference of the glass divided by the diameter gave me pi, what does that mean?"

"Er... I don't know?"

"Well, if I divide 10 by 2, what do I get?"

"Five"

".. and what does that mean? How many twos are in ten"

"five twos go into ten?"

"Right, so if I divide the circumference by the diameter and get pi, how many diameters are in the circumference?"

"..umm... seven?"

"WHAT?!? Why seven?"

"..uhh, two?"

"why two?"

"because diameter means two?"

"two what?"

"two radius"

...

and so on ad infinitum.

She doesn't have any learning disabilities or mental handicaps, so it irritates me to no end that she won't put any effort into learning things that are essential to her understanding and that she could easily grasp. 

How do you teach someone to understand math when they are capable but unwilling to do so?
AnswersKenntnis
AnswerKenntnis:
If one does not want to do something, then one can't do it. The question is how to get past any resistance and issues one has with, in this case, mathematics. From the conversation above, I can make a few recommendations. First, avoid asking simple questions for which the answer is obvious to you and should be obvious to your student. The reason is that it might not be obvious, and the student, sensing the elementary nature of the question by the tone of your voice, will try to guess quickly, most likely get it wrong, forcing an irresistible gasp from you, which will signal to the student... only bad things. When the student is already having issues that are psychological, it's best to avoid such questions and instead try to engage the student by asking to affirm things you know should be trivial (so something like "so this is the radius of the circle, right?" while you are pointing right at it. Then you can go to "and what would that be?", pointing to the diameter, and perhaps immediately adding "well, it can't be the radius since that was this guy over here, so this must be the diameter..." etc.). 

As for the particular issue with $\pi$, it is actually not so trivial at all. First, there is the issue of comparing "divide the circumference by the diameter, hey look, we got almost 3.14, so that means that the diameter fits into the circumference $\pi$ times" to "divide 10 apples by 2 people, each has 5, so 5 apples fit into 10 two times" is problematic. What the hell is $\pi$ times? The quantitative intuition most students will have for multiplying natural numbers goes down the drain when going to real numbers that are not fractions. The common way to 'solve' this in schools is to drill the students with endless computations with decimal expansions until the students think they understand it. Of course, then most students will insist that $0.999\cdots\ne 1 $, which shows how ineffective this method is to understanding what the real numbers are. 

Then, there is another issue. The fact that for all circles the ratio of the circumference to the diameter is a constant is far from obvious, nor is it a trivial matter to actually give a proof of that fact. In fact, I remember that when at school we were given the formula $c=\pi \cdot d$, I didn't understand why it was true, and since it was presented like it's something obvious, I felt I was being stupid for not seeing why it's true. So if one presents the formula $c=\pi \cdot  d$ as something that should be clear, that's a problem. It's not clear. It only becomes 'clear' to those students going through the system being drilled endlessly with that formula until they think they understand it. What I do is define $\pi$ as the circumference of the circle of diameter $1$ or as the area of the circle with radius $1$. Then you can discuss the weird behaviour of length (i.e., that it is extremely sensitive to small perturbations and that it is only lower semi-continuous) and I try to convince the student that $\pi=4$ and immediately show it must be smaller than $4$ by various geometric approximations. Then a quick discussion of the stability of area compared to length, and thus that we should prefer the area definition of $\pi$ rather than the length definition. Then comes the non-trivial formula $c=\pi \cdot d$. It is now not just an empty formula, but something that carries meaning. 

And finally, learning comes when the students want to learn. The motivation can come from different sources and for different reasons. At times, the student is not motivated. It's no big deal. There is no reason to expect somebody to be interested in something just because somebody at school decided they should be. Not knowing what $\pi$ is never killed anybody. And, the best way to create and re-enforce issues with mathematics is to push the student when the student is not interested. I can confess that I quite hated mathematics at school due to the way it was (and still is) taught. When I became motivated, which was when I encountered university level mathematics through a book I found, I very quickly learnt what I did not know. You'll find that all of the material taught in school sums up to very little, and can be comprehended quite quickly if one is motivated.
AnswerKenntnis:
I am a high school teacher, so here are some comments specific to the situation that don't necessarily answer the question directly:

One hour is around the maximum that a normal 13-year old student can concentrate on intense mathematical learning.
You need to manage this by sticking to maximum one-hour sessions, maybe with a 10-minute break in the middle. This may not be your own experience, but this is common. The fact that your sister is telling you this shows she has good self-awareness.

From the point of view of your sister's immediate need, she wants simply to answer the homework questions to avoid getting in trouble at school (or be able to answer exam-style questions, or similar). In order to achieve this, she actually doesn't need to know the theory behind it, she needs to know the formula. Again, she is showing good understanding of her situation.

I understand why you are disappointed in that... but she needs to understand that she can get appropriate help of the kind that she needs (i.e. how to accurately apply an algebraic formula to answer the questions), or she will be less inclined to ask you for help in the future. Self-discovery is definitely not the only way to learn maths. Your 'Socratic method' of discovering knowledge is very powerful if you have time to fully explore it - but this may not actually be appropriate help in this context.

If your sister has shown a lack of understanding of division, then she will find it very difficult to understand your attempt to explain pi as the ratio (division) of circumference and diameter. Understanding division is a prerequisite for following the concept that you are trying to explain. Even if she can follow what you're doing with her, her weakness in ratio problems will make it impossible for her to do this independently, and she may get confused by thinking about what you have done where she is expected to just remember and apply the formula.

To help her understand pi as a ratio, you may want to go back to an earlier step, for example: 'recipe' problems 


if this recipe makes 2 cakes, how can I make 4 cakes? 
if this recipe makes 3 cakes, how can I make 7 cakes?


At first with simple numbers, but getting more complicated over (perhaps several lessons) time. 
Then take out the recipe context: use other contexts, or a little more abstract, use it to reintroduce the equivalent fractions problem you quoted above, until your sister is fully ready to tackle the circumference/diameter problem.

Note, it will still be difficult to understand pi in this way, at a stage when students typically only have experience of integer solutions in this type of problem.

And also note, it will be difficult to convince your sister to agree to this work. You need to show your willingness to help her (i.e. help her with what she immediately needs, first), and also let her understand how learning with you will be helpful for her in the longer term. She has to be engaged with the learning experience or this will be frustrating for both of you and not worth spending time on. Sometimes this puts pressure on family relationships and, in that case, it may be better to hire a tutor to work on this with her.

Good luck!
AnswerKenntnis:
First, let her calculate lots of easy exercises. There should be only about 3 types of exercises. She has to choose the correct algorithm.

When she can calculate the trivial exercises without problems, move to the more complicated exercises. Add some abstraction, some real world examples. Add abstractions slowly. It's important letting her discover abstractions by herself.

There are several principles:


Let her be successful. She has to be able to solve some exercises. If she can't solve anything, she will get bored.
Let her try to solve it by herself, without intervening.
Don't let her guess. Don't ask simple questions. Show her how to solve one exercise and then let her do another by herself. If she can't do it, explain it again and give her another exercise. Then let her explain it to you. Many people will tell you they understand the exercise but if they can't explain it to you, they don't. It's interesting letting her solve exactly the same exercise you just explained.
You need 5 minute breaks after every 30 minutes. Don't talk about math during the break. People can concentrate for long periods of time only if they are interested in the subject. If they only listen to someone else explaining, they get tired/bored fast.
Don't get carried away. Don't try to explain deep relationships because they fascinate you. Keep it simple.


[I am actually a programmer but I studied math in the University and I spent several years teaching maths to my high school classmates and their friends].
AnswerKenntnis:
Your sister has developed a strategy that was successful to cope with a lot of typical problems given in school. So of course she is trying "more of the same" to solve any further problems. 

You are trying to force her to think in a very different way about these problems, often a way that will not instantly produce answers, but that is exactly what she is looking for. 

There are different ways to cope with this situation, my following personal example was successful but not the most pedagogical way to cope with problems in mathematics: My sister had to do a presentation on a fairly advanced mathematical idea for her final year of high school. She always was mediocre in math but managed to survive. This topic was clearly beyond anything that you could solve with pattern matching but required some real thinking. So I offered to help but did not have much time as I was in university three hours away. I started off by testing at which grade level we could start the journey. After a few hours and quite a lot of tears we ended up somewhere 3 or 4 years below her current class. She had managed to get by with exactly the same strategy as your sister but without much understanding for several years. In my opinion there was only one way to solve this: I said we have to repeat all the stuff and understand it this time in six weeks (the time to the presentation). Of course that only provoked more tears. The good side was my sister needed a good grade and was highly motivated. I tried to explain that this is not an impossible task and gave her lots of books (university level) and daily feedback. After the very rough start she understood more and more and managed to give an impressive presentation and understood the subject deeper than we ever hoped for and completely lost any fear of mathematics. 

So I would try to explain your sister, that her approach was quite clever but will fail for any more advanced problems. She can either start trying the hard way trying to build a mathematical understanding now or suffer for all the years to come as no other subject requires such a continuous learning effort as mathematics.
AnswerKenntnis:
It's hard to beat Feynman's Abacus story in Surely You're Joking, Mr. Feynman!.

This excerpt copied from here which notes that the story is taking place in Brazil.


  A Japanese man came into the restaurant. I had seen him before,
  wandering around; he was trying to sell abacuses. He started to talk
  to the waiters, and challenged them: He said he could add numbers
  faster than any of them could do. The waiters didn't want to lose
  face, so they said, "Yeah, yeah. Why don't you go over and challenge
  the customer over there?"
  
  The man came over. I protested, "But I don't speak Portuguese well!"
  
  The waiters laughed. "The numbers are easy," they said.
  
  They brought me a paper and pencil.
  
  The man asked a waiter to call out some numbers to add. He beat me
  hollow, because while I was writing the numbers down, he was already
  adding them as he went along.
  
  I suggested that the waiter write down two identical lists of numbers
  and hand them to us at the same time. It didn't make much difference.
  He still beat me by quite a bit.
  
  However, the man got a little bit excited: he wanted to prove himself
  some more. "Multiplica├º├úo!" he said.
  
  Somebody wrote down a problem. He beat me again, but not by much,
  because I'm pretty good at products.
  
  The man then made a mistake: he proposed we go on to division. What he
  didn't realize was, the harder the problem, the better chance I had.
  
  We both did a long division problem. It was a tie.
  
  The bothered the hell out of the Japanese man, because he was
  apparently well trained on the abacus, and here he was almost beaten
  by this customer in a restaurant.
  
  "Raios cubicos!" he says with a vengeance. Cube roots! He wants to do
  cube roots by arithmetic. It's hard to find a more difficult
  fundamental problem in arithmetic. It must have been his topnotch
  exercise in abacus-land.
  
  He writes down a number on some paperΓÇö any old numberΓÇö and I still
  remember it: 1729.03. He starts working on it, mumbling and grumbling:
  "Mmmmmmagmmmmbrrr"ΓÇö he's working like a demon! He's poring away, doing
  this cube root.
  
  Meanwhile I'm just sitting there.
  
  One of the waiters says, "What are you doing?".
  
  I point to my head. "Thinking!" I say. I write down 12 on the paper.
  After a little while I've got 12.002.
  
  The man with the abacus wipes the sweat off his forehead: "Twelve!" he
  says.
  
  "Oh, no!" I say. "More digits! More digits!" I know that in taking a
  cube root by arithmetic, each new digit is even more work that the one
  before. It's a hard job.
  
  He buries himself again, grunting "Rrrrgrrrrmmmmmm ...," while I add
  on two more digits. He finally lifts his head to say, "12.01!"
  
  The waiter are all excited and happy. They tell the man, "Look! He
  does it only by thinking, and you need an abacus! He's got more
  digits!"
  
  He was completely washed out, and left, humiliated. The waiters
  congratulated each other.
  
  How did the customer beat the abacus?
  
  The number was 1729.03. I happened to know that a cubic foot contains
  1728 cubic inches, so the answer is a tiny bit more than 12. The
  excess, 1.03 is only one part in nearly 2000, and I had learned in
  calculus that for small fractions, the cube root's excess is one-third
  of the number's excess. So all I had to do is find the fraction
  1/1728, and multiply by 4 (divide by 3 and multiply by 12). So I was
  able to pull out a whole lot of digits that way.
  
  A few weeks later, the man came into the cocktail lounge of the hotel
  I was staying at. He recognized me and came over. "Tell me," he said,
  "how were you able to do that cube-root problem so fast?"
  
  I started to explain that it was an approximate method, and had to do
  with the percentage of error. "Suppose you had given me 28. Now the
  cube root of 27 is 3 ..."
  
  He picks up his abacus: zzzzzzzzzzzzzzzΓÇö "Oh yes," he says.
  
  I realized something: he doesn't know numbers. With the abacus, you
  don't have to memorize a lot of arithmetic combinations; all you have
  to do is to learn to push the little beads up and down. You don't have
  to memorize 9+7=16; you just know that when you add 9, you push a
  ten's bead up and pull a one's bead down. So we're slower at basic
  arithmetic, but we know numbers.
  
  Furthermore, the whole idea of an approximate method was beyond him,
  even though a cubic root often cannot be computed exactly by any
  method. So I never could teach him how I did cube roots or explain how
  lucky I was that he happened to choose 1729.03.
AnswerKenntnis:
Some people cannot/don't want to learn maths simply because it is... maths, much too abstract and, at first glance, not linked to the realities of life. 

Take the opposite approach: instead of teaching maths and, then, find applications in real life, give her as many analogies as you can. Ie try to go from the maths practical approach - and help her to understand/be interested by choosing subjects she is interested in.
AnswerKenntnis:
Give her a loan at some tiny daily percentage rate.

Collect interest daily, if she forgets, add that to outstanding amount.

Report outstanding amount and interest due daily.

After a while she will realize just how much she'd paying you back.

If that doesn't encourage her to learn math, nothing will.
AnswerKenntnis:
Often times I find that the reason people are averse to mathematics is because they can't relate to the numbers.  Instructors teach the way that they were taught, and since the instructor is smart obviously the way they learned it must be the correct way to learn it.

I once tutored a girl very similar to your sister, she assumed that she simply "wasn't good" at math.  This girl, despite being in college algebra, had been pushed along by the system.  She could not even say large numbers properly (she mixed up millions, billions, etc.).  Her teachers and parents were no help, because they couldn't explain it in any other way than the way they had learned it themselves.

So I changed my method of teaching to relate to something she did understand.  I called the numbers between the commas "families", and the hundreds place digit was the "papa", the tens place digit was the "mama" and the single place digit was the "baby".  The million family lived next door to the thousand family, and the billion family lived next door to the million family.

It's absurd to describe math this way, at least I think so.  It has very little to do with actual math, and it's easier for me to memorize and "just know".  But you know what?  The girl I was tutoring finally learned how to read numbers properly.

The fault I see with the description you've given is that you are trying to lead her to getting her own answer.  You're asking question after question, expecting her to follow your lead and provide answer after answer.  You're trying to get her to justify why she's doing something in the process.  It's clear she doesn't care about math, why would she ask questions like that of herself?  She just wants to get it done and over with.

So adapt the method.  Get creative with your explanations, as if they were "word problems".

In the circumference example, stop talking about the circumference of a circle.  You might explain it as, "I need a new belt for Christmas, but you can't ask me what size belt I wear because HELLO that's rude.  But if you looked at me from the top of the stairs, I'd look like this circle.  If I'm the circle, then the belt goes around my waist, which is like going around this circle.  Now, of course if you look at me from the front you know that x inches goes from one hip to the other."  That's when you draw the diameter.  You can then explain the radius and give her a formula; the objective is to get her to relate the numbers and meaning of things in a purely non-math way.

Check out this "I Can't Do Math" Article
AnswerKenntnis:
Personally, I would say there is no way of teaching anything (not just maths) to someone who is unwilling to do so; I think it would be better to give her a reason to want to do it.

While you make the comment that your sister has no learning handicaps, I would like to point out (not as a specific comment to you) that there are math specific learning disorders, such as Dyscalculia, and that this can affect people who are academically gifted in other areas; a person who cannot do maths is not always a person who doesn't want to.
AnswerKenntnis:
Bear in mind that this may not generalize as much as it seems to - part of the problem may well be that she is your sister.  

I used to tutor quite a few people in math when I was in high school, and, though I often encountered problems similar to yours, no one was anything close to as much trouble as my sister.  

Someone who goes to trouble (usually with a lot a parental pushing, but still) of getting help from a stranger is more ready to listen than someone asking a close family member.  

Also, it's hard to learn from a sibling - there is often at least a bit of an element of competition, or at minimum you form part of the background level of competence she compares herself against, so the better that you are at the math you are tutoring her in, the worse she feels herself to be.  It's not your fault, it can't be helped.

Based on my own tutoring experience, usually the first thing to overcome for someone in your sister's situation is the feeling that she is naturally bad at math.  The good news is that she probably isn't - she has never really tried it so there is no reason to suppose she is actually bad at it.  You were right to try to move it from meaningless symbol manipulation to something meaningful about the real world, but she also needs some successes to make her think that she isn't hopeless and just wasting her time.  Unfortunately, the mere fact that you are her brother and (currently) much better at math just reinforces the idea that she is bad at math.
AnswerKenntnis:
I want to offer my situation as an example. Until high school ($10^{th}$standard), I was an average student in Maths. I was good at algebra, mensuration and statistics, but I performed poorly in geometry.

When my teacher asked me to prove Thales theorem, I couldn't; that was because I would memorize, but without knowing the meaning of any steps. My teacher insulted me in front of the whole class, and said that this is guaranteed to be a question in exams:


  There is less than a week until exam time, and you don't know how to
  solve this theorem!


I was weeping by then. At last, I passed my exam but I never forget that insult, so over the summer, I revised every previous geometry concept.

In $11^{th}$ I went to a new school where my new teacher made geometry a simple thing to me. From that time. when I use any formula, I also learn how to derive the formula. So learning is self-motivated. It may come from someone insulting you or you are motivated when you're lagging behind the rest of the class.

There is one more incident that happened to me in $11^{th}$. I never memorized values of trig ratios of common angles. One day my teacher asked me, I just took a shot in the dark. He didn't say anything, went on and asked another boy. But then I realized that if my classmate knew the value, then why didn't I? The next day I started trig chapter and tried to solve problems myself and in 3 days, I'd memorized the whole table. So I think that until your sister listens  to her inner voice, she will have no interest in maths. That is how I thought about math, and at that time, I was also 13-14 years old.

* There is an Indian Hindi movie on this type of student. Try to watch this movie: Taare Zamin par.
AnswerKenntnis:
In math we don't understand things we get used to them. don't try to explain what diameter is. teach her how to measure things, make her notice the INVARIANTS and then suggest the relations. For one part of the problem i think this will work:

draw a circle make her measure the distance from a Fixed point P that you choose to the center that you have specified. then tell her to choose another point for herself and measure it. do  this several times. then choose another point. Ask her to GUESS the distance from that point to the center. she probably will guess it. then do it for diameter. then mention the relation. now draw a new circle. make her measure the radius and make her GUESS the diameter of the  new one.  

the idea above can also be used to make the center a magical point for her. choose another point beside the center. and make her make measurements. she'll notice that the distance from CENTER is invariant. center is magical. she'll get curious i think.

you can make lots of games out of such things. for example can you choose a point that is the same distance from all the points?

PS: As i said i tried to give a solution to one part of the problem, the teaching method. the motivation is still an issue even if my teaching method worked. i don't know much about motivation. but i think that --and this is just my opinion based on my life's experience- that people's opinion about things like this are just noise, no matter who says it. :)
AnswerKenntnis:
I think the best way to tudor is with the Book right in front of them. For this situation I would never provide the formula but instead help the student by teaching her how to look back through the book and find the right formulas. This will cause the student to eventually with enough practice do two things:


Be able to find her own answer by looking for the right formula
Learn which formulas apply to which situations


It is never OK to just give the formula and that is giving a starving man fish instead of teaching him how to fish. One will solve the problem then the other will solve all problems after. If she doesn't understand what a circumference or diameter is do not tell her but instead have her use her own book to find the definition. All good math books should have a glossary and index in the back. By using this method the student will eventually be able to solve all of the small problems like this on their own by showing them how to do some basic research and review in the text book. And if you do not have a glossary or your text book is not very good, then find a good dictionary or let her search online (Google) for the right definition. There are three barriers to learning and there seem to be two prevalent here:


The Misunderstood Word (Will cause everything past the word to be missed)

Can be found by asking what does diameter mean? and anything besides the right answer quickly, even hesitation, means that there is not 100% certainty and understanding. 
Solved by clearing words that are misunderstood with a good dictionary and using them in sentences verbally.

Too Steep a Gradient (Trying to learn something advanced before the simple is fully understood)

Can be found by asking to solve simpler situations and working your way up until there is a point where the situation can not be solved.
Solved by practicing and getting a good understanding of one step before moving on. Maybe several demonstrations should be made to help explain why it is so.

A Lack of Mass (trying to learn a subject without be able to do any physical work on the subject)

Can be found by someone who is getting very frustrated and repeating the same thing over and over without being able to get the concept.
A simple fix is again to use some demonstrations. Instead of saying 10 apples divided by 2 equals five apples, go and get something to demonstrate with such as play-dough. I know it sounds elementary, but you will be surprised how fast someone will brighten up when they have the actual physical situation to learn with. Try learning how to fix an engine without ever seeing or touching an engine. You will not remember and be able to apply much at all. This is why the more hands on the more learning that can be achieved.



Here is a good reference that will help you out:
http://ftp.appliedscholastics.org/bookstore/item-description.php?id=6
AnswerKenntnis:
Note that recognizing and applying patterns is intrinsic to reasoning.  The main complaint is that unlike someone better versed in mathematics, your sister doesn't have a large number of fine-grained patters for math, just some "dumb" ones based on how the printed layout of a particular equation. However, what you're working with is still patterns. Mathematicians, scientists, engineers: everyone works with and recognizes patterns. How does your physician diagnose what is wrong? From the pattern of diagnosable symptoms. It's okay to use the patterns and work out the justification for those patterns later, or to apply some problem solving patterns developed by specialists without understanding all the underpinnings.
AnswerKenntnis:
You can derive cross multiplying to her by multiplying the equation sidewise by 1) the left hand side denominator and 2) by the right hand side denominator.
AnswerKenntnis:
There are no "tricks". It is difficult! I am recommending listening a little to what star teacher Jaime Escalante says, a short video is:

http://www.youtube.com/watch?v=FFMz8JRg8Y8

Search for Jaime Escalante on youtube and elsewhere!
AnswerKenntnis:
In general: Visualization, Visualization, Visualization!

Using words or formulas doesn't seem to help your sister. Every formula can be visualized. Be it the easy case of a circle or the slightly more difficult one solving for $x$.

In particular for the circle:


Take a cup, place it on a paper upside down. Take a pen and draw the circle around it
Take a cord and cut out a piece of the length of $d$
Take a cord and lay it around the cup. Cut it.
Cut out 3 more pieces of length $d$ (4 total)
Lay down the cord pieces representing $\pi$ and $d$ and let her compare them. Ask her how many times the small piece fits in the large piece. Let her guess.


There is also A LOT of animations available on the internet.
AnswerKenntnis:
I have given math coaching a few times and this is quite common amongst students who take math coaching.  Not sure how much time you want to spend to give her math lessons, but 1 hour per week is absolute minimum.  If don't have this time, hire someone who could give her math coaching.

My approach is this:


find out what the student is good at and what the student is not good at
find or invent exercises that are near the student's comfort zone limit


And then, you guess it: do the exercises.  When your sister's concentration is high, do the more difficult exercises.  When her concentration gets lower, do easier exercises.  And when she gets tired, do easy exercises or even do the exercises yourself.  While doing the exercises explain each step loudly.

In your case the limit of the comfort zone are abstract methods.  Find exercises that are hard to do with her approach.  Or exercises that are tedious to do with her approach and easy to do with yours.

Also don't forgot to do pauses.  One hour without pause is way too long, 20 minutes or so is fine.  In between talk with her about something non-mathematical for roughly 5 minutes.

I have absolutely no idea what is going on in those students' minds but obviously math is something that bores them to hell.  Sometimes I explain things, they understand them and forget them the next lesson.  So it means I need to explain things over and over again, 5 times or so.

Anyway I strongly recommend you to hire someone that does one or two lessons every week, if you have the money.  Math tutoring is a long term thing, at least for written performance.  Short term improvements in class are possible though.  But I think this is just a motivational thing.
AnswerKenntnis:
I don't count myself as a Mathematician but I was pretty good at math in my school days. I was not fascinated with all sort of math. Measuring distances, areas, volumes etc was very nice but I hated symbol manipulation and limits. I could see the areas and volumes around me but relating equations to reality was very hard. Not everyone is born with love for mathematics like Terrence Tao and Ramanujam.

The way I feel about mathematics and kids is following.


Don't force math on kids. If she hasn't developed a love for mathematics, there is still hope. But talking too much math to her will definitely make her hate it. I doubt if she can recover after developing a feeling of hate for mathematics. Math already have a 'nerd' image.
Try to make her see mathematics in her daily experience. Stories do wonder to kids. I was told a story by my school teacher about limitations of average. Once there was a group of students on trek led by their math teacher. On the way, they encountered a river. The teacher measured the depth of river at many places and took the average. Since the average was less than the height of smallest child in the group, he declared that it is safe to cross the river. Needless to say, the story did not have a happy ending. But it made me very conscious of averages (especially when people talk about per capita income etc.). 


Make her see numbers in her day to day experience and make her realize how she can use math. Ask her when she is playing (and not during when she is doing homework) how many chocolate she can buy if she has \$21 and each cost \$5?

These are my two cents. If you can make her love maths, write a blog about it. One day, I'd find it useful when I'd have my own kids.
AnswerKenntnis:
I think the best way to engage kid into mathemathics is to give it interesting book with text exercises describing common problems. Like: Tom is 4 and his brother Jon is two times older. How old will Jon be when Tom is 10 etc. At least I liked it mostly, because it was real use of mathematics. I just got a simple example but I think you know what I mean. You can also find some contest exercises to get her involved\interested in, but if she doesn't want to you won't force her.

It's also a lot about teacher I think. Me and my brother were going to very good primary school, when my sister and second brother went to local one. It's about how they are taught from beginning. My sister nor my second brother didn't understand math, cause they were taught that they have to stick to one and only one proper way of solving problem. And when for example my sister did something differently her teacher removed her page from the exercise book( My father's intervention was required). I, in this case was given an 'A' for exploring, also no one bothered that I did the whole exercise book in 1 month instead of 1 year. And we knew about every contest and could attend no matter the skill, when they barely knew about any contests. So I suggest to check the methodical approach in the school. Maybe your sister was brain washed by a narrow-minded teacher.

Explaining things from the basics is very important as well. I remember I didn't understand cos/sin and all the things about them really until I saw the circle definition. But in my country it's not in the learning program. They just say you that this side of a triangle to this side of a triangle is that. So I like the university level stuff comment, cause sometimes it's so obvious and you wonder why they teach you the formulas instead of the concept behind it.
AnswerKenntnis:
I think you need examples, I mean real life examples. When I learned this equation, I always imagining we are measuring a map. That means if we know 1 centimeter means 10 km in real, what we will get in real if there are 2 centimeters on the map? It somehow feels like a ratio projection, and there are so many things feel like a projection in real life. For example, you height is 1.5m, and you know that at 4:00 pm, your shadow should be 1.5 of your real height, what is the length of your shadow? Purely talking about numbers are way abstract for children, we need real life scenarios to let them feel the numbers. And a more better example maybe the sugar-water-inequality: (a+c)/(b+c) > a/b  (a<b and c>0). Just imagine adding sugar into the water, and the inequality just means after adding sugar the sugar density is higher compared to before. Straightforward, easy to remember, easy to understand. Although real proof is a little tricky, this example truly expresses the implicit beauty of math.
AnswerKenntnis:
May be you could try an explorative approach rather than a teacher-student one? I mean, don't shoot out questions one after another or somehow hide the fact that you already know the answer (I know it is difficult!). As to my childhood days, whenever my well-educated uncle came visiting, he used to ask questions blindly and out of fear or whatever, I never answered them correctly (in fact I told wrong answers). I think there is a (tiny) bit of "hate" against the "teaching setup" in everybody (at least during schooldays).
AnswerKenntnis:
It may be heresy to say on this site, but I'm of the opinion that beyond basic arithmetic it's not so important to learn math as to be worth the damage caused by forcing people to grind through a subject they do not like and will not become proficient at.  In the United States, pushing kids through advanced math classes and then failing them because they can't comprehend it has a corrosive effect on all their studies that directly contributes to raising the high-school drop out rate, which is a net negative for the society and a tragedy for the students who miss out on the opportunities of an education in other areas.  How would you feel if you were held back a year in high school because you flunked poetry and gymnastics?

"But math is so much more important," you say.  Well, 2,000 years ago learning how to make a fire from nothing more than stones and twigs and wood was a critical survival skill; it was literally a matter of life and death.  Do they still even teach that in school?  No, because we have matches and electric heaters and gas furnaces and professionals to install and maintain them.  In modern times only a very few people are proficient at making a fire from natural elements and most people can't do it at all. Even survivalists depend on having a knife.  So it is with math: between calculators, Excel, Google, websites and other computer software, and professional services it is completely possible to live a full and rich life without knowing advanced math.

On the career front, the most satisfying careers according to several surveys include (in no particular order since surveys disagree to some extent) are:


clergy
physical therapist
firefighter
K-12 and Special Ed teachers
fine artists


While of course a passionate mathematician can find math concepts in some of these fields, understanding those concepts in mathematical terms is not required to be a successful practitioner. 

If you love math or are even curious about it, then by all means pursue it.  I'm all for having a high quality math education available.  But this question is about how to deal with someone who's tried math and hates it and doesn't want to waste any more energy on it.  I say let them go and pursue what they are curious and passionate about instead. 

Have some empathy and try to maintain some perspective on the full range of the human condition.  Concert musicians are upset that people don't learn how to play musical instruments.  Polyglots can't imagine why people don't spend more effort at learning other languages.  Athletes don't understand why people would stay inside and read books all day.  Mathematicians want everyone to learn math. 

When someone complains to you that they don't want to learn math, remember why you don't want to learn 4 foreign languages, 2 musical instruments, art history, gymnastics, sociology, biology, plumbing, auto mechanics, carpentry, sculpture, drawing, painting, modern dance, and creative writing.  Sure, you may want to learn some of those, but all if them?  (I doubt it, but even if you really do, then you have a worse curse of never being able to devote yourself to becoming excellent at everything you want to pursue.)
AnswerKenntnis:
I remember having trouble with Linear Algebra due to the way it was taught at my university, but I pulled through when I found a better teacher online.

I suggest going to Khan Academy and watching a few relevant videos together with your sister.
This guy covers a lot, from basic math to advanced stuff, so you can pick out the most relevant videos, and you can go back and cover the basics if necessary.

I admit, it's not the most direct solution, but it helped my brother catch up on his math, and I'd recommend it to anyone.
AnswerKenntnis:
Games..  as user76556 menioned, games are a good way to spark interest. 

For example, the Towers of Hanoi.  http://www.mazeworks.com/hanoi/

Grab one set of these wooden rings:

http://www.goodtoknow.co.uk/money/galleries/34552/20-kids-gifts-for-under-a-fiver/7

and let her go at it!  

Of course finding a game is the difficult part but there are a lot of free online math games which depending on the level your sister is at could really help.

Hope this helps - I have a lot of luck with the Towers of Hanoi (of course it is usually employed at parties with adults and lots of alcohol).

Brian
AnswerKenntnis:
The problem is that you are trying to help her in a way that she doesn't want to be helped. She wants to get her homework done. In her mind you are wasting her time with long explanations when you could just give her a formula.

If you want to address her fundamental mathematical issues, you should dedicate some time in the holidays (when she doesn't have maths homework...) and make up some problems of your own. You will have to make this fun, but the advantage is that there is no time limit. You can take as long as you like, and go back as far as you like. 

I recently noticed my sister was having trouble with algebra because she had trouble with fractions. She knew the rules for getting common denominators, but she didn't realise that those same rules could be applied to purely algebraic fractions. To help her realise this, I filled an A4 page with fraction problems, starting with really easy ones that I knew she could do, then continuing to slightly harder ones.

I was surprised to notice that she could actually add fractions like the following: (she was better at fractions than I realised...)

$$
\frac{a}{b} + \frac{c}{d}
$$

but she had troubles when I finally asked her to add fractions like the following:

$$
\frac{a+b}{c+d} + \frac{a+b}{a+c}
$$

I realised that her fundamental problem was not fraction laws, but with aspects of the order of operations. She didn't realise that the numerator and denominator of a fraction are essentially surrounded by invisible brackets. Once I told her that she could add brackets around the numerators and denominators, she was able to do the problems.

In your case, I suggest you determine the highest level of mathematics at which she is confident and proficient, and create your own worksheets that slowly build on things which she already knows. (I handwrote mine. I thought of making them in $\LaTeX$, but nicely formatted questions are not important here, and you will end up procrastinating and never get them done anyway...) This will require a lot of work on your part, and you will have to convince your sister that it is worth it. You will also have to keep working on it each holidays. Your sister won't learn all the she needs to learn in just one holidays. 

When your sister works through the problems, sit next to her and show how the hard questions can be solved using methods from the easy ones. Try to make it really obvious how the hard problems are just combinations of easier problems that she already knows how to do.
AnswerKenntnis:
Try Elementary Level first, expalin basic rules step by step..

3/5 = x/10

3*10 = x*5

30 = 5x ( once again tell her the rule is applicable even if one element will move..)

Sometimes when children are learning, they will be provided a specific scenario, and with that if they have learned something wrong(logically wrong) that becomes a problem for future..

so explain her one rule at time(divide and rule), in detail with various examples so she comes to know her mistakes...

so that will lead her answer to ...

30/5 =x

6 =x 

i.e x=6

I think if some one have weak conceptual knowledge, please correct the roots so that the other things will automatically sum up in proper way gradually with practice..

You may try this method its, working on my side,..
AnswerKenntnis:
Many answers here seem to be about how to teach math, but I think that misses the point. This is about how to make someone interested in learning math.

In a situation like this, I think the best option might just be to refuse to help her. If someone really doesn't want to learn, then they're not going to. Nothing you can do is going to force them to want to learn, so it may be best to just say that you are always going to refuse to just give her the answers, and that the only way she's going to get your help is if she actually makes the effort to learn the way you'd like to teach her.

This may seem cold, but it should be possible to break it to her kindly. Make sure she understands that this isn't just for your benefit, but for hers. Remember to look at things from her point of view. For her, learning math is just an obstacle that has to be gotten over. She just wants to get the homework out of the way, pass the tests and be done with it. Approach her on those grounds. She has another five or so years of math ahead of her, and explain to her that there are two paths she can go down. She can continue to insist on memorizing everything without attempting to understand it. In that case, the next five years of math classes will continue to be absolute torture. She'll hate every moment of them, every bit of homework will be an ordeal, and I guarantee her grades will only get worse.

Or she can make the effort now to try it your way. Describe for her exactly what awaits her in that case, and contrast it with the alternative scenario. All of her math classes will become not only easy, but obvious. Much of the homework might even become fun for her. And even if she never develops a taste for the subject, at least she'll have the ability to effortlessly and quickly finish every assignment given her so that she doesn't have to waste any more of her time with them.

And of course, refuse to help her until she decides to go down that second path.

If she comes around, you'll still need to break down the barrier that math is only formulae, and get her to understand that mathematics is meaningful, not arbitrary. For that, you should refer to one of the other answers here.

PS: It's probably obvious I don't have much experience talking to 13 year olds. Reader discretion advised in how to actually word any of the above.
AnswerKenntnis:
I think the best way to get her involved is via numbers (integers). for example, the $3n+1$  problem or other elementary problems in number theory. You could also ask her to add (using a calculator) the first 50 odd integers while you give her the answer in a second (using $\sum\limits_{i=1}^n (2i-1)=n^2$).

If everything works ok, you can move on to some algebra and geometry, maybe challenging her to double a square using a non-graduated ruler and a compass.

I know how hard it could be, I'm a teacher.
QuestionKenntnis:
Examples of apparent patterns that eventually fail
qn_description:
Often, when I try to describe mathematics to the layman, I find myself struggling to convince them of the importance and consequence of 'proof'. I receive responses like: "surely if the Collatz Conjecture is true up to $20 \times 2^{58}$, then it must always be true?'; and "the sequence of number of edges on a complete graph starts $0,1,3,6,10$, so the next term must be $15$ etc".

Granted, this second statement is less logically unsound than the first since it's not difficult to see the reason why the sequence must continue as such; nevertheless, the statement was made on a premise that boils down to "interesting patterns must always continue".

I try to counter this logic by creating a ridiculous argument like "the numbers $1,2,3,4,5$ are less than $100$, so surely all numbers are", but this usually fails to be convincing. 



So, are there any examples of non-trivial patterns that appear to be true for a large number of small cases, but then fail for some larger case? A good answer to this question should:


be one which could be explained to the layman without having to subject them to a 24 lecture course of background material, and 
have as a minimal counterexample a case which cannot (feasibly) be checked without the use of a computer.


I believe conditions 1. and 2. make my question specific enough to have in some sense a "right" (or at least a "not wrong") answer; but I'd be happy to clarify if this is not the case. I suppose I'm expecting an answer to come from number theory, but can see that areas like graph theory, combinatorics more generally and set theory could potentially offer suitable answers.
AnswersKenntnis
AnswerKenntnis:
I'll translate an entry in the blog Gaussianos ("Gaussians") about Polya's conjecture, titled:

A BELIEF IS NOT A PROOF.


  We'll say a number is of even kind if in its prime factorization, an even number of primes appear. For example $6 = 2\cdot 3$ is a number of even kind. And we'll say a number is of odd kind if the number of primes in its factorization is odd. For example, $18 = 2┬╖3┬╖3$ is of odd kind. ($1$ is considered of even kind).
  
  Let $n$ be any natural number. We'll consider the following numbers:
  
  
  $E(n) =$ number of positive integers less or equal to $n$ that are of even kind. 
  $O(n) =$  number of positive integers less or equal to $n$ that are of odd kind.
  
  
  Let's consider $n=7$. In this case $O(7) = 4$ (number 2, 3, 5 and 7 itself) and $E(7) = 3$ ( 1,  4 and 6). So $O(7) >E(7)$.
  
  For $n = 6$: $O(6) = 3$ and $E(6) = 3$. Thus $O(6) = E(6)$.
  
  In 1919 George Polya proposed the following result, know as Polya's Conjecture:
  
  For all $n > 2$, $O(n)$ is greater than or equal to $E(n)$.
  
  Polya had checked this for $n < 1500$. In the following years this was tested up to $n=1000000$, which is a reason why the conjecture might be thought to be true. But that is wrong.
  
  In 1962, Lehman found an explicit counterexample: for $n = 906180359$, we have $O(n) = E(n) ΓÇô 1$, so:
  
  $$O(906180359) < E(906180359).$$
  
  By an exhaustive search, the smallest counterexample is $n = 906150257$, found by Tanaka in 1980.
  
  Thus Polya's Conjecture is false. 
  
  What do we learn from this? Well, it is simple: unfortunately in mathematics we cannot trust intuition or what happens for a finite number of cases, no matter how large the number is. Until the result is proved for the general case, we have no certainty that it is true.
AnswerKenntnis:
From "Experimentation in Mathematics" Borwein, Bailey and Girgensohn 2004 :
$$\sum_{n=1}^{\infty} \lfloor n\cdot e^{\frac{\pi}3\sqrt{163}}\rfloor 2^{-n}=1280640\ \ \text{(correct to at least half a billion digits!)}$$
Using the $\mathrm{sinc}$ function ($\mathrm{sinc}(x)=\frac{\sin(x)}x$ and this paper) :
$$\int_0^{\infty} \mathrm{sinc}\left(\frac x1\right) dx=\frac{\pi}2$$
$$\int_0^{\infty} \mathrm{sinc}\left(\frac x1\right)\cdot \mathrm{sinc}\left(\frac x3\right)dx=\frac{\pi}2$$
$$\int_0^{\infty} \mathrm{sinc}\left(\frac x1\right)\cdot \mathrm{sinc}\left(\frac x3\right)\cdot \mathrm{sinc}\left(\frac x5\right)dx=\frac{\pi}2$$
$$\cdots$$
$$\int_0^{\infty} \mathrm{sinc}\left(\frac x1\right)\cdot \mathrm{sinc}\left(\frac x3\right)\cdot \mathrm{sinc}\left(\frac x5\right)\cdots \mathrm{sinc}\left(\frac x{13}\right)dx=\frac{\pi}2$$
$$\int_0^{\infty} \mathrm{sinc}\left(\frac x1\right)\cdot \mathrm{sinc}\left(\frac x3\right)\cdots \mathrm{sinc}\left(\frac x{15}\right)dx=\frac{467807924713440738696537864469}{
935615849440640907310521750000}\pi$$



In fact the story doesn't end here! It was found (see Baillie and Borweins' "Surprising Sinc Sums and Integrals") that you could replace the integrals by the corresponding $\frac 12 + \sum_1^{\infty}$ series :
$$\frac 12 + \sum_{m=1}^{\infty} \prod_{k=0}^N \mathrm{sinc}\left(\frac m{2k+1}\right)=\int_0^{\infty} \prod_{k=0}^{N} \mathrm{sinc}\left(\frac x{2k+1}\right)\ dx.$$

for the previous values of ($N=0,1,2,3\cdots 7$) but also for larger values of $N$ up to $40248$. For $N\gt 40248$ the left part is always larger than the integral at the right!

At this point the reciprocals of the odd integers could be replaced by other values (see the paper for the conditions required for the equality to hold) for example by the reciprocals of the prime numbers. Now, because of the slow divergence in this case, the equality breaks down only for $N \approx 10^{176}$ (when the sum of values slowly crosses the $2\pi$ barrier) and with an error smaller than $\displaystyle 10^{-10^{86}}$.
AnswerKenntnis:
The seminal paper on this is Richarg Guy's The Strong Law of Small Numbers Proclaiming "there aren't enough small numbers to meet the many demands made of them," it lists $35$ patterns that don't pan out. Others have expanded on the 'law of small numbers' Such as here (and a few more links on that page)

A particularly great example from the second link:


$\gcd(n^{17}+9, (n+1)^{17}+9)$ seems to always be one. In fact, if you had your computer checking this for $n=1, 2, 3, \dots$ successively, it would never find a counter-example. That is because the first counter-example is $$8424432925592889329288197322308900672459420460792433\;.$$
AnswerKenntnis:
Choose n points around the circumference of a circle, and join every point to every other with a line segment.  Assuming that no three of the line segments concur, how many regions does this divide the circle into?

There's a rather obvious pattern, that breaks down at n=6.
AnswerKenntnis:
I am kind of partial to the old $n^2 + n + 41$ chestnut, namely that the expression is prime for all $n$.  It fools an awful lot of people.
AnswerKenntnis:
Claim: The cyclotomic polynomials $\phi_n(x)$ have coefficients in the set $$\{ -1, 0, 1 \}$$

It holds for any number that doesn't have at least $3$ distinct odd prime factors, which means the smallest counterexample is $3 \cdot 5 \cdot 7 = 105$. So a naive undergrad probably won't ever see a counterexample unless he is specifically shown $\phi_{105}$.
AnswerKenntnis:
Take from Joseph Rotman's "A First Course in Algebra: with applications":

The smallest value of $n$ for which the function $f(n) = 991n^2 + 1$ is a perfect square is

$$
n = \mbox{12,055,735,790,331,359,447,442,538,767}.
$$

(This number is approximately $50$ times larger than the square of the United States' national debt!)



On a similar note, the smallest value of $n$ such that the function $g(n) = 1,000,099n^2 + 1$ is a perfect square has  $1116$ digits.
AnswerKenntnis:
Perhaps a little technical, but I think you can give the flavour without the details. It was long believed that the logarithmic integral $\operatorname{Li}(x)$ is greater than the prime counting function $\pi(x)$ for all $x$, and computations verified this for a lot of "small" (but by most people's standards fairly large) $x$. It was proved to be false in 1914 by J.E. Littlewood, who did not find a counterexample explicitly, but showed that one must exist - it is believed to be around $10^{316}$, way outside the range of computations at the time.

So this example isn't great, because the logarithmic integral is fairly technical, but the specifics of $\operatorname{Li}(x)$ aren't that important, so it's just about one function being bigger than another.

More details on Wikipedia.
AnswerKenntnis:
Heather360 gives the following amusing example:

US presidents elected in 1840, 1860, 1880, 1900, 1920, 1940, and 1960 all died in office, but Ronald Reagan did not.

But the following example is probably more along the lines of what you had in mind.  The pattern is not very long, but it is very simple and could be explained to anyone of any background:

http://threesixty360.wordpress.com/2008/10/26/one-two-three-four-six-again-and-then-again/

Also, since you started your question without reference to patterns, per se, but to the importance of mathematical proof, I would point to the Banach-Tarski paradox.  I think most people, especially non-mathematicians, have trouble believing this result, so it is certainly an example of mathematical proof establishing a counter-intuitive result.
AnswerKenntnis:
The "chinese remainder" prime-test :
 $\qquad \small \text{ if    } 2^n-1 \equiv 1 \pmod  n \qquad \text{ then } n \in \mathbb P $
fails first time at n=341 . That was one of the things that really made me thinking when I began hobbying with number-theory in a more serious way...
AnswerKenntnis:
I like to point to the many tuples of numbers that are part of multiple sequences at OEIS.org. I just typed in 1, 1, 2, 3, 5 and got 751 results.
AnswerKenntnis:
Does Goodstein's Theorem fit the bill? 

(By the way, here is a nice applet.)

The question was:


  So, are there any examples of non-trivial patterns that appear to be true for a large number of small cases, but then fail for some larger case? A good answer to this question should:
  
  $(1)$ be one which could be explained to the layman without having to subject them to a $24$ lecture course of background material, and 
  
  $(2)$ have as a minimal counterexample a case which cannot (feasibly) be checked without the use of a computer.


Requirement $(1)$ is obviously satisfied. 

Is requirement $(2)$ is satisfied?

In some sense it is not, because a computer wouldn't help. 

But, in another sense, it is over satisfied, because, even with the most powerful imaginable computer, the statement cannot be checked. That is, it cannot be checked by any calculation, although it only involves addition, multiplication and exponentiation of positive integers. But with a very simple notion (that of ordinal), it becomes almost trivial.

To say it in another way: It is very easy to prove that the apparent pattern will break eventually, but the argument doesn't give the slightest clue about when it will break.

So, Goodstein's Theorem is, I think, a quite instructive piece of mathematics.
AnswerKenntnis:
Fermat numbers would be a good example.  The numbers $F_n = 2^{2^n}+1$ are prime for $n=1,2,3,4$, however $F_5 = 4,294,967,297 = 641 × 6,700,417$ is not prime. In fact, there are no known Fermat primes $F_n$ with $n > 4$.

Admittedly this isn't impossible to check by hand, but the rapid increase in $F_n$ makes it factoring such numbers by hand highly impractical.  I can't imagine any layman who would be comfortable trying to factor even a 10 digit number.  In the case of $F_5$, trying to check for prime factors by brute force you would have to check 115 primes before you get to 641.
AnswerKenntnis:
Let
$$\pi^{(4)}_1(N) = \text{ Number of primes }\leq N\text{ that are of the form } 1 \bmod 4$$ and $$\pi^{(4)}_3(N) = \text{ Number of primes }\leq N\text{ that are of the form } 3 \bmod 4$$

$$
\begin{array}{ccc}
N & \pi^{(4)}_1(N) & \pi^{(4)}_3(N) \\
100 & 11 & 13\\
200 & 21 & 24\\
300 & 29 & 32\\
400 & 37 & 40\\
500 & 44 & 50
\end{array}
$$

Looking at the pattern, one can wonder if $\pi^{(4)}_1(N) \leq \pi^{(4)}_3(N)$ is true for all $N$. In fact, this remains true for $N$ up-to $26,860$.

$26,861$ is a prime $\equiv 1 \bmod 4$ and we find that $\pi^{(4)}_1(26,861) = \pi^{(4)}_3(26,861) + 1 > \pi^{(4)}_3(26,861)$. You can read more about this and similar questions on primes here.
AnswerKenntnis:
This might be a simple example. 

If we inscribe a circle of radius 1 in a square of side 2, the ratio of the area of the circle to the square is $\frac{\pi}{4}$. You can show that any time we put a square number of circles into this square, the ratio of the area of the circles to that of the square is (for the simple symmetric arrangement) again $\frac{\pi}{4} $. So for 1, 4, 9, 16 circles, this packing is the best we can do. 

I had mistakenly assumed, based on this "obvious" pattern, that the limit of optimal packings of circles into the square did not converge, but rather continued to drop down to this same ratio every time a square number was reached. 

This turns out not to be true, as I learned here. 

There are many other examples, but this served as a reminder for me.
AnswerKenntnis:
Euler's sum of powers conjecture, proposed in  1769, is a generalization of Fermat's Last Theorem about the following Diophantine equation $$\sum_{i=1}^n X_i^k=Y^k\textrm{, where }n\neq 1$$

It states that for the equation to have any solutions in positive integers, $n$ must be at least $k$ (FLT is the statement that $n\ge 2$ if $k\ge 2$).  For small values of $X_i,Y$, the conjecture appears to be true. 

In 1966, L. J. Lander and T. R. Parkin found a counterexample for the $k=5$ case: 

$$25^5+84^5+110^5+133^5=144^5.$$

In 1986, Noam Elkies found an infinite family of solutions to $X^4+Y^4+Z^4=W^4$ - another counterexample.  In 1988, Roger Frye used a computer and Elkies's method to find the smallest such counterexample to the $k=4$ case: 

$$95800^4+217519^4+414560^4=422481^4.$$

This is the only solution where $W,X,Y$ and $Z$ are less than $1,000,000$.
AnswerKenntnis:
Can a circle be cut up into a finite number of parts and rearranged to form a square? Laczkovich proved in 1990 that this can be done with about $10^{50}$ pieces.

A good source for this kind of thing is "Old and new unsolved problems in plane geometry and number theory," by Klee and Wagon. The advantage is that none of the problems use more than arithmetic and geometry, so the examples are accessible to people who aren't mathematicians.
AnswerKenntnis:
This recent question on math.SE provides an example, although the apparent pattern is fairly short.

Consider two unit spheres in $n$ dimensions whose centers are $1$ unit apart. What is the fraction $\phi_n$ of the area of one sphere that lies inside the other?

As it turns out, the answer is quite nice for small $n$, but quickly breaks down:
$$\begin{align}
\phi_1 &= \frac12, \\
\phi_2 &= \frac13, \\
\phi_3 &= \frac14, \\
\phi_4 &= \frac13-\frac{\sqrt3}{4\pi} \approx 0.195501\!\ldots, \\
\phi_5 &= \frac5{32}, \\
&\vdots
\end{align}$$

The general formula is $$\phi_n = \frac{\int_{\pi/6}^{\pi/2}\cos^{n-2}\theta\,\mathrm d\theta}{\int_{-\pi/2}^{\pi/2}\cos^{n-2}\theta\,\mathrm d\theta} = \frac12 I_{3/4}\left(\frac{n-1}2,\frac12\right)$$
(thanks @joriki and Wikipedia), where $I_x(a,b)$ is the regularized incomplete beta function.
AnswerKenntnis:
This is a bit complicated for laymen, but it's great for aspiring number theorists. We have two conjectures:

(1) The prime $k$-tuples conjecture: every admissible sequence occurs infinitely often. This is a generalization of the twin prime conjecture, which corresponds to the $k=2$ case. The $k=3$ case is that there are infinitely many $p \in \mathbb{N}$ such that $p$, $p+2$, and $p+6$ are all prime.

(2) The Hardy-Littlewood convexity conjecture: $\pi(x+y)\leq \pi(x)+\pi(y)\ \forall\ x,y\geq 2$, where $\pi(x)$ is the prime counting function. This conjecture claims that the primes are densest for small $x$.

No counterexamples are known for either (1) or (2). In isolation, both (1) and (2) seem reasonable. However, it turns out that (1) and (2) are mutually exclusive, which you might imagine if you stare at them both long enough with a glass of whisky. 

This example comes from Crandall and Pomerance, pp. 20-21: "... the current thinking is that the Hardy-Littlewood convexity [conjecture] is false ... but it also may be that any value of $x$ required to demolish the convexity conjecture is enormous."

For laymen, what you can say is that there are conjectures for which no counterexamples are known, even after checking many billions of cases with computers, but which are nevertheless known to be false.  Another such example is the $\pi(x) < \operatorname{Li}(x)$ false conjecture in Matt Pressland's answer.
AnswerKenntnis:
Here is a true story which might be entertaining, if not strictly following your conditions.

We were working on an algorithm for solving problem X. As is quite usual with algorithms, there is some parameter $n$ measuring the complexity of the input. Our algorithm depended on a set of parameters for each $n$. We were able to find suitable parameters for each $n$.

Then we tried to generalize the algorithm to problem Y, using the same parameters derived for problem X. We worked hard on proving that this approach works. My coauthor proved the cases $n=2,3,4,5$ by hand, each progressively more difficult. The computer (with my help) was able to find a proof for $n = 6$. When asked about $n = 7$, the computer thought for a while and then announced that it couldn't find a proof because for $n = 7$ our approach fails!

Not only were our hearts broken (we stopped working on the problem for a few months), but we were quite at a loss to figure out what goes wrong at $n = 7$, and how to fix it. When algorithms fail, the minimal counterexample is usually small and there is hope of getting around the problem. Not so in this case.

Fortunately, later on we were able to find another set of parameters for problem Y which did work for $n = 7$. This time we held our breath until the computer verified all cases up to $n = 50$, though we were not in peace with ourselves until we proved that our new parameters work for all $n$.
AnswerKenntnis:
Here is  a short sequence: 1, 2, 3, 4, 5, 6 What is next term ? Next term is 1000, obviously.

$a(n)= n + ((n-1)(n-2)(n-3)(n-4)(n-5)(n-6)(p-7))/6!  $

Choose p = 1000 and you┬┤ll get seventh term a(7)= p = 1000, obviously. Choose p = 7 and    you┬┤ll get 7, also obviously. We get $a(7) = p$ and so a(7) is always whatever you want; but  $a(8) = 7p -41 ; a(9) = 56p -383$ are deteremined by p.
 Naturally you can easily extend the formula to whatever 1,2,3,4,5,6,7,8,9,1000111,... as an also obvious example. I found this formula in the book "Planetas" by the Spaniard astrophysicist Eduardo Battaner. I recommend reading his great book: "F├¡sica de las noches estrelladas", full of equations but the better divulgative astrophysics (and in general) book i have ever read, and i read a few. Great book to learn how to divulgate ┬┐"difficult"? problems to amateurs and newcomers in general who could not formally learn it at school/university. After reading it you┬┤ll have a much better idea of what the Universe is without being messed with the abundant (bad) literature. I do not think, though,  there is a translation of the 280 pages book into English or French or German.

See : 

http://lit-et-raire.blogspot.com.es/2013/02/una-sucesion-muy-natural-y-tu-medida.html
AnswerKenntnis:
Here is an example relating to a Diophantine equation. Consider positive integer solutions of $a^3 + b^3 + c^3 = d^3$. The first few primitive solutions all contain 2 odd and 2 even integers, i.e. (3,4,5,6), (1,6,8,9), (3,10,18,19), (7,14,17,20), (4,17,22,25) and (18,19,21,28).  But then the pattern breaks down with (11,15,27,29).

A list of the small solutions is at http://mathworld.wolfram.com/DiophantineEquation3rdPowers.html
AnswerKenntnis:
Here is one example that is incredibly simple, requires no Greek or variables to explain to a layman, and really is wonderfully ridiculous:

Take the series $1-2+3-4...$

Here are the first few partial sums:

$1 = 1$

$1-2= -1$

$1-2+3= 2$

$1-2+3-4= -2$

$1-2+3-4+5= 3$

$1-2+3-4+5-6= -3$

Obviously this series somehow ends at $\infty$ or $-\infty$, or really probably diverges and is neither...right? But here's the kicker - the whole thing ends up at $\dfrac{1}{4}$. That is,

$$1-2+3-4...=\dfrac{1}{4}$$

So we were summing integers, and we were somehow trending towards $\pm\infty$, and then we ended up with a number that is neither an integer nor infinite. How? The proof is simple:

If $s$ is the sum, solve for $4s$:

$4s = (1-2+3-4\cdots) + (1-2+3-4\cdots) + (1-2+3-4\cdots) + (1-2+3-4\cdots)$

$4s = (1-2+3-4\cdots) + 1+(-2+3-4+5\cdots) + 1+(-2+3-4+5\cdots) + (1-2)+(3-4+5-6\cdots)$

$4s = (1-2+3-4\cdots) + 1+(-2+3-4+5\cdots) + 1+(-2+3-4+5\cdots) -1+(3-4+5-6\cdots)$

$4s = 1 + (1-2+3-4\cdots) + (-2+3-4+5\cdots) + (-2+3-4+5\cdots) + (3-4+5-6\cdots)$

$4s = 1 + [ (1-2-2+3) + (-2+3+3-4) + (3-4-4+5) + (-4+5+5-6) \cdots]$

$4s=1 + [0 + 0 + 0 + 0 \cdots]$

$4s=1$

$s=\dfrac{1}{4}$

And voil├á, a mathematical paradox: An interesting pattern that always continues and at the same time ends up somewhere you weren't expecting in the least.
AnswerKenntnis:
From Fermat's Little theorem, for primes $p$, we know that

$$ p \mid 2^p - 2. $$

For which primes $p$ does 

$$p^2 \mid 2^{p} - 2 ?$$



Most people when first seeing this question, would try small cases of $p$, and realize that it doesn't work. They  may then look at

$$\frac{(1+1) ^p - 2}{p} = \frac{{ p \choose 1} + { p\choose 2} + \ldots + { p \choose p-1}}{p} \equiv \frac{1}{1} + \frac{-1}{2} + \frac{1}{3} + \ldots + \frac{(-1)^{p}}{p-1} \pmod{p}$$

and try and prove that it is not 0.

As it turns out, the Wieferich primes satisfy $p^2 | 2^p-2$. There are only 2 known examples of such primes, namely $p=1093, 5311$. There are no other examples less that $10^{17}$.
AnswerKenntnis:
Let $n>0$ and $s_n=\sum_{k=1}^n k$. Now look at the expression $\displaystyle\frac{s_n!}{(s_n-n)!}$. You'll get
$$\frac{1!}{0!}=1=1!,\frac{3!}{(3-2)!}=6=3!,\frac{6!}{(6-3)!}=120=5!,\frac{10!}{(10-4)!}=5040=7!
$$ 
but pattern $\displaystyle \frac{s_n!}{(s_n-n)!}= (2n+1)!$ stops here since $\frac{15!}{(15-5)!}= 360360\neq 9!=362880$
AnswerKenntnis:
An example of a pattern I thought would hold is Waring's Problem. The theorem is that for any natural numbers  $k$ and $n$ if $n>n_0$ there is a $l$ such that $n$ is expressible as the sum of $l$ $k$-th powers. The patter comes in when we attempt to compute these numbers. Obviously any number is the sum of $1$ first power. Lagrange's Theorem shows that any $n$ is the sum of $4$ squares. Also, any large enough $n$ is the sum of $9$ cubes. One may be tempted to think that we would want $16$ fourth powers, however, this is where the pattern diverges. We actually need $19$, and we need $37$ fifth powers, and $73$ sixth powers.
AnswerKenntnis:
The sierpinski numbers would be a good example. All odd integers up to 10,221 have been checked and are known to lead to a prime number of the form k2^n+1, where k is the original odd integer, and n is any integer. One would think that, if the trend continued, there would be no such integers. However, several integers have been proven to generate only composite numbers of the form k2^n+1. The smallest such integer known is 78,557. In addition, it has been proven that there are infinitely many such integers.
QuestionKenntnis:
Does Pi contain all possible number combinations?
qn_description:
I came across the following image, which states:


  $\pi$ Pi
  
  Pi is an infinite, nonrepeating (sic) decimal - meaning that
  every possible number combination exists somewhere in pi.  Converted
  into ASCII text, somewhere in that infinite string if digits is the
  name of every person you will ever love, the date, time and manner of
  your death, and the answers to all the great questions of the
  universe.


Is this true? Does it make absolutely any sense ?
AnswersKenntnis
AnswerKenntnis:
It is not true that an infinite, non-repeating decimal must contain ΓÇÿevery possible number combinationΓÇÖ. The decimal $0.011000111100000111111\dots$ is an easy counterexample. However, if the decimal expansion of $\pi$ contains every possible finite string of digits, which seems quite likely, then the rest of the statement is indeed correct. Of course, in that case it also contains numerical equivalents of every book that will never be written, among other things.
AnswerKenntnis:
Let me summarize the things that have been said which are true and add one more thing.


$\pi$ is not known to have this property, but it is expected to be true.
This property does not follow from the fact that the decimal expansion of $\pi$ is infinite and does not repeat.


The one more thing is the following. The assertion that the answer to every question you could possibly want to ask is contained somewhere in the digits of $\pi$ may be true, but it's useless. Here is a string which may make this point clearer: just string together every possible sentence in English, first by length and then by alphabetical order. The resulting string contains the answer to every question you could possibly want to ask, but


most of what it contains is garbage, 
you have no way of knowing what is and isn't garbage a priori, and
the only way to refer to a part of the string that isn't garbage is to describe its position in the string, and the bits required to do this themselves constitute a (terrible) encoding of the string. So finding this location is exactly as hard as finding the string itself (that is, finding the answer to whatever question you wanted to ask).


In other words, a string which contains everything contains nothing. Useful communication is useful because of what it does not contain.

You should keep all of the above in mind and then read Jorge Luis Borges' The Library of Babel. (A library which contains every book contains no books.)
AnswerKenntnis:
It is widely believed that $\pi$ is a normal number. This (or even the weaker property of being disjunctive) implies that every possible string occurs somewhere in its expansion.

So yes, it has the story of your life -- but it also has many false stories, many subtly wrong statements, and lots of gibberish.
AnswerKenntnis:
This is an open question. It is not yet known if $\pi$ is a normal number.

http://mathworld.wolfram.com/NormalNumber.html
AnswerKenntnis:
According to Mathematica, when $\pi$ is expressed in base 128 (whose digits can therefore be interpreted as ASCII characters),


"NO" appears at position 702;
"Yes" appears at position 303351.


Given (following Feynman in his Lectures on Physics) that any question $A$ with possible answer $A'$ (correct or not) can be re-expressed in the form "Is $A'$ a correct answer to $A$?", and that such questions have either "no" or "yes" answers,  this proves the second sentence of the claim--and shows just how empty an assertion it is.  (As others have remarked, the first sentence--depending on its interpretation--is either wrong or has unknown truth value.)



Code

pNO = FromCharacterCode[RealDigits[\[Pi], 128, 710]];
pYes = FromCharacterCode[RealDigits[\[Pi], 128, 303400]];
{StringPosition[pNO, "NO"], StringPosition[pYes, "Yes"]}



  {{{{702, 703}}, {}}, {{{303351, 303353}}, {}}}
AnswerKenntnis:
In general it it not true that an "infinite non-repeating decimal" contains any sequence in it. Consider for example the number $0.01001000100001000001000000100000001...$.

However, it is not known if $\pi$ does contain ever sequence.
AnswerKenntnis:
This is False.
Claim: Infinite and Non-Repeating, therefore must have EVERY combination.

Counterexample:
01001100011100001111...   This is infinite and non-repeating yet does not have every combination.

Just because something is infinite and non-repeating doesn't mean it has every combination.

Pi may indeed have every combination but you cant use this claim to say that it does.
AnswerKenntnis:
Whether or not it's true, it's absolutely useless.

Imagine finding your life story: a copiously documented and flawless recounting of every day of your life... right up until yesterday where it states that you died and abruptly reverts back to gibberish. If pi truly contains every possible string, then that story is in there, too. Now, imagine if it said you die tomorrow. Would you believe it, or keep searching for the next copy of your life story?

The problem is that there is no structure to the information. It would take a herculean effort to process all of that data to get to the "correct" section, and immense wisdom to recognize it as correct. So if you were thinking of using pi as an oracle to determine these things, you might as well count every single atom that comprises planet Earth. That should serve as a nice warm up.
AnswerKenntnis:
Challenge accepted. In the following file are the first 1,048,576 digits (1 Megabyte) of pi (including the leading 3) converted to ANSI (with assistance from the algorithm described in http://stackoverflow.com/questions/12991606/):

https://docs.google.com/file/d/0B9plORbvSu2ra1Atc0QwOGhYZms/edit
AnswerKenntnis:
I believe the statement could be worded more accurately. Given the reasonable assumption that PI is infinitely non repeating, it doesn't follow that it would actually incude any particular sequence.

Take this thought experiment as an analogy. Imagine you had to sit in a room for all eternity sayings words, without every ever uttering the same word twice. You would very soon find yourself saying very long words. But there's no logical reason why you should have to use up all the possible short words first. In fact you could systematically exclude the words "yes" or every word containing the letter "y", or any other arbitrary subset of the infinite set of possible words.

Same goes for digit sequences in PI. It's highly probably that any conceivable sequence can be found in PI if you calculate for long enough, but it's not guaranteed by the prescribed conditions.
AnswerKenntnis:
And even if your statement is true with $\pi$, it does not make $\pi$ special. If we hit a real number at random, with probability $1$ we will hit a normal number. That is "almost all" real number is like that. The set of not-normal numbers have Lebesgue measure zero.
AnswerKenntnis:
Yes and no.  Yes, any non-repeating infinite sequence can be translated into an ascii representation of random gibberish, which will of course randomly contain everything.  No, that isn't particularly amazing or useful, because whatever message you are looking for is also mistated and refuted an infinite number of times.

(For those that say that it isn't necessarily normal, that is unnecessary as the transformation into ascii can be as complex as you like in order to get the result you desire).
AnswerKenntnis:
It seems like the biggest problem is that it isn't repeating! How could it contain every sequence if repeated sequences are not allowed
QuestionKenntnis:
"The Egg:" Bizarre behavior of the roots of a family of polynomials.
qn_description:
In this MO post, I ran into the following family of polynomials: $$f_n(x)=\sum_{m=0}^{n}\prod_{k=0}^{m-1}\frac{x^n-x^k}{x^m-x^k}.$$
In the context of the post, $x$ was a prime number, and $f_n(x)$ counted the number of subspaces of an $n$-dimensional vector space over $GF(x)$ (which I was using to determine the number of subgroups of an elementary abelian group $E_{x^n}$).

Anyway, while I was investigating asymptotic behavior of $f_n(x)$ in Mathematica, I got sidetracked and (just for fun) looked at the set of complex roots when I set $f_n(x)=0$.  For $n=24$, the plot looked like this: (The real and imaginary axes are from $-1$ to $1$.)



Surprised by the unusual symmetry of the solutions, I made the same plot for a few more values of $n$.  Note the clearly defined "tails" (on the left when even, top and bottom when odd) and "cusps" (both sides).



You can see that after $n=60$-ish, the "circle" of solutions started to expand into a band of solutions with a defined outline.  To fully absorb the weirdness of this, I animated the solutions from $n=2$ to $n=112$.  The following is the result.



Pretty weird right!?  Anyhow, here are my questions:


  
  First, has anybody ever seen anything at all like this before?
  What's up with those "tails?"  They seem to occur only on even $n$, and they are surely distinguishable from the rest of the solutions.
  Look how the "enclosed" solutions rotate as $n$ increases.  Why does this happen? [Explained in edits.]
  Anybody have any idea what happens to the solution set as $n\rightarrow \infty$?
  These are polynomials in $\mathbb{Z}[x]$.  Can anybody think of a way to rewrite the formula (perhaps recursively?) for the simplified polynomial, with no denominator?  If so, we could use the new formula to prove the series converges to a function on the unit disc, as well as cut computation time in half.  [See edits for progress.]
  Does anybody know a numerical method specifically for finding roots of high degree polynomials?  Or any other way to efficiently compute solution sets for high $n$? [Thanks @Hooked!]
  


Thanks everyone.  This may not turn out to be particularly mathematically profound, but it sure is neat.



EDIT: Thanks to suggestions in the comments, I cranked up the working precision to maximum and recalculated the animation.  As Hurkyl and mercio suspected, the rotation was indeed a software artifact, and in fact evidently so was the thickening of the solution set.  The new animation looks like this:



So, that solves one mystery: the rotation and inflation were caused by tiny roundoff errors in the computation.  With the image clearer, however, I see the behavior of the cusps more clearly.  Is there an explanation for the gradual accumulation of "cusps" around the roots of unity?  (Especially 1.)



EDIT: Here is an animation $Arg(f_n)$ up to $n=30$.  I think we can see from this that $f_n$ should converge to some function on the unit disk as $n\rightarrow \infty$.  I'd love to include higher $n$, but this was already rather computationally exhausting.



Now, I've been tinkering and I may be onto something with respect to point $5$ (i.e. seeking a better formula for $f_n(x)$).  The folowing claims aren't proven yet, but I've checked each up to $n=100$, and they seem inductively consistent.  Here denote $\displaystyle f_n(x)=\sum_{m}a_{n,m}x^m$, so that $a_{n,m}\in \mathbb{Z}$ are the coefficients in the simplified expansion of $f_n(x)$.


First, I found $\text{deg}(f_n)=\text{deg}(f_{n-1})+\lfloor \frac{n}{2} \rfloor$.  The solution to this recurrence relation is $$\text{deg}(f_n)=\frac{1}{2}\left({\left\lceil\frac{1-n}{2}\right\rceil}^2 -\left\lceil\frac{1-n}{2}\right\rceil+{\left\lfloor \frac{n}{2} \right\rfloor}^2 + \left\lfloor \frac{n}{2} \right\rfloor\right)=\left\lceil\frac{n^2}{4}\right\rceil.$$
If $f_n(x)$ has $r$ more coefficients than $f_{n-1}(x)$, the leading $r$ coefficients are the same as the leading $r$ coefficients of $f_{n-2}(x)$, pairwise.
When $n>m$, $a_{n,m}=a_{n-1,m}+\rho(m)$, where $\rho(m)$ is the number of integer partitions of $m$.  (This comes from observation, but I bet an actual proof could follow from some of the formulas here.)  For $n\leq m$ the $\rho(m)$ formula first fails at $n=m=6$, and not before for some reason.  There is probably a simple correction term I'm not seeing - and whatever that term is, I bet it's what's causing those cusps.


Anyhow, with this, we can make almost make a recursive relation for $a_{n,m}$,
$$a_{n,m}= \left\{
     \begin{array}{ll}
       a_{n-2,m+\left\lceil\frac{n-2}{2}\right\rceil^2-\left\lceil\frac{n}{2}\right\rceil^2} & : \text{deg}(f_{n-1}) < m \leq \text{deg}(f_n)\\
       a_{n-1,m}+\rho(m) & : m \leq \text{deg}(f_{n-1})  \text{ and } n > m \\
       ? & : m \leq \text{deg}(f_{n-1})  \text{ and } n \leq m
     \end{array}
   \right.
$$
but I can't figure out the last part yet.



EDIT:
Someone pointed out to me that if we write $\lim_{n\rightarrow\infty}f_n(x)=\sum_{m=0}^\infty b_{m} x^m$, then it appears that $f_n(x)=\sum_{m=0}^n b_m x^m + O(x^{n+1})$.  The $b_m$ there seem to me to be relatively well approximated by the $\rho(m)$ formula, considering the correction term only applies for a finite number of recursions.

So, if we have the coefficients up to an order of $O(x^{n+1})$, we can at least prove the polynomials converge on the open unit disk, which the $Arg$ animation suggests is true.  (To be precise, it looks like $f_{2n}$ and $f_{2n+1}$ may have different limit functions, but I suspect the coefficients of both sequences will come from the same recursive formula.)  With this in mind, I put a bounty up for the correction term, since from that all the behavior will probably be explained.



EDIT: The limit function proposed by Gottfriend and Aleks has the formal expression $$\lim_{n\rightarrow \infty}f_n(x)=1+\prod_{m=1}^\infty \frac{1}{1-x^m}.$$
I made an $Arg$ plot of $1+\prod_{m=1}^r \frac{1}{1-x^m}$ for up to $r=24$ to see if I could figure out what that ought to ultimately end up looking like, and came up with this:



Purely based off the plots, it seems not entirely unlikely that $f_n(x)$ is going to the same place this is, at least inside the unit disc.  Now the question is, how do we determine the solution set at the limit?  I speculate that the unit circle may become a dense combination of zeroes and singularities, with fractal-like concentric "circles of singularity" around the roots of unity...  :)
AnswersKenntnis
AnswerKenntnis:
First, has anybody ever seen anything at all like this before?


Yes, and in fact the interesting patterns that arise here are more than just a mathematical curiosity, they can be interpreted to have a physical context. 

Statistical Mechanics

In a simple spin system, say the Ising model, a discrete set of points are arranged on a grid. In physics, we like to define the energy of the system by the Hamiltonian, which gives the energy of any particular microstate. In this system, if the spins are aligned they form a bond. This favorable and the energy is negative. If they are misaligned, the energy is positive. Let's consider a simple system of two points, adjacent to each other. Furthermore, let each site point up (1) or down (-1). For an Ising-like system we would write the Hamiltonian as:

$$
H = - \sum_{ij} J \sigma_i \sigma_j
$$

where $\sigma_i$ is the spin of the $i$th point and the summation runs over all pairs of adjacent sites. $J$ is the strength of the bond (which we can set to one for our example).

In our simple system we have only four possible states:

0 - 0     H = -J
1 - 0     H =  0
0 - 1     H =  0
1 - 1     H = -J


Now we can write the partition function $\mathcal{Z}$, a term which encompasses all information of the Hamiltonian from the perspective of statistical mechanics:

$$
\mathcal{Z} = \sum_s \exp (H(s)/kT)
$$

Here the summation runs over all possible (micro)states of the system. The partition function is really useful as it is related to the free energy $A = -kT \ln{\mathcal{Z} }$. When the partition function goes to zero, the free energy explodes and this signifies a  phase change - a physically interesting event.

What about our simple system? 

$$
\mathcal{Z} = 2 \exp({\beta J}) + 2 = 2x + 2
$$

You'll notice that I changed $x=\exp({\beta J})$ to make things a little neater. You may also notice that $\mathcal{Z}$ looks like polynomial. Which means if we want to find the interesting events in the system we find the zeros of the partition function $\mathcal{Z}=0$. This zero will correspond to a particular temperature $T$. In this case the only temperature we get is a complex one ...

Complex Temperatures?

Before you discount the idea that a temperature not on the real number line is impossible (and that $T<0$ is strange as well), let's see where this takes us. If we continue the to add sites to our simple little system, our polynomial will get a bit more complicated and we will find more roots on the complex plane. In fact, as we take ever more roots the points appear to form a pattern, much like the pattern you've shown above.

For a finite spin system, you'll never find a zero on the real axis, however...


  Anybody have any idea what happens to the solution set as nΓåÆΓê₧?


At the thermodynamic limit (which corresponds to an infinite number of sites) the points become dense on the plane. At this limit the points can touch the real axis (corresponding to a phase change in the system). For example, in the 2D Ising model the points do touch the real axis (and make a beautiful circle on the complex plane) where the system undergoes a phase transition from ordered to disordered.

Prior work

The study of these zeros (from a physics perspective) is fascinating and started with the seminal papers by Yang and Lee:

Yang, C. N.; Lee, T. D. (1952), "Statistical Theory of Equations of State and Phase Transitions. I. Theory of Condensation", Physical Review 87: 404ΓÇô409, doi:10.1103/PhysRev.87.404

Lee, T. D.; Yang, C. N. (1952), "Statistical Theory of Equations of State and Phase Transitions. II. Lattice Gas and Ising Model", Physical Review 87: 410ΓÇô419, doi:10.1103/PhysRev.87.410

Which are surprisingly accessible. For a good time, search for images of Yang-Lee zeros. In addition you can extend the fugacity to the complex plane, these are called the Fisher zeros and make even more complex patterns!
AnswerKenntnis:
A nicer(?) recursive scheme (for the polynomials, not yet for the roots) is the following. We initialize $f_0(x)$ and $f_1(x)$ with series constants (notation:Pari/GP): $f_0=Ser(1) $ and $f_1 = Ser(2)$. Then we proceed recursively:     

$$ \quad \begin{array} {rcll}
f_0 & = & 1 \\
f_1 & = & 2 \\
\hline 
f_2 & = & 2*f_1 -f_0+f_0*x^1 \\
f_3 & = & 2*f_2 -f_1+f_1*x^2 \\
f_4 & = & 2*f_3 -f_2+f_2*x^3 \\
f_5 & = & 2*f_4 -f_3+f_3*x^4 \\
f_6 & = & 2*f_5 -f_4+f_4*x^5 \\
 \vdots & & \vdots \\
f_k & = & 2*f_{k-1} - (1-x^{k-1})*f_{k-2}\\
 \end{array}
$$    

[update]
For the coefficients $a_{r,c}$ we get
$$a_{r,c} = 2 a_{r-1,c}- a_{r-2,c} + a_{r-2,c-(r-1)} $$
where we assume that negative column indices $c$ in the rightmost term simply produce zeros in the referred $a_{r,c}$ coefficients.

The degrees of the polynomials are
$$ \begin{eqnarray*}\quad \deg(f_{2r})&=&r^2  \text{    and}\\
 \quad \deg(f_{2r+1})&=&r^2+r.\\ \end{eqnarray*}$$
AnswerKenntnis:
I've so far a reformulation in terms of q-binomials, which might make it easier to understand the result. 
First I reformulated your sum-of-products as
$$ \begin{align} f_n(x)&=\sum_{m=0}^n \prod_{k=1}^m {x^{n-(k-1)}-1\over x^k-1} 
 \\ &=1 
 \\ &+{x^{n}-1\over x^1-1} 
 \\ &+{x^{n}-1\over x^1-1} \cdot {x^{n-1}-1\over x^2-1} 
 \\ &+{x^{n}-1\over x^1-1} \cdot {x^{n-1}-1\over x^2-1} \cdot {x^{n-2}-1\over x^3-1}
 \\ & \vdots
 \\ &+{x^{n}-1\over x^1-1} \cdot \ldots \cdot{x^{1}-1\over x^n-1}
\end{align}
$$
where the summands are also the "q-binomials" (here with base q=x) such that
$$ f_n(x) = \sum_{k=0}^n {n\choose k}_{[x]} $$
$\qquad \qquad$(For instance, for the base x=1 we get $f_n(1)=2^n \ $ using $\lim_{x\to 0}$. )   

There is some interesting literature on q-binomials online (wikipedia,mathworld,...) , maybe you can find something in it which allows to conclude on the polynomial roots this way with more ease...    

The above sum $f_n(x)$ can  also be factored: 
$$ f_n(x) = 1 + {x^n-1\over x^1-1}
    \left(1+ {x^{n-1}-1\over x^2-1} 
       \left(1+ {x^{n-2}-1\over x^3-1}
          \left( \ldots \right)
       \right)
    \right)$$
This gives yet another access to the polynomial roots, however I don't see really the benefit of the latter reformulation.

In the wikipedia-article there is also a limit for the q-binomial where $n \to \infty$ as $$ \lim_{n \to \infty} {n\choose r}_x = {1 \over [r]_x! \cdot (1-x)^r }$$
That means that the sum $ \lim_{n \to \infty}f_n(x)$ has a (formal) expression like
$$ \lim_{n \to \infty}f_n(x) = 1 + {1\over 1-x} + {1\over (1-x)(1-x^2)} + {1\over (1-x)(1-x^2)(1-x^3)} + \cdots $$
I don't see however yet, how one could extract the polynomial roots for the case of that limiting process...
AnswerKenntnis:
I wanted to make a quick point which is implicit in the comments (particularly  Steven Stadnicki's link to John Baez).  It is tempting when considering a specific family of functions with an interesting form, to conclude that this behavior is an interesting pattern about this particular family of examples.  What the calculations at Baez's site suggest is that it may be that this behavior might just be the behavior of a random family of polynomials.  That is, what you're seeing may not be something about this family being sufficiently structured, but rather a way in which this family is sufficiently random.
AnswerKenntnis:
This is by no means a complete answer but I made an interesting observation. Let

$$g_{n,m}(x) = \prod_{k=0}^{m-1}\frac{x^n-x^k}{x^m-x^k}$$

so that $f_n(x) = \sum_{m=0}^n g_{n,m}(x)$. We want to examine the behavior of $g_{n,m}(x)$ as $n\to \infty$. I made a table of these for several $n$ and $m$ in mathematica and noticed that they probably each converge to some functions:  $g_{n,m}(x) \to g_m(x)$ as $n \to \infty$. Assuming $|x|<1$, I ran a limit as $n \to \infty$ of the ratio of two consecutive $g$'s and got

$$\lim_{n\to\infty} \frac{g_{n,m-1}(x)}{g_{n,m}(x)} = 1-x^m$$

(It requires proof still). Since $g_0(x) = 1$ we obtain the formula

$$\lim_{n\to\infty} g_{n,m}(x) = g_m(x) = \frac{1}{(1-x)(1-x^2)\dots(1-x^m)}$$

I think one could hope that as $n\to\infty$, that

$$f_n(x) \to 1 + \sum_{m=1}^{\infty} g_m(x) = 1 + \sum_{m=1}^{\infty} \frac{1}{(1-x)(1-x^2)\dots(1-x^m)}$$

but of course this probably won't happen, because at the very least neither $f_n$ nor this function on the RHS above converge - for example, the constant coefficient becomes unbounded. Here is something to think about though. We have the following identity by Euler

$$1+\sum_{n=1}^{\infty} \frac{s^n x^n}{(1-x)(1-x^2)\dots(1-x^n)} = \prod_{i=1}^{\infty} \frac{1}{1-sx^i}$$

which has to do with partitions. Maybe there is a way to modify $f_n(x)$ that will make it converge properly. For example, dividing $f_n(x)$ by $n+1$ keeps the constant coefficient at 1.

EDIT: Wow, this is a blast from the past and maybe it's just late at night or something but I decided to look at the series representation of $F_n(x)/n$ where 

$$F_n(x) = 1+ \sum_{m=1}^{n} \frac{1}{(1-x)(1-x^2)\dots(1-x^m)}$$
for large $n$. For example for $n = 1000$ we have the series

$$F_{1000}(x) = 1.001 + 1. x + 1.999 x^2 + 2.997x^3 + 4.993x^4 + 6.987x^5 + 10.976 x^6 + 14.961 x^7 +  21.936x^8 + 29.902 x^ 9 + 41.85 x^{10}$$

These coefficients are getting suspiciously close to the numbers 

$$ \{1, 1 , 2, 3 , 5, 7, 11, 15, 22, 30, 42, \ldots \} $$

which you may recognize as the number of partitions of $n$ for $n = 0, 1, 2 ,3,\ldots$. As such it's probably safe to conjecture that as $n \to \infty$

$$ \frac{F_n(x)}{n} \to P(x) = \sum_{n=0}^{\infty} p(n) x^n = \prod_{k=1}^\infty \frac {1}{1-x^k}$$

where $p(n)$ is the number of partitions of $n$ and $P(x)$ is its generating function.
AnswerKenntnis:
I just want to jump on the bandwagon to make an observation which I don't believe anyone has made so far, and which I think is interesting (if only for having been overlooked). The formula

$$f(x) = 1 + \prod_{m=1}^\infty (1-x^m)^{-1}$$

which Gottfriend and Aleks have found for the limiting function, should jump in the face of anyone who has worked with modular forms. In fact, the function 

$$\eta(x) = x^{1/24}\prod_{m=1}^\infty (1-x^m)$$

is known as the Dedekind eta function. It is (more or less) a modular form of weight $1/2$ and level one. Its twenty-fourth-th power is known as the modular discriminant, and it is an important function in the theory of elliptic curves.

Why the Dedekind eta function should appear in this context, I have not a clue.
QuestionKenntnis:
Is value of $\pi = 4$?
qn_description:
What is wrong with this?



SOURCE
AnswersKenntnis
AnswerKenntnis:
This question is usually posed as the length of the diagonal of a unit square.  You start going from one corner to the opposite one following the perimeter and observe the length is 2, then take shorter and shorter stair-steps and the length is 2 but your path approaches the diagonal.  So $\sqrt{2}=2$  In both cases, you are approaching the area but not the path length.  You can make this more rigorous by breaking into increments and following the proof of the Riemann sum.  The difference in area between the two curves goes nicely to zero, but the difference in arc length stays constant.

Edit:  making the square more explicit.  Imagine dividing the diagonal into n segments and a stairstep approximation.  Each triangle is $(\frac{1}{n},\frac{1}{n},\frac{\sqrt{2}}{n})$.  So the area between the stairsteps and the diagonal is $n \frac{1}{n^2}$ which converges to 0.  The path length is $n \frac{2}{n}$, which converges even more nicely to 2.
AnswerKenntnis:
This problem illustrates the fact that two functions can be very close: $|f(x)-g(x)|<\epsilon$
for all $x\in [0,1]$, but their derivatives can still be far apart, $|f'(x)-g'(x)|>c$ for some
constant $c>0$. 
In our case, let $x=a(t),y=b(t),0\le t\le 1$ and $x=c(t),y=d(t), 0\le t\le 1$ be the 
parametrizations of the two curves. By smoothing the corners, we may assume that both
are smooth. $$ \|(a(t),b(t))\|\approx \|(c(t),d(t))\|$$ does not imply
$$  \|(a'(t),b'(t))\|\approx \|(c'(t),d'(t))\|$$
Therefore $\int_0^1 \|(a'(t),b'(t))\| dt$ need not be close to $\int_0^1 \|(c'(t),d'(t))\| dt.$
Here $\|(x,y)\|$ denotes $\sqrt{x^2+y^2}$.
AnswerKenntnis:
The pithy expression for this "paradox" is as follows: let $x_n(t)$ be a sequence of parameterized curves which converges uniformly to a limit curve $x(t)$.  Then it need not be the case that the arclengths of $x_n(t)$ approach the arclength of $x(t)$.

[Added after seeing TCL's answer: it is also true that uniform convergence of a sequence of functions does not imply convergence of their derivatives.  See Section 3 here for some discussion of this.  As TCL points out, since arclength elements are computed using derivatives, the observation about derivatives may be in some sense more fundamental.  In other words, I think I like TCL's answer better than mine.]

As Ross Millikan points out, this is more familiarly shown by approximating the hypotenuse of a right triangle by a staircase pattern of horizontal and vertical line segments.  I still remember being a senior in high school and having a friend (whom I had had no prior mathematical interactions with) show this to me.  I definitely remember thinking that it was not paradoxical but certainly surprising.  (And I have mathematically respected this person ever since, even though I haven't seen her since I was a teenager.)  

Added much later: if you think about the phenomenon physically rather than geometrically, it seems to me that the surprise disappears.  For instance, suppose I'm running and you're driving a motorcycle.  It is possible for your speed at every instant to be 25 times (say) faster than mine while maintaining a very small distance from me: e.g. you could drive very small, very fast circles around me.
AnswerKenntnis:
Hilarious! Of course, the circumference is not approximated by the sum of lengths of the lines constructed as shown, but by the sum of the hypotenuses of each of the right-angle triangles formed around the edge of the circle (forming a polygon with vertices on the circle).
AnswerKenntnis:
What is wrong with this?


Fundamentally, that you have jumped in without a definition of the length of a arc.
AnswerKenntnis:
R.I.P. Archimedes



A photogenic answer to such a question!
AnswerKenntnis:
I am probably going a little off-topic with these comments, so feel free to downvote :)

In my opinion this type of proof emphasizes why it is wrong to teach/take ΓÇ£CalculusΓÇ¥ instead of Analysis.

For most of the nice applications of integration, we always use the following approach: take some quantity/expression, break it in many pieces, identify the sum of many pieces as a Riemann sum, and thus our quantity is the limit of the Riemann sums, thus the corresponding integralΓÇª

Unfortunately, except in serious Analysis courses, not even once do we go into the subtle details: why is the Riemann sum a good approximation for our quantity, namely why does the error in our approximation go to zeroΓÇª

Most students who take Calculus end up ΓÇ£understandingΓÇ¥ lots of false results, which we donΓÇÖt have the time to disprove in general: any derivative is continuous, any approximation that looks good is good, ΓÇª

To come back to this problem, not all approximations that look good are good. We always MUST prove that the errors in our approximations go to zero. And for all the formulas we ΓÇ£proveΓÇ¥ in calculus, there is an actual mathematical proof, which is pretty technical (and most non-mathematicians would say boring and stupid, but then without such proofs one cannot really understand why the ΓÇ£proofΓÇ¥ from the above picture is wrong). But without going through the formal proofs, one cannot truly understand why that particular approximation works in that case, and more importantly why a different approximation wonΓÇÖt work.

Coming back to the above picture, one way to understand it is the following: we approximate the circle by a sequence of polygons. Let $c_n$ be the length of the $n$th polygon and $c$ be the length of the circle. At each step the error in our approximation is $4-\pi$, which doesnΓÇÖt go to zero. This means that the arclength of the circle might not be the limit of arclengths of the polygons. The only thing we can conclude is that, if all the quantities and limits that appear in the picture exist, then the limit approximates the arclength of the circle with an error of at most the limsup of the errors. In other words, $4 \approx \pi$ with an error less than or equal to $4-\pi$. Hmm, what is wrong with this?
AnswerKenntnis:
(non-rigorous:)

This is simply another example of why the "limit of the sum" is not the "sum of the limit."

(Length of curves are a subset of Sums/Integrals which are really the same thing in my mind.  If you like, in this case "the limit of the lengths of the curves " is not the "length of the limit curve")
AnswerKenntnis:
(non rigorous) If you repeat the process a million times it "seems" (visually) that the perimeter approaches in length to the circumference, but if you magnify the picture of a single "tooth" to full screen, you will notice a big difference from the orthogonal segments and the arc of the circumference. No matter how many times you repeat the process that difference will never fade.

ADDED: A visual example of what I meant is folding of a rope. If you imagine the rope not having thickness, you can fold it so many times that you can tend to a point (zero length?). If you unfold it, it will return to its original shape. In the example the perimeter will always be of total length = 4, but it only appears to blend with the circumference.
AnswerKenntnis:
This is an old chestnut, and is usually given in the form mentioned by Ross Millikan in his answer, just as he says.

The concise answer is that topological convergence does not imply convergence in measure. Once you have this correct big picture in your head, the problem disappears. The detailed analysis, such as supplied by Ross Millikan, is just the closing argument for a case already won. Thus, the real purpose of this problem is to bring to the attention of the student the distinction between topological convergence and convergence in measure.

As a bonus, this problem (in the ΓÇ£diagonal of a unit squareΓÇ¥ version) shows why wiggly coastlines are preferred, in regard to sea-faring vessels: Such coastlines provide much more opportunities for docking/harboring.

edit (18.Dec.2011 Taiyuan China):
I suppose that this conundrum can appear in quite a number of forms. One such other form is what we might call the ΓÇ£helicopter paradoxΓÇ¥, namely, that if you double the length of the helicopter rotor, but halve its speed, you obtain the same lift, and, if youΓÇÖre not careful, you also obtain the false conclusion that a rotor of infinite length not rotating would exert the same lift on the helicopter as a normal rotor. The solution to this enigma (ΓÇ£What is the lift of an infinite helicopter rotor at rest?ΓÇ¥) is that the convergence alluded to in the statement of the problem is merely topological convergence, but the conclusion of convergence-in-measure is, fallaciously, being drawn from this. A presentation of this conundrum, as a purported ΓÇ£thought experimentΓÇ¥ is given at the following link, where there seems to be no hint that the proposer is aware of its real solution:

http://www.pitt.edu/~jdnorton/Goodies/TE-antiTE/index.html
AnswerKenntnis:
Ah, the old engineer vs mathematician thought process.

Place an engineer and a mathematician at one end of a room. At the other end is a beautiful woman. At each "step", they can each move half of the remaining distance between their current position and the woman. The mathematician will say you'll never reach her. The engineer will say you can get close enough.

This problem is similar. A unit square's outermost corners are being "bent" inward to touch a 1/2-unit circle until there are so many corners that the square is, at this zoom level, indistinguishable from the circle itself (similar to using rectangular pixels). Repeated "to infinity" the two shapes would have the same area. However, this process will never yield a mathematical circle; only an engineer's approximation ("close enough") This will always produce the same perimeter measurement even as the areas of the two shapes converge. If instead you were to measure around the hypotenuses as you iterated this shape definition, the perimeter WOULD begin to approach that of the circumference of the half-unit circle, $\pi$.

The fallacy of the proof is illustrated if you consider the shape made by any two line segments that intersect at a point other than on the circle. These two lines will inscribe an arc length as they each intersect a different point on the circle. For simplicity, you can think of the resulting shape as a right triangle. The proof is basically claiming that the sum of the length of the two legs of that triangle is equal to the hypotenuse. This is never true, because the Pythagorean Theorem of $a^2+b^2=c^2$ never holds for any $a,b,c > 0$ where $a+b=c$. 

The only way it can work is for an $a$ or $b$ that is zero and thus the area of the shape is zero; this never happens in the construction being generated, at any interval, because by the definition of the construction we have two points that lie on the circle and one point lying outside the circle, and from geometry, any three non-colinear points will always inscribe a shape within a plane of non-zero area.
AnswerKenntnis:
Correct answer: Nothing is wrong with this, as long as your space is defined using a Manhattan metric.  Normal Euclidean space is defined using a Euclidean metric.
AnswerKenntnis:
What if the measurement we use, patterning it after a string wrapped around this circle, weaves back and forth? Essentially, we can find a series of connected line segments with length that total $1000000000$ and yet "hug" the circle very closely. A string analogy follows closely though line segments have width $0$ so we can fit arbitrarily many.

This is why not just any reasoning about infinity will do. Mathematicians have developed well reasoned arguments and axioms that correlate well in many cases with reality (see also this argument).

So the question of why doesn't $\pi = 4$ is best answered by asking, "Why should it?" We can just as well have used the ridiculous construction above to suggest $\pi =$ any number $> 3.15$.

The approach we take to argue convincingly that the sum of the line segments approaches the "length of the curve" is to find sequences (from series partial sums) that match to functions (note the question example and the weaving example do not constitute a function because of its multiple values at a given "$x$") which have certain characteristics. For example we might use a lower and upper bounding pair of sequences that correspond to function values of line segment endpoints for such created polygons where one remains on one side of the curve and the other on the other side at all times and where these two sequences approach the same limiting value. We might use the Mean Value Theorem or related results to help prove our final answer. In any case, mathematicians leverage a convincing set of arguments and assumptions and don't just ad hoc throw a bunch of twisted string at a problem and claim the amount of string used proves the unprovable.
AnswerKenntnis:
The picture shows a sequence of curves $\gamma_n$ which approach (in what is called "uniform distance") the circumference of a circle $\gamma$. Then the picture says that the length of these curves is always the same: $\ell (\gamma_n) = 4$. If the function $\ell$ were a continuous function you would get the stated result:
$$
4 = \lim_{n\to \infty} \ell(\gamma_n) = \ell(\gamma) = \pi.
$$

Unfortunately $\ell$ is not a continuous function, and this example is a proof of this fact.
AnswerKenntnis:
This is an interesting question. Although all of the above answers explain it properly, I would like to add a visual to this question. This will provide more insight into this question, hopefully. Thanks! Basically, the converged circle won't be a smooth circle and the perimeter is more!
QuestionKenntnis:
Proofs that every mathematician should know?
qn_description:
There are mathematical proofs that have that "wow" factor in being elegant, simplifying one's view of mathematics, lifting one's perception into the light of knowledge etc.

So I'd like to know what mathematical proofs you've come across that you think other mathematicans should know, and why.
AnswersKenntnis
AnswerKenntnis:
Here is my favourite "wow" proof .  

Theorem
There exist two  positive irrational numbers $s,t$  such that $s^t$ is rational.
Proof
If $\sqrt2^\sqrt 2$ is rational, we may take $s=t=\sqrt 2$ .
 If $\sqrt 2^\sqrt 2$ is irrational , we may take $s=\sqrt 2^\sqrt 2$ and  $t=\sqrt 2$ since  $(\sqrt 2^\sqrt 2)^\sqrt 2=(\sqrt 2)^ 2=2$.
AnswerKenntnis:
I think every mathematician should know the following (in no particular order):


Pythagorean Theorem.
Summing $\sum_{k = 1}^{n} k$ using Gauss' triangle trick.
Irrationality of $\sqrt{2}$ by proof without words.
Niven's proof of the irrationality of $\pi$.
Uncountability of the Reals by Cantor's Diagonal Argument.
Denumerability of the Algebraics by Heights and Counting Roots.
Infinitude of primes by both Euclid's proof and Euler's proof.
Constructibility of the Regular 17-gon by Gauss' explicit construction.
Binomial Theorem by Induction.
FLT $n = 4$ by Fermat's Infinite Descent.
Every PID is a UFD.
The $\lim_{n \to \infty} (1 + \frac{1}{n})^{n} = e$ by L'H├┤pital's Rule.
Pick's Theorem by reduction to triangles and squares.
Fibonacci numbers in terms of the Golden Ratio by recurrence relations.
$\mathbb{R}^{n}$ is a metric space in more than one way.
Euler's Formula $e^{i \theta} = \cos \theta + i \sin \theta$ by differentiation.
Summing $\sum_{k \geq 1} \frac{1}{k^{2}}$ by Fourier series.
Quadratic reciprocity by Eisenstein's proof (counting lattice points).
$(\mathbb{Z}/n \mathbb{Z})^{\times}$ is a group (of units) for $n \in \mathbb{N}$, and $\mathbb{Z} / p \mathbb{Z}$ is a field for prime $p$.
Euler's formula $v - e + f = 2$ for planar graphs.
Fundamental Theorem of Algebra by Liouville's Theorem.


This is, of course, my opinion....

NB: When I write "by ..." I mean that particular proof methodology (as opposed to another perhaps easier method), because of the pedagogical benefit of that route of proof.
AnswerKenntnis:
Cantor's Theorem: There is no surjection from $A$ onto $\mathcal P(A)$.
AnswerKenntnis:
.... and of course the neat proof that
$$
\int_{-\infty}^\infty e^{-x^2}\,dx=\sqrt{\pi}.
$$
AnswerKenntnis:
Proofs from THE BOOK is a brilliant compilation of such beautiful succinct proofs.
AnswerKenntnis:
Here is one strategy for proving Fermat's Last Theorem: suppose you could show that $x^n + y^n = z^n$ has no nontrivial solutions ${}\bmod p$ for infinitely many primes $p$. Then any nontrivial solution over $\mathbb{Z}$ necessarily reduces to a nontrivial solution mod a sufficiently large prime, so you've proven FLT.

Unfortunately, this is false: for fixed $n$, the Fermat equation has nontrivial solutions ${}\bmod p$ for all sufficiently large primes $p$! This was first proven by Schur (I am told), and the proof uses Ramsey theory and very little actual number theory. I think this proof teaches the following valuable lessons:


What seems like a problem in one field might be best thought of as a problem in another.
Sometimes the way to solve a problem is to ignore a lot of its structure.
AnswerKenntnis:
G├╢del's theorem was definitely a "wow" for me.

Also interesting, the proof around the non-Enumerability of $\mathbb{R}$.

In the same area, the Fact that $\mathbb{Q}$ is a dense subset of $\mathbb{R}$, despite the fact that $\mathbb{Q}$ is numerable while $\mathbb{R}$ is not. It kind of suggests that $n(\mathbb{Q}) = n(\mathbb{R}-\mathbb{Q})$ while at the same time $\mathbb{R}-\mathbb{Q}$ is infinitely bigger than $\mathbb{Q}$...

Church numerals if you're into computer science.
AnswerKenntnis:
I would say the proof of the Brouwer Fixed Point Theorem for $D^n$ using the fact that $H_n(S^n) \cong \Bbb{Z}$ and $H_n(D^n) = 0$ is nice. The idea of the proof by contradiction that if for no $x$ is $f(x) = x$, we can draw a straight line through these points, that for me was very elegant.
AnswerKenntnis:
The proof of the Fundamental Theorem of Algebra via Liouville's theorem is short and sweet.
AnswerKenntnis:
I'm particularly fond of Ramsey's Theorem.
AnswerKenntnis:
The ultrafilter proof of Tychonoff's theorem.

The proof is simple, show the power of working with filters and incorporats a good deal of what "everyone should know about compactness".

The strategy-stealing argument for why the first player can force a win in hex.

The argument is simple, elegant, clever and there is eesentially no effort in learning it.

The proof of Zorn's lemma by way of ordinals.

Too many people believe that Zorns lemma is an inherently incomprehensible black box. It is not. 

Heine-Borel by "induction."

The argument is very neat and shows exactly where the completeness of $\mathbb{R}$ matters.

The visual argument for finding the area of a circle, given radius and circumference.

It's simply beautiful.
AnswerKenntnis:
$$2+2=4$$

Of course I am talking in the context of Peano Axioms (or some other reasonable theory of arithmetics).

Indeed most mathematicians could come up with the proof in a matter of minutes, after seeing the axioms, the trick of course is to understand what is there to prove here anyway?


   We defined $+$ by induction. We denote by $2=S(1)$ and $4=S(S(S(1)))$. Now we need to prove that the terms $S(1)+S(1)$ and $S(S(S(1)))$ are equal, because there is no axiom tell us that directly.
AnswerKenntnis:
I would have to include (at least) one of the proofs available for quadratic reciprocity. My personal preference would be for the proof due to Eisenstein presented in Ireland and Rosen, but there are so many others to choose from.

A second one I would include would be Minkowski's lattice point theorem, as proved in Hasse's "Number Theory".
AnswerKenntnis:
I personally believe some of the proofs of Pythagoras' theorem can be both beautiful and elegant, though it is unfortunate that it is not taught in school (at least as far as I am aware).

Take any square with sides of length $x+y$.  Then $x$ units from each corner, connect to the next corner, again $x$ units away.  Call this distance $z$.  Therefore you have a square with side length $x+y$ with four triangles with base and height $x$ and $y$ and a smaller square in the middle with a side length of $z$.

$$(x+y)^2=4\frac{1}{2}xy+z^2$$
$$x^2+y^2+2xy-2xy=z^2$$
$$x^2+y^2=z^2$$
AnswerKenntnis:
Euclid's proof. Very simple, very elegant

Theorem

There are more primes than found in any finite list of primes. 

Proof 

Call the primes in our finite list $p_1, p_2, ..., p_r$.  Let P be any common multiple of these primes plus one (for example, $P = p_1p_2...p_r+1$).  Now P is either prime or it is not.  If it is prime, then P is a prime that was not in our list.  If P is not prime, then it is divisible by some prime, call it p.  Notice p can not be any of $p_1, p_2, ..., p_r$, otherwise p would divide 1, which is impossible.  So this prime p is some prime that was not in our original list.  Either way, the original list was incomplete.
AnswerKenntnis:
As a beginner (and far from being a mathematician) there are two proofs that I have come across that I would say, for me, were "symphonic" capers of some areas of study - showing what can be done with material you've studied.

An additional point is that the actual presentation of the proofs themselves were instructive in their elegance. Sort of like a virtuoso performer. 

The Stone-Weierstrass Theorem - Vaughan Jones
https://sites.google.com/site/math104sp2011/lecture-notes

The Sylow Theorems - Benedict Gross
http://www.extension.harvard.edu/open-learning-initiative/abstract-algebra
AnswerKenntnis:
The Weyl Character formula is an excellent example of a deep result with a clever proof. The result states (in one form) that the irreducible characters of a compact, connected Lie group are parametrized uniquely by their heighest weight vectors! The intuition is that characters on a compact, connected Lie group $G$ are class functions on $G$ and their restrictions to a maximal torus of $G$ are $W$-invariant functions on $T$ where $W$ is the Weyl group of $T$. The $W$-invariance of a character on $T$ allows you to parametrize it by a heighest weight vector using the theory of roots and weights. However, the clever point of the proof is that one studies $W$-anti-invariant functions on $T$ rather than $W$-invariant functions on $T$! The quotient of two $W$-anti-invariant functions on $T$ is a $W$-invariant function on $T$. I think that this is a deep and extremely important result in mathematics with a clever proof.
AnswerKenntnis:
The full classical proof of the classification theorem of compact surfaces has always been-and remains-one of my favorite proofs. Despite it's tediousness, it demonstrates to the beginner how important it is to be able to prove results constructively,using very little beyond the definitions of a surface and the fundamental group.
AnswerKenntnis:
Perhaps geometric and algebraic proofs of the fundamental theorem of calculus.
AnswerKenntnis:
My all time favorite proof? 

Furstenberg's proof of the infinity of primes by point-set topology. I know, a lot people think it's not a big deal. I think: 

a) It's an immensely clever way to use point set topology to prove a result in a seemingly unrelated field, namely number theory. 

b) I used it as the beginnings of my first research in additive number theory; looking to generalize this result to create similar proofs of results for sumsets and arithmetic progressions. Sadly, my health failed again,but I hope to return to this research soon.
AnswerKenntnis:
When I did my first analysis course I found the proof the Lebesgue differentiation theorem using maximal functions and covering lemma arguments to be very beautiful.
AnswerKenntnis:
I really like the simple and nice proof of the 5-color theorem (i.e. that for every planar graph there exists a vertex coloring with not more than 5 colors) and how surprisingly difficult it is to proof the sharper 4-color theorem.
AnswerKenntnis:
It is propably not something which everybody should know, nevertheless it is simply beautiful!

The stable Hurewicz theorem using that the sphere spectrum is a compact generator of the stable homotopy category.
In particular Serre's theorem that the rational stable homotpy groups of spheres are trivial for degrees bigger than 1.
QuestionKenntnis:
Pedagogy: How to cure students of the "law of universal linearity"?
qn_description:
One of the commonest mistakes made by students, appearing at every level of maths education up to about early undergraduate, is the so-called ΓÇ£Law of Universal LinearityΓÇ¥:

$$ \frac{1}{a+b} \mathrel{\text{ΓÇ£=ΓÇ¥}} \frac{1}{a} + \frac{1}{b} $$

$$ 2^{-3} \mathrel{\text{ΓÇ£=ΓÇ¥}} -2^3 $$

$$ \sin (5x + 3y) \mathrel{\text{ΓÇ£=ΓÇ¥}} \sin 5x + \sin 3y$$

and so on.  Slightly more precisely, IΓÇÖd call it: the tendency to commute or distribute operations through each other, without even noticing that theyΓÇÖre doing anything, except for operations where theyΓÇÖve specifically learned not to do so.

Does anyone have a good cure for this ΓÇö a particularly clear and memorable explanation that will stick with students?

IΓÇÖve tried explaining it several ways, but never found an approach that I was really happy with, from a pedagogical point of view.
AnswersKenntnis
AnswerKenntnis:
I think this is a symptom of how students are taught basic algebra. Rather than being told explicit axioms like $a(x+y)= ax+ay$ and theorems like $(x+y)/a = x/a+y/a,$ students are bombarded with examples of how these axioms/theorems are used, without ever being explicitly told: hey, here's a new rule you're allowed to use from now on. So they just kind of wing it. They learn to guess.

So the solution, really, is to teach the material properly. Make it clear that $a(x+y)=ax+ay$ is a truth (perhaps derive it from a geometric argument). Then make it clear how to use such truths: for example, we can deduce that $3 \times (5+1) = (3 \times 5) + (3 \times 1)$. We can also deduce that $x(x^2+1) = xx^2 + x 1$. Then make it clear how to use those truths. For example, if we have an expression possessing $x(x^2+1)$ as a subexpression, we're allowed to replace this subexpression by $x x^2 + x 1.$ The new expression obtained in this way is guaranteed to equal the original, because we replaced a subexpression with an equal subexpression.

Perhaps have a cheat-sheet online, of all the truths students are allowed to use so far, which is updated with more truths as the class progresses.

I think that, if you teach in this way, students will learn to trust that if a rule (truth, whatever) hasn't been explicitly written down, then its either false, or at the very least, not strictly necessary to solve the problems at hand. This should cure most instances of universal linearity.
AnswerKenntnis:
My interaction with the students (non-mathematically inclined ones, in the United States) has lead me to suspect that for some reason they are not taught the following two crucial ideas.


Mathematical expressions have meaning.
The validity of a rule for manipulating mathematical expressions is determined by what those expressions mean. In particular, the rules themselves are derived from what the expressions mean.


Understanding of those two ideas seems to me is the key difference between the students who "get it" (i.e., the ones that simply do things correctly and their mistakes usually boil down to not noticing something) versus the one who don't "get it" (which do only as well as they can memorize a bunch of boring, arbitrary-seeming rules).

Consequently, I am of the opinion that searching for


  a particularly clear and memorable explanation [of when a particular rule is applicable] that will stick with students


is not at all the correct approach to this issue (unfortunately, given the structure and expectations of the educational systems . The sad reality (as I perceive it) is that for the majority of (U.S.) students, mathematics is the art of manipulating weird, meaningless strings of symbols according to equally weird and exception-filled rules that they barely have the mental capacity to remember. In essence, the kind of content that students appear to taught seems much more appropriate for simple-minded, inhumanly precise computer, than a human being with the capacity to reason.

This is why no matter how much we illustrate and explain the rules to them, they keep misusing them: what they are missing is not explanations or illustrations, but the ability and mental habit of determining on their own whether the mathematics they are doing is correct or not (which is still hard for a computer: computer proof assistants are still in their infancy). 

I personally have no idea how such this skill of doing mathematics right can be cultivated without awareness of the two facts above, and I believe that what separates the students who do demonstrate this skill is that they have (at least an implicit) understanding of those two ideas. Furthermore, I do believe that exposing them to, making them think about, and making them use the meanings of the symbols they write, and doing it again, and again, and again, and again, will have a much more significant effect than reminding them of one-off examples and illustrations of why a particular manipulation they did is not allowed. The one-offs they will forget and not be able to reproduce because of their infrequency, but the repeated insistence on using the meaning of the expressions to establish the validity of the manipulations will hopefully make it habitual for them.

In terms of implementing this in practice, I think that college is way too late, and also quite difficult because college math (and STEM) courses tend to be mostly about transmitting massive amounts of boring technical content and technical skills, leaving little to no room for actual ideas or ways of thinking. Nevertheless, I do think it would be an interesting experiment to have students keep something akin to a "vocabulary notebook" where they record the meaning (as opposed to the formal definition) of the various kinds of expressions they run in to. For example, a fraction $\frac ab$ is supposed to mean "a number which when multiplied by $b$ gives $a$"; it is short and illuminating work to figure out from this (using distributivity of multiplication over addition, which we definitely want numbers to satisfy) that $\frac ab+\frac cd=\frac{ad+bc}{bd}$, that there is no number meant by $\frac a0$, and that $\frac00$ can mean any number). This of course, presupposes that somebody takes the time and makes sure that the language in which these meanings are explained is coherent, so it would be a lot of work to design a course around this method.



I did in fact once successfully disabuse a(n Honors Calculus) student of "the Law of Universal Linearity" using these ideas. The particular instance concerned manipulating the Fibonacci sequence, and the student had made the error of writing something like $F_x+F_x=F_{2x}$. What I did is explain the stuff above and had the student apply them by analyzing the meaning of the various expressions he had written down was, and then ask whether that equality was justified based on what he knew the expressions meant. That seemed to make an impression on the student, but I personally believe it was an impression made ten years too late...
AnswerKenntnis:
(This is a rather "soft" answer!)

I don't think there is a solution to this.

In my experience the problem is that math beginners don't understand / assimilate formal laws: they agree that $(a + b)^2 \neq a^2 + b^2$ (because "$2ab$ is missing") but they have no problem writing $(x + 3)^2 = x^2 + 3^2$ two minutes later.

The only "solution" is to take money from them / hit them every time they use the "law of universal linearity", but it takes years to have any effect (and earns you thousands of dollars)
AnswerKenntnis:
I had a teacher in college who was very fond of repeating phrases like "The Flarn of the Klarp is the Klarp of the Flarn" and "The Flarn of the Klarp is the Twarble of the Flarn." I believe these are from Lewis Carroll. But the way they were incorporated in lecture was like an call-and-response. 

For example, the teacher might rapid-fire questions at the student audience such as "The product of the sum is the sum of the product?" followed by "The derivative of the sum is the sum of the derivative?" followed by "The product of the logs is the log of the products?" Just seeing if students would get into a pattern of saying "yes.. yes.." and then whacking them with something to think about. I can imagine this working with trig functions as well.

This teacher would also routinely use small hand-drawn pictures in place of variables like x or y. For instance, I learned about the Taylor series expansion of "e-to-the-doggie" being the sum of "doggie-to-the-n-over-n-factorial". We similarly talked about moment generating functions as "e-to-the-tree-x" with a little tree drawn where the transform variable (usually t or s) would go, and then the moment-generating function's domain was the "tree domain" since that was the independent variable there. 

I know this sounds ridiculous, but boy did it work. After a few weeks of acclimating to the sheer bizarreness of it, it really started to make the concept of variables disappear. Rather than fixating on why particular weird non-number symbols like x were showing up, you had to hold onto your butt because it might be a little tulip or a fire hydrant on the test and you were supposed to solve equations and whatnot. It was like there was no time to be confused about symbols because the sheer whimsical arbitrariness of whatever the symbols might be forced you to understand how to manipulate any symbol, which was the whole point.

This was for a first course in calculus-based probability, and eventually we started talking about things like variance, which then naturally became a discussion about how Var(X) = E[X^2] - E[X]^2 is totally a kind of measurement of "non-commuting-ness" between the squaring operation and the expectation operation. So whereas E[X] is linear, (i.e. the flarn of the klarp is the klarp of the flarn), for variance this is not true unless it's a Dirac variable with no variance. For everything else, one measure of central tendency is to say "the flarn of the klarp minus the klarp of the flarn equals ..." so you know just how far off you are from those operations commuting with each other.

I'm not sure if this would work with classes where aptitudes vary considerable, or where there are time constraints to hit materials in time for a standardized test. And it certainly is weird and requires great confidence on the teacher's part (the teacher who taught this to me was a Vietnam veteran who truly didn't give a damn about what students or administration thought of him... he was a bit like the character Walter Sobchak from The Big Lebowski actually). But it seemed to be extremely effective in my class and was one of the big milestones in my own study of mathematics where I went from merely knowing how to compute things when given problem set-ups to really trying to suss out deeper connections, analogies, patterns, etc.
AnswerKenntnis:
TL;DR: Teach your students that "distribution" over addition only works with multiplication over addition, and nothing else (that matters at this point in their education, at least), and maybe show examples like $(a+b)/c = a/c + b/c$ that mix different operations to make things clear.

Longer answer: I personally have thought a lot about this, and it really has to come down to the usual villain, quick, but confusing notation. We are taught  addition as $a+b$ and multiplication as $a\times b$, but soon after primary, we drop the $\times$ and let $ab:=a\times b$. This places addition at a different footing than multiplication at a subconscious level for it is now an implied operation, and this leads to trip ups like the ones you mention.

When one sees distribution of multiplication over addition, like $a(b+c)=ab+ac$, it is easier to pseudo-generalize this rule to anything, like $f(x+y)=f(x)+f(y)$ or $1/(a+b)=1/a+1/b$ since they aren't mindful of the words "multiplication over addition." This is because the implicitness of of multiplication is forgotten and thus it's easy to think that distribution is a property of addition only, and therefore applies wherever there is an addition.

Of course it doesn't. For example, $(a+b)/c=a/c+b/c$ but $a/(b+c) \ne a/b+a/c$ because division over a field is only linear in the first argument, not the second, and of course, division isn't Abelian. You can't tell your students that at this point, so the best way is just to be clear of when it works in their world: multiplication over addition. For the "linear in first argument" for division, and may be use a cheat like $(a+b)/c = 1/c \times (a+b)= a/c+b/c$. At this point, since you can't teach them basic abstract algebra, you'll have to do with just keeping them straight with where distribution works, and if they are so keen, tell them they'll learn why one day.
AnswerKenntnis:
$1.$ Be brutal ! Give them an F when caught red-handed in the act of perpetrating such unholy and illegal activities ! That should teach them ! :-)

$2.$ Show them nice pictures.

$3.$ Give counterexamples ! $\qquad\qquad\dfrac12=\dfrac1{1+1}\color{red}\neq\dfrac11+\dfrac11=2.$

Or just tell them to ΓÇ£read fractionsΓÇ¥ : $\dfrac13+\dfrac23=1$ third $+2$ thirds $=3$ thirds $=\dfrac33=1$, for the same reason that $1$ sheep $+2$ sheep $=3$ sheep.

$4.$ Tell them that $2^{-3}\neq(-2)^3$ for the same ΓÇ£reasonΓÇ¥ that $2^{-3}\neq2-3$.

$5.$ In short, just teach them to think, rather than rely on ΓÇ£magicΓÇ¥ formulas.
AnswerKenntnis:
I can't give you advice what to do against it, but I may help you understand why it is happening. 

The point is that the "feeling of knowing", or "being certain", is an emotion, just like feeling sad or happy. It can also be compared to visual perception: instead of perceiving something about the state of the outside world (e.g. a blue mug on your desk), you perceive something about the state of your own cognitive processes: you came up with a piece of knowledge and it feels right. 

And just like vision, it is susceptible to illusions which can completely fool your brain. Being convinced that (x+1)^2 = x^2 + 1^2 is right is very similar to being convinced that square A and square B are different shades. 

The reason these illusions happen come from the way neuronal based intelligence works. Our brains are specialized at recognized similarity in patterns. If we are exposed to one pattern very frequently, it feels more "right" than other patterns. There are also other details, especially for visual illusions, which are dependent on the particular ways neurons in V1 and other perceptional areas work, but here the analogy between visual-illusion and feeling-of-knowing illusion breaks down. But the point is that feeling certain is not related to factual truth directly; it is related to noticing that the new pattern looks similar to older patterns we have come to believe are true trough repeated observation (or being repeatedly assured that they are true). The reason this works is that if we observe a pattern being true frequently enough, or if most people around us have come to recognize it as being true, it is indeed because it is true. Still, it is a matter of persuasion, not logic. Logic can make us understand something, but not make us believe in it intuitively. 

So a person who lives in a world where most visible processes are described by simple linear and proportional relationships will intuitively feel that "linear" or "proportional" explanations for everything are right. This happens on a broad level, where exponential growth is completely counterintuitive and people freshly exposed to it are always surprised by the true magnitude of the calculated results even if they have cognitively understood the underlying principle. I think of myself that I should know better by now, but I still get surprised frequently. 

It also happens in some specific ways, like the one you describe with math students. Your pupils have been exposed to linear relationships for years. Their neural networks have learned to react with a "this looks good" signal the way pavlov's dog's neural networks have learned to react with "food comes" signal. When they consider possible solutions, once the linear one comes up, it just feels right. Learning to ignore this inner certainty is possible, but it is a hard and slow process which physically requires rewiring the neurons in their brains. You cannot expect a silver bullet for it. Especially trying to find a way to make it better understandable won't work; they have already understood it in their higher, reasoning processes. It is their affect-level response which has to be overruled, and it responds to repeated training, not to logic. 

For a better insight in how the feeling of knowing works, read "On being certain" by R. Burton. It is a great book, and I would recommend it for all pedagogues (and actually for everybody else too, but if you are interested in creating a feeling of knowing in your students, it might be especially helpful). 



Edit A way of thinking about how to solve the problem is using mental models. A mental model is an understanding of how a mechanism works. "A wolf eats the sun each day and it gets reborn the next day" is a mental model of how days and nights work. "The earth is a sphere revolving around its axis with the sun to one side" is another mental model for the same mechanism. *

Humans are capable of solving problems when they don't have a clear mental model of the forces working in the background, but they usually do it haltingly, step by step, and cannot monitor the outcome of their steps for veracity of the solution. It is like trying to cross a labyrinth using some algorithm like taking only right turns and retracing to the left when you run into a blind end. It is possible to do it, but at no point do you actually know the way through the labyrinth, even after you have emerged on the other side. On the other hand, if you have memorized a map of the labyrinth, and the labyrinth is of low enough complexity to fit in your spatial reasoning brain areas, you have a good mental model of the labyrinth and you can easily find a way to the other side, and at each step you can monitor your concrete surroundings and relate them to the mental model of the whole, and it will always feel right when you are on the right way and wrong when you are on the wrong way, because your spatial reasoning "subsystems" will create a feeling of certainty for you. Another example which is probably much more "intuitively right" :) for math teachers would be simple geometry problems about triangles. Read the word description, and you probably could solve it step by step, but it would be hard, and you can't keep all the details in your mind at once. Make a drawing, and everything falls into place; you know the solution before you have calculated it. 

What you certainly want is that your pupils get a mental model of nonlinear relationships which can be reasoned about on an intuitive level. Getting exposed to nonlinear relationships written as abstract numbers is not good enough, even if the exposure is very frequent. We humans don't have inborn neural circuits for evaluating rational numbers, this is a learned skill. We have inborn neural circuits for evaluating tangible entities, visual input, smells, language, etc. If you want your pupils to create a mental model at all, instead of running around the numbers blindly, you will have to help them relate the numbers to something. I don't know what this something will be, centuries of teaching math have tried to find such solutions and to my knowledge have not gotten beyond cutting one apple in thirds and one in halfs and then showing that one piece of each together don't make a fifth of an apple. But any working solution, if it exists, will have to work along the lines of creating a good, solid mental model. Then pupils will be able to think properly about the problem at hand, to reason about it on a level which creates the feeling of knowing at the right times except of floating in uncertainty at each step. 

I don't have a single good book recommendation on mental models the way I had on the feeling of certainty. They are researched within the context of usability, so a textbook on software usability might contain relevant chapters and/or lead you to better, more specialized literature on mental models. 




The days and nights provide another nice example of how conviction works against logic and how mental models fit into it all. Note that we as individuals are only convinced that "earth revolves around its axis and around the sun" is the true one because we have been told that it is true. I learned in sixth grade about Foucault's pendulum, and Earth's horizon curvature, and all the other experiments together which prove it; but I have never seen the pendulum or conducted these experiments. It doesn't matter, because when I was four, my father had bought me a globe and told me how it works, and I believed it, long before I knew what a physics experiment is. Had I been constantly told that the Earth is flat up until I started taking sixth grade physics, my teacher describing those experiments wouldn't have convinced me. It was seeing the rotating globe, and hearing the explanation from a person whom I trusted, which helped me create a mental model leading to true convictions, as opposed to mere logical inferences.
AnswerKenntnis:
There is no one good answer.  Distributive/commutative properties are confusing in large part because they are seemingly arbitrary rules.  

$$ \frac{c}{a+b} \mathrel{\text{ΓÇ£=ΓÇ¥}} \frac{c}{a} + \frac{c}{b} $$

versus

$$ \frac{a+b}{c} \mathrel{\text{ΓÇ£=ΓÇ¥}} \frac{a}{c} + \frac{b}{c} $$

is confusing to a lot of people, because they look the same.  You can certainly teach them the rule - but the reason for that isn't the same reason that

$$ 2^{-3} \mathrel{\text{ΓÇ£=ΓÇ¥}} -2^3 $$

doesn't work, or that

$$ \sin (5x + 3y) \mathrel{\text{ΓÇ£=ΓÇ¥}} \sin 5x + \sin 3y$$

doesn't work (well, sort of in the second case).

The general answer for lower levels (high school non-advanced) is simply to teach each of the cases as they come up, and remind students that commutation/distribution only works in specific instances - in particular, primarily with multiplication.  

By the time they get to undergraduate or 'advanced' high school math, then, it would be appropriate to teach them some of the skills of proofs; and then explain that if they want to verify whether distribution works with a particular operator or function, it is fairly simple to prove.  That's the only true way that will work in every circumstance (and still requires understanding of how the functions, like sin/etc., work, though in those cases you can always try to disprove it by testing a few example cases first).
AnswerKenntnis:
I would like to be more fancy, since you all seem fancy, but I taught adult literacy for a few years. Adults with 1st - 5th grade math level coming in to try and get their GED.

Cut up a  circular pizza into $1/2$ and $1/3$ each, and then have them cut up a pizza into $1/5$. They will then intuitively get that $1/2 + 1/3 \,=' 1/5$, because that's way less pizza.

Then you can do the same with the numerator to show that $2/5 + 3/5 = 5/5$ a whole pizza.

In two years of teaching that class, my most powerful techniques bar none were pizzas and dollars. Even the most self-proclaimed math illiterate will learn percentages when there's a sale going on.
AnswerKenntnis:
My views on this matter differ dramatically from all other current answers.  Others seem eager to agree about the prevalence of this "disease", and have many theories about causes and treatments.  Instead I believe that you are simply finding a pattern among a disparate variety of errors made by learners of mathematics; it is your own mathematical skill at pattern-matching that connects the dots and gives it a name.  However for them it is not one missing skill that a silver bullet will kill, but many puzzles that are missing pieces.

Every learner of mathematics, at every stage, struggles with learning not only the uses of a mathematical skill, but its limitations. This is an iterative process, and mastery is achieved only through repeated efforts. 
It is difficult to learn that $\frac 25 + \frac 15=\frac 35$, and also difficult to generalize to $\frac ac + \frac bc= \frac{a+b}{c}$.  It is also difficult to learn that $\frac 15 + \frac 13 \neq \frac 18$, and still more difficult to generalize this fact. Those of us with math Ph.D.'s may not remember these difficulties, because we have have so many additional layers piled on top, but for precalculus and calculus students, these struggles are still quite fresh.

Consequently I believe that even attempting to impose a single answer, no matter how clever, will be entirely counterproductive.  Someone that has not yet mastered $\frac 1a + \frac 1b\neq \frac{1}{a+b}$ is nowhere ready to generalize to $f(a+b)\neq f(a)+f(b)$; on the contrary, such a general approach is likely to intimidate and confuse.  Simply identify the specific error they made and state that this is an invalid operation.  An explanation should be only given upon request, and should be limited to the context of the error, not a general screed about nonlinear functions and the general deterioration of the human intellect.
AnswerKenntnis:
This is supposed to be cured in early elementary schooling. By around the fifth grade, kids are supposed to know that addition of fractions requires a conversion of all fractions to a "common denominator", and subsequent addition of the resulting numerators, by a procedure that is supposed to be drilled into their heads via numerous homework instances, and which is directly applicable to symbolic quantities. It's not easy to see how it is possible to get through high school algebra without having to apply this procedure to fractional polynomials, like $\frac{1}{x + 1} + \frac{1}{x + 2}$.

I would suggest that someone who cannot work out the above sum cannot be considered to have the prerequisite skills for entering into an undergraduate program in the sciences, engineering or mathematics.

One mnemonic device is a trivial counterexample against the incorrect rule:


  Two halves make a whole, and not a quarter:  ${1\over 2} + {1\over 2} = 1 \neq {1\over 4}$.


There isn't really anything to be done. Weed out the dunces by marking their wrong answers wrong on homework assignments and tests. 

Don't try to compensate for breakage elsewhere; you will just cause local breakage in your pocket of the educational system. Catering to the dunces will only introduce inefficiencies and resource waste that will frustrate and hold back those who deserve to be there.

Not everyone needs a university diploma. The job of the school is to reduce a starting class of 500 down to 30-40 over the course of four years, not to ensure that everyone knows how to add fractions, which is the job of elementary school.

Slippery slope fallacy, for entertainment value: where does it end? If fresh undergrads come in lacking toilet training, do you look for ways to accommodate mid-lecture diaper changes?
AnswerKenntnis:
I want to point out that two issues should be separated when talking about what students know:


Being able to consciously and correctly state some fact. (E.g. the formula for the square of a binom or the correct verb form after "if".)
Being able to apply the fact routinely, automatically and with high reliability.


None of them implies the other. Native speakers correctly apply grammatical "rules" that they have never heard of to invented words because the brain can extract rules from a huge number of examples. People can memorize the meaning of the letters of another alphabet (Russian, Greek, ...) in a very short time, but this does not enable them to read known words in the other alphabet with reasonable speed.

I certainly agree with teaching students, meaning, understanding and context, but if you want them to calculate efficiently and reliably, it cannot be avoided that they do a certain significant amount of computations themselves to give their brains a chance to automatize the routine. (And if they do not care about the results of the computations, it will take much, much longer.)

The mere fact that people over-apply patterns to new situations is not something that I find disturbing at all. It is exactly what I want students to do when I introduce matrix exponentials. The goal is to be able to switch between routine mode and reflection mode.
AnswerKenntnis:
The prevailing attitude is "I just need to fudge the numbers around until it looks like the answer". This can basically be attributed to two causes:


Not caring about the subject
Missing some basic knowledge


The latter is easily solvable with a few hours of tutoring, but ultimately the former seems more prevalent. To most of these students, it's all just a list of formulas that they have to memorize for no apparent reason, followed by busywork applying the same formulas mindlessly a few dozen times every other night.

The only reliable way to generate interest in a subject is for it to have immediately obvious benefits to the student.

For things like factoring, commutativity/associativity etc, there is no direct benefit - most of the time, in the real world you can compute the value of an expression exactly as it's written (if I have a 3x4 and a 2x4 flat of soda cans, why would I bother rearranging it into 4 rows of 5 cans before counting them?).

The benefit to the student lies in being able to use these manipulations to create their own formulas that can be used as shortcuts for boring and repetitive tasks in the future. In other words, it needs to be clear to them that the time invested in learning/memorizing concepts and formulas will be paid off with interest in laziness/time saved in the future.

Once a student is genuinely interested in learning concepts and is able to tie them to real-world examples, they then have a vested interest in sanity checking that what they're writing makes sense - otherwise they are just shooting themselves in the foot.
AnswerKenntnis:
In the examples you cited, "numerators" are subject to "linearity" but "denominators" are not.

For instance, $$ \frac{a+b}{c} \mathrel{\text{ΓÇ£=ΓÇ¥}} \frac{a}{c} + \frac{b}{c} $$

is true, but $$ \frac{1}{a+b} \mathrel{\text{ΓÇ£=ΓÇ¥}} \frac{1}{a} + \frac{1}{b} $$ is not.

And $$ 2^{-3} \mathrel{\text{ΓÇ£=ΓÇ¥}} 1/2^3 $$, meaning that once you put $$ 2^{3} $$ in the denominator, the linear relationship breaks down.

Once I learned that expressions are linear in numerators but not in denominators, it was a big step forward for me.
AnswerKenntnis:
It must start early, and it must start by divorcing ourselves from educational approaches that teach students to approach problems algorithmically. 

Students write $(x+3)^2 = x^2 + 3^2$ because by the time they start looking at things involving $(x+3)^2$, they've just gotten a hang of the distributive property. And it's taken them a while to get a hang of the distributive property because we insist on teaching it as "first multiply this by the first thing, next multiply by the second thing, now add those two results together," and not as an abstract representation of the product of quantities, or even better, the equivalence between multiplying 5 and 11 and 5 and (10 plus 1).

Students are encumbered with homework (yours is not the only homework they have to do!), laziness, distractions, and life. Of course they're looking for shortcuts, foolproof algorithms to solve the problem, and the like.
AnswerKenntnis:
Go back to the basics!

I've seen this in many (all?) of the students I've tutored.  I always attribute it to students being taught 'what' and not 'how' which always leads to a gross lack of understanding of 'what' they're REALLY doing with these operations.  

$$\mathbf{2^{ΓêÆ3}\,ΓÇ£=ΓÇ¥\,(ΓêÆ2)^3}$$

This is sheer lack of understanding what a negative exponent is.  Broken down...

$\dfrac{x^4}{x^2} =\dfrac{x*x*x*x}{x*x}$

so we can cancel out pairs -- something they're good at, and we're left with  $x^2$.

So if it's reversed: 

$\dfrac{x*x}{x*x*x*x*} 
{}
= \dfrac1{x*x}$ 

(we're clearly in 'negative territory' in our numerator now...) 

$= x^{-2} $

Now they should be able to see why the "premise of equality" makes no sense.
AnswerKenntnis:
This is one of the things that I find very discouraging as a teacher, and which I have never really understood.  However I feel that part of the problem is to do with students' basic attitude towards mathematics.  A significant number appear to think that it's all a game: the rules are there not "because they are true" but "because the teacher said so".

And what do you do if you are playing a game in which the rules are complicated and you are not very successful? - simple, you play a different game in which you can make up your own rules!

Sadly, I think that many of the suggestions made to overcome the problem are way too sophisticated.  In my experience, counter-examples are of little use.  If you show a student a counterexample they will generally nod, smile, agree with you and go away to do exactly the same thing: anyone who has trouble simplifying fractions is scarcely going to appreciate the logic which says that a single counterexample disproves an "all" statement.  As Jesse Madnick pointed out, many students will happily (or unhappily, but that doesn't help...) write $\frac{1}{x}+\frac{1}{y}=\frac{1}{x+y}$ when $x,y$ are variables, but will not make this mistake if $x,y$ are specific numbers.

One thing I have noticed is that this error is not "symmetric".  It is less common, especially when $x,y$ are specific numbers rather than variables, for students to write
$$\frac{1}{x+y}=\frac{1}{x}+\frac{1}{y}$$
than
$$\frac{1}{x}+\frac{1}{y}=\frac{1}{x+y}.$$
Perhaps this is because in the first case they look at the left hand side and recognise that the first thing to do is to add $x$ and $y$, which is easy; whereas in the second case they do not know what to do with the left hand side and so, once again, they just make up their own rules.
AnswerKenntnis:
Functions, like $\exp$, $\sin$, $x\mapsto 1/x$, $x\mapsto x^2$, or $f$,  are laws that assign to an input value $x$ an output value $f(x)$. Only in very special cases this law is additive. An example is the price $f(x)$ of $x$ gallons of gasoline: $f(x+y)=f(x)+f(y)$. When $f(0)\ne0$ we don't even have
$f(x)=f(x+0)=f(x)+f(0)$, and when the graph of $f$ is not "linear", i.e., a line, then also some weaker form of "additivity" fails.
AnswerKenntnis:
I had problems myself with this when I was starting out. I can't remember what I used to get around your first example. For your second example I got it into my head that the minus sign was the "line in the fraction", so
$$ 2^{-3} $$ became $$ \frac{1}{2^{3}} $$
Perhaps not for everyone but I found it an easy trick to remember.

For your example
$$ \sin (5x + 3y) $$
I just had to hammer it into my head with examples and the log tables.  Essentially starting out with something like what's here http://www.math.com/tables/trig/identities.htm and building slowly on that.  I know you've said you tried examples but this was worth a shot.

I would have to agree that a students attitude does contribute greatly to the learning/remembering process with such things like this. Our school teacher broke it down to basics.  Students were saying "When will I actually need this in the real world", so she asked us all what we would like to do when we finished school. When she came in the next day she had an example for each of us about how at least one of these laws/examples would be needed in our future career.  The overall attitude in the class quickly changed and we got the hang of it. I find this very useful in a tutoring situation as many students are sent to find tutors because their parents want them to do better, thus starting with a bad attitude. It may work on a few of your students and even if it is a small few it is a start.
AnswerKenntnis:
for young kids, it might be too early to teach them about linearity. I would prefer to teach them the distribution/commutation instead. That is:
$a+b=b+a$
$a \times b = b \times a$
$(a+b)\times c = a \times c + b\times c$  

As @noobermin said, you can stress that the laws work on multiplication and addition only. Hence,  

$\frac{1}{a+b}=1:(a+b) \neq 1:a + 1:b$ as this is division, not multiplication. But  

$\frac{a+b}{c} = (a+b)\times \frac{1}{c} = a\times \frac{1}{c}+b\times \frac{1}{c}$ since we have multiplication with addition here.  

Similarly,
$2^{-3} \neq -2^3$ becuase $2^{-3}$ is not $2\times (-3)$
so the only way to to approach is to apply one of the exponential rules $x^{-n}=\frac{1}{x^n}$  

However, for the following expression we can apply either rules and get both correct:
$(-2)^3=-2^3$
Approach1: commutation
$(-2)^3=(-2)\times (-2)\times(-2)=(-1)\times2\times(-1)\times2\times(-1)\times2=\\=(-1)\times(-1)\times(-1)\times2\times2\times2=(-1)\times2^3=-2^3$  

Approach2: apply another exponential rule $(a\times b)^n=a^n\times b^n$ with a=-1, b=2, n=3
Of course if the students are eager to learn, you can show them that the above exponential rule can be proved using the commutation property.  

The $\sin(a+b) \neq \sin a+\sin b$ can be explained in the same way..

In conclusion, my universal rule is as follows:  


The distribution/commutation apply on multiplication and addition only
When a new concept is introduced, it comes with its own rules (e.g. exponent, trigonometry, complex number...). Try to learn their rules by heart.
AnswerKenntnis:
$$ \frac{1}{a+b} \mathrel{\text{ΓÇ£=ΓÇ¥}} \frac{1}{a} + \frac{1}{b} $$

$$ \sin (5x + 3y) \mathrel{\text{ΓÇ£=ΓÇ¥}} \sin 5x + \sin 3y$$

In these two cases, the error of the student's method is clearly demonstrated by plugging in some arbitrary values:

$$ \frac{1}{2+3} = \frac{1}{5} \neq \frac{1}{2} + \frac{1}{3} $$

This one should be obvious when you make the student think about it for a second; you can't add two positive numbers and get a number smaller than the ones you started with. The sine equation is a little harder to visualize, but try $x = 9, y = 15$; then $ \sin (5x + 3y) = sin(90) = 1$, while $\sin 5x + \sin 3y = \sin 45 + \sin 45 \approxeq 1.4142 \neq 1$.

Exponent signage is harder because overall it's less intuitive; you have to see the math work to understand why negative exponents are fractions and not negative numbers.

Consider that $5^4 / 5 = 5^4 / 5^1 = 5^{(4-1)} = 5^3 = 225$. Therefore, by the same math,  $2^{-3} = 2^{(0-3)} = 2^0/2^3 = 1/(2^3) = 1/8$. However, on the other side of the "equation", $-2^3 = -(2^3) = -8$.

As other answers have said, this is all part of elementary math education, which unfortunately in the U.S. is often taught as a series of "do this, don't do this" without the kind of explanation behind why one transformation is valid and works while the other doesn't.
AnswerKenntnis:
I think the best way is to give them counter examples, for instance: 

$\dfrac1{a+b}=\dfrac1a+\dfrac1b$

$\dfrac1{2+1}=\dfrac13\,\text{ and }\,\dfrac12+\dfrac11=\dfrac32$

so $1/3$ is not $3/2$ and they will see by themselves that they got it wrong, that's what I do to my students most of the time: counter examples.
AnswerKenntnis:
Try once more with an example which really brings the error right in front of Them. I like to say, "Would You:


Wake up
Go to school
Put on clothes
Shower
Wipe Your behind
Poop
Pull down pants and sit on the toilet


in that order? Of course not because order of operations can be significant."
AnswerKenntnis:
This is an example of only one kind of "linearity."  I don't think it's been mentioned yet.

Whenever I write something like $$\dfrac{2x+3}{2}$$ on the board, somebody will inevitably say, "Cancel the twos!!" And I respond, "Wait!  So that means five divided by two is three, right?"
$$ \dfrac{5}{2} = 3 $$
"because"
$$\dfrac{5}{3}=\dfrac{2+3}{2}=3$$
"Right??"

And then I proceed with showing them the way to factor and cancel in an expression such as

$$\dfrac{4x+6}{2} = \dfrac{2(2x+3)}{2} = 2x+3$$
AnswerKenntnis:
Well, I think that the problem resides in the comprehension of the definition of respective operations. And we know that some textbooks and teachers said that "linear function" consists in functions of the form "$ax+b$", fatal error of mathematical language.
AnswerKenntnis:
Pre 16 I actually made that mistake with the 

$$ \frac{1}{a+b} \mathrel{\text{ΓÇ£=ΓÇ¥}} \frac{1}{a} + \frac{1}{b} $$

The above mistake was from never being corrected up to 16.

Once at 16, I got a new teacher who corrected me on that, and I only needed to be told once such that I understood what he said. It's a significant thing so I thought about it a lot and remebered it. Alternatively I could have memorized it from drills he assigned, but I was probably smart enough at 16 to write my own drills for something so basic that I understood and just needed to practice a bit without making that mistake.  I realised the error came from a)not learning the axioms formally and b)knowing $(a+b)/c$ breaks down like that and assuming that a/(b+c) did.  I checked with the teacher that $(a+b)/c$ broke down but $a/(b+c)$ didn't.

Regarding this mistake

$$ 2^{-3} \mathrel{\text{ΓÇ£=ΓÇ¥}} -2^3 $$

I would not hae made that mistake because I never invented my own rules, and pre 16 i'd not seen a negative indice. By 16 I had a good teacher that taught us that  one surprise, that -2^3 was -(2^3)  So in BO DM AS  there is a U here BOU DM AS.  And he taught us   

$$ 2^{-3}  \mathrel{\text{=}} \frac{1}{2^{3}} $$

So we learnt indice rules from scratch from him. Nobody would have done the mistake you mention. He made sure that anybody taking Math post 16 got an absolute minimum of an A grade in the exam before that(GCSE), to qualify.  If we had made up our own rules and not remembered fundamentals it'd have been a problem.

Regarding this mistake
$$ \sin (5x + 3y) \mathrel{\text{ΓÇ£=ΓÇ¥}} \sin 5x + \sin 3y$$

I learnt one or two rules pre 16 regarding sin and cos and even back then i'd have been sure as hell not to do the above. It takes a real idiot to make a mistake like that. Back then I didn't really know f(x) notation that well but still.  We wouldn't have got an A in GCSE math if we had done that. There's no way somebosy that did that would have qualified well enough for the teacher to have allowed them to do  Math A level (Math post 16).

At 16 our new math book (A level is post GCSE) on Pure Math gave clear axioms all on one or two pages  so it got even easier not to do something stupid like that.

The 1/(a+b) though is a classic error no doubt from learning (a+b)/c at a young age and assuming and not neing corrected. The rest, especially the last, no way.

The best one can do is show them the're wrong and when they understand, then give them practice examples, mark them, and remind them and test them and so on and see if they're remembering. Give basic examples that goad them into using their made up rule, see if they do. Make an impression and they should be thinking about their mistake for the rest of the day, and they should remember.  Their scores in your drills/tests should improve if you're testing the same thing.

I didn't take Math at degree level. It's questionable whether I could have!
AnswerKenntnis:
My hypothesis is that all these examples of "suspect algebra" are really examples of "imitative algebra"1.

Much learning is imitation, something that we are basically "hard-wired" for, and therefore lying largely beyond of the constraints of deliberative/logical reasoning.  It takes some training to turn off this tendency to "learn by imitation" (in which reasoning plays no role) in contexts, such as learning math, where it is inappropriate.

My point is: don't be alarmed; IMO, what you're seeing is perfectly normal.  "It's just a phase," as they say.

My advice would be, first: don't have a cow over such doozies.  (It'd be like despairing over the incomprehensibility of an infant's babbling.)  (BTW, I suspect that overreacting to such errors may be the genesis of, or at least contribute significantly to, life-long "math phobia".)

Second: use these mistake as teaching opportunities.  For example, when you come across something like

$$\frac{1}{a+b} \mathrel{\text{ΓÇ£=ΓÇ¥}} \frac{1}{a} + \frac{1}{b}$$

ask the student to check the equality by replacing $a$ and $b$ with some actual numbers.  Learning how to check one's derivations is a crucial, and extremely general, skill, far more important than any one algebraic "rule", and the sooner such "derivation self-checking" becomes second-nature, the better.

1 Infants and young toddlers babble.  The hypothesis that babbling is an imitation of talking is supported by the fact that children (whether hearing or not) of parents who use sign language will display "manual babbling" at the stage when "vocal babbling" normally occurs.  Less common than babbling, but in a similar vein, some pre-school children will display "mock reading".
AnswerKenntnis:
I think many of the answers here are giving the students too much credit. In my experience teaching a college algebra course, the basic problem is this:


  Students do not understand what they are doing.


(this obviously doesn't apply to all students, but it definitely applies to a nontrivial number of them)

Students don't apply $\log(x + y) = \log(x) + \log(y)$ because they think it is true. They are playing algebra blindfolded. They learned a bunch of tricks early on (for my students, it was in high school), and they are faced with new things that they don't really understand, so they just play it by ear hoping that it will work. Sometimes it does work, because they really are using the rules correctly, and every once in a while by accident their mistakes would "cancel each other out" to give the right answer, but usually it doesn't, leading to frustration.

When I taught logarithms, this was probably the most common blatant mistake (it would be more common except due to the focus on the multiplicative log rules logs with additions are not shown very often). But there were others, like solving expressions without equals signs (the instructions would usually just say to simplify), and "canceling" functions (like $\log$), or otherwise treating them like they were just multiplying. 

I don't know the solution to this. One thing that I've found really doesn't work is teaching rules. The reason, it seems, is that such students are really bad at pattern matching. We mathematicians tend to be good at pattern matching, and so we think of this as a good way to impart information, but students can get that $\log(a + b) \neq \log(a) + \log(b)$ and then turn right around and apply $\log(3x + 1) = \log(3x) + \log(1)$.  Similarly, even if you can convince them that $\log(1000000 + 100)$ is quite different from $\log(1000000) + \log(100)$, they won't apply it to symbolic versions.
AnswerKenntnis:
Provide them with concrete examples, using real numbers (not Real as in the complete ordered field, but "real" as in quantitative).

Next time a student thinks that they can use $$\frac{a}{b+c} "=" \frac{a}{b}+\frac{a}{c}$$ give them an easy problem to check: does $\frac{12}{2+4} = \frac{12}{2}+\frac{12}{4}$? No, so the property must not hold.

The problem most (middle and high school) students have is that they can't yet deal with variables in the same way as numbers. They think it's a whole different world; it's too abstract. So give them problems they can understand, with actual numbers. Then they'll begin to notice patterns, which will lead to the abstract.
AnswerKenntnis:
I would say that the main causation, the underlying disease, is the fact that, here in the U.S. we often have too many students, all crammed into a small room, that lack a love for math. Students are worried about grades, not the inner machinations of mathematics. Teach them to love maths and they ought to take care of the rest on their own.
QuestionKenntnis:
On "familiarity" (or How to avoid "going down the Math Rabbit Hole"?)
qn_description:
Anyone trying to learn mathematics on his/her own has had the experience of "going down the Math Rabbit Hole".

For example, suppose you come across the novel term vector space, and want to learn more about it.  You look up various definitions, and they all refer to something called a field.  So now you're off to learn what a field is, but it's the same story all over again: all the definitions you find refer to something called a group.  Off to learn about what a group is.  Ad infinitum.  That's what I'm calling here "to go down the Math Rabbit Hole."

Upon first encountering the situation described above one may think: "well, if that's what it takes to learn about vector spaces, then I'll have to toughen up, and do it."   I picked this particular example, however, because I'm sure that the course of action it envisions is one that is not just arduous: it is in fact utterly misguided.

I can say so with some confidence, for this particular case, thanks to some serendipitous personal experience.  It turns out that, luckily for me, some kind calculus professor in college gave me the tip to take a course in linear algebra (something that I would have never thought of on my own), and therefore I had the luxury of learning about vector spaces without having to venture into the dreaded MRH.  I did well in this class, and got a good intuitive grasp of vector spaces, but even after I had studied for my final exams (let alone the first day of class), I couldn't have said what a field was.  Therefore, from my experience, and that of pretty much all my fellow students in that class, I know that one does not need to know a whole lot about fields to get the hang of vector spaces.  All one needs is a familiarity with some field ($\mathbb{R}$, say).

Now, it's hard to pin down more precisely what this familiarity amounts to.  The only thing that I can say about it is that it is a state somewhere between, and quite distinct from, (a) the state right after reading and understanding the definition of whatever it is one wants to learn about (say, "vector spaces"), and (b) the state right after (say) acing a graduate-level pure math course in that topic.

Even harder than defining this familiarity is coming up with an efficient way to attain it...

I'd like to ask all the math autodidacts reading this: how do you avoid falling into the Math Rabbit Hole?  And more specifically, how do you efficiently attain enough familiarity with pre-requisite concepts to move on to the topics that you want to learn about?

PS: John von Neumann allegedly once said "Young man, in mathematics you don't understand things. You just get used to them."  I think that this "getting used to things" is much of what I'm calling familiarity above.  The problem of learning mathematics efficiently then becomes the problem of "getting used to things" quickly.

EDIT: Several answers and comments have suggested to use textbooks rather than, e.g., the Wikipedia, to learn math.  But textbooks usually have the same problem.  There are exceptions, like Gilbert Strang's books, which generally avoid technicalities and instead focus on the big picture, and they are indeed ideal introductions to a subject, but they are exceedingly rare.  For example, as I already mentioned in one comment, I've been looking for an intro book on homotopy theory that focuses on the big picture, to no avail; all the books I've found bristle with technicalities from the get go: Hausdorff this, locally compact that, yadda yadda...

I'm sure that when one mathematician asks another for an introduction to some branch of math, the latter does not start spewing all these formal technicalities, but instead gives a big-picture account, based on simple examples.  I wish authors of mathematics books sometimes wrote books in such an informal vein.  Note that I'm not talking here about books written for math-phobes (in fact I detest it when a math book adopts a condescending "for-dummies", "let's-not-fry-our-little-brains-now" tone).  Informal does not mean "dumbed down".  There's a huge gap in the mathematics literature (at least in English), and I can't figure out why.

(BTW, I'm glad that MJD brought up Strang's Linear Algebra book, because it's a concrete example that shows it's not impossible to write a successful math textbook that stays on the big picture, and doesn't fuss over technicalities.  It goes without saying that I'm not advocating that all math books be written this way.  Attention to such technical details, precision, and rigor are all essential to doing mathematics, but they can easily overwhelm an introductory exposition.)
AnswersKenntnis
AnswerKenntnis:
Your example makes me think of graphs.

Imagine some nice, helpful fellow came along, and made a big graph of every math concept ever, where each concept is one node and related concepts are connected by edges. Now you can take a copy of this graph, and color every node green based on whether you "know" that concept (unknowns can be grey).

How to define "know"? In this case, when somebody mentions that concept while talking about something, do you immediately feel confused and get the urge to look the concept up? If no, then you know it (funnily enough, you may be deluding yourself into thinking you know something that you completely misunderstand, and it would be classed as "knowing" based on this rule - but that's fine and I'll explain why in a bit). For purposes of determining whether you "know" it, try to assume that the particular thing the person is talking about isn't some intricate argument that hinges on obscure details of the concept or bizarre interpretations - it's just mentioned matter-of-factly, as a tangential remark.

When you are studying a topic, you are basically picking one grey node and trying to color it green. But you may discover that to do this, you must color some adjacent grey nodes first. So the moment you discover a prerequisite node, you go to color it right away, and put your original topic on hold. But this node also has prerequisites, so you put it on hold, and... What you are doing is known as a depth first search. It's natural for it to  feel like a rabbit hole - you are trying to go as deep as possible. The hope is that sooner or later you will run into a wall of greens, which is when your long, arduous search will have born fruit, and you will get to feel that unique rush of climbing back up the stack with your little jewel of recursion terminating return value.

Then you get back to coloring your original node and find out about the other prerequisite, so now you can do it all over again.

DFS is suited for some applications, but it is bad for others. If your goal is to color the whole graph (ie. learn all of math), any strategy will have you visit the same number of nodes, so it doesn't matter as much. But if you are not seriously attempting to learn everything right now, DFS is not the best choice.

So, the solution to your problem is straightforward - use a more appropriate search algorithm!

Immediately obvious is breadth-first search. This means, when reading an article (or page, or book chapter), don't rush off to look up every new term as soon as you see it. Circle it or make a note of it on a separate paper, but force yourself to finish your text even if its completely incomprehensible to you without knowing the new term. You will now have a list of prerequisite nodes, and can deal with them in a more organized manner.

Compared to your DFS, this already makes it much easier to avoid straying too far from your original area of interest. It also has another benefit which is not common in actual graph problems: Often in math, and in general, understanding is cooperative. If you have a concept A which has prerequisite concept B and C, you may find that B is very difficult to understand (it leads down a deep rabbit hole), but only if you don't yet know the very easy topic C, which if you do, make B very easy to "get" because you quickly figure out the salient and relevant points (or it may be turn out that knowing either B or C is sufficient to learn A). In this case, you really don't want to have a learning strategy which will not make sure you do C before B!

BFS not only allows you to exploit cooperativities, but it also allows you to manage your time better. After your first pass, let's say you ended up with a list of 30 topics you need to learn first. They won't all be equally hard. Maybe 10 will take you 5 minutes of skimming wikipedia to figure out. Maybe another 10 are so simple, that the first Google Image diagram explains everything. Then there will be 1 or 2 which will take days or even months of work. You don't want to get tripped up on the big ones while you have the small ones to take care of. After all, it may turn out that the big topic is not essential, but the small topic is. If that's the case, you would feel very silly if you tried to tackle the big topic first! But if the small one proves useless, you haven't really lost much energy or time.

Once you're doing BFS, you might as well benefit from the other, very nice and clever twists on it, such as Dijkstra or A*. When you have the list of topics, can you order them by how promising they seem? Chances are you can, and chances are, your intuition will be right. Another thing to do - since ultimately, your aim is to link up with some green nodes, why not try to prioritize topics which seem like they would be getting closer to things you do know? The beauty of A* is that these heuristics don't even have to be very correct - even "wrong" or "unrealistic" heuristics may end up making your search faster.
AnswerKenntnis:
You don't learn what a vector space is by swallowing a definition that says


  A vector space $\langle V, S\rangle$ is a set $V$ and a field $S$ that satisfy the following 8 axioms: ΓÇª


Or at least I don't, and from the sound of things that isn't working for you either.  That definition is for someone who not only already knows what a field is, but who also already knows what a vector space is, and for whom the formal statement may illuminate what they already know.

Instead, if you want to learn what a vector space is, you pick up an elementary textbook on linear algebra and you start reading it.  I picked up Linear Algebra and its Applications (G. Strang, 1988) from next to the bed just now, and I find that "vector space" isn't even defined.  The first page of chapter 2 (ΓÇ£Vector Spaces and Linear EquationsΓÇ¥) introduces the idea informally, leaning heavily on the example of $\Bbb R^n$, which was already introduced in Chapter 1,  and then emphasizes the crucial property: ΓÇ£We can add any two vectors, and we can multiply vectors by scalars.ΓÇ¥ The next page reiterates this idea: ΓÇ£a real vector space is a set of ΓÇÿvectorsΓÇÖ together with rules for vector addition and multiplication by real numbers.ΓÇ¥ Then there follow three examples that are different from the $\Bbb R^n$ examples. 

A good textbook will do this: it will reduce those 8 axioms to a brief statement of what the axioms are actually about, and provide a set of illuminating examples.  In the case of the vector space, the brief statement I quoted, boldface in the original, was it: we can add any two vectors, and we can multiply vectors by scalars. 

You don't need to know what a field is to understand any of this, because it's restricted to real vector spaces, rather than to vector spaces over arbitrary fields. But it sets you up to understand the idea in its full generality once you do find out what a field is: ΓÇ£Just like the vector spaces you're used to, except instead of the scalars being real numbers, they can be elements of any field.ΓÇ¥

If you find yourself chasing an endless series of definitions, that's because you're trying to learn mathematics from a mathematical encyclopedia.  Well, it's worth a try; it worked for Ramanujan.  But if you find that you're not Ramanujan, you might try what the rest of us non-Ramanujans do, and try reading a textbook instead.  And if the textbook starts off by saying something like:


  A vector space $\langle V, S\rangle$ is a set $V$ and a field $S$ that satisfy the following 8 axioms: ΓÇª


then that means you have mistakenly gotten hold of a textbook that was written for people who already know what a vector space is, and you need to put it aside and get another one. (This is not a joke; there are many such books.) 

The Strang book is really good, by the way. I recommend it.

One last note: It's not usually enough to read the book; you have to do a bunch of the exercises also.
AnswerKenntnis:
A very well known mathematician showed me how he avoids the rabbit hole. I copied his method, and now I can stay out of it most of the time.

I had private weekly seminars with him. Every week, he would research a topic he knew nothing about (that was our deal and that's what was in it for him). I would name the topic (examples: Bloom Filters, Knuth-Bendix Theorem, Linear Logic), and the following week he would give a zero-frills Power-Point presentation of what he found out. The presentations had a uniform pattern:

Motivating Example
Definitions
Lemmas and Theorems
Applications


By beginning with the motivating example, we never got lost in the thicket of technicalities, and the Applications section would circle back and explain the Motivating Example (and maybe some others if time allowed) in terms of the technicalities. 

This is how he taught himself a topic without going down the MRH. 

Limit your rabbit-hole time (one week)
your presentation must be one hour long
Focus on a Motivating Example
do just enough technicalities to explain the example and optional variations


I have since copied this style. When I teach myself a new topic, I make a slide presentation like that, and then I present it to others in a weekly reading group.
AnswerKenntnis:
I think that sometimes, you don't really need to know exactly what every term used means, not right away, anyway. Most of the time, a vague idea is enough to get you started.

Check out the definition (without necessarily understanding it at first -- ploughing through a huge mess of a formal definition is not always helpful at this point, but it helps to see its general structure), then see some examples, tinker a little, see how it works. If I told you everything about horse riding for a month, you probably wouldn't be as good at horse riding as you would be if you had instead tried practised horse riding for a week (and not just because I don't know a thing about horse riding ;) ).

As you get deeper into the subject matter, it might help to understand the details of the definitions, as well as the auxiliary objects. What are they for? What do they really mean? But at first, you shouldn't expect to understand everything, especially when studying more in-depth stuff which (unlike vector spaces) can get you really deep into... rabbit hole.

Familiarity comes with experience. There is no other way.

As a side comment about your vector spaces example: I don't think you can really understand linear algebra if you restrict yourself to reals. They have characteristic zero, are not algebraically closed, they are naturally ordered... this can be very misleading. It's good for starters, but I wouldn't say you understand vector spaces if you just understand real vector spaces.
AnswerKenntnis:
It is a good idea to learn about vector spaces first in the context of real scalars rather than general fields.  But afterward, it is worthwhile to observe that, in most of what you learned (everything short of inner product spaces, in the usual presentations of the subject), you never used the fact that the real numbers come with an ordering; you never needed to consider whether numbers were positive or negative.  And for some purposes, like eigenvalues and eigenvectors, it's actually helpful to allow complex numbers into your picture.  In fact, all you needed about the real numbers was that you can add, subtract, multiply, and divide them (except of course that you can't divide by $0$) and you can manipulate equations as you learned in elementary algebra.  That's why it's safe to allow complex numbers into your picture --- they share all those essential (for linear algebra) properties of the real numbers.  And at this point, you know what a field is, even if you've never seen the definition or even the word, because a field is just a collection of things that resemble numbers to the extent that you can add, subtract, multiply, and divide them (except of course that you can't divide by $0$) and you can manipulate equations as you learned in elementary algebra. The formal axioms that define "field" are just the result of the observation that all those algebraic rules you learned are consequences of just a few of the rules; i.e., most of them are redundant. So "field" can be defined by giving just the necessary rules, not all the redundant ones.  Of course, that makes it easier to check that something is a field, because you have far fewer rules to verify, and it also makes it easier to write the definition of "field" in a book, because it's shorter than it would otherwise be. But the true idea of "field" remains that all the usual manipulations of equations are valid.
AnswerKenntnis:
I have fallen into this vortex with a lot of my studying. The only way I think you can get out of it is to first start off by reading soft math books that don't focus in the details/proofs but try to convey what the general goal of the topic is. 

I'm referring here to such books like Garrity's "All the Mathematics You Missed: But Need to Know for Graduate School" which outlines the different disciplines of mathematics, what their roles are and how they relate. 

I think anybody who self-studies (and if you're learning math I think you have no choice) has figured out that there are two kinds of math books: those that explain things to you so that you understand them and those that assume you already know the basics and put a new perspective on things.

For me a recent example is combinatorics. A lot of people on here suggested Peter Cameron's book - which is great if you already know a lot of stuff he neglects to mention. If you don't, you're in hell trying to figure out where he is coming up with stuff. And then there is there is Brualdi's combinatorics book which explains things so that you understand them and is a joy to read. Now to properly understand and appreciate combinatorics, I think you need both books (Brualdi first and Cameron second). But I would have saved myself a lot of grief if I had started off with Brualdi first.
AnswerKenntnis:
Learning in an organized manner (as opposed to "on your own") may help.  Plans of what order the topics should be studied in have been worked out by teachers and textbook authors over the years.  Trying to start in the middle (with "Vector Space", for example) probably will be difficult.
AnswerKenntnis:
Metacademy is a community driven, open source web platform that tries to solve this exact problem. In their own words: 


  When you try to learn a given concept, Metacademy can show you the full prerequisite structure of the concept and provide a custom learning plan for you to learn the concept as efficiently as possible, complete with curated learning resources as well as discussions on the concept's relationship to other relevant subjects
AnswerKenntnis:
how do you avoid falling into the Math Rabbit Hole? And more specifically, how do you efficiently attain enough familiarity with pre-requisite concepts to move on to the topics that you want to learn about?


the "rabbit hole" you describe exists in all scientific fields and in many ways is part of the difficulty of its highly specialized nature in the modern age in which it can take many years of study to get to the frontiers of modern research. yet, it is somewhat unacknowledged by experts and considered unavoidable/inevitable. (its great to get some visibility on this prominent issue with your question here.)

in many ways it is unavoidable, yet here are a few ways/strategies around it.


toy problems. there are sometimes simple problems in an advanced theory that are accessible with a few key definitions in that theory. that doesnt mean they are solvable with those pieces only that they are expressible. this can be psychological leverage to delve deeper in the field.
textbooks instead of/vs papers. textbooks often are more organized than papers, have a better sense of the overall map of the theory, and are written with beginners in mind sometimes with very careful description and order of introduction of concepts (eg calculus). there can be a lot of variation in coverage/style in textbooks on the same subject. try to find the best ones and then pick a textbook that suits your style.
"survey papers". these are papers that dont try to prove anything new but "survey" the field. if the field is significant then typically these papers exist. they are not always easy to locate. "insiders" know about them.
brilliant teacher-writers. often a field has a few writers who are known for their expository rather than research skills, and it pays to focus on their conceptualizations of the field. in some rare cases this can overlap eg Feynman comes to mind. (and conversely there may be few hard-core high-prestige researchers who clearly have little interest in making it all comprehensible/accessible to neophytes or disregard the problem entirely, understanding their primary agenda can help avoid frustration.) 
software/algorithms. approaching mathematical subjects from the pov of algorithms that compute the various entities can be a useful pedagogical approach and has increasing relevance as some key advanced areas of math/TCS are starting to overlap. (eg combinatorics field).
seek discrete versions of continuous problems. sometimes it seems that math gets most abstract with continuous aspects. discrete versions of the same problem exist and can be simpler to understand/conceptualize. for example the Riemann hypothesis has a lot of very advanced continous math associated with the Zeta function, but there is a discrete version of the conjecture that doesnt even mention the Zeta function.
possibly approach the field from the problems it addresses/solves (aka "applications") rather than its overarching theories. more generally, there are often equivalent formulations of problems, one simpler to conceptualize for beginners than another.
look for interesting "bridge theorems" between fields that you know about, and fields that you are interested in. this is a theorem that shows something like an "uncanny correspondence" that seems to have hints it can or will be be developed further.
wikipedia can be useful but note it often is unnecessarily complex/technical on difficult areas of math/science. at times on some topics it reads as if its written by experts for other experts. raid the references at the end of the article.
blogs written by experts are increasingly more common and contain remarkably sophisticated expositions, some even surpassing what can be found in textbooks. it will be hard to find specific pages on subjects but once found can be gems. use google and search only on a specific blog, use their topic organization links, etc.
visual approaches to mathematics. many concepts can be graphed or have visual representations that may be more accessable or intuitive to beginners.
there are sometimes articles written on "common misconceptions in this field". they can be useful for beginners to avoid common mistakes.
AnswerKenntnis:
In favor of the rabbit hole

Begin at the beginning, and go on till you come to the end: then stop.

My answer is somewhat contrarian, but I do believe it strongly: You have to fall into the rabbit hole, and you have to go as deep as possible at all times. 

Math isn't science. To understand why a frog croaks we might study its respiratory system, to understand this we might get into how cells divide, then the chemical processes in living organisms, organic molecules in general, then the physics of atoms, the sub-atomic particles, etc. By now we have certainly gone too far. The best way of understanding how a frog breathes is to make simplifying assumptions at much higher scales. So we assume that cells are little machines that do a certain thing, or at least that atoms are small balls that bounce off each other and stick together.

To understand vector spaces, there is no point trying to 'gloss over' fields. Best is to know fields inside out. If you can't learn them inside out, you should know the basics as well as possible. The rabbit hole doesn't go on forever - in all cases you will reach either basic definitions, or things that we all agree on intuitively (like the counting numbers).

Sentence first, verdict afterwards

I have adopted a discipline of studying mathematics, where I never go past a single word that I don't know what it means, and I never skip over a statement that I can't understand, or justify, or understand the justification of. As soon as I have a question of the type "but why wouldn't that work if that condition wasn't true", I stop and think about it until I understand it. If I need to go back earlier in the book or to another book, I do so, even if it means I end up reading books backwards.

I don't always work like this, and there could be places where it is unnecessary, but your example definitely isn't one of them. Suppose that you are trying to learn about vector spaces. Frankly you aren't doing yourself any favors if you believe deep down that all fields are $\mathbb{R}$ and all vector spaces are $\mathbb{R}^n$ for some small natural $n$. Each time you justify something or try to picture something using this model you are storing up problems for yourself when you encounter infinite dimensional spaces, finite fields, or spaces over $\mathbb{C}$ and your mental models don't work anymore. Not to mention the huge problems you would have encountered if you had some misconception about a field (a field is a special case of a group, or a field is an ordered set with some other properties...) and had continued studying vector spaces for a while with this wrong picture in your mind. 

Obviously you wouldn't adopt this method to read a newspaper, or a history book. If you don't know what an arquebuse is, but you have an idea that it's some kind of weapon, you might as well assume it's a type of sword. When you find out it's a kind of gun, you can simply slot this knowledge into the understanding of whatever you were reading about arquebuses. Similarly if you think Wisconsin is in Canada. Either it doesn't matter to the story which country it is in, or it does matter, and you find out soon enough where it is, with little effort wasted in reinterpreting other parts of the story.

Curiouser and curiouser

Now suppose that you do follow my method. You start to research fields. The information about fields you need is this: 


You need to know the axioms that define a field. These easily fit on a sheet of notepaper in large caps written in sharpie. All of them are pretty much self-explanatory. Knowing the names (commutativity etc.) will be invaluable. Arguable any pure mathematician should know them.
You should know several examples of fields, eg $\mathbb{Q}$, $\mathbb{R}$, $\mathbb{C}$, $\mathbb{F_p}$. If the p-adics or other more advanced fields are accessible to you, then all the better, but if not you can live without them. Again, there is nothing here that is not worth knowing to anyone in any branch of pure maths (or in other words, this material is something all undergraduate mathematicians have to learn before they specialize).
You should know some examples of things that are a bit like fields, but not fields. Eg $\mathbb{N}$, $\mathbb{Z}$, residue sets modulo a composite, reduced residue sets, $\mathbb{R}^n$, boolean rings. There is nothing extra to learn here, you only need to be able to check that various objects you have already heard of don't satisfy the definition of a field. If you haven't heard of some space, you don't need to know that it's not a field. In each case you just figure out one line of the definition that you can point to and say 'This fails, therefore not a field'.
You should be aware of some theorems about fields. In particular, you should know which properties of 'numbers' apply to all fields. This is again just a case of chasing the definition of a field through some knowledge you already have. Is the quadratic formula applicable in any field? No because square roots are not part of the definition. Is the formula for the solution of a linear equation applicable in any field? Yes, because the multiplicative inverse must exist because...
You should be aware of some differences between fields. Which fields are finite? Which fields are complete (if you already know what complete means)? What is the characteristic of a field (a one line definition)?
You should understand how a field has two groups embedded in it.


Now, in all of this there are really only three things which could cause you to get pulled further down the rabbit hole. $\mathbb{C}$, $\mathbb{F}_p$, and the definition of a group. All of these are things that everyone should know. In the case of the first two, all you need to know is the how the field structure works, not any other properties. This can be worked out or taught in an hour (how to add, how to multiply, how to divide, in $\mathbb{C}$ or $\mathbb{F}_p$). As for groups, you need to know the equivalent of the list above for fields. But you would honestly not be wasting your time if you were to read a whole introductory book on groups, studying every proof in detail, even if your goal is vector spaces. A vector space is also a group, as are half of the next thousand spaces/objects you are going learn about. Furthermore, as you learn about groups you are learning:


how abstract algebra works: you don't assume inverses, commutativity, etc unless the axioms say you can.
how to do logical proofs, eg how to prove that two sets are equal
notation in abstract algebra, eg writing binary operations as sums, as products, or in some other way.
some examples of groups that you can later think about when you are trying to consider vector spaces or fields in generality (for instance, why can you add a multiplicative structure to some additive groups but not others).


All of these are going to help you massively. Even if you NEVER get to vector spaces (you will), it will have been worth you while. Someone who understands groups is a better mathematician than someone who thinks they know what a vector space is, but doesn't understand groups.

Now, instead of thinking of $\mathbb{R}$ everytime you read a fact about a vector space, you can think of vector spaces over all the fields you know. Rather than limiting your imagination, you are challenging it to understand the statements you read in as close to full generality as possible.

Did I load my example? If you are studying something more specialized, then the 'rabbit hole' subjects are not things everyone needs to know, but they are things you need to know. If you are studying Brownian motion, any fact about elementary probability you come across is something you should be able to master.

Everything's got a moral, if only you can find it

When we speak to professors and other experienced mathematicians about difficult mathematical concepts, they are often able to summarize them with beautiful and compelling generalizations ('Harmonic analysis is about dualities between smooth behavior at small scales and convergent behavior near infinity'). This often makes us worry, because we aren't able to figure these things out ourselves, and they don't appear in our elementary textbooks. 

The person who can make that generalization isn't fluent at doing manipulations and solving problems about Fourier transforms because she has understood 'what harmonic analysis is about'. She is fluent, AND she can come out with nice generalizations, because of all the work she has done on the mechanics of harmonic analysis, solving problems, reading slowly through proofs etc. To emulate this person, we shouldn't try to be able to summarize a topic in a neat way. We should try and acquire their detailed knowledge of the mechanics of their subject. Once we've done this, the flashes of insight will come by themselves.

You should also know that some harmonic analysts might think that this 'motivation' for harmonic analysis is wrong, irrelevant or trivial. However all kinds of harmonic analysts would be able to follow each others work by giving the precise definitions they are working with, starting with the things they all agree with.

Seeing the big picture is nice, but you can often afford to miss it. Miss the small picture, and you're not doing mathematics anymore, just reading about it.
AnswerKenntnis:
My 2 cents: break the text into chunks you can swallow by allowing yourself multiple passes, where you accept less and less on faith and intuition each time through. I dimly recall Terry Tao giving similar advice on his blog somewhere; hopefully someone can give a link.

For elementary topics, a lot of us are able to "absorb" everything at once, all the definitions, examples, theorems, proofs, unspoken intuitions, etc. At some point it just becomes too much, so do the only thing mathematicians know how to do: break the problem into pieces. Get a high level overview on the first pass, get a sense for what's important on the second pass, figure out what you care to understand on the third pass, and break up those parts you care about iteratively until you reach something manageable.

To take a hypothetical, suppose you're reading a chapter with 50 propositions, lemmas, theorems, and examples. On the first pass you might read the introduction and very quickly skim the rest. After you have a very hazy idea of what the chapter is about, re-skim enough to identify the important theorems and examples. Here I sometimes write a paragraph or two summarizing the chapter. (It'll be incomplete and might be badly wrong, which is fine. It's kind of funny to read my own hazy ideas after I actually understand a topic.)

Now figure out what you actually want to understand; at some point there just isn't time to understand every detail, so you'll have to pick and choose anyway. Perhaps the first half of the chapter proves Theorem M and the second half Theorem Y, which you don't care about yet. Great, no need to slog through Lemmas P, Q, and R, since those are only used in the second half. Maybe Theorem M roughly says Example A is the "only" example; that really says you should get comfortable with Example A, maybe play around with it a little on scratch paper before starting the journey to Theorem M. If it's a long journey, break it up into multiple passes too--maybe start by reading its proof so you know which lemmas are important, and make another rough summary. Perhaps make the path easier by assuming an abstract object is something particular, eg. that a general field is just $\mathbb{R}$. It's fine to read non-linearly.

Eventually you'll have to actually "reach the bottom" and get your hands dirty with technical details, but at least for me it's very helpful to have a high level overview of where things fit into each other before getting down and dirty. I have no hope of retaining much of a complicated topic otherwise. Oh, sometimes I write myself a technical summary, which can be helpful--perhaps rigorous definitions and statements of the ingredients to Theorem M together with a proof of Theorem M in my own words using those ingredients. If I really want to understand something, I add "proof ideas" to a technical summary, where (at the time) I can reconstruct rigorous proofs from my summary. Exercises can also help; sometimes I look for relevant exercises after the first few pages, to get me used to basic definitions that are fundamental to the rest of the chapter.

This works better with some sources than others. If you can't even begin to give a  hazy summary (maybe you have no idea what any of the words mean), you're probably reading something written for experts, which doesn't yet include you, so a gentler introduction might be in order. Always be kind to yourself: written math is typically the product of years (or decades, or centuries) of labor by brilliant people. It's no wonder it often takes a long time to absorb.

Finally, I'd like to note that I wrote this post roughly in the style I advocate. The first paragraph is a sketchy overview of the main idea, the second fills in some details, and the third through fifth "get down and dirty" with actionable advice.
AnswerKenntnis:
It's possible to visualise a 2D or 3D spatial object with some structure in your imagination, which is made of abstract stuff and behaves in a certain way. For example, for a vector space, I visualise something like a couple of arrows from a point (the origin), pointing in general direction (in the actual imagined instance, the directions are quite specific), and a part of a plane stretched between and a bit beyond them. And all these are in a state of frozen animation.

As one gets used to vector spaces (for example), this sort of thing helps. The reason is that a lot of questions about all vector spaces could be answered by considering just one non-trivial example that you are familiar with. This speeds up the search through the list of things you know, by using extensive spatial reasoning and memory capabilities of the brain.

In general, the behaviour of, say, a vector space, is infinitely complex. The rabbit hole is infinite! (And splits into exponentially many burrows as a function of depth). That is to say, while the definitions are small and finite, the set of all possible behaviours is infinitely complex, for objects such as groups, fields, vector spaces.

If someone spent a lifetime working with vector spaces, they would probably have in their mind a museum of representative visualised objects, and some efficient ways to choose which to use in order to answer some question or other. Some people, I'm pretty sure, also have at least one other way of thinking that is much faster than this kind of spatial visualisation but consistently yields intuitive answers. Some students in the International Mathematical Olympiad can solve previously unseen problems ten times faster than the average professional mathematician, and I'd like to know how. I've also read that some (most?) chess grandmasters maintain their level of performance when they are asked to continuously solve simple sums while playing chess. So perhaps there is another form of familiarity.

Anyway, to answer the question:


It's very useful to explore the nearby reaches of the rabbit hole. With a short Ariadne's thread. It's easy to miss interesting areas even there, so a solid set of exercises from a classic set of lecture notes is invaluable to get good coverage rapidly, and train whatever construct is your understanding.
If you have some goal, that's even better, and while some pure mathematicians find their nirvana in a random walk through relatively scary reaches of the rabbit hole (which gets rapidly more horrendous and useless with depth; though I'm sure there are elusive veins of gold and astonishing shortcuts etc.), you can't go wrong with a useful goal from the real world.
AnswerKenntnis:
The real question from the OP:


  How do you avoid falling into the Math Rabbit Hole?


MJD's answer hints the the answer to this question: Read a textbook. Textbooks are designed to introduce the material in the correct order, without overburdening or going into too much detail. They are designed to help you progress.

Knowing which textbook to read is a problem unto itself, and for that you should really ask a professional (See: asking a doctor instead of self-diagnosis). To get an idea if the textbook is suitable for you, skim through the first chapter only. If you feel that you grasp or could grasp the content of that chapter, then you're golden. If not, then go find the textbook which will bring you up to speed for that first chapter.
AnswerKenntnis:
What you are talking about is the process of learning and curiosity.

When researching, you have to keep in mind your goal.  Why do you need to study rings when you are just trying to implement an FFT?  You don't.  So you have to know when to cut off curiosity in exchange for working towards your set out goals.

Now if you don't have defined goal in your study of math, then your goal was to wander about in the rabbit hole.  And there's nothing wrong with that, you'll become a stronger analytical thinker the more you study mathematics.
AnswerKenntnis:
I read a lot of math on my own as a young person. I would go sit in the stacks, and sift through the books on what I wanted to learn about till I found one that "spoke to me". Part of that test was if I could work some exercises. Once I found such a book, I went through it, working as many exercises as I could. If I couldn't find such a book, I just spun my wheels for a bit till my interests shifted.
AnswerKenntnis:
Avoid swallowing definitions and going from there. While they give you the illusion you are learning, you are potentially missing insights and masking problems.

What I'd suggest is reading some university textbooks aimed at first and second year mathematic-students. In my experience (limited) they start from the ground up and go from there.

However, if you don't want to spend your time working through books, most universities offer non-degree programs. You can select the classes you want and learn what you want thoroughly.
This has the advantage that you'll have access to cheap summaries, exercises and somebody willing to explain it to you.

For vector spaces specifically, every introductory book in linear algebra should do.
AnswerKenntnis:
Here's my short naive answer, not always possible but really good when it is: ask someone who knows and whose pedagogical skills you respect. Interrupt when you need less (or more) technical precision in his/her response.
AnswerKenntnis:
I'm not good at algebra but as far i can tell you is that when you need it, you will get it. "deep stuff" exists only as answers to deeper questions, and this kind of learning appears to be systematic in every age. Is tempting to dig on Wikipedia, but previously said is like you here acting like a graph visitor algorithm: visiting adjacent nodes and stacking previous. Note also that Wikipedia is turning a Monster - contributors are more concerned about the completeness than the audience. And this completeness in a mathematical sense is ... formality and verbosity!!! Thats why we need books and exercises. After a lot of exercises your brain will ask  "why i'm not organizing or relating those mathematical objects in that in someway"... and then you go to Wikipedia looking for answers to find out that another set of brains did that. And then you acknowledge that you understand 5 or 6 hyperlinks and you say "thanks wikipedia! without you wouldnt be possible" :P
AnswerKenntnis:
As one of many "Alices" in the MRH called stackexchange I rather think that studying math with out structure is like waking up in free fall. You see everything around you, you may even come to understand a few things that wiz by your head but you can't shake the feeling that you are falling.  More to the point it is like reading a book in a foreign language with a translation book near by. Its a difficult read but doable
AnswerKenntnis:
This question has much broader implication. "Going down the Math Rabbit Hole" simply reveals the nature of being any kind of academic, not just a mathematician. This kind of no ending thing is good for some people who enjoy having things they do not know so that they can keep doing things (whether the things they are doing are worthwhile is a completely different question). This no ending thing, however, really is bad for other people since it indeed is frustrating to know that you can never finish and you can never have a closure. As an actuarial graduate who tries to make up sufficient mathematics, I find it is helpful to take some fundamental subjects like calculus and algebra without which it simply is too difficult to do anything else. Also I suggest a healthy attitude towards study. Nowadays, inter-discipline work is the norm. One could never acquire all the knowledge they need for their work. For my own purpose, I only need to know enough so that I can communicate with my colleagues who are mathematicians, which is the ideal balance in my opinion.
AnswerKenntnis:
The thing is, you don't have to know what a field is in order to work with vector spaces. The field "stuff" relates vector spaces to a generalization which connects them to other spaces. Skip the rabbit hole, read the rest of the chapter, and do some exercises.

You don't have to understand the word "beverage" in order to swallow the Kool-Aid.
AnswerKenntnis:
Present day there are 9 types of textbook authors in mathematics at undergraduate-level and graduate-level. Some are Mr 1/2, some are Mr 1/3, ..., some are Mr 1/10. Right now, Mr 1/1 is nowhere. We are waiting anxiously to welcome him. Now, what Mr 1/n does? From the early draft of his proposed book, they meticulously delete (n-1)/n parts from the proof sections. Now the book becomes like a "riddle book" or a "fill-up the black" type of a book. The miseries of beginners start from here. The day, Mr 1/1 will turned up as Math author, autodidacts will dance with joy.
QuestionKenntnis:
Different methods to compute $\sum\limits_{n=1}^\infty \frac{1}{n^2}$
qn_description:
As I have heard people did not trust Euler when he first discovered the formula
$$\zeta(2)=\sum_{n=1}^\infty \frac{1}{n^2}=\frac{\pi^2}{6}.$$
However, Euler was Euler and he gave other proofs. 

I believe many of you know some nice proofs of this, can you please share it with us?



This is being repurposed in an effort to cut down on duplicates, see: 
   Coping with abstract duplicate questions and
   List of abstract duplicates.
AnswersKenntnis
AnswerKenntnis:
OK, here's my favorite. I thought of this after reading a proof from the book "Proofs from the book" by Aigner & Ziegler, but later I found more or less the same proof as mine in a paper published a few years earlier by Josef Hofbauer. On Robin's list, the proof most similar to this is number 9
(EDIT: ...which is actually the proof that I read in Aigner & Ziegler).

When $0 < x < \pi/2$ we have $0<\sin x < x < \tan x$ and thus
$$\frac{1}{\tan^2 x} < \frac{1}{x^2} < \frac{1}{\sin^2 x}.$$
Note that $1/\tan^2 x = 1/\sin^2 x - 1$.
Split the interval $(0,\pi/2)$ into $2^n$ equal parts, and sum
the inequality over the (inner) "gridpoints" $x_k=(\pi/2) \cdot (k/2^n)$:
$$\sum_{k=1}^{2^n-1} \frac{1}{\sin^2 x_k} - \sum_{k=1}^{2^n-1} 1 < \sum_{k=1}^{2^n-1} \frac{1}{x_k^2} < \sum_{k=1}^{2^n-1} \frac{1}{\sin^2 x_k}.$$
Denoting the sum on the right-hand side by $S_n$, we can write this as
$$S_n - (2^n - 1) < \sum_{k=1}^{2^n-1} \left( \frac{2 \cdot 2^n}{\pi} \right)^2 \frac{1}{k^2} < S_n.$$

Although $S_n$ looks like a complicated sum, it can actually be computed fairly easily. To begin with,
$$\frac{1}{\sin^2 x} + \frac{1}{\sin^2 (\frac{\pi}{2}-x)} = \frac{\cos^2 x + \sin^2 x}{\cos^2 x \cdot \sin^2 x} = \frac{4}{\sin^2 2x}.$$
Therefore, if we pair up the terms in the sum $S_n$ except the midpoint $\pi/4$ (take the point $x_k$ in the left half of the interval $(0,\pi/2)$ together with the point $\pi/2-x_k$ in the right half) we get 4 times a sum of the same form, but taking twice as big steps so that we only sum over every other gridpoint; that is, over those gridpoints that correspond to splitting the interval into $2^{n-1}$ parts. And the midpoint $\pi/4$ contributes with $1/\sin^2(\pi/4)=2$ to the sum. In short,
$$S_n = 4 S_{n-1} + 2.$$
Since $S_1=2$, the solution of this recurrence is
$$S_n = \frac{2(4^n-1)}{3}.$$
(For example like this: the particular (constant) solution $(S_p)_n = -2/3$ plus the general solution to the homogeneous equation $(S_h)_n = A \cdot 4^n$, with the constant $A$ determined by the initial condition $S_1=(S_p)_1+(S_h)_1=2$.)

We now have
$$ \frac{2(4^n-1)}{3} - (2^n-1) \leq  \frac{4^{n+1}}{\pi^2} \sum_{k=1}^{2^n-1} \frac{1}{k^2}  \leq \frac{2(4^n-1)}{3}.$$
Multiply by $\pi^2/4^{n+1}$ and let $n\to\infty$. This squeezes the partial sums between two sequences both tending to $\pi^2/6$. Voil├á!
AnswerKenntnis:
We can use the function $f(x)=x^{2}$ with $-\pi \leq x\leq \pi $ and find
its expansion into a trigonometric Fourier series

$$\dfrac{a_{0}}{2}+\sum_{n=1}^{\infty }(a_{n}\cos nx+b_{n}\sin x),$$ 

which is periodic and converges to $f(x)$ in $-\pi \leq x\leq \pi $.

Observing that $f(x)$ is even, it is enough to determine the coefficients 

$$a_{n}=\dfrac{1}{\pi }\int_{-\pi }^{\pi }f(x)\cos nx\;dx\qquad n=0,1,2,3,...,$$ 

because 

$$b_{n}=\dfrac{1}{\pi }\int_{-\pi }^{\pi }f(x)\sin nx\;dx=0\qquad n=1,2,3,... .$$ 

For $n=0$ we have 

$$a_{0}=\dfrac{1}{\pi }\int_{-\pi }^{\pi }x^{2}dx=\dfrac{2}{\pi }\int_{0}^{\pi
}x^{2}dx=\dfrac{2\pi ^{2}}{3}.$$ 

And for $n=1,2,3,...$ we get

$$a_{n}=\dfrac{1}{\pi }\int_{-\pi }^{\pi }x^{2}\cos nx\;dx$$

$$=\dfrac{2}{\pi }\int_{0}^{\pi }x^{2}\cos nx\;dx=\dfrac{2}{\pi }\times \dfrac{
2\pi }{n^{2}}(-1)^{n}=(-1)^{n}\dfrac{4}{n^{2}},$$

because

$$\int x^2\cos nx\;dx=\dfrac{2x}{n^{2}}\cos nx+\left( \frac{x^{2}}{
n}-\dfrac{2}{n^{3}}\right) \sin nx.$$

Thus

$$f(x)=\dfrac{\pi ^{2}}{3}+\sum_{n=1}^{\infty }\left( (-1)^{n}\dfrac{4}{n^{2}}
\cos nx\right) .$$

Since $f(\pi )=\pi ^{2}$, we obtain

$$\pi ^{2}=\dfrac{\pi ^{2}}{3}+\sum_{n=1}^{\infty }\left( (-1)^{n}\dfrac{4}{
n^{2}}\cos \left( n\pi \right) \right) $$ 

$$\pi ^{2}=\dfrac{\pi ^{2}}{3}+4\sum_{n=1}^{\infty }\left( (-1)^{n}(-1)^{n}
\dfrac{1}{n^{2}}\right) $$

$$\pi ^{2}=\dfrac{\pi ^{2}}{3}+4\sum_{n=1}^{\infty }\dfrac{1}{n^{2}}.$$

Therefore

$$\sum_{n=1}^{\infty }\dfrac{1}{n^{2}}=\dfrac{\pi ^{2}}{4}-\dfrac{\pi ^{2}}{12}=
\dfrac{\pi ^{2}}{6}$$



Second method (available on-line a few years ago) by Eric Rowland. From

$$\log (1-t)=-\sum_{n=1}^{\infty}\dfrac{t^n}{n}$$

and making the substitution $t=e^{ix}$ one gets the series expansion

$$w=\text{Log}(1-e^{ix})=-\sum_{n=1}^{\infty }\dfrac{e^{inx}}{n}=-\sum_{n=1}^{
\infty }\dfrac{1}{n}\cos nx-i\sum_{n=1}^{\infty }\dfrac{1}{n}\sin nx,$$

whose radius of convergence is $1$. Now if we take the imaginary part of both sides, the RHS becomes

$$\Im w=-\sum_{n=1}^{\infty }\dfrac{1}{n}\sin nx,$$

and the LHS

$$\Im w=\arg \left( 1-\cos x-i\sin x\right) =\arctan \dfrac{-\sin x}{
1-\cos x}.$$

Since

$$\arctan \dfrac{-\sin x}{1-\cos x}=-\arctan \dfrac{2\sin \dfrac{x}{2}\cdot \cos \dfrac{x}{2}}{2\sin ^{2}\dfrac{x}{2}}$$

$$=-\arctan \cot \dfrac{x}{2}=-\arctan \tan \left( \dfrac{\pi }{2}-\dfrac{x}{2}
\right) =\dfrac{x}{2}-\dfrac{\pi }{2},$$

the following expansion holds

$$\dfrac{\pi }{2}-\frac{x}{2}=\sum_{n=1}^{\infty }\dfrac{1}{n}\sin nx.\qquad
(\ast )$$

Integrating the identity $(\ast )$, we obtain

$$\dfrac{\pi }{2}x-\dfrac{x^{2}}{4}+C=-\sum_{n=1}^{\infty }\dfrac{1}{n^{2}}\cos
nx.\qquad (\ast \ast )$$

Setting $x=0$, we get the relation between $C$ and $\zeta (2)$ 

$$C=-\sum_{n=1}^{\infty }\dfrac{1}{n^{2}}=-\zeta (2).$$

And for $x=\pi $, since

$$\zeta (2)=2\sum_{n=1}^{\infty }\dfrac{(-1)^{n-1}}{n^{2}},$$

we deduce

$$\dfrac{\pi ^{2}}{4}+C=-\sum_{n=1}^{\infty }\dfrac{1}{n^{2}}\cos n\pi
=\sum_{n=1}^{\infty }\dfrac{(-1)^{n-1}}{n^{2}}=\dfrac{1}{2}\zeta (2)=-\dfrac{1}{
2}C.$$

Solving for $C$

$$C=-\dfrac{\pi ^{2}}{6},$$

we thus prove

$$\zeta (2)=\dfrac{\pi ^{2}}{6}.$$

Note: this 2nd method can generate all the zeta values $\zeta (2n)$ by integrating repeatedly $(\ast\ast )$. This is the reason why I appreciate it. Unfortunately it does not work for $\zeta (2n+1)$.
AnswerKenntnis:
Here is an other one which is more or less what Euler did in one of his proofs.

The function $\sin x$ where $x\in\mathbb{R}$ is zero exactly at $x=n\pi$ for each integer $n$. If we factorized it as an infinite product we get

$$\sin x = \cdots\left(1+\frac{x}{3\pi}\right)\left(1+\frac{x}{2\pi}\right)\left(1+\frac{x}{\pi}\right)x\left(1-\frac{x}{\pi}\right)\left(1-\frac{x}{2\pi}\right)\left(1-\frac{x}{3\pi}\right)\cdots =$$
$$= x\left(1-\frac{x^2}{\pi^2}\right)\left(1-\frac{x^2}{2^2\pi^2}\right)\left(1-\frac{x^2}{3^2\pi^2}\right)\cdots\quad.$$

We can also represent $\sin x$ as a Taylor series at $x=0$:

$$\sin x = x - \frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots\quad.$$

Multiplying the product and identifying the coefficient of $x^3$ we see that

$$\frac{x^3}{3!}=x\left(\frac{x^2}{\pi^2} + \frac{x^2}{2^2\pi^2}+ \frac{x^2}{3^2\pi^2}+\cdots\right)=x^3\sum_{n=1}^{\infty}\frac{1}{n^2\pi^2}$$
or 
$$\sum_{n=1}^\infty\frac{1}{n^2}=\frac{\pi^2}{6}.$$

Here are two interesting links: 


Euler's papers;
EulerΓÇÖs Solution of the Basel Problem ΓÇô The Longer Story an essay on the subject written by Ed Sandifer.
AnswerKenntnis:
Define the following series for $ x > 0 $

$$\frac{\sin x}{x} = 1 - \frac{x^2}{3!}+\frac{x^4}{5!}-\frac{x^6}{7!}+\cdots\quad.$$

Now substitute $ x = \sqrt{y}\ $ to arrive at 

$$\frac{\sin \sqrt{y}\ }{\sqrt{y}\ } = 1 - \frac{y}{3!}+\frac{y^2}{5!}-\frac{y^3}{7!}+\cdots\quad.$$

if we find the roots of $\frac{\sin \sqrt{y}\ }{\sqrt{y}\ } = 0 $ we find that 

$ y = n^2\pi^2\ $ for $ n \neq 0 $ and $ n $ in the integers

With all of this in mind, recall that for a polynomial

$ P(x) = a_{n}x^n + a_{n-1}x^{n-1} +\cdots+a_{1}x + a_{0} $ with roots
$ r_{1}, r_{2}, \cdots , r_{n} $ 

$$\frac{1}{r_{1}} + \frac{1}{r_{2}} + \cdots + \frac{1}{r_{n}} = -\frac{a_{1}}{a_{0}}$$

Treating the above series for $ \frac{\sin \sqrt{y}\ }{\sqrt{y}\ } $ as polynomial we see that

$$\frac{1}{1^2\pi^2} + \frac{1}{2^2\pi^2} + \frac{1}{3^2\pi^2} + \cdots =  -\frac{-\frac{1}{3!}}{1}$$

then multiplying both sides by $ \pi^2 $ gives the desired series.

$$\frac{1}{1^2} + \frac{1}{2^2} + \frac{1}{3^2} + \cdots =  \frac{\pi^2}{6}$$
AnswerKenntnis:
I have two favorite proofs.  One is the last proof in Robin Chapman's collection; you really should take a look at it.

The other is a proof that generalizes to the evaluation of $\zeta(2n)$ for all $n$, although I'll do it "Euler-style" to shorten the presentation.  The basic idea is that meromorphic functions have infinite partial fraction decompositions that generalize the partial fraction decompositions of rational functions.

The particular function we're interested in is $B(x) = \frac{x}{e^x - 1}$, the exponential generating function of the Bernoulli numbers $B_n$.  $B$ is meromorphic with poles at $x = 2 \pi i n, n \in \mathbb{Z}$, and at these poles it has residue $2\pi i n$.  It follows that we can write, a la Euler,

$$\frac{x}{e^x - 1} = \sum_{n \in \mathbb{Z}} \frac{2\pi i n}{x - 2 \pi i n} = \sum_{n \in \mathbb{Z}} - \left( \frac{1}{1 - \frac{x}{2\pi i n}} \right).$$

Now we can expand each of the terms on the RHS as a geometric series, again a la Euler, to obtain

$$\frac{x}{e^x - 1} = - \sum_{n \in \mathbb{Z}} \sum_{k \ge 0} \left( \frac{x}{2\pi i n} \right)^k = \sum_{k \ge 0} (-1)^{n+1} \frac{2 \zeta(2n)}{(2\pi )^{2n}} x^{2n}$$

because, after rearranging terms, the sum over odd powers cancels out and the sum over even powers doesn't.  (This is one indication of why there is no known closed form for $\zeta(2n+1)$.)  Equating terms on both sides, it follows that

$$B_{2n} = (-1)^{n+1} \frac{2 \zeta(2n)}{(2\pi)^{2n}}$$

or

$$\zeta(2n) = (-1)^{n+1} \frac{B_{2n} (2\pi)^{2n}}{2}$$

as desired.  To compute $\zeta(2)$ it suffices to compute that $B_2 = \frac{1}{6}$, which then gives the usual answer.
AnswerKenntnis:
Here is one more nice proof, I learned it from Grisha Mikhalkin: 

Lemma: Let $Z$ be a complex curve in $\mathbb{C}^2$. Let $R(Z) \subset \mathbb{R}^2$ be the projection of $Z$ onto its real parts and $I(Z)$ the projection onto its complex parts. If these projections are both one to one, then the area of $R(Z)$ is equal to the area of $I(Z)$. 

Proof: There is an obvious map from $R(Z)$ to $I(Z)$, given by lifting $(x_1, x_2) \in R(Z)$ to $(x_1+i y_1, x_2 + i y_2) \in Z$, and then projecting to $(y_1, y_2) \in I(Z)$. We must prove this map has Jacobian $1$. WLOG, translate $(x_1, y_1, x_2, y_2)$ to $(0,0,0,0)$ and let $Z$ obey $\partial z_2/\partial z_1 = a+bi$ near $(0,0)$. To first order, we have $x_2 = a x_1 - b y_1$ and $y_2 = a y_1 + b x_1$. So $y_1 = (a/b) x_1 - (1/b) x_2$ and $y_2 = (a^2 + b^2)/b x_1 - (a/b) x_2$. So the derivative of $(x_1, x_2) \mapsto (y_1, y_2)$ is $\left( \begin{smallmatrix} a/b & - 1/b \\ (a^2 + b^2)/b & -a/b \end{smallmatrix} \right)$ and the Jacobian is $1$. QED

Now, consider the curve $e^{-z_1} + e^{-z_2} = 1$, where $z_1$ and $z_2$ obey the following inequalities: $x_1 \geq 0$, $x_2 \geq 0$, $-\pi \leq y_1 \leq 0$ and $0 \leq y_2 \leq \pi$. 

Given a point on $e^{-z_1} + e^{-z_2} = 1$, consider the triangle with vertices at $0$, $e^{-z_1}$ and $e^{-z_1} + e^{-z_2} = 1$. The inequalities on the $y$'s states that the triangle should lie above the real axis; the inequalities on the $x$'s state the horizontal base should be the longest side.

Projecting onto the $x$ coordinates, we see that the triangle exists if and only if the triangle inequality $e^{-x_1} + e^{-x_2} \geq 1$ is obeyed. So $R(Z)$ is the region under the curve $x_2 = - \log(1-e^{-x_1})$. The area under this curve is
$$\int_{0}^{\infty} - \log(1-e^{-x}) dx = \int_{0}^{\infty} \sum \frac{e^{-kx}}{k} dx = \sum \frac{1}{k^2}.$$

Now, project onto the $y$ coordinates. Set $(y_1, y_2) = (-\theta_1, \theta_2)$ for convenience, so the angles of the triangle are $(\theta_1, \theta_2, \pi - \theta_1 - \theta_2)$. The largest angle of a triangle is opposite the largest side, so we want $\theta_1$, $\theta_2 \leq \pi - \theta_1 - \theta_2$, plus the obvious inequalities $\theta_1$, $\theta_2 \geq 0$. So $I(Z)$ is the quadrilateral with vertices at $(0,0)$, $(0, \pi/2)$, $(\pi/3, \pi/3)$ and $(\pi/2, 0)$ and, by elementary geometry, this has area $\pi^2/6$.
AnswerKenntnis:
The most recent issue of The American Mathematical Monthly (August-September 2011, pp. 641-643) has a new proof by Luigi Pace based on elementary probability.  Here's the argument.

Let $X_1$ and $X_2$ be independent, identically distributed standard half-Cauchy random variables.  Thus their common pdf is $p(x) = \frac{2}{\pi (1+x^2)}$ for $x > 0$.

Let $Y = X_1/X_2$.  Then the pdf of $Y$ is, for $y > 0$, $$p_Y(y) = \int_0^{\infty} x p_{X_1} (xy) p_{X_2}(x) dx = \frac{4}{\pi^2} \int_0^\infty \frac{x}{(1+x^2 y^2)(1+x^2)}dx$$
$$=\frac{2}{\pi^2 (y^2-1)} \left[\log \left( \frac{1+x^2 y^2}{1+x^2}\right) \right]_{x=0}^{\infty} = \frac{2}{\pi^2} \frac{\log(y^2)}{y^2-1} = \frac{4}{\pi^2} \frac{\log(y)}{y^2-1}.$$

Since $X_1$ and $X_2$ are equally likely to be the larger of the two, we have $P(Y < 1) = 1/2$.  Thus 
$$\frac{1}{2} = \int_0^1 \frac{4}{\pi^2} \frac{\log(y)}{y^2-1} dy.$$  This is equivalent to $$\frac{\pi^2}{8} = \int_0^1 \frac{-\log(y)}{1-y^2} dy = -\int_0^1 \log(y) (1+y^2+y^4 + \cdots)  dy = \sum_{k=0}^\infty \frac{1}{(2k+1)^2},$$
which, as others have pointed out, implies $\zeta(2) = \pi^2/6$.
AnswerKenntnis:
Here is a complex-analytic proof.

For $z\in D=\mathbb{C}\backslash${$0,1$}, let

$$R(z)=\sum\frac{1}{\log^2 z}$$

where the sum is taken over all branches of the logarithm. Each point in $D$ has a neighbourhood on which the branches of $\log(z)$ are analytic. Since the series converges uniformly away from $z=1$, $R(z)$ is analytic on $D$. 

Now a few observations:

(i) Each term of the series tends to $0$ as $z\to0$. Thanks to the uniform convergence this implies that the singularity at $z=0$ is removable and we can set $R(0)=0$.

(ii) The only singularity of $R$ is a double pole at $z=1$ due to the contribution of the principal branch of $\log z$. Moreover, $\lim_{z\to1}(z-1)^2R(z)=1$.

(iii) $R(1/z)=R(z)$.

By (i) and (iii) $R$ is meromorphic on the extended complex plane, therefore it is rational. By (ii) the denominator of $R(z)$ is $(z-1)^2$. Since $R(0)=R(\infty)=0$, the numerator has the form $az$. Then (ii) implies $a=1$, so that
$$R(z)=\frac{z}{(z-1)^2}.$$

Now, setting $z=e^{2\pi i w}$ yields
$$\sum\limits_{n=-\infty}^{\infty}\frac{1}{(w-n)^2}=\frac{\pi^2}{\sin^2(\pi w)}$$
which implies that $$\sum\limits_{k=0}^{\infty}\frac{1}{(2k+1)^2}=\frac{\pi^2}{8},$$
and the identity $\zeta(2)=\pi^2/6$ follows.

The proof is due to T. Marshall (American Mathematical Monthly, Vol. 117(4), 2010, P. 352).
AnswerKenntnis:
This is not really an answer, but rather a long comment prompted by David Speyer's answer.
The proof that David gives seems to be the one in How to compute $\sum 1/n^2$ by solving triangles by Mikael Passare,
although that paper uses a slightly different way of seeing that
the area of the region $U_0$ (in Passare's notation)
bounded by the positive axes and the curve $e^{-x}+e^{-y}=1$,
$$\int_0^{\infty} -\ln(1-e^{-x}) dx,$$
is equal to $\sum_{n\ge 1} \frac{1}{n^2}$.

This brings me to what I really wanted to mention, namely another curious
way to see why $U_0$ has that area; I learned this from
Johan W├ñstlund.
Consider the region $D_N$ illustrated below for $N=8$:



Although it's not immediately obvious,
the area of $D_N$ is $\sum_{n=1}^N \frac{1}{n^2}$.
Proof: The area of $D_1$ is 1. To get from $D_N$ to $D_{N+1}$ one removes the boxes along the
top diagonal, and adds a new leftmost column of rectangles of width $1/(N+1)$
and heights $1/1,1/2,\ldots,1/N$,
plus a new bottom row which is the "transpose" of the new column,
plus a square of side $1/(N+1)$ in the bottom left corner.
The $k$th rectangle from the top in the new column
and the $k$th rectangle from the left in the new row (not counting the
square) have a combined area which exactly matches the $k$th box in the removed diagonal:
$$ \frac{1}{k} \frac{1}{N+1} + \frac{1}{N+1} \frac{1}{N+1-k} = \frac{1}{k} \frac{1}{N+1-k}. $$
Thus the area added in the process is just that of the square, $1/(N+1)^2$.
Q.E.D.

(Apparently this shape somehow comes up in connection with the "random
assignment problem", where there's an expected value of something which
turns out to be $\sum_{n=1}^N \frac{1}{n^2}$.)

Now place $D_N$ in the first quadrant, with the lower left corner at the origin.
Letting $N\to\infty$ gives nothing but the region $U_0$:
for large $N$ and for $0<\alpha<1$,
the upper corner of column number $\lceil \alpha N \rceil$ in $D_N$ lies at
$$ (x,y) =
   \left(
    \sum_{n=\lceil (1-\alpha) N \rceil}^N \frac{1}{n},
    \sum_{n=\lceil \alpha N \rceil}^N \frac{1}{n}
   \right)
   \sim
   \left(\ln\frac{1}{1-\alpha}, \ln\frac{1}{\alpha}\right),$$
hence (in the limit) on the curve $e^{-x}+e^{-y}=1$.
AnswerKenntnis:
I'll post the one I know since it is Euler's, and is quite easy and stays in $\mathbb{R}$. (I'm guessing Euler didn't have tools like residues back then).

Let

$$s = {\sin ^{ - 1}}x$$

Then

$$\int\limits_0^{\frac{\pi }{2}} {sds}  = \frac{{{\pi ^2}}}{8}$$

But then 

$$\int\limits_0^1 {\frac{{{{\sin }^{ - 1}}x}}{{\sqrt {1 - {x^2}} }}dx}  = \frac{{{\pi ^2}}}{8}$$

Since

$${\sin ^{ - 1}}x = \int {\frac{{dx}}{{\sqrt {1 - {x^2}} }}}  = x + \frac{1}{2}\frac{{{x^3}}}{3} + \frac{{1 \cdot 3}}{{2 \cdot 4}}\frac{{{x^5}}}{5} + \frac{{1 \cdot 3 \cdot 5}}{{2 \cdot 4 \cdot 6}}\frac{{{x^7}}}{7} +  \cdots $$

We have

$$\int\limits_0^1 {\left\{ {\frac{{dx}}{{\sqrt {1 - {x^2}} }}\int {\frac{{dx}}{{\sqrt {1 - {x^2}} }}} } \right\}}  = \int\limits_0^1 {\left\{ {x + \frac{1}{2}\frac{{{x^3}}}{3}\frac{{dx}}{{\sqrt {1 - {x^2}} }} + \frac{{1 \cdot 3}}{{2 \cdot 4}}\frac{{{x^5}}}{5}\frac{{dx}}{{\sqrt {1 - {x^2}} }} +  \cdots } \right\}} $$

But

$$\int\limits_0^1 {\frac{{{x^{2n + 1}}}}{{\sqrt {1 - {x^2}} }}dx}  = \frac{{2n}}{{2n + 1}}\int\limits_0^1 {\frac{{{x^{2n - 1}}}}{{\sqrt {1 - {x^2}} }}dx} $$

which yields

$$\int\limits_0^1 {\frac{{{x^{2n + 1}}}}{{\sqrt {1 - {x^2}} }}dx}  = \frac{{\left( {2n} \right)!!}}{{\left( {2n + 1} \right)!!}}$$

since all powers are odd.

This ultimately produces:

$$\frac{{{\pi ^2}}}{8} = 1 + \frac{1}{2}\frac{1}{3}\left( {\frac{2}{3}} \right) + \frac{{1 \cdot 3}}{{2 \cdot 4}}\frac{1}{5}\left( {\frac{{2 \cdot 4}}{{3 \cdot 5}}} \right) + \frac{{1 \cdot 3 \cdot 5}}{{2 \cdot 4 \cdot 6}}\frac{1}{7}\left( {\frac{{2 \cdot 4 \cdot 6}}{{3 \cdot 5 \cdot 7}}} \right) \cdots $$

$$\frac{{{\pi ^2}}}{8} = 1 + \frac{1}{{{3^2}}} + \frac{1}{{{5^2}}} + \frac{1}{{{7^2}}} +  \cdots $$

Let

$$1 + \frac{1}{{{2^2}}} + \frac{1}{{{3^2}}} + \frac{1}{{{4^2}}} +  \cdots  = \omega $$

Then

$$\frac{1}{{{2^2}}} + \frac{1}{{{4^2}}} + \frac{1}{{{6^2}}} + \frac{1}{{{8^2}}} +  \cdots  = \frac{\omega }{4}$$

Which means

$$\frac{\omega }{4} + \frac{{{\pi ^2}}}{8} = \omega $$

or

$$\omega  = \frac{{{\pi ^2}}}{6}$$
AnswerKenntnis:
Note that
$$ \frac{\pi^2}{\sin^2\pi z}=\sum_{n=-\infty}^{\infty}\frac{1}{(z-n)^2} $$
from complex analysis and that both sides are analytic everywhere except $n=0,\pm 1,\pm 2,\cdots$. Then one can obtain
$$ \frac{\pi^2}{\sin^2\pi z}-\frac{1}{z^2}=\sum_{n=1}^{\infty}\frac{1}{(z-n)^2}+\sum_{n=1}^{\infty}\frac{1}{(z+n)^2}. $$
Now the right hand side is analytic at $z=0$ and hence 
$$\lim_{z\to 0}\left(\frac{\pi^2}{\sin^2\pi z}-\frac{1}{z^2}\right)=2\sum_{n=1}^{\infty}\frac{1}{n^2}.$$
Note 
$$\lim_{z\to 0}\left(\frac{\pi^2}{\sin^2\pi z}-\frac{1}{z^2}\right)=\frac{\pi^2}{3}.$$
Thus
$$\sum_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}.$$
AnswerKenntnis:
In response to a request here: Compute $\oint z^{-2k} \cot (\pi z) dz$ where the integral is taken around a square of side $2N+1$. Routine estimates show that the integral goes to $0$ as $N \to \infty$.

Now, let's compute the integral by residues. At $z=0$, the residue is $\pi^{2k-1} q$, where $q$ is some rational number coming from the power series for $\cot$. For example, if $k=1$, then we get $- \pi/3$. 

At $m \pi$, for $m \neq 0$, the residue is $z^{-2k} \pi^{-1}$. So
$$\pi^{-1} \lim_{N \to \infty} \sum_{-N \leq m \leq N\ m \neq 0} m^{-2k} + \pi^{2k-1} q=0$$
or
$$\sum_{m=1}^{\infty} m^{-2k} = -\pi^{2k} q/2$$
as desired. In particular, $\sum m^{-2} = - (\pi^2/3)/2 = \pi^2/6$.

Common variants: We can replace $\cot$ with $\tan$, with $1/(e^{2 \pi i z}-1)$, or with similar formulas. 

This is reminiscent of Qiaochu's proof but, rather than actually establishing the relation $\pi^{-1} \cot(\pi z) = \sum (z-n)^{-1}$, one simply establishes that both sides contribute the same residues to a certain integral.
AnswerKenntnis:
Another variation. We make use of the following identity (proved at the bottom of this note):

$$\sum_{k=1}^n \cot^2 \left( \frac {2k-1}{2n} \frac{\pi}{2} \right) = 2n^2 ΓÇô n. \quad (1)$$

Now $1/\theta > \cot \theta > 1/\theta - \theta/3 > 0$ for $0< \theta< \pi/2 < \sqrt{3}$ and so
$$ 1/\theta^2 ΓÇô 2/3 < \cot^2 \theta < 1/\theta^2. \quad (2)$$

With $\theta_k = (2k-1)\pi/4n,$ summing the inequalities $(2)$ from $k=1$ to $n$ we obtain   

$$2n^2 ΓÇô n < \sum_{k=1}^n \left( \frac{2n}{2k-1}\frac{2}{\pi} \right)^2 < 2n^2 ΓÇô n + 2n/3.$$

Hence

$$\frac{\pi^2}{16}\frac{2n^2-n}{n^2} < \sum_{k=1}^n \frac{1}{(2k-1)^2} <
\frac{\pi^2}{16}\frac{2n^2-n/3}{n^2}.$$

Taking the limit as $n \rightarrow \infty$ we obtain

$$  \sum_{k=1}^\infty \frac{1}{(2k-1)^2} = \frac{\pi^2}{8},$$

from which the result for $\sum_{k=1}^\infty 1/k^2$ follows easily.

To prove $(1)$ we note that

$$ \cos 2n\theta = \text{Re}(\cos\theta + i \sin\theta)^{2n} = 
\sum_{k=0}^n (-1)^k {2n \choose 2k}\cos^{2n-2k}\theta\sin^{2k}\theta.$$

Therefore

$$\frac{\cos 2n\theta}{\sin^{2n}\theta} =  \sum_{k=0}^n (-1)^k {2n \choose 2k}\cot^{2n-2k}\theta.$$

And so setting $x = \cot^2\theta$ we note that

$$f(x) = \sum_{k=0}^n (-1)^k {2n \choose 2k}x^{n-k}$$

has roots $x_j = \cot^2 (2j-1)\pi/4n,$ for $j=1,2,\ldots,n,$ from which $(1)$ follows since
${2n \choose 2n-2} = 2n^2-n.$
AnswerKenntnis:
At risk of contravening group etiquette w.r.t. old questions, I'm going to take this opportunity to post my own version. I don't see it in a transparent form in any of the other posts or in Robin Chapman's article, so I invite anyone to point out the correspondence if it's there. I like this argument because it's physical and can be followed without mathematical formalism.

We start by assuming the well-known series for $\pi/4$ in alternating odd fractions. We can recognize it as the sum of the Fourier series of the square wave, evaluated at the origin:

$\cos(x) - \cos(3x)/3 + \cos(5x)/5 ...$

It is easily argued on physical grounds that this adds up to a square wave; and that the height of the wave is pi/4 follows from the alternating sequence already mentioned. Now we are going to interpret this wave as an electric current flowing through a resistor. There are two ways of calculating the power and they must agree. First, we can just take square of the amplitude; in the case of this square wave, this is obviously a constant and it is just $\,\,\pi^2/16$. The other way is to add up the power of the sinusoidal components. These are the squares of the individual amplitudes:

$1 + 1/9 + 1/25 .... = (?)\, \pi^2/16       \,\,??$

No, not quite; I've been a little sloppy and neglected to mention that when calculating the power of a sine wave, you use its RMS amplitude and not its peak amplitude. This introduces a factor of two; so in fact the series as written adds up to $\,\pi^2/8.$ This isn't quite what we want; remember we've just added up the odd fractions. But the even fractions contribute in a rather picturesque way; it's easy to group them by powers of two into a geometric sum leading to the desired result of $\,\,\pi^2/6.$
AnswerKenntnis:
A short way to get the sum is to use Fourier's expansion of $x^2$ in $x\in(-\pi,\pi)$. Recall that Fourier's expansion of $f(x)$ is
$$ \tilde{f}(x)=\frac{1}{2}a_0+\sum_{n=1}^\infty(a_n\cos nx+b_n\sin nx), x\in(-\pi,\pi)$$ 
where
$$ a_0=\frac{2}{\pi}\int_{-\pi}^{\pi}f(x)\;dx, a_n=\frac{2}{\pi}\int_{-\pi}^{\pi}f(x)\cos nx\; dx, b_n=\frac{2}{\pi}\int_{-\pi}^{\pi}f(x)\sin nx\; dx, n=1,2,3,\cdots $$
and 
$$ \tilde{f}(x)=\frac{f(x-0)+f(x+0)}{2}. $$
Easy calculation shows
$$ x^2=\frac{\pi^2}{3}+4\sum_{n=1}^\infty(-1)^n\frac{\cos nx}{n^2}, x\in[-\pi,\pi]. $$
Letting $x=\pi$ in both sides gives
$$ \sum_{n=1}^\infty\frac{1}{n^2}=\frac{\pi^2}{6}.$$

Another way to get the sum is to use Parseval's Identity for Fourier's expansion of $x$ in $(-\pi,\pi)$. Recall that Parseval's Identity is
$$ \int_{-\pi}^{\pi}|f(x)|^2dx=\frac{1}{2}a_0^2+\sum_{n=1}^\infty(a_n^2+b_n^2). $$
Note
$$ x=2\sum_{n=1}^\infty(-1)^{n+1}\frac{\sin nx}{n}, x\in(-\pi,\pi). $$
Using Parseval's Identity gives
$$ 4\sum_{n=1}^\infty\frac{1}{n^2}=\int_{-\pi}^{\pi}|x|^2dx$$
or 
$$ \sum_{n=1}^\infty\frac{1}{n^2}=\frac{\pi^2}{6}.$$
AnswerKenntnis:
This method apparently was used by Tom Apostol in $1983$. I will outline the main ideas of the proof, the details can be found in here or this presentation (page $27$)

Consider 

$$\begin{align}
\int_{0}^{1} \int_{0}^{1} \frac{1}{1 - xy} dy dx &= \int_{0}^{1} \int_{0}^{1} \sum_{n \geq 0} (xy)^n dy dx \\ 
&= \sum_{n \geq 0} \int_{0}^{1} \int_{0}^{1} x^n y^n dy dx \\
&= \sum_{n \geq 1} \frac{1}{n^2} \\
\end{align}$$

You can verify that the left hand side is indeed $\frac{\pi^2}{6}$ by letting $x = u - v$ and $y = v + u.$
AnswerKenntnis:
I like this one: 

Let $f\in Lip(S^{1})$, where $Lip(S^{1})$ is the space of Lipschitz functions on $S^{1}$. So its well defined the number for $k\in \mathbb{Z}$ (called Fourier series of $f$) $$\hat{f}(k)=\frac{1}{2\pi}\int \hat{f}(\theta)e^{-ik\theta}d\theta.$$

By the inversion formula, we have $$f(\theta)=\sum_{k\in\mathbb{Z}}\hat{f}(k)e^{ik\theta}.$$

Now take $f(\theta)=|\theta|$, $\theta\in [-\pi,\pi]$. Note that $f\in Lip(S^{1})$

We have $$
\hat{f}(k) = \left\{ \begin{array}{rl}
 \frac{\pi}{2} &\mbox{ if $k=0$} \\
  0 &\mbox{ if $|k|\neq 0$ and $|k|$ is even} \\ -\frac{2}{k^{2}\pi} &\mbox{if $|k|\neq 0$ and $|k|$ is odd}
       \end{array} \right.
$$

Using the inversion formula, we have on $\theta=0$ that $$0=\sum_{k\in\mathbb{Z}}\hat{f}(k).$$

Then,

\begin{eqnarray}
 0 &=& \frac{\pi}{2}-\sum_{k\in\mathbb{Z}\ |k|\ odd}\frac{2}{k^{2}\pi}     \nonumber \\
   &=& \frac{\pi}{2}-\sum_{k\in\mathbb{N}\ |k|\ odd}\frac{4}{k^{2}\pi}      \nonumber \\
\end{eqnarray}

This implies $$\sum_{k\in\mathbb{N}\ |k|\ odd}\frac{1}{k^{2}} =\frac{\pi^{2}}{8}$$

If we multiply the last equation by $\frac{1}{2^{2n}}$ with $n=0,1,2,...$ ,we get $$\sum_{k\in\mathbb{N}\ |k|\ odd}\frac{1}{(2^{n}k)^{2}} =\frac{\pi^{2}}{2^{2n}8}$$

Now $$\sum_{n=0,1,...}(\sum_{k\in\mathbb{N}\ |k|\ odd}\frac{1}{(2^{n}k)^{2}}) =\sum_{n=0,1,...}\frac{\pi^{2}}{2^{2n}8}$$

The sum in the left is equal to: $\sum_{k\in\mathbb{N}}\frac{1}{k^{2}}$

The sum in the right is equal to :$\frac{\pi^{2}}{6}$

So we conclude: $$\sum_{k\in\mathbb{N}}\frac{1}{k^{2}}=\frac{\pi^{2}}{6}$$

Note: This is problem 9, Page 208 from the boof of Michael Eugene Taylor - Partial Differential Equation  Volume 1.
AnswerKenntnis:
Just as a curiosity, a one-line-real-analytic-proof I found by combining different ideas from this thread and this question:

$$\zeta(2)=\frac{4}{3}\sum_{n=0}^{+\infty}\frac{1}{(2n+1)^2}=\frac{4}{3}\int_{0}^{1}\frac{\log y}{y^2-1}dy=\frac{2}{3}\int_{0}^{1}\frac{1}{y^2-1}\left[\log\left(\frac{1+x^2 y^2}{1+x^2}\right)\right]_{x=0}^{+\infty}dy=\frac{4}{3}\int_{0}^{1}\int_{0}^{+\infty}\frac{x}{(1+x^2)(1+x^2 y^2)}dx\,dy=\frac{4}{3}\int_{0}^{1}\int_{0}^{+\infty}\frac{dx\, dz}{(1+x^2)(1+z^2)}=\frac{4}{3}\cdot\frac{\pi}{4}\cdot\frac{\pi}{2}=\frac{\pi^2}{6}.$$
AnswerKenntnis:
Theorem:
Let $\lbrace a_n\rbrace$ be a nonincreasing sequence of positive numbers such that $\sum a_n^2$ converges. Then both series
$$s:=\sum_{n=0}^\infty(-1)^na_n,\,\delta_k:=\sum_{n=0}^\infty a_na_{n+k},\,k\in\mathbb N $$
converge. Morevere $\Delta:=\sum_{k=1}^\infty(-1)^{k-1}\delta_k$ also converges, and we have the formula
$$\sum_{n=0}^\infty a_n^2=s^2+2\Delta.$$
Proof: Knopp. Konrad, Theory and Application of Infinite Series, page 323.

If we let $a_n=\frac1{2n+1}$ in this theorem, then we have
$$s=\sum_{n=0}^\infty(-1)^n\frac1{2n+1}=\frac\pi 4$$
$$\delta_k=\sum_{n=0}^\infty\frac1{(2n+1)(2n+2k+1)}=\frac1{2k}\sum_{n=0}^\infty\left(\frac1{2n+1}-\frac1{2n+2k+1}\right)=\frac{1}{2k}\left(1+\frac1 3+...+\frac1 {2k-1}\right)$$
Hence,
$$\sum_{n=0}^\infty\frac1{(2n+1)^2}=\left(\frac\pi 4\right)^2+\sum_{k=1}^\infty\frac{(-1)^{k-1}}{k}\left(1+\frac1 3+...+\frac1 {2k-1}\right)=\frac{\pi^2}{16}+\frac{\pi^2}{16}=\frac{\pi^2}{8}$$
and now
$$\zeta(2)=\frac4 3\sum_{n=0}^\infty\frac1{(2n+1)^2}=\frac{\pi^2}6.$$
AnswerKenntnis:
See evaluations fo Riemann Zeta Function $\zeta(2)=\sum_{n=1}^\infty\frac{1}{n^2}$ in mathworld.wolfram.com and a solution by  in D. P. Giesy in Mathematics Magazine: 


  D. P. Giesy, Still another elementary proof that $\sum_{n=1}^\infty \frac{1}{n^2}=\frac{\pi^2}{6}$, Math. Mag. 45 (1972) 148ΓÇô149.


Unfortunately I did not get a link to this article. But there is a link to a note from Robin Chapman seems to me a variation of proof's Giesy.
AnswerKenntnis:
Consider the function $\pi \cot(\pi z)$ which has poles at $z=\pm n$ where n is an integer. Using the L'hopital rule you can see that the residue at these poles is 1. 

Now consider the integral $\int_{\gamma_N} \frac{\pi\cot(\pi z)}{z^2} dz$ where the contour $\gamma_N$ is the rectangle with corners given by ┬▒(N + 1/2) ┬▒ i(N + 1/2) so that the contour avoids the poles of $\cot(\pi z)$. The integral is bouond in the following way:
$\int_{\gamma_N} |\frac{\pi\cot(\pi z)}{z^2} |dz\le Max |(\frac{\pi\cot(\pi z)}{z^2}) | Length(\gamma_N)$. It can easily be shown that on the contour $\gamma_N$ that $\pi \cot(\pi z)< M$ where M is some constant. Then we have  

$\int_{\gamma_N} |\frac{\pi\cot(\pi z)}{z^2} |dz\le M Max |\frac{1}{z^2} | Length(\gamma_N) = (8N+4) \frac{M}{\sqrt{2(1/2+N)^2}^2}$ 

where (8N+4) is the lenght of the contour and $\sqrt{2(1/2+N)^2}$ is half the diagonal of $\gamma_N$. In the limit that N goes to infinity the integral is bound by 0 so we have 
$\int_{\gamma_N} \frac{\pi\cot(\pi z)}{z^2} dz =0$

by the cauchy residue theorem we have  2╧ÇiRes(z = 0) + 2╧Çi$\sum$Residues(z$\ne$ 0) = 0. At z=0 we have Res(z=0)=$-\frac{\pi^2}{3}$, and $Res (z=n)=\frac{1}{n^2}$ so we have 

$2\pi iRes(z = 0) + 2\pi i\sum Residues(z\ne 0) = -\frac{\pi^2}{3}+2\sum_{1}^{\infty} \frac{1}{n^2} =0$

Where the 2 in front of the residue at n is because they occur twice at +/- n.

We now have the desired result $\sum_{1}^{\infty} \frac{1}{n^2}=\frac{\pi^2}{6}$.
QuestionKenntnis:
Unusual 5th grade problem, how to solve it
qn_description:
Find a positive integer solution $(x,y,z,a,b)$ for which

$$\frac{1}{x}+ \frac{1}{y} + \frac{1}{z} + \frac{1}{a} + \frac{1}{b} = 1\;.$$

Is your answer the only solution? If so, show why. 

I was surprised that a teacher would assign this kind of problem to a 5th grade child. (I'm a college student tutor) This girl goes to a private school in a wealthy neighborhood.

Please avoid the trivial $x=y=z=a=b=5$. Try looking for a solution where $ x \neq y \neq z \neq a \neq b$ or if not, look for one where one variable equals to another, but explain your reasoning. The girl was covering "unit fractions" in her class.
AnswersKenntnis
AnswerKenntnis:
The perfect number $28=1+2+4+7+14$ provides a solution:

$$\frac1{28}+\frac1{14}+\frac17+\frac14+\frac12=\frac{1+2+4+7+14}{28}=1\;.$$

If theyΓÇÖve been doing unit (or ΓÇÿEgyptianΓÇÖ) fractions, IΓÇÖd expect some to see that since $\frac16+\frac13=\frac12$, $$\frac16+\frac16+\frac16+\frac16+\frac13=1$$ is a solution, though not a much more interesting one than the trivial solution. The choice of letters might well suggest the solution

$$\frac16+\frac16+\frac16+\frac14+\frac14\;.$$

A little playing around would show that $\frac14+\frac15=\frac9{20}$, which differs from $\frac12$ by just $\frac1{20}$; that yields the solution

$$\frac1{20}+\frac15+\frac14+\frac14+\frac14\;.$$

If I were the teacher, IΓÇÖd hope that some kids would realize that since the average of the fractions is $\frac15$, in any non-trivial solution at least one denominator must be less than $5$, and at least one must be greater than $5$. Say that $x\le y\le z\le a\le b$. Clearly $x\ge 2$, so letΓÇÖs try $x=2$. Then we need to solve 

$$\frac1y+\frac1z+\frac1a+\frac1b=\frac12\;.$$

Now $y\ge 3$. Suppose that $y=3$; then $$\frac1z+\frac1a+\frac1b=\frac16\;.$$

Now $1,2$, and $3$ all divide $36$, and $\frac16=\frac6{36}$, so we can write

$$\frac1{36}+\frac1{18}+\frac1{12}=\frac{1+2+3}{36}=\frac6{36}=\frac16\;,$$

and we get another ΓÇÿniceΓÇÖ solution,

$$\frac12+\frac13+\frac1{12}+\frac1{18}+\frac1{36}\;.$$
AnswerKenntnis:
You could connect it to geometry. Cut the square into equally-sized pieces, then take some of those pieces and cut them into even-smaller ones until you get five pieces. e.g.





After that, you could try some different-sized pieces and have a good chance of getting something like this:
AnswerKenntnis:
This solution may be too advanced for a fifth-grader, but you can do this problem algorithmically - simply by searching all the possible fractions.

The gist of it is to use a greedy algorithm - start with the biggest fraction, and continue iterating small fractions until you can't anymore. For example, $\displaystyle \frac 1 2 + \frac 1 3 + \frac 1 7 + \frac 1 {43} + \frac 1 {1806}$ would be the first one you find. The next one would be $\displaystyle \frac 1 2 + \frac 1 3 + \frac 1 7 + \frac 1 {44} + \frac 1 {924}$, then $\displaystyle \frac 1 2 + \frac 1 3 + \frac 1 7 + \frac 1 {45} + \frac 1 {630}$, and so on.

Here's the algorithm in more detail:


For the first number, start with $\displaystyle \frac 12$, eventually working your way down to $\displaystyle \frac15$ (which is the smallest that the largest fraction can be, so you can stop there).
Subtract this fraction from 1, and use the remaining part to determine what the next few numbers will iterate through.
For each of the subsequent fractions, start with the largest unit fraction smaller than both the "remaining part" that's left and the fraction before it, and work down until you reach the smallest unit fraction larger than $\displaystyle \frac1n$ the "remaining part", where your fraction is the $n$th last fraction, and do the same as above, subtracting the unit fraction from the "remaining part" for the next fraction to use.
Once you have four fractions, if the "remaining part" for the last fraction can be expressed as a unit fraction, you have a solution. Otherwise, you don't, and continue onwards.


This algorithm will eventually return all the possible unit fraction combinations, starting from $\displaystyle \frac 1 2 + \frac 1 3 + \frac 1 7 + \frac 1 {43} + \frac 1 {1806}$ and ending with $\displaystyle \frac 15 + \frac 15 + \frac 15 + \frac 15 + \frac 15$.



http://joezeng.com/code/fractions/fractions.html $\leftarrow$ This is a list of all of the fractions, dynamically generated using some recursive Javascript that implements the algorithm above. You can view the source code here, which I have MIT-licensed for demonstration purposes.

According to the generator, there are a total of 147 solutions for 5 fractions, and the "minimum unique solution" such that all denominators are distinct and their sum is the lowest possible is $\displaystyle \frac 13 + \frac 14 + \frac 15 + \frac 16 + \frac 1 {20}$. There is another "minimum unique solution", such that the largest denominator is the lowest, which is $\displaystyle \frac 12 + \frac 14 + \frac 1{10} + \frac 1{12} + \frac 1{15}$.

You can also use the generator to generate fraction lists of arbitrary sizes by modifying the initial function call to use 6 levels (or 2, 3, or 4) instead of 5, as well as generate Egyptian fraction expansions for arbitrary fractions (by modifying the first two terms 1, 1 to be other things).
AnswerKenntnis:
Yet another method would be to start with $${1\over2}+{1\over3}+{1\over 6}=1$$
Divide by two and add $1\over 2$; this yields $${1\over 2}+{1\over 4}+{1\over 6}+{1\over 12}=1$$
Again, divide by two and add $1\over 2$; this yields $${1\over 2}+{1\over 4}+{1\over8}+{1\over 12}+{1\over 24}=1$$
AnswerKenntnis:
The number of solutions of $$1={1\over x_1}+{1\over x_2}+\cdots+{1\over x_n},\ \ \ 0\lt x_1\le x_2\le\cdots\le x_n$$ is tabulated, as a function of $n$, at http://oeis.org/A002966 but only a few terms are given: $1, 1, 3, 14, 147, 3462, 294314, 159330691$. I don't know whether the number of solutions with all denominators distinct has been tabulated at that site.
AnswerKenntnis:
There are many ways to obtain many solutions. Here is one systematic way to obtain solutions.

First look at a class of solutions such that $x \leq y \leq z \leq a \leq b \leq 10$ (other solution can be obtained as permutation of these).

This implies that $2 \leq x \leq 5$. So now start with $x=2$. This now means that $3 \leq y \leq 8$. Choose $y=3$. This now means that $7 \leq z \leq 10$. You will quickly find that no solution exists such that $x \leq y \leq z \leq a \leq b \leq 10$. Then choose $y=4$. Again you will find that no solution exists such that $x \leq y \leq z \leq a \leq b \leq 10$.

Going through this you will find that if we want $x=2$, and $x \leq y \leq z \leq a \leq b \leq 10$, then $$[2, 5, 10, 10, 10]; 
[2, 6, 9, 9, 9]; 
[2, 8, 8, 8, 8]$$ are the only solutions with $x=2$ and $x \leq y \leq z \leq a \leq b \leq 10$.

Now set $x=3$ and get bounds for the remaining variables to see that $$ 
[3, 3, 9, 9, 9]; 
[3, 4, 6, 8, 8]; 
[3, 5, 5, 6, 10]; 
[3, 6, 6, 6, 6]; $$ are the only solutions with $x=3$ and $x \leq y \leq z \leq a \leq b \leq 10$.

Here are the solutions such that $x \leq y \leq z \leq a \leq b \leq 10$
$$[x,y,z,a,b] \in \{[2, 5, 10, 10, 10]; 
[2, 6, 9, 9, 9]; 
[2, 8, 8, 8, 8]; 
[3, 3, 9, 9, 9]; 
[3, 4, 6, 8, 8]; 
[3, 5, 5, 6, 10];\\ 
[3, 6, 6, 6, 6]; 
[4, 4, 4, 8, 8]; 
[4, 4, 5, 5, 10]; 
[4, 4, 6, 6, 6]; 
[5, 5, 5, 5, 5]; \}
$$

There are $114$ distinct solutions i.e. without permutations such that
$$x \leq y \leq z \leq a \leq b \leq 100$$ and can be found here.
AnswerKenntnis:
A simple C++ code to find the a-b-c-x-y pairs for the first positive 100 integers.

const double MAX_NUM = 100.0;
const double EPSILON = 0.0000001;
double Sum;
for (double a=1; a<=MAX_NUM; a++)
{
    for (double b=1; b<=a; b++)
    {
        for (double c=1; c<=b; c++)
        {
            for (double x=1; x<=c; x++)
            {
                for (double y=1; y<=x; y++)
                {
                    Sum = 1.0/a + 1.0/b + 1.0/c + 1.0/x + 1.0/y;
                    if (abs(Sum - 1.0) < EPSILON)
                    {
                        std::cout << a << "\t" << b << "\t" << c
                            << "\t" << x << "\t" << y << std::endl;
                    }
                }
            }
        }
    }
}


Its output is:

5       5       5       5       5
6       6       6       4       4
6       6       6       6       3
8       8       4       4       4
8       8       6       4       3
8       8       8       8       2
9       9       9       3       3
9       9       9       6       2
10      5       5       4       4
10      6       5       5       3
10      10      10      5       2
12      6       4       4       4
12      6       6       4       3
12      8       8       3       3
12      8       8       6       2
12      12      4       4       3
12      12      6       3       3
12      12      6       6       2
12      12      12      4       2
14      7       7       7       2
15      5       5       5       3
15      10      4       4       3
15      10      6       3       3
15      10      6       6       2
15      12      10      4       2
15      15      5       3       3
15      15      6       5       2
16      16      8       4       2
18      9       4       4       3
18      9       6       3       3
18      9       6       6       2
18      12      9       4       2
18      18      18      3       2
20      5       4       4       4
20      6       5       4       3
20      8       8       5       2
20      10      10      4       2
20      12      5       3       3
20      12      6       5       2
20      20      5       5       2
20      20      15      3       2
21      7       7       3       3
21      7       7       6       2
21      21      14      3       2
24      8       4       4       3
24      8       6       3       3
24      8       6       6       2
24      12      8       4       2
24      16      16      3       2
24      24      4       3       3
24      24      6       4       2
24      24      12      3       2
28      14      7       4       2
28      21      4       3       3
28      21      6       4       2
28      21      12      3       2
30      10      5       3       3
30      10      6       5       2
30      15      5       5       2
30      15      15      3       2
30      20      4       3       3
30      20      6       4       2
30      20      12      3       2
30      30      10      3       2
33      22      11      3       2
35      14      5       5       2
35      15      14      3       2
36      9       9       4       2
36      18      4       3       3
36      18      6       4       2
36      18      12      3       2
36      36      9       3       2
40      10      8       4       2
40      24      10      3       2
40      40      5       4       2
42      7       4       4       3
42      7       6       3       3
42      7       6       6       2
42      12      7       4       2
42      14      14      3       2
45      9       5       3       3
45      9       6       5       2
45      30      9       3       2
45      36      5       4       2
48      16      4       3       3
48      16      6       4       2
48      16      12      3       2
48      48      8       3       2
54      27      9       3       2
56      42      8       3       2
60      5       5       4       3
60      12      5       5       2
60      15      4       3       3
60      15      6       4       2
60      15      12      3       2
60      20      10      3       2
60      30      5       4       2
60      40      8       3       2
70      7       7       5       2
70      28      5       4       2
72      9       8       4       2
72      24      9       3       2
72      36      8       3       2
78      13      13      3       2
84      14      4       3       3
84      14      6       4       2
84      14      12      3       2
84      84      7       3       2
88      33      8       3       2
90      18      10      3       2
91      78      7       3       2
96      32      8       3       2
99      22      9       3       2
100     25      5       4       2
AnswerKenntnis:
First, without context, there is no way to tell if the problem is suitable for a given grade. It doesn't seem likely, but then maybe they did some work on the Egyptian representation of fractions, which is close enough that they might think of it. For me, that was my first thought, and I then came to:

$$\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\frac{1}{16}+\frac{1}{16}=1$$

Even with that hint, the question about uniqueness is not trivial. You can play with replacing only part of the expression, for example:

$$\frac{1}{8}+\frac{1}{16} = \frac{1}{6}+\frac{1}{48}$$

which yields:

$$\frac{1}{2}+\frac{1}{4}+\frac{1}{6}+\frac{1}{16}+\frac{1}{48}=1$$

but I don't see how 5th grade student can do that other than trial and error.

Other than that, I don't see what ΓÇ£typical fith-gradeΓÇ¥ reasoning can be used. Perfect numbers seem out of the question.
AnswerKenntnis:
My first reaction to the question was $\frac12+\frac14+\frac18+\frac1{16}+\frac1{16}$. sorry, but it seems too natural to need explaining, but also not satisfactory because not all denominators are different.

Then other replies remind me of the "5th grade level" equation $1 = \frac12 + \frac13 + \frac16$.

Well, then the pupil will probably try to use the same equation to divide one of the three fractions and realize that the only one that will provide different denominators is the $\frac16$.

That is $1/6 = \frac{1/6}2 + \frac{1/6}3 + \frac{1/6}6 = \frac1{12} + \frac1{18} + \frac1{36}$

Thus building the solution $1 = \frac12 + \frac13 + \frac1{12} + \frac1{18} + \frac1{36}$



Thinking further about it, I assume that anybody confronted with fractions will easily agree with the simple statement: $1 = \frac1n + \frac{n-1}n$. 

Dividing the equation by $n-1$ and arranging differently will produce $\frac1{n-1} = \frac1n + \frac1{n(n-1)}$, of which $\frac12 = \frac13 + \frac16$ is a special case.

once you have a couple of these equations spelled out, like:
$$\frac12 = \frac13 + \frac16 $$
$$\frac13 = \frac14 + \frac1{12} $$
$$\frac14 = \frac15 + \frac1{20} $$
$$\frac15 = \frac16 + \frac1{30} $$

it should be a kid's game to expand
$$1 = \frac12 + \frac14 + \frac14$$
into a solution of the given problem.

you might also want to include the case for $n=2$:
$$1 = \frac12 + \frac12$$
and start with the expansion of $1$.
AnswerKenntnis:
Please avoid the trivial x=y=z=a=b=5. Try looking for a solution where xΓëáyΓëázΓëáaΓëáb or if not, look for one where one variable equals to another, but explain your reasoning. The girl was covering "unit fractions" in her class.


Was this a requirement in the homework problem? The easiest way to prove that there is more than one solution to a problem is to find more than one solution to the problem, even if the additional solution is trivial. A starting point of any arbitrary number of unit fractions that sum to 1 and that also can be combined into other unit fractions is a very valid starting point.

Case in point: I would propose that this be solved at the fifth-grade level by splitting fractions, with a little special knowledge to produce unique values. 1 = 1/2 + 1/2. Now we need to come up with three more fractions and differentiate the two we have. We do this by continuing to split, with some clever knowledge of prime factors.

For instance, if a number in the denominator is divisible by both 2 and 3, then you can combine two or three of that unit fraction, and when reducing to lowest terms you will get a new unit fraction. 6 is the simplest example; 1/6 + 1/6 = 1/3 and 1/6 + 1/6 + 1/6 = 1/2. This is useful to us: 1/6 + 1/3 = 1/2, so 1/6 + 1/3 + 1/2 = 1. Now we just need two more unique fractions. Well, let's split up the largest fraction, 1/2, into more pieces than we tried before. If we divide it into 12 units, each of those will be 1/24 of the whole. 2/24 = 1/12, 3/24 = 1/8, and 6/24 = 1/4. We can also combine 4 and 8 of these, but those two produce the fractions 1/6 and 1/3 which we already have. Now, by serendipity (or not), 1 + 2 + 3 + 6 = 12. That would give us 1/24 + 1/12 + 1/8 + 1/4 = 1/2. That's four of the five we need, and 1/2 (the remaining fraction of the whole) isn't spoken for yet and can be produced by recombining 1/3 and 1/6, so 1/2 + 1/4 + 1/8 + 1/12 + 1/24 = 1, and thus {2,4,8,12,24} is a valid solution.

This generalizes into the following statement: find five numbers, j,k,m,n,and p, that are all factors of an arbitrary z, and that sum to z. Then 1/x=j/z, 1/y=k/z, and so on.

A good z-value to try in this case is 100, which turns the fractions into simple integer percentages. 100 has the following prime factorization: $2^2*5^2$. Each unique combination of those factors, plus the universal factor 1, is a factor of 100 and thus a possible value for the set of 5 we need. There are 8 factors of 100, not including 100; 1, 2, 4, 5, 10, 20, 25, and 50. We can now apply a variation of the value-splitting; find numbers in this set that will sum to other numbers in the set. 100=50+50. 50=25+25. 25=20+5, and 5=4+1. Putting these identities together, 1+4+20+25+50 = 100. Dividing everything by 100 and finding lowest terms gives 1/100+1/25+1/5+1/4+1/2 = 1, so {2,4,5,25,100} is another valid solution.

Pretty much any number with 4 or more factors other than 1 and itself is a candidate z-value. It helps to have a few extra factors laying around, as was shown from the example above; a number with only 4 unique factors, say 20 (2, 4, 5, 10), is unlikely to have those factors all sum to the original number as well (in this case the sum of those four factors is 21; close but no cigar). It also helps if the prime factorization of the number (a graspable concept for a fifth grader, with multiplication, division and primes under her belt) includes more than one prime factor; this allows you to do the "divide by one, then multiply by the other" trick to produce unique denominators.
AnswerKenntnis:
Surprised that no-one proposed 1,-1,1,-1,1 and a whole bunch of variations around it.
AnswerKenntnis:
You can try taking x,y,z,a each with value larger than 5 which may or may not be equal. Now find b such a way that the given relation is satisfied. But this question is way beyond fifth grade student(My opinion).
QuestionKenntnis:
What's an intuitive way to think about the determinant?
qn_description:
In my linear algebra class, we just talked about determinants. So far IΓÇÖve been understanding the material okay, but now IΓÇÖm very confused. I get that when the determinant is zero, the matrix doesnΓÇÖt have an inverse. I can find the determinant of a $2\times 2$ matrix by the formula. Our teacher showed us how to compute the determinant of an $N \times N$ matrix by breaking it up into the determinants of smaller matrices, and apparently there is a way by summing over a bunch of permutations. But the notation is really hard for me and I donΓÇÖt really know whatΓÇÖs going on with them anymore. Can someone help me figure out what a determinant is, intuitively, and how all those definitions of it are related?
AnswersKenntnis
AnswerKenntnis:
Your trouble with determinants is pretty common. TheyΓÇÖre a hard thing to teach well, too, for two main reasons that I can see: the formulas you learn for computing them are messy and complicated, and thereΓÇÖs no ΓÇ£naturalΓÇ¥ way to interpret the value of the determinant, the way itΓÇÖs easy to interpret the derivatives you do in calculus at first as the slope of the tangent line. ItΓÇÖs hard to believe things like the invertibility condition youΓÇÖve stated when itΓÇÖs not even clear what the numbers mean and where they come from.

Rather than show that the many usual definitions are all the same by comparing them to each other, IΓÇÖm going to state some general properties of the determinant that I claim are enough to specify uniquely what number you should get when you put in a given matrix. Then itΓÇÖs not too bad to check that all of the definitions for determinant that youΓÇÖve seen satisfy those properties IΓÇÖll state.

The first thing to think about if you want an ΓÇ£abstractΓÇ¥ definition of the determinant to unify all those others is that itΓÇÖs not an array of numbers with bars on the side. What weΓÇÖre really looking for is a function that takes N vectors (the N columns of the matrix) and returns a number. LetΓÇÖs assume weΓÇÖre working with real numbers for now.

Remember how those operations you mentioned change the value of the determinant? 

(1) Switching two rows or columns changes the sign. 

(2) Multiplying one row by a constant multiplies the whole determinant by that constant. 

(3) The general fact that number two draws from: the determinant is linear in each row. That is, if you think of it as a function $\det: \mathbb{R}^{n^2} \rightarrow \mathbb{R}$, then $ \det(a \vec{v_1} +b \vec{w_1}, \vec{v_2},...,\vec{v_n}) = a \det(\vec{v_1},\vec{v_2},...,\vec{v_n}) + b \det(\vec{w_1}, \vec{v_2}, ...,\vec{v_n})$, and the corresponding condition in each other slot.

I claim that these facts, together with the fact that the determinant of the identity matrix is one, is enough to define a unique function that takes in N vectors (each of length N) and returns a real number, the determinant of the matrix given by those vectors. I wonΓÇÖt prove that, but IΓÇÖll show you how it helps with some other interpretations of the determinant.

In particular, thereΓÇÖs a nice geometric way to think of a determinant. Consider the unit cube in N dimensional space: the set of vectors of length N with coordinates 0 or 1 in each spot. The determinant of the linear transformation (matrix) T is the signed volume of the region gotten by applying T to the unit cube. (DonΓÇÖt worry too much if you donΓÇÖt know what the ΓÇ£signedΓÇ¥ part means, for now).

How does that follow from our abstract definition?

Well, if you apply the identity to the unit cube, you get back the unit cube. And the volume of the unit cube is 1.

If you stretch the cube by a constant factor in one direction only, the new volume is that constant. And if you stack two blocks together aligned on the same direction, their combined volume is the sum of their volumes: this all shows that the signed volume we have is linear in each coordinate when considered as a function of the input vectors.

Finally, when you switch two of the vectors that define the unit cube, you flip the orientation. (Again, this is something to come back to later if you donΓÇÖt know what that means).

So there are ways to think about the determinant that arenΓÇÖt symbol-pushing. If youΓÇÖve studied multivariable calculus, you could think about, with this geometric definition of determinant, why determinants (the Jacobian) pop up when we change coordinates doing integration. Hint: a derivative is a linear approximations of the associated function, and consider a ΓÇ£differential volume elementΓÇ¥ in your starting coordinate system.

ItΓÇÖs not too much work to check that the area of the parallelogram formed by vectors $(a,b)$ and $(c,d)$ is $\det((a,b),(c,d))$, either: you might try that to get a sense for things.
AnswerKenntnis:
You could think of a determinant as a volume.  Think of the columns of the matrix as vectors at the origin forming the edges of a skewed box.  The determinant gives the volume of that box.  For example, in 2 dimensions, the columns of the matrix are the edges of a rhombus.

You can derive the algebraic properties from this geometrical interpretation.  For example, if two of the columns are linearly dependent, your box is missing a dimension and so it's been flattened to have zero volume.
AnswerKenntnis:
In addition to the answers, above, the determinant is a function from the set of set of square matrices into the real numbers that preserves the operation of multiplication:
\begin{equation}\det(AB) = \det(A)\det(B) \end{equation}
and so it carries $some$ information about square matrices into the much more familiar set of real numbers.

Some examples: 

The determinant function maps the identity matrix $I$ to the identity element of the real numbers ($\det(I) = 1$.)

Which real number does not have a multiplicative inverse?  The number 0.  So which square matrices do not have multiplicative inverses? Those which are mapped to 0 by the determinant function.

What is the determinant of the inverse of a matrix?  The inverse of the determinant, of course.  (Etc.)

This "operation preserving" property of the determinant explains some of the value of the determinant function and provides a certain level of "intuition" for me in working with matrices.
AnswerKenntnis:
The top exterior power of an $n$-dimensional vector space $V$ is one-dimensional. Its elements are sometimes called pseudoscalars, and they represent oriented $n$-dimensional volume elements.

A linear operator $f$ on $V$ can be extended to a linear map on the exterior algebra according to the rules $f(\alpha) = \alpha$ for $\alpha$ a scalar and $f(A \wedge B) = f(A) \wedge f(B), f(A + B) = f(A) + f(B)$ for $A$ and $B$ blades of arbitrary grade. Trivia: some authors call this extension an outermorphism. The extended map will be grade-preserving; that is, if $A$ is a homogeneous element of the exterior algebra of grade $m$, then $f(A)$ will also have grade $m$. (This can be verified from the properties of the extended map I just listed.)

All this implies that a linear map on the exterior algebra of $V$ once restricted to the top exterior power reduces to multiplication by a constant: the determinant of the original linear transformation. Since pseudoscalars represent oriented volume elements, this means that the determinant is precisely the factor by which the map scales oriented volumes.
AnswerKenntnis:
For the record I'll try to give a reply to this old question, since I think some elements can be added to what has been already said.

Even though they are basically just (complicated) expressions, determinants can be mysterious when first encountered. Questions that arise naturally are: (1) how are they defined in general?, (2) what are their important properties?, (3) why do they exist?, (4) why should we care?, and (5) why does their expression get so huge for large matrices?

Since $2\times2$ and $3\times3$ determinants are easily defined explicitly, question (1) can wait. While (2) has many answers, the most important ones are, to me: determinants detect (by becoming 0) the linear dependence of $n$ vectors in dimension $n$, and they are an expression in the coordinates of those vectors (rather than for instance an algorithm). If you have a family of vectors that depend (or at least one of them depends) on a parameter, and you're asking (or are being asked) for which parameter values they are linearly dependent, than trying to use Gaussian elimination or something similar to detect linear dependence can run into trouble: one might need assumptions on the parameter to assure some coefficient is nonzero, and even then dividing by it gives very messy expressions. Provided the number of vectors equals the dimension $n$ of the space, taking a determinant will however immediately transform the question into an equation for the parameter (which one may or may not be capable of solving, but that is another matter). This is exactly how one obtains an equation in eigenvalue problems, in case you've seen those. This provides a first answer to (4). (But there is a lot more you can do with determinants once you get used to them.)

As for question (3), the mystery of why determinants exist in the first place can be reduced by considering the situation where one has $n-1$ given linearly independent vectors, and asks when a final unknown vector $\vec x$ will remain independent from them, in terms of its coordinates. The answer is that it usually will, in fact always unless $\vec x$ happens to be in the linear span $S$ of those $n-1$ vectors, which is a subspace of dimension $n-1$. For instance, if $n=2$ (with one vector $\vec v$ given) the answer is "unless $\vec x$ is a scalar multiple of $\vec v$". Now if one imagines a fixed (nonzero) linear combination of the coordinates of $\vec x$ (the technical term is a linear form on the space), then it will become 0 precisely when $\vec x$ is in some subspace of dimension $n-1$. With some luck, this can be arranged to be precisely the linear span $S$. (In fact no luck is involved: if one extends the $n-1$ vectors by one more vector to a basis, then expressing $\vec x$ in that basis and taking its final coordinate will define such a linear form; however you can ignore  this argument unless you are particularly suspicious.) Now the crucial observation is that not only does such a linear combination exist, its coefficients can be taken to be expressions in the coordinates of our $n-1$ vectors. For instance in the case $n=2$ if one puts $\vec v={a\choose b}$ and $\vec x={x_1\choose x_2}$, then the linear combination $-bx_1+ax_2$ does the job (it becomes 0 precisely when $\vec x$ is a scalar multiple of $\vec v$), and $-b$ and $a$ are clearly expressions in the coordinates of $\vec v$. In fact they are linear expressions. For $n=3$ with two given vectors, the expressions for the coefficients of the linear combination are more complicated, but they can still be explicitly written down (each coefficient is the difference of two products of coordinates, one form each vector). These expressions are linear in each of the vectors, if the other one is fixed.

Thus one arrives at the notion of a multilinear expression (or form). The determinant is in fact a multilinear form: an expression that depends on $n$ vectors, and is linear in each of them taken individually (fixing the other vectors to arbitrary values). This means it is a sum of terms, each of which is the product of a coefficient, and of one coordinate each of all the $n$ vectors. But even ignoring the coefficients, there are many such terms possible: a whopping $n^n$ of them!

However, we want an expression that becomes 0 when the vectors are linearly dependent. Now the magic (sort of) is that even the seemingly much weaker requirement that the expression becomes 0 when two successive vectors among the $n$ are equal will assure this, and it will moreover almost force the form of our expression upon us. Multilinear forms that satisfy this requirement are called alternating. I'll skip the (easy) arguments, but an alternating form cannot involve terms that take the same coordinate of any two different vectors, and they must change sign whenever one interchanges the role of two vectors (in particular they cannot be symmetric with respect to the vectors, even though the notion of linear dependence is symmetric; note that already $-bx_1+ax_2$ is not symmetric in $(a,b)$ and $(x_1,x_2)$). Thus any one term must involve each of the $n$ coordinates once, but not necessarily in order: it applies a permutation of the coordinates 1,2,...,$n$ to the successive vectors. Moreover, if a term involves one such permutation, then any term obtained by interchanging two positions in the permutation must also occur, with an opposite coefficient. But any two permutations can be transformed into one another by repeating such interchanges, so if there are any terms at all, then there must be terms for all $n!$ permutations and their coefficients are all equal or opposite. This explains question (5), why the determinant is such a huge expression when $n$ is large.

Finally the fact that determinants exist turns out to be directly related to the fact that signs can be associated to all permutations in such a way that interchanging entries always changes the sign, which is part of the answer to question (3).
As for question (1), we can now say that the determinant is uniquely determined by being an $n$-linear alternating expression in the entires of $n$ column vectors, which contains a term consisting of the product of their coordinates 1,2,...,$n$ in that order (the diagonal term) with coefficient $+1$. The explicit expression is a sum over all $n!$ permutations, the corresponding term being obtained by applying those coordinates in permuted order, and with the sign of the permutation as coefficient. A lot more can be said about question (2), but I'll stop here.
AnswerKenntnis:
I recorded a lecture on the geometric definition of determinants:

Geometric definition of determinants

It has elements from the answers by Katie Banks and John Cook, and goes into details in a leisurely manner.
AnswerKenntnis:
If you have a matrix 


$H$
then you can calculate the correlationmatrix with 
$G = H \times H^H$
(H^H denotes the complex conjugated and transposed version of $H$).


If you do a eigenvalue decomposition of $G$ you get eigenvalues $\lambda$ and eigenvectors $v$, that in combination $\lambda\times v$ describes the same space.

Now there is the following equation, saying:


Determinant($H*H^H$) = Product of all eigenvalues $\lambda$


I.e., if you have a $3\times3$ matrix $H$ then $G$ is $3\times3$ too giving us three eigenvalues.
The product of these eigenvalues give as the volume of a cuboid.
With every extra dimension/eigenvalue the cuboid gets an extra dimension.
AnswerKenntnis:
I too find the way determinants are treated in exterior algebra most intuitive. The definition is given on page 46 of Landsberg's "Tensors: Geometry and Applications". Two examples below will tell you everything you need to know.

Say, you are give a matrix 
$$A=\begin{pmatrix}a&b\\c&d\end{pmatrix}$$
and asked to compute its determinant. You can think of the matrix as a linear operator $f:\mathbb R^2\to\mathbb R^2$ defined by

$$\begin{pmatrix}x\\y\end{pmatrix}\mapsto\begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}x\\y\end{pmatrix}.$$

If you define the standard basis vector by $e_1=\begin{pmatrix}1\\0\end{pmatrix}$ and $e_2=\begin{pmatrix}0\\1\end{pmatrix}$, you can then define $f$ by the values it assumes on the basis vectors: $f(e_1)=ae_1+ce_2$ and $f(e_2)=be_1+de_2$.

The linear operator $f$ is extended to bivectors by 
$$f(e_1\wedge e_2)=f(e_1)\wedge f(e_2).$$ 

Then you can write 

$$f(e_1\wedge e_2)=(ae_1+ce_2)\wedge(be_1+de_2)=(ad-bc)e_1\wedge e_2,$$

where I used distributivity and anticommutativity of the wedge product (the latter implies $a\wedge a=0$ for any vector $a$). So, we get the determinant as a scalar factor in the above equation, that is

$$f(e_1\wedge e_2)=\det(A)\,e_1\wedge e_2.$$

The same procedure works for 3-by-3 matrices, you just need to use a trivector. Say, you are given $$B=\begin{pmatrix}a_{11}&a_{12}&a_{13}\\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33}\end{pmatrix}.$$ 

It defines a linear operator $g:\mathbb R^3\to \mathbb R^3$

$$\begin{pmatrix}x\\y\\z\end{pmatrix}\mapsto \begin{pmatrix}a_{11}&a_{12}&a_{13}\\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33}\end{pmatrix} \begin{pmatrix}x\\y\\z\end{pmatrix},$$

for which we have

$$g(e_1)=a_{11}e_1+a_{21}e_2+a_{31}e_3,\quad g(e_2)=a_{12}e_1+a_{22}e_2+a_{32}e_3,\quad g(e_3)=a_{13}e_1+a_{23}e_2+a_{33}e_3$$

on the standard basis $e_1=\begin{pmatrix}1\\0\\0\end{pmatrix}$, $e_2=\begin{pmatrix}0\\1\\0\end{pmatrix}$, $e_3=\begin{pmatrix}0\\0\\1\end{pmatrix}$. The operator $g$ is extended to trivectors by 
$$g(e_1\wedge e_2\wedge e_3)=g(e_1)\wedge g(e_2)\wedge g(e_3),$$ 

which gives

$$g(e_1\wedge e_2\wedge e_3)=(a_{11}e_1+a_{21}e_2+a_{31}e_3)\wedge(a_{12}e_1+a_{22}e_2+a_{32}e_3)\wedge(a_{13}e_1+a_{23}e_2+a_{33}e_3).$$

If you then follows the rules of $\wedge$ such as distributivity, anticommutativity, and associativity, you get 
$$g(e_1\wedge e_2\wedge e_3)=\det(B)\, e_1\wedge e_2\wedge e_3.$$

It works in exactly the same way in higher dimensions.
AnswerKenntnis:
Think about a scalar equation,
$$ax = b$$
where we want to solve for $x$.  We know we can always solve the equation if $a\neq 0$, however, if $a=0$ then the answer is "it depends".  If $b\neq 0$, then we cannot solve it, however, if $b=0$ then there are many solutions (i.e. $x \in \mathbb{R}$).  The key point is that the ability to solve the equation unambiguously depends on whether $a=0$.

When we consider the similar equation for matrices

$$\mathbf{Ax} = \mathbf{b}$$

the question as to whether we can solve it is not so easily settled by whether $\mathbf{A}=\mathbf{0}$ because  $\mathbf{A}$ could consist of all non-zero elements and still not be solvable for $\mathbf{b}\neq\mathbf{0}$. In fact, for two different vectors $\mathbf{y}_1 \neq \mathbf{0}$ and $\mathbf{y}_2\neq \mathbf{0}$ we could very well have that

$$\mathbf{Ay}_1 \neq \mathbf{0}$$
and
$$\mathbf{Ay}_2 = \mathbf{0}.$$

If we think of $\mathbf{y}$ as a vector, then there are some directions in which $\mathbf{A}$ behaves like non-zero (this is called the row space) and other directions where $\mathbf{A}$ behaves like zero (this is called the null space).  The bottom line is that if $\mathbf{A}$ behaves like zero in some directions, then the answer to the question "is $\mathbf{Ax} = \mathbf{b}$ generally solvable for any $\mathbf{b}$?" is "it depends on $\mathbf{b}$".  More specifically, if $\mathbf{b}$ is in the column space of $\mathbf{A}$, then there is a solution.

So is there a way that we can tell whether $\mathbf{A}$ behaves like zero in some directions?  Yes, it is the determinant! If $\det(\mathbf{A})\neq 0$ then $\mathbf{Ax} = \mathbf{b}$ always  has a solution.  However if, $\det(\mathbf{A}) = 0$ then $\mathbf{Ax} = \mathbf{b}$ may or may not have a solution depending on $\mathbf{b}$ and if there is one, then there are an infinite number of solutions.
AnswerKenntnis:
(I considered making this a comment, but I thought it might deserve more attention than a comment would receive. Upvotes and downvotes will tell if I am right or wrong).

Complement about the sign of the determinant

I loved the accepted answer by Jamie, but I was frustrated that it did not give more explanation about the sign of the determinant and the notion of "rotation" or "orientation" of a vector. The answer from Marc Van Leeuwen comments more on this, but maybe not enough for everyone -- at least for me -- to understand what it means for a matrix to change the orientation of the space it transforms. So I googled the issue and ended up on the following explanation which I find excellent and accessible:

http://mathinsight.org/determinant_linear_transformation#lintrans3D
AnswerKenntnis:
now, to get an intuitive idea we first have to consider a set of simultaneous linear equqtions .In order to get an answer we should eliminate one variable and equate another.......... for example 
2a+3b=13  and a+b=5  equating this we get a=2 and b=3 ........... but the thing toobserve is if the equations are proportional then it is impossible to come to an conclusion...... like.... a+b=2 and 2a+2b=4. we cannot find an solution to this bcoz theyre nothing but the same equations!!!(hint: divide eq. 2a+2b=4 by 2) ..... and hence determinant are used to determine the consistency of an equation here the first set is consistent(can be verified easily) .... but the second one is not bcoz the two rows are proportional!!
QuestionKenntnis:
Is '10' a magical number or I am missing something?
qn_description:
It's a hilarious witty joke that points out how every base is '10' in its base. Like,

2 = 10 (base 2)
8 = 10 (base 8)


My question is if whoever invented the decimal system had chosen 9 numbers or 11, or whatever, would this still be applicable? I am confused - Is 10 a special number which we had chosen several centuries ago or am I just missing some point?
AnswersKenntnis
AnswerKenntnis:
Short answer: your confusion about whether ten is special may come from reading aloud "Every base is base 10" as "Every base is base ten" — this is wrong; not every base is base ten, only base ten is base ten. It is a joke that works better in writing. If you want to read it aloud, you should read it as "Every base is base one-zero".



You must distinguish between numbers and representations. A pile of rocks has some number of rocks; this number does not depend on what base you use. A representation is a string of symbols, like "10", and depends on the base. There are "four" rocks in the cartoon, whatever the base may be. (Well, the word "four" may vary with language, but the number is the same.) But the representation of this number "four" may be "4" or "10" or "11" or "100" depending on what base is used.

The number "ten" — the number of dots in ".........." — is not mathematically special. In different bases it has different representations: in base ten it is "10", in base six it is "14", etc.

The representation "10" (one-zero) is special: whatever your base is, this representation denotes that number. For base $b$, the representation "10" means $1\times b + 0 = b$.

When we consider the base ten that we normally use, then "ten" is by definition the base for this particular representation, so it is in that sense "special" for this representation. But this is only an artefact of the base ten representation. If we were using the base six representation, then the representation "10" would correspond to the number six, so six would be special in that sense, for that representation.
AnswerKenntnis:
The magic of the number 10 comes from the fact that "1" is the multiplicative unit and "0" is the additive unit. The first two-digit-number in positional notation is always 10 and also always denotes the number of digits.
AnswerKenntnis:
Yes, ten ( ..... ..... ) is a special number. Not magical but special because it a very convenient base for species that have ten fingers.

Arguably we can use hands and fingers to encode 1024 numbers using the binary system, but that would be less robust across reading directions and some configurations/gestures are physiologically hard to do.
AnswerKenntnis:
I do not accept your concept of "1-0" as being a number.

The 1-0 you are using is a notation used on different numbers. So, as special the number 10decimal is, the notation 1-0 is not a special number.

To me, it is a special notation.

1-0 is the notation for the number 10decimal.
1-0 is the notation for the number 2binary
1-0 is the notation for the number 8octal
1-0 is the notation for the number 12radix12
1-0 is the notation for the number 13radix13
1-0 is the notation for the number 14radix14
1-0 is the notation for the number 15radix15
1-0 is the notation for the number 16hexadec


So, calling number 10dec a special number because the notation 1-0 is special would be akin to expressing the correlation

cows eat corn. cows are stupid.
Mary eats corn. And therefore, Mary is stupid.


However, you could say that the notation 1-0 denotes a number that is special within each radix. That is saying that every number is a special number in the set of all radix systems.


There are innumerable radix systems.
There are innumerable numbers.
A radix system is denoted by radix(n)
where n is a special number within the set of numbers in radix(n) because it is denoted by the notation 1-0radix(n)
Therefore, every number is a special number within the radix denoted by that number.
So is the notation 1-0-0 special, as is the notation 1-0-0-.......-0


The notation 1-9 is also a special notation, for all radix systems greater than radix(8), because it signifies the special occasion when the number mutates from 1-8 to 1-9 or from 1-A to 1-9

In fact, every notation member of the sets of all possible notations is special, by the virtue that that notation signifies a transition from a lesser value to a greater value, vice versa.

The notation A is also special notation, for all radix systems greater than radix(9).
Because it signifies the transition from a numeral digit procession to an alphabetic procession.

Therefore, the number 10dec is indeed a special number not by the virtue of the notation 1-0, but by the virtue of the notation A. Because for all radix systems greater than radix(10), the value 10dec is always denoted by the special notation A. Where A is special because it is a consequence of the end of numeric digit procession into an alphabetic one.

That is like every parent in the world saying "My kid is special".
AnswerKenntnis:
Your comic is not talking about the number ten, it's talking about the string "10" (read that as "one-zero," not "ten"). "10" ("one-zero") only represents the integer ten in base-ten.  In other bases, "10" represents a different number.

In base-nine, the string "10" would represent the integer nine (ten would be "11").

Similarly, in base-eleven, "10" would represent eleven (ten would be represented by a new symbol, traditionally "A").

The point of the comic is the fact that the string "10" in base-n always represents n.  There's nothing deeper to it than that.
AnswerKenntnis:
One point you may be missing (I did initially) is that the little guy has only two fingers on each hand. Also, he miraculously speeks English, and knows how to distinguish 4 from 10, even though he doesn't know what 4 is.
AnswerKenntnis:
The fact that humans have 10 fingers in their hands gives to the number 10 special status. Historically are used bases 20 if we count fingers of our hands and feet. Base 60 we use because the number 60 has many divisors. If we suppose that in planet Mars lives intelligent creatures with two ,,hands,, in each hand with 3 ,,fingers,, then their ,,magical,, number probably will be the number 6.
AnswerKenntnis:
Yes, it would still be 10. The base number is always denoted by 10. If you had 11 numbers you would require eleven symbols. Since we already have 10 symbols for the first 10 numbers (0,1,..,9) you would only need one to symbolize the one we call ten. For example, in base 16, the letters A,B,C,D,E,F are used to denote 10, 11, 12, 13, 14 and 15 respectively. So:

10 = A (base 16)

11 = B (base 16) 

and so on. You should check : http://en.wikipedia.org/wiki/Radix
AnswerKenntnis:
10 is not magic (see the other answers for the reason), but 1 and 0 are magic (or at least special) :
for any number n, we have


0├ùn=0, since 0 is the neutral element of addition, and therefore the absorbing element of multiplication
1├ùn=n, since 1 is the neutral element of multiplication.


Therefore, 10 in basis b is always 1├ùb+0├ù1=b. Less surprisingly zero and one are always written 0 and 1, no matter the basis, and 100 always is b┬▓.
AnswerKenntnis:
I've always assumed it was the number of fingers on the human hand that originated the decimal system.  I sometimes make people feel better about their age by saying something like, "Hey, if humans has 6 fingers on each hand you'd still be in your thirties."
QuestionKenntnis:
Why don't we define "imaginary" numbers for every "impossibility"?
qn_description:
Before the concept of imaginary numbers, the number $i = \sqrt{-1}$ was shown to have no solution among the numbers that we had, so we said $i$ to be a new type of number. How come we don't do the same for other "impossible" equations, such as
$x = x + 1$, or $x = 1/0$?

Edit:
OK, a lot of people have said that a number $x$ such that $x = x + 1$ would break the rule that $0 \neq 1$. However, let's look at the extension from whole numbers to include negative numbers (yes, I said that I wasn't going to include this) by defining $-1$ to be the number such that $-1 + 1 = 0$. Note that this breaks the "rule" that "if $x \leq y$, then $ax \leq ay$", which was true for all $a, x, y$ before the introduction of negative numbers. So I'm not convinced that "That would break some obvious truth about all numbers" is necessarily an argument against this sort of thing.
AnswersKenntnis
AnswerKenntnis:
Here's one key difference between the cases.

Suppose we add to the reals an element $i$ such that $i^2 = -1$ (and include everything else you can get by applying addition and multiplication, while still preserving the usual rules of addition and multiplication). Expanding the reals to the complex numbers in this way does not enable us to prove new equations among the reals inconsistent with previously established ones.

Suppose by contrast we add to the reals a new element $k$ postulated to be such that $k + 1 = k$ (and then also add every further element you can get by applying addition and multiplication to the reals and this new element $k$). Then we have, for example,  $k + 1 + 1 = k + 1$. Hence -- assuming that old and new elements together still obey the usual rules of arithmetic -- we can cheerfully subtract $k$ from each side to "prove" $2 = 1$. Ooops! Adding the postulated element $k$ enables us to prove new equations flatly inconsistent what we already know. Unless, that is, we do muck about with the usual rules of addition. 

Of course, if we do not only add new elements but change the rules of arithmetic, then we can stay safe. This is what happens when we add the infinite ordinals to the finite ones, but at the cost e.g. of having cases where $\alpha + 1 \neq 1 + \alpha$ and $1 + 1 + \alpha = 1 + \alpha$.
AnswerKenntnis:
In ordinal arithmetic we have $1+\omega=\omega$. There is an algebraic downside: it turns out that $\omega+1\ne \omega$.
AnswerKenntnis:
The short answer is that you can add any made up solution to any equation you want and extend whatever number system (or any system) you have to a larger one. 

The slightly longer answer is that in mathematics it is usually with some aim in mind that an extension is made. Particularly for the imaginary numbers you mentioned, the square root of $-1$ was contemplated because it simplified manipulations on polynomials when looking for their roots. 

The irrationals are added to the rational numbers since the rational do not suffice for measuring distances (i.e., the hypotenuse of a triangle with sides equal to $1$ is $\sqrt2$). 

Infinitesimals are added to the real numbers in order to make rigorous heuristic arguments using such entities. 

Infinitely large natural numbers are added to the ordinary natural numbers in order to construct certain models showing the independence of certain axioms from others. 

Infinite sets are added to the more tame finite sets since it is convenient to be able to talk about infinite collections of, say, numbers. 

100-150 years ago 'function' assumed a very narrow meaning (not well defined) basically what we today would call: a function that is analytic everywhere except possibly at isolated points. There were even attempts to prove that every continuous function must be differentiable at almost all points. Gradually, the more exotic beasts - functions that are continuous but nowhere differentiable - entered the scene. Thus extending the study of functions from the narrow class of almost everywhere differentiable ones to the class of continuous ones. This was necessitated again by applications since such functions occur as uniform limits of analytic functions. 

There are many more such examples where some extension is made fueled by some applications or a need to better understand the axiomatics of some system.
AnswerKenntnis:
Adding an "imaginary" solution to a previous "impossible" equation always breaks existing rules (by definition, because one of the existing rules was that the impossible equation was impossible).  The question is whether the gain of the new solution is worth the loss.  In the case of extending reals to complex numbers, you lose the usual ordering property (an ordering $\le$ that is compatible with $+$ and $\cdot$ must have all squares nonnegative), but the resulting gain is huge because you can solve so many equations you couldn't before.

In your example of going from nonnegative numbers to all numbers, you give up the property $x \le y$ implies $ax \le ay$, but it's easy enough to fix up slightly, namely, to add the condition that $a \ge 0$ (and perhaps to say that the inequality is reversed if $a < 0$).  This is also a small change.

If you add a solution to $x=x+1$, then as others have mentioned, you either have to give up $0 \ne 1$ or else give up subtraction.  The first one would pretty much makes the new system useless.  The second can be useful under certain circumstances.  For example (as is done in measure theory, among other places), you can introduce a symbol $\infty$ that satisfies $\infty=\infty+1$.  You can also define addition involving $\infty$, and most multiplications, and even most subtractions.  A problem arises when you try to define the difference $\infty - \infty$, or the product $\infty \cdot 0$, so you leave those undefined.  You have given up the ability to always subtract or multiply, but in some contexts that is okay.  You just have to remember those restrictions when you're working in those contexts.
AnswerKenntnis:
If you can use sets to define  a structure that has some properties (like $\exists x[x=x+1]$, of course one has to know what $1$ is.), then we are done. Formal Constructions using sets is what is used to make the natural numbers, integers, rationals, real numbers,....  

This part uses abstract algebra:

The ring $R[x]/\langle x^2+1\rangle$ has solutions to the equation $x^2+1=0$. (Where $1$ is the multiplicative identity of $R[x]/\langle x^2+1\rangle$)

In a similar way, the ring $R[x]/\langle1\rangle$ has solutions to the equation $x+1=x$. 

This is the trivial ring. However, the trivial ring is not really interesting.
AnswerKenntnis:
To your edit:


  So I'm not convinced that "That would break some obvious truth about all numbers" is necessarily an argument against this sort of thing.


You're right, of course. Some obvious truths simply need to be bent or broken in order for mathematics to be useful - if we insisted that every rule we learnt in primary school held for every concept we ever came across in more advanced mathematics, we'd never encounter new breakthroughs. And in the same way, $i^2 = -1$ breaks the 'obvious truth' that all numbers have non-negative square. So we're not scared of doing it - it would have held back both mathematics and physics hugely to be scared of $i$ just because it was a little unfamiliar.

However, the people who are telling you that a new number $x$ with the property that $x=x+1$ would break the rules have a point too. The introduction of this new number - with some exceptions - is a gratuitous breaking of the rules. That is, there is little sense behind it - it's not motivated by a mathematical (in the sense of 'mathematics research') question or observation, it screws arithmetic right up, and it doesn't seem to have much benefit. But don't take my word for it - spend a few minutes (a few hours, a few years) playing with the concept. The thing is, if you do so, you'll soon realise one of two things:


You come up with a system like ordinal arithmetic (look it up!), a very interesting system of numbers with well-defined notions of $+$ and $\times$, in which there is a number $\omega$ with the property that $\omega = 1+\omega$. Unfortunately, you're really really unlikely to come up with ordinals by approaching them from this angle: after all, ordinals are weird things that are only really mentioned in very specific (and rather esoteric, if I may say so!) areas of study. Anyway, here are some reasons why ordinals are probably too weird to come up with from this angle: in ordinal arithmetic, $+$ and $\times$ are non-commutative (look it up), for a start, and $-$ and $\div$ don't exist. And you'd have to get rid of negative numbers and stick a whole shedload of infinities in there too. More than just introducing a number, you're having to break almost all the rules of arithmetic to even begin to talk about these things! Or even...
You come up with a weird and useful system that nobody has ever discovered before. Except nobody's ever discovered it before, so it's probably even harder to find and weirder than ordinals. Okay, much more likely...
The thing you come up with is ugly and useless. It's no coincidence that ordinals look so different to ordinary arithmetic: if you try to retain too many of the properties of ordinary arithmetic but add in your new number, it will simply all collapse in on itself. Let's take an example. Suppose $x = x+1$, and your system of arithmetic allows me to subtract $x$. Then suddenly $0 = 1$, and we can multiply both sides of that equation by $a$ to get that $0 = a$, for any number $a$. And even $0 = x$. So everything is equal to zero, and the equation "$x = x+1$" simply says "$0 = 0+0$". Oops!


The problem with questions like this is that they are invariably not fruitful directions to follow. That's not to say that they won't eventually have interesting and useful answers, but rather the process of answering them probably will come indirectly - usually via trying to answer a different, much more specific mathematically-motivated question.
AnswerKenntnis:
It's because you'd be forced to break other rules. Say $\frac 10=j$. Then

$$\frac jjj=j$$
$$\frac {\frac 10}{\frac 10}\frac 10=\frac 10$$

Actually do out the fractional division first and you get

$$\frac 00=\frac 10$$
$$0=1$$

You can prove, once you've introduced this number, that all numbers are equal. So you've inadvertently collapsed the whole number line, in a sense. The difference between $0$ and $1$ in this system is the same as the difference between $4$ and the roman IV: one of notation, not of value. All "numbers" are really the same quantity (i.e. equal), and this quantity adds, subtracts, and multiplies to be itself (this is the trivial ring). It's all consistent when looked at in this way, but it's also very boring. If you want to add $\frac 10$ and not run into this boring situation, then you have to drop/change enough algebraic rules to remove your ability to  prove $0=1$. This happens in say, wheel theory.

On the other hand, introducing $i^2=-1$ poses no such problem. In fact, we can keep essentially everything about the real numbers that we knew previously. So this addition doesn't destroy structure, it creates it. The idea is this: say you want to extend the real numbers. Then defining the new system:

$$\text{"The real numbers, but with $i$"}$$

is a perfectly consistent statement to make.

$$\text{"The real numbers, but with $j$"}$$

with $j$ as defined above, does not. They're contradictory ideas. You can declare whatever kinds of numbers you want, so long as you have consistent rules. And if you want those numbers to extend the real numbers without seriously modifying them, that requirement of "having consistent behaviour with what we know about $\mathbb{R}$" puts constraints on the kinds of extensions you can define.
AnswerKenntnis:
The complex numbers were an excellent and highly useful abstraction.  It is because exploration of them yielded significant and productive mathematical results.  

It's the usefulness of an abstraction that matters.
AnswerKenntnis:
The reason why the complex numbers are so special is that they are the end of a chain of questions of the form "How can we solve this equation?" or "What are the roots of this equation?".

We start with the positive integers.

We get the positive rationals by asking "How can we solve $a*x = b$ for $x$ ($a \ne 0$)?"

From the positive rationals, we get all the rationals by asking "How can we solve $a+x=b$ for $x$?"

From the rationals we get the algebraic numbers by asking "How can we solve $\sum a_i x^i = 0$ for x?"

We get the reals from the rationals (one of a number of ways) by asking "What is $\lim_{n \to \infty} a_n$?" 

We get the complex numbers from the reals by asking "What are the roots of $\sum a_i x^i = 0$?"

But here it stops. All the roots of $\sum a_i x^i = 0$, where the $a_i$ are complex are complex - no new types of numbers need to be introduced.

For the details of this, I recommend Landau's "Foundations of Analysis".
AnswerKenntnis:
There is a problem with that: not all impossibilities behave as nicely as imaginary numbers. $i \cdot i $ will always result in a nice and solid -1 no matter how you got the two $i$. Meanwhile, ${\infty \over \infty} $ may turn out pretty much damned everything depending on how you obtained these two infinities.
AnswerKenntnis:
$x=x+1$ will define the trivial ring as other people have discussed.  

However, it also defines an abelian (commutative) group over the set $[0, 1)$ with the operator $+$.  The elements of this group are the equivalence classes of real numbers with the same fractional part.

For example, $3/4+1/3=13/12=1+1/12=1/12$        ($=2+1/12 = 3+1/12...$)

The inverse in this group is $x^{-1}=1-x$  The identity element is $0$
AnswerKenntnis:
I like marty cohen's answer above but I am going to extend it a bit. In the beginning there were only the natural counting numbers

1,2,3,4,...

But then we couldn't solve equations like $x+4=4$ so the concept of zero was grasped and slowly adopted. Quick side note, the concept of zero was not trivial at all and in Europe wasn't even fully accepted until after the dark ages. Anyway, after adding zero, our number system is

0,1,2,3,4...

But then we couldn't solve equations like $x+4=2$ so negative integers are added and now our number system is

...,-3,-2,-1,0,1,2,3,4,...

But then we couldn't solve equations like $3x=1$ so then rational number are added so now we have the all numbers which can be written as a ratio of two integers without the denominator being zero.  But then we couldn't solve equations like $x^2=2$ and $\cos(x)=0$ so then we added all of the irrationals. This step can be broken into algebraic and transcendental numbers but I am just including both in a single step. Now we have all of the real numbers but now we can't solve equations like $x^2=-1$ so then the imaginary unit $i$ is added to the real numbers preserving all of the old operations like addition, subtraction, multiplication, division, and so on. And just by adding a single number $i$ to the real line gives us the entire complex plane.

Here I do disagree that this is the "end". This is not the end and there are still many "impossible" equations and depending on what you want to solve, how do you "want" the solution to "look", and if the extension will be useful and consistent with the "number system" we have in the past, you can throw in more solutions and keep expanding. An example I can give you is, even with complex numbers, we still cannot solve an equation like $xy-yx=1$ so now we have quaternions (matrices are another number system where "impossible" equations like $AB\neq BA$ hold but quaternions are a direct extension of the complex numbers). The article on wikipedia on quaternions is very nicely written and I would urge you to read at least the history part of it which explains how Hamilton pondered the problem of expanding the complex plane and defining multiplication and division so that it would stay consistent with what we have in the complex plane.

And by the way in case you are interested, after quaternions we do have octonions too.

So to answer your question, yes we can define imaginary numbers for all "impossible" equations but the trick is to try to expand the "old" number system, then to expand it in such a way as to stay consistent with what we have in the "old" number system, and then have the expansion be useful in some way.
AnswerKenntnis:
Another factor not yet mentioned is that in the physical sciences, many real-world systems behave in ways which are beautifully described by complex numbers.  For example, Ohm's law dictates that a certain resistance R through which current I is flowing will drop voltage E=IR.  Although the law was written to work only with DC resistances, it can also describe the behavior of any fixed network of resistors, capacitors, and inductors, at any fixed frequency; all one needs to do is define the impedance of capacitors and inductors as being imaginary numbers (of one sign for capacitors, and the other sign for inductors), and define real voltages and currents as being in phase with a reference frequency, and imaginary ones as being 90 degrees out of phase.  When things are defined in that way, using complex arithmetic to perform the same calculations one would perform using real numbers if one was limited to DC signals and resistors, the rules of complex arithmetic will properly capture the interactions between resistances, capacitances, and inductances, and the ways in which they will affect the phase of the voltage and current waveforms.

I doubt that the first people who invented and worked with complex numbers knew that they would be so useful in the physical sciences, but it turns out that the analysis of many real-world things is greatly facilitated by the use of complex numbers, notwithstanding the "imaginary" name.
AnswerKenntnis:
$x = x + 1$ means that $1=0$, as others have pointed out. You can do this, but you don't get anything interesting.  What you get is called the trivial ring, and it only contains one element, $0$ (or $1$, since they are the same thing).  That's because $x = 1x = 0x = 0$ for any $x$.  

As others have pointed out also, you can define $\frac{1}{0} = \infty$.  This is actually quite useful as a formality if you are dealing with infinites, but you have to be careful, because there is no consistant way to define things like $\frac{0}{0}$, $\frac{\infty}{\infty}$ or $\infty - \infty$.  This is called either the extended real numbers or the extended complex numbers, depending on what other kinds of numbers you allow.

The common theme here is that we define things because they are useful.  We "invent" $i = \sqrt{-1}$ because this formality gives us some useful things. In particular, any nonzero complex number $a + bi$ has a multiplicative inverse when defined this way, so that it gives a field. And in this field, very nice properties happen, for example, any polynomial has a root, so that we no longer have equations like $x^2 + 1 = 0$ that don't have solutions. 

So what we do is first assert that some object exists by satisfying some equation (like $x^2 + 1 = 0$ or $x = 1/0$ or $x = x + 1$), and then we see what that implies given the other operations that we still want to hold, and what kinds of things can be well-defined and what can't.  For $x^2 + 1 = 0$ (i.e., $i$), we get something very nice, a field.  For $x = 1/0$, we get something useful, but not as nice (not all operations can be consistently defined on $\infty$, so that it is not a field).  For $x = x + 1$, we do get a field, but it is so simple that there is absolutely no use for it, other than as a field that exists for the sake of completeness.
AnswerKenntnis:
There are two ways in which modifying a system can "break a rule about all numbers": you can break them in the original system, or only in an extension.


Suppose we have the natural numbers with addition, multiplication and ordering. If we add a solution to the equation $x=x+1$ then, if we still want subtraction to work, $0=1$. Since $0$ and $1$ are natural numbers, this breaks the rule about natural numbers which says that $0\ne 1$. If we want multiplication to also behave as before, we get that $x=1\cdot x=0\cdot x=0$ for all (natural) numbers $x$ which means that instead of extending the system, we have collapsed it into a zero. So we have broken pretty much every rule of the original system.
But what if we instead add negative numbers? You said that the rule "$x\le y\implies ax\le ay$ for all $a,x,y$" breaks. And formulated like this, it does, but if you think about it closer, the original statement wasn't about all numbers but all natural numbers. And in this form it still holds. In fact, if you only speak about natural numbers in the new system, no rules have changed. A similar thing happens when you add a solution to $x^2=-1$ in the reals. In these cases we only "break rules" in the extended part of the system.
AnswerKenntnis:
We already have such a symbol for x = x + 1 ~  the infinity symbol
AnswerKenntnis:
So much discussion...

In fact it's very easy to construct a setting where x=x+1 by making them angles, postulating your "1" to be 360deg and only considering the modulus 360 of each number :)
AnswerKenntnis:
If you make $x + 1 = x$ and still want the ring axioms to hold, you end up with the (very uninteresting) ring $\mathbb{Z}/1 \mathbb{Z}$ (just like postulating $x + 3 = x$ gives $\mathbb{Z}/3 \mathbb{Z}$).
AnswerKenntnis:
i should not be defined as a solution to x^2=-1 (i.e. as an artificial way to find a "solution" to a previously considered "impossible" equation. Complex numbers are defined as orderer pairs (a,b) of real numbers. You define arithmetic rules (+,x,-,/) for such ordered pairs which can be done in a way that makes (a,0) equivalent with the ordinary real number a. Complex numbers (0,b) will be found to satisfy (0,b)^2=(-b^2,0). Voila, we have found a certain kind of numbers (0,b) also called "imaginary" numbers which when squared will give a complex number (-b^2,0) equivalent with the negative real number -b^2. A similar construction of a new type of number x satisfying x=x+1 cannot be made with preservation of established arithmetic rules.
AnswerKenntnis:
You cant simply ask for a new number to solve an unverifiable equation, unlike the root of negative one which introduced an extension to number theory .. otherwise everyday we will have new numbers introduced that have no impact and not even verifiable .. for example I will need a new number set for x=x+2 and so forth
QuestionKenntnis:
In Russian roulette, is it best to go first?
qn_description:
Assume that we are playing a game of Russian roulette (6 chambers). Assume that there is no shuffling after the shot is fired.

I was wondering if you have an advantage in going first?

If so, how big of an advantage?

I was just debating this with friends, and I wouldn't know what probability to use to prove it. I'm thinking binomial distribution or something like that.

If n=2, then there's no advantage. Just 50/50 if the person survives or dies. 

If n=3, then maybe the other guy has an advantage. The person who goes second should have an advantage. 

Or maybe I'm wrong.
AnswersKenntnis
AnswerKenntnis:
For a 2 Player Game, it's obvious that player one will play, and 1/6 chance of losing.  Player 2, has a 1/6 chance of winning on turn one, so there is a 5/6 chance he will have to take his turn. (I've intentionally left fractions without reducing them as it's clearer where the numbers came from)

Player 1 - 6/6 (Chance Turn 1 happening) * 1/6 (chance of dying) = 1/6

Player 2 - 5/6 (Chance Turn 2 happening) * 1/5 (chance of dying) = 1/6

Player 1 - 4/6 (Chance Turn 3 happening) * 1/4 (chance of dying) = 1/6

Player 2 - 3/6 (Chance Turn 4 happening) * 1/3 (chance of dying) = 1/6

Player 1 - 2/6 (Chance Turn 5 happening) * 1/2 (chance of dying) = 1/6

Player 2 - 1/6 (Chance Turn 6 happening) * 1/1 (chance of dying) = 1/6

So the two player game is fair without shuffling.
Similarly, the 3 and 6 player versions are fair.

It's the 4 and 5 player versions where you want to go last, in hopes that the bullets will run out before your second turn.

For a for 4 player game, it's
P1-2/6,
P2-2/6,
P3-1/6,
P4-1/6

Now, the idea in a 2 player game is that it is best to be player 2, because in the event you end up on turn six, you KNOW you have a chambered round, and can use it to shoot player 1 (or your captor), thus winning, changing your total odds of losing to P1 - 3/6, P2 - 2/6, Captor -  1/6
AnswerKenntnis:
Your best bet is actually to go last, because this will either make no difference or decrease the probability of shooting yourself. Why? If there are $n$ people and $n$ divides $6$, then the probability of any one person taking the bullet is equal, since the probability distribution is assumed to be uniform over the number of times the trigger is pulled. If $n \le 6$ does not divide $6$, i.e. if $n=4$ or $5$, then the turns wrap around and begin with the first person again, so the first one or two people have to shoot again; naturally, this doubles their probability of being shot. And finally, if $n>6$ then the bullets will have run out before they come to you if you go last.
AnswerKenntnis:
This reminds me of a similar interview question; you see your interviewer load two bullets into consecutive chambers of a gun, point at his head and pulls the trigger, but survives as it was an empty chamber.  He then gives you the gun to fire at your head, giving you the option to either spin the barrel before shooting or to just take the next shot.



You then decide not to spin the barrel; as with spinning you have a 2/6 ~ 33$\frac{1}{3}$% chance of killing yourself.  Without spinning and knowing that the last shot was nonlethal you leave only 5 chambers; two of which have bullets; however knowing the bullets are in consecutive chambers, you are only afraid of running into the group of bullets which appears in only 1 of 4 spots (of consecutive bullets) so there's only a 1/4 ~ 25% chance of dying.
AnswerKenntnis:
They are all the same, because you only shuffle once.

The order of blank chambers and bullet are determined in the very beginning of the game.

Prob(Player A got shot) is just the probability of that bullet lies on the chamber player A will shot, for every one it is (number of bullets)$/$(number of chambers)
AnswerKenntnis:
This is a question on conditional probability. The first player will have a 5/6 chance of surviving. If the first player doesn't die, the second player will have a 4/5 chance of surviving, etc. etc. Think about if there are six players, and the first five dudes don't die. Would you want to be the sixth player?
QuestionKenntnis:
Optimizing response times of an ambulance corp: short-term versus average
qn_description:
Background: I work for an Ambulance service. We are one of the largest ambulance services in the world. We have a dispatch system that will always send the closest ambulance to any emergency call. There is a belief that this results in the fastest response time as an average across the system.

Example: Suppose we have the following simplified scenario. We have 3 ambulances available (labelled A, B and C). At any given point in time, there is an random chance of an emergency call originating equally anywhere inside this box:


If an emergency job appears (labelled 1), we will send the closest ambulance (in this case Ambulance C)


You will notice that Ambulances A and B are very close together on the left side of the box (lets pretend they are just leaving a hospital after dropping off their patients). There is now a large gap on the right. Suppose a small amount of time passes, and another emergency call drops in (labelled 2).



Ambulance C is no longer available, so you must use Ambulance A or B. They have a significantly longer distance to travel to reach incident 2. In this case we have sent Ambulance A to the job.

Hypothesis: If you always send the closest ambulance to an emergency call, you will have the quickest response time to that specific call, but the overall average response time of the ambulance service is not optimised.

Using that hypothesis - it would seem to be better to send Ambulance A or B to the original incident 1. This would mean the the next incident to happen, there will be "on average" a significantly shorter distance for the next ambulance to travel.


Question: How can I "prove" this? Is there a mathematical theory or formula? This is obviously a simplifed scenario, there are some other issues - but I just need to prove the fundamental issue that the "closest ambulance being sent to the next incident" actually results in a non-optimal response time across the system as a whole.

To answer some generic concerns:

"Just move A to C's location after C goes on the job"
Yes - we already try to do this - however there is often another "incident" before A gets into the new position. And for other reasons {which are beyond this question} it is not always an option.

"Why are A+B so close together? Perhaps B should be elsewhere?"
There are lots of reasons for ambulances to be 'clumped' together. The main reason is they have probably just offloaded a patient at a hospital - this often causes uneven dispersal of ambulances resources. Other reasons include the physical locations of our stations/depots.

"Volume of work"
We are one of the largest ambulance services in the world. In my scenario I have 3 ambulances. In reality there are approx 100 ambulances, and we service approx 2000 "incidents" per day in our main metropolitan area. At some points in time we run at very high capacity - i.e. almost every ambulance is on an 'incident' - so applying a optimal response strategy across the system will have a significant impact to our response times.

"Ethics of not sending closest ambulance"
Yes - this is not just a mathematical issue. But for the purpose of this Stack Exchange, please limit responses to a mathematical answer. In regards to ethics, I would suggest that if we can lower the "overall" response time (i.e. from 12mins to 10min average) - then "overall" we are ethically providing the best service. If we use a sub-optimal response, and "overall" we provide a slower response, then is not a bad ethical decision? Also - there would probably be exceptions to the rule (i.e. a heart attack or choking would ALWAYS get the closet ambulance - because seconds matter. But for this scenario lets not make it complicated)
AnswersKenntnis
AnswerKenntnis:
Operations problems like this are tricky, because they always include a large element of uncertainty.

As Willie Wong points out, it is possible to construct a scenario in which "closest-first" is a non-optimal strategy. However, proving that there exists a non-optimal strategy does not mean that globally such a strategy is non-optimal.

Wait, what?

In these cases, you have to consider the probability distribution of events as a spatio-temporal process. In such a case, you may construct an algorithm for dispatching emergency services that is almost never optimal for any isolated case, but is globally optimal over all possible cases!

Here is an example: say that your region is circular, and that events only happen on the circumference. Your job is to determine where inside the circle to position your only ambulance. If the distribution of emergency events is uniformly distributed over the circumference, the solution is clearly to position the ambulance at the center of the circle. However, this solution is not optimal for any individual event.

Your question is to prove that the closest ambulance first scheme is not optimal "across the system as a whole." In order to prove that, you need to establish that the probability of a second event happening closer to $C$'s original position than any other ambulance within the time it takes for $C$ to complete its call is higher than not.

If the process is truly Poisson (i.e. completely spatially random in a 2-D region), then this process is simple -- the area of $C$'s Voronoi tessellation would need to be greater than half of the area of your district, assuming that the process intensity is such that the expected call time is short enough that only one event happens on average with Poisson intensity $\lambda$.



Let's explain that last paragraph.

Let's say that you run an ambulance service in Squareville, Australia. This city is completely flat, square, has no roads, and is one unit wide by one unit high.

Say emergencies happen randomly, anywhere in the city. This can be described by a completely uniform spatial 2D point process; the distribution of such a process is called a Poisson distribution. In a Poisson 2D point process, existing points have no influence on the location of the occurrence of subsequent points -- indeed, the location is truly random.

Let's say in an hour, $n$ events occur. The area of Squareville is 1 square unit. This leaves us with an average spatial intensity of $n$ events/unit area. This is known as the intensity factor, or Poisson parameter, often called $\lambda$ and is equivalent to both the mean and variance of the distribution.

In other words,
$$\lambda = n.$$

Now, let's take a connected subset of Squareville, called Squareville Heights. This subset has some area less than 1, let's call it $a < 1$. Because the area of Squareville is 1 square unit, Squareville Heights covers exactly $100a$ percent of Squareville. (For example, if $a = .5$, the region covers 50% of the city).

If you look at the number of events that occur in this region, the average number will be $\lambda a$ -- the global probability, times the area of Squareville Heights. This turns out to be exactly $100a$ percent of the events.

We can look at this another way.

Let's take an hour, and chop it into small intervals $dt$ that are small enough that in any finite region of the city, no more than one emergency will occur. The probability of this emergency happening in Squareville Heights is exactly $a$.



Let's say we have $k$ ambulances distributed somehow throughout Squareville. We want to investigate the probabilities of events happening closer to one ambulance than to another. It turns out this is very easy.

Let $A$ be the co-ordinates of your ambulances. The Voronoi tesselation of a point pattern, $V(A)$, is a set of 2D regions such that each $v_i$ in $V(A)$ is the subset of Squareville such that every point in $v_i$ is closer to ambulance $a_i$ than to any other ambulance.

If an emergency happens in $v_i$, then $a_i$ will be the closest ambulance to the event.

We can inspect the probabilities. Let's say that an emergency happens in $v_1$, and $a_1$ responds. Now let a second event occur while $a_1$ is still responding. The probability of this happening in $a_1$'s original Voronoi tile, $v_1$, is exactly the area of $v_1$, denoted $|v_1|$.

As a result, we can then compute -- in this trivially simplified case -- the probability that sending $a_2$ to the first call would be better than $a_1$.

In this case, there is a $|v_1|$ percent chance that holding $a_1$ and sending $a_2$ to the first call will result in a response-time reduction for the second call.

If the ambulances are also randomly distributed, the mean areas of the tiles will be about .33; however, operationally, the distribution of ambulances is not Poisson, so you will probably have some ambulances that possess relatively large Voronoi tiles.
AnswerKenntnis:
I have little familiarity with ambulances and am not sure if they are stationed when on call, such as a fire truck, but if they are not then you could simply position them such that the distance from any point in the region to the nearest ambulance is minimized.  When a call comes in, the nearest ambulance could respond and the entire formation would reposition immediately such that the distance from any point to any current ambulance was again minimized.

Not sending the nearest available ambulance to an emergency sounds like a liability nightmare.

(Edit)
If the ambulances must be stationed, I would propose the same solution with the only placement positions for the ambulances being the available stations.

In your example, I would still respond with C, and as soon as C leaves I would send A to C's station.
AnswerKenntnis:
I actually see this problem a lot, believe it or not, in World of Warcraft.

The problem is vastly simplified, granted, as it comes in the context of a wargame with fixed points to defend and attack.  But the general idea is the same: one may have, say, three points to defend.  If one base comes under attack, the natural thing to do is to reinforce it--forces not engaged in combat are wasted, after all, but one still has to have adequate protection for the other two bases to deter an opportunistic attack.  What I would do is move forces from the closest unthreatened base to the base being attacked, and then reinforce that base with forces from the furthest base.  So lots of people are in motion, but each has a relatively short distance to go, compared to sending from the furthest base.

So, I suspect--though I certainly couldn't say I can prove--that the optimal strategy here is to still use ambulance C to respond to the initial call and then move ambulance A to a position such that, for any random point in the box, the expected best response time of A and B is minimized.  When C becomes available again, move A back to the configuration that is optimal for 3 ambulances.

By no means do I want to suggest this as the overall strategy without some level of rigor.  I think the things you would want to consider are what the usual timescales are between time to respond to a call, tend to a call, and time between calls.
AnswerKenntnis:
What I propose is this:
Before assigning an ambulance to a call, check the coverage of that ambulance's current vicinity by OTHER ambulances. If you find the coverage to be poor, run the same algorithm on the SECOND nearest ambulance, and so forth. 
(Fundamentally, what we're trying to do is not just assign an ambulance to a call, but to assign an ambulance whose absence will not drag average times down too much.)

To prove its usefulness, I think you can use real-life statistical data and compare real-time response times vs. simulated response times (i.e. the calls are real-time data, but ambulance assignments are hypothetical).
AnswerKenntnis:
Let's simplify the situation to the limit so that you'll see clearly what is going on without heavy computations. Assume that you have two stations at $A$ and $B$, which are $1$ mile apart on a straight road and you get calls from random places in between independently with the uniform distribution. Assume also that the total number of calls is exactly the same as the total number of vehicles. Start with the simplest case when you have $a$ vehicles at $A$ and nothing at $B$. Then you have no choice, so the average travel distance is $\frac a2$. The same is true if your vehicles are all at $B$. Now suppose that you have $1$ vehicle at $A$ and $1$ vehicle at $B$. Then for every position $x$ of the first call ($A=0$ and $B=1$), no matter which vehicle you send, the second call will be at the average distance $1/2$ from the remaining vehicle. Thus, your best bet for the first call is to send the nearest vehicle to it, averaging the distance $1/4$ with the total average $3/4$ for two calls. Suppose now that you have $2$ vehicles at $A$ and $1$ at $B$. Now it gets interesting. Let $x$ be the position of the first call. If you send the vehicle at $A$, you'll travel $x$ and will be left with the $1-1$ situation, which averages to $3/4$. So, your total is $x+\frac 34$. If you send the $B$-vehicle, you travel $1-x$ but after that you are left with $2-0$ and average $1$. So $A$-vehicle should be sent if $x+\frac 34<1-x+1$, i.e., if $x<5/8$. The average will be then $\frac 58(\frac 5{16}+\frac 34)+\frac 38(\frac 3{16}+1)=\frac{71}{64}$. For comparison, the nearest vehicle strategy will give $\frac 12(\frac 14+\frac 34)+\frac 12(\frac 14+1)=\frac 98$. There is a small gain of $\frac 1{64}$ on three calls if you use the optimal strategy. Now let us assume that we have $3$ vehicles at $A$ and $1$ at $B$. Let's run the same analysis. Let $x$ be the place of the first call. If you send an $A$-vehicle, you get $x+\frac{71}{64}$ for the expectation. If you send the $B$-vehicle, you get $1-x+\frac 32$. Now the cutoff is at $x$ satisfying $2x=\frac 52-\frac{71}{64}=\frac{89}{64}$, so $x=\frac{89}{128}$, i.e., now it makes sense to use the better staffed station more than $2/3$ of the way on the first call. I guess you see now what's going on: the better staffed stations (or the places with more stations per unit area) should sometimes be given preference even when the distance is larger (but not too much larger). It is not hard to make a full analysis of this two station model even when the number of calls is random and you have $a$ vehicles at $A$ and $b$ at $B$ and I'll gladly do it for you if you get interested and if I find free time (if you got the idea, you can play with it yourself too now). How much will it tell about the real life? Well, as much as any overly simplified math. model: the general conclusion is correct but the exact cutoffs, etc. are not very realistic.
AnswerKenntnis:
If you just want an explicit example, make your second incident happen exactly where C is stationed. Then in the scenario where


  A picks up incident 2, C picks up incident 1


the total distance traveled is "distance between 1 and C" plus "distance between A and C" (since 2 is where C is stationed). 

In the scenario where


  A picks up incident 1, C picks up incident 2


the total distance traveled is "distance between A and 1" plus "distance between C and 2" (which is zero). 

So we draw a picture with A, C, and 1 on it. The total distance traveled in the first scenario is two legs of the triangle formed by the three points. The total distance traveled in the second scenario is only one leg of the triangle. By the triangle inequality, the sum of lengths of two legs of one triangle must be bigger than the length of the third. This shows that the total distance traveled in scenario one, which is the "closest responder" scenario", can be non-optimal.
AnswerKenntnis:
Scheduling algorithms have only access to information about the past, and are making guesses about what will optimize the unknown future. You have no clue when or where the next emergency will occur. By not sending the closest ambulance to a current emergency, you're risking somebody for a potential gain, which seems unethical. What if you send an ambulance from 10 miles away instead of from 2 miles away, and someone dies? And after that incident, there is no emergency for another 45 minutes?

The problem of keeping the ambulances geographically distributed can be solved without doing away with the closest ambulance policy.

If an ambulance is dispatched somewhere, what you can do is instruct other ambulances to move around in order to keep the ambulances evenly distributed.
AnswerKenntnis:
This is a neat problem and can be approached using stochastic calculus and non-linear optimization. I don't believe its explicitly solvable unless trivial assumptions are made. I'll first describe a way to optimize the initial positions of the ambulance. We will then use cost functions developed in from this optimization to discuss how sending a different ambulance effects response time for future visits.

Things you will need:

EventPdf(x,y): A Probability Distribution Function that describes the probability that an emergency event will occur in over an area. Some models might be equal probability in a bound range, equal probability proportional to population density, the best may be a PDF constructed from real world emergencies occurances.

AverageEmergencyTime: A constant or PDF describing how long an ambulance will be unavailable when going to a call. You can probably get away with a normal distribution or constant on this one.

Cost function:

You'll need a cost function that you will attempt to minimize. You'll probably start with this in time. This will probably include: 

Standard Movement Cost: The average cost in time to move from one position to another. You'll achieve this by integrating over a combination of the ambulance position (x_i,y_i) and their distance from a service area times the frequency of calls in that area. For a grid element you'll always take the cost from the least expensive ambulance.

ElementCost(x,y,x_i,y_i) = distanceFrom(x,x_i,y,y_i)*EventPdf(x,y);

LeastElementCost(x,y) = Min( AmbulanceList.ElementCost(x,y) );

TotalStandardCost = integral(serviceAreaBounds) {(Least_Movement_Cost(x,y))}; 


This will give you a baseline for computing average response time. 

ModifiedCost_i - Removed Ambulance Movement cost: You'll need to then compute the cost if one or more of these ambulances is removed. 

W_i: You'll weight these proportional to the standard cost based on how likely they will be removed and how long they will be removed for. If you have alot of idle time, the standard will be weighted heavily. If one ambulance is almost always busy, you'll find the others weighted heavily. I'm not going to model this, but it can be modeled. You might want to throw out unlikely scenarios.

Cost: Now you construct a total cost function to be minimized.

Cost = W_0*TotalStandardCost + W_1*ModifiedCost_1 ... W_N*ModifiedCost_N


Now you put this into a non-linear optimizer, with x_i,y_i for each ambulance as input variables, and your Cost variable as an output and you tell it to minimize your cost by selecting x_i and y_i for the ambulances.



Anyway, this is a good starting point and is a somewhat realistic model but needs alot of work. You may want to weight your costs more heavily for long response times (e.g. getting sued for taking to long). You may also want to account for ambulances being able to move to new positions when one is busy.

Now that we have a good model we can address your question of sending a different ambulance rather than the closest ambulance. Now we assume a predefined set of x_i,y_i for each ambulance. We can makes changes to the function:

LeastElementCost(x,y) = Min( AmbulanceList.ElementCost(x,y) );


To pick out a different ambulance than the closest one for a response. This will create a different PDF for each of the weighted costs. Integrating over the new PDF will compute a new total cost that can be compared to the unmodified one, it will tell you if you benefit from sending a different ambulance. 

This is a discrete case and can't be handled with a continuous solver. If you have a small number of ambulances ( N is not large), you can search over the entire solution space. I'm betting it'd take a few seconds for 10 ambulances if its coded right.
AnswerKenntnis:
I would approach this by making clear assumptions to you model first.

if you say that

1) all points in the square are equiprobable for an incident

2) all incidents must be responded to by immediately sending an ambulance

3) the cost (time) can be measured as the simple distance between two points



=>you would always try to to have the ambulances distributed across the area (here square) as uniformly as possible.

=> you can always send the nearest ambulance immediately

=> directly after, you send the remaining ambulances to the new points for optimal coverage

=> if two ambulances are equidistant from an incident, you send the one which makes the other ambulances travel as little as possible to reach the new coverage points.



I am sure that this can be proven, however I am not sure if these assumptions are acceptable for you...

Cheers
Fab
AnswerKenntnis:
I think first you need to prove that better assignments are possible with hindsight.
Get a log with, for each call, the time the ambulance was sent out, the positions of the ambulances and of the incident, the ambulance sent, and the time of arrival.  If the availability of ambulances varies, also log the times that they are in service.  If this information isn't available, make it available.  Collect these logs for a year (the density of incidents and maximum traveling speed are likely to fluctuate).

Now you can make a model of travel times between any two points in the area on any time of the day.

Based on this model, determine, per day in the log, all alternative assignments of ambulances to incidents and for each assignment compute the sum of the expected travel time from assigned ambulances to incidents.  Plot the results.  Show how much of a difference it makes.  Translate into numbers of lives lost or similar.  Do the circumstances matter?  (Is the difference lower or higher when the density of incidents is higher?)

Once you've done this, you've established that a different assignment policy may exist that will improve the average response time in the long run.  The next step is to propose such an algorithm and to compare the assignments it produces against the actual assignments in the log.  One idea is to estimate the probability of an incident occurring per area and per time of day, and somehow use this in deciding which ambulance to send.
AnswerKenntnis:
I think we should discuss the modeling of the scenario a bit before discussing optimizing the strategies handling it.

First thing is, we have an area relevant for the scenario that has a probability for an emergency to occur. This probability surely is directly proportional to the density of inhabitants, to the dangers connected with living there. In a big city that is only partly covered with your "area", the emergency probability is likely to be equally high everywhere. Compare this to having ambulances A and B inside a medium town, and ambulance C in a small town, with nothing but outback in between - the emergency probability would have some hot spots around each ambulance with nothing in between.

Second thing is: How urgent can every emergency call be? Not every emergency call is the same. While several situations require medical assistance, only some of them require immediate attention because lifes are in danger. This directly influences the dispatching of any ambulance car: If the second emergency needs more immediate attention, unless the ambulance C has already reached incident 1, can be rerouted to incident 2 while ambulance A or B can be sent to handle incident 1. But this topic is one of the solving strategies, let's save it for later.

Third thing is the positioning of the ambulances. Is having them stationary on defined spots required, or might they be located anywhere? Is every ambulance connected to it's home spot, or are they able to occupy ANY defined spot - at least temporarily.

Fourth: The thing missing is the fact that an emergency evolves in several phases. 1. Emergency call is received. 2. Ambulance is dispatched. 3. Ambulance is on it's way to destination. 4. Ambulance arrives and does first help. 5. Ambulance leaves emergency and transports casualty to a hospital. 6. Ambulance delivers casualty at hospital. 7. Ambulance leaves hospital and returns. 8. Ambulance arrives at home base. (Instead of the visit to the hospital, the ambulance might directly return home.) At each of these phases the ability of the ambulance to react to a new emergency call might be different, so this might offer an option to change plans if incident 2 gets known. But even being unable to change the plan for an already dispatched ambulance, the relevant factor is how long it usually takes to fully handle an emergency call.

Im pretty sure reality inflicts plenty of more factors that have to be considered, like rush hour, quality of the roads, average and maximum speed, etc. but they should be irrelevant for this discussion.

Edge cases: The time it takes for ambulances A or B to arrive at incident 2 has to be less than it takes for ambulance C to handle incidents 1 and 2 one after another, otherwise it's useless to think about dispatching them.

Now about strategies. If we construct a scenario where the two incidents happen within few minutes after each other, and it is impossible to reroute an already dispatched ambulance because the second emergency would be more life threatening, this ambulance will take way longer to handle it's incident than it takes the second ambulance to arrive, and the positions for all the ambulances are fixed, and no ambulance should be sent elsewhere because of the first incident happening, then there really is nothing left to change to improve the situation.

Having the incident handling set in stone allows you to calculate the likeliness of such unfortunate situation to occur based on the factors I described above: a) How likely is it that two incidents occur shortly after another? b) How likely is it that the second incident occurs in a place that is located nearer to the now dispatched ambulance? Think about the emergency probability distribution on the map. c) How likely is it that the second incident is more urgent than the first, and the first is so unhasty that the proper order would be to handle the second first if both emergencies would have been reported at the same time, thus allowing to choose the order.

If you think about it, it might be easy to construct a scenario where dispatching ambulance A to the first emergency makes sense: If ambulance C is located in an area with high emergency probability, thus high probability of two emergencies to occur, and both being equally urgent, and ambulance A being close enough that it can reach emergency 1 in time. But in such a scenario it might be a better option to permanently relocate ambulance A next to ambulance C to improve the situation, because the probability distribution for an emergency would make it somehow predictable that such a situation will occur.

I would conclude that it is in general the best strategy to send the nearest available ambulance to any emergency that occurs. Deviating from such strategy can only be justified if the initial location of ambulances is suboptimal compared to the probability of an emergency.
AnswerKenntnis:
Ignoring ethics, and only going for the most optimal solution speaking only in terms of outcomes, how about applying the Kelly Criterion?  (Anyways, Kelly'll probably tell you to go ahead and send the closest ambulance allowing you to avoid all of those legal/ethical complications in court but most importantly where to place all unoccupied ambulances at a given time.)

While the stock market versions would probably be best since it's geometric rather than arithmetic, and almost everything in the natural world is geometric, the basic version can provide an example, but the distribution of your probabilities should be your guide.

So, as a quick and dirty example, calculate the probability of the call "succeeding" if it takes a call for each point on the map relative to each point on the map.  Calculate the probability of the call "failing" if it takes a call for each point on the map relative to each point on the map.

"b" in the basic model might be harder to come up with, but I bet you and others in the industry probably already have some ideas.  Maybe there are more experienced ambulances who can provide better outcomes for clients/patients?

You can play with this any way you want and make it as complex as you want, but I think you get the picture.  Kelly will stabilize your results and improve outcomes if applied properly.



Rereading the end of question, it sounds like the real question is "how can clustering be dissipated?" since any answer will always have this kink in the calculation.  Remove the clusters, combine almost all answers, and risk will have to approach 0.

(To prevent the user from scrolling)


  There are lots of reasons for ambulances to be 'clumped' together. The
  main reason is they have probably just offloaded a patient at a
  hospital - this often causes uneven dispersal of ambulances resources.
  Other reasons include the physical locations of our stations/depots.


Is it possible to apply the probabilities to the stations' positions?  If there are already areas known to be good hangouts for the ambulances, move a station there from the low probability areas.  

Are there low risk transports that turn your high value EMTs into mere low value taxis?  If so, transport drops could be set up along high probability roads that could allow the EMTs to get back into position faster.  Costs should drop, and revenue should rise allowing more EMTs & taxis.  Despite the improvements in outcomes, you'll still have to use some variant of Jack's Recall (Expected Value) Formula.
AnswerKenntnis:
Considering that there is no real way to know where or when the next call comes in then there is no real way to pick an ambulance other than the current closest one.

However, you can alter the situation a bit in order to optimize response times.

To do this rebalance the equation.  What I mean by this is that once ambulance C has responded to the first call, then you should reposition ambulance A to provide equal coverage across the given area.  

This means that ambulances must be constantly manned and they will be in motion quite a bit moving from one part of the area to another.  This will result in increased costs (for example gas).  However, if you pay attention and properly place your ambulances while constantly rebalancing the target coverage you will end up with reduced response times.
AnswerKenntnis:
I'd like to work the solution in a slightly different way, by refining the model to conform a bit more to reality, and also decrease the problem complexity a bit.

In reality there isn't a continuum of points across the space which are being dealt with, but rather a discrete set of vertices (addresses) connected by (or placed along) edges (roads) of some length (weights) (in other words, the ambulances can't travel through space freely, like a helicopter, but have to use roads to get between points). Additionally the roads are directed in most cities (one-way streets) so we can take lanes of traffic flow to each be a unique edge in a weighted digraph. Additionally each "incident location" can be stated to occur at the intersection closest to the address of the event along the edge (since that's just a shortest distance along a line problem and is easily found).

So to be clear my assumptions are the following:


The incidents occur at intersections only (as they are aggregated to the closest intersection to the actual location of incident)
The ambulances must travel along the roads between intersections
Roads have lengths (which can also be thought of as travel times) between intersections (weights), and directions (for one-way travel).


This means that the problem can be reduced to a weighted digraph within the space. The objective then becomes to minimize the average time taken for an ambulance to get from its current location to any other location after a sequence of random events.

There is some additional information we can get from this model however, mainly the fact that a vertex will have a probability of incident relative to the number of people within its range of effect. As a result the probability distribution need not be considered uniform anymore (Which allows much easier optimization).

Additionally the graph can be thought of as a planar graph in most cases due to the way roads in any service area are likely considered. This gives a very restricted model (of less mathematical complexity) compared to the original (which is also a better approximation of reality). 

Now, for optimization of the response times, let's take another thing into consideration, that the vertex is only considered "in" the graph with probability equal to the probability that an incident will occur at the vertex (a fuzzy set). There is then a "maximal" fuzzy dominating subset of the vertices which will have the highest probability of forming a dominating set over the graph (A set for which every vertex is adjacent to at least one vertex in the dominating set). The ambulances will the attempt to move towards this arrangement constantly unless they are "used" (going to or unloading at a hospital). 

To be mathematically clear:
Given a fuzzy graph $G = (V,E)$ with probability that a vertex v is in G of $\mu_v$

for $D \subseteq V$, D dominates V with probability P(V).

The probability of a set dominating the graph is then the aggregate probability of all of the vertices existing, and the probability that their removal from the graph will cause a non-dominated graph (the expression is a complicated dependent events probability over the entire graph).

By taking only the set which maximizes this as the objective we will minimize the distance from an event that an ambulance is likely to have to travel (which optimizes positioning). The ambulance which should be sent to any location is then the one for which a ratio of the difference in dominating probability should that ambulance go, to the distance of the ambulance from the event:

So given the set of ambulances $A = {a_1, ..., a_n}$ (which can also be thought of as the vertex closest to their location), the one which should go would then be:
$$max(\frac{|P(D)-P(D-{a_i})|}{\delta(a_i,v)} | a_i \in A) = min(\frac{P(D-a_i)}{\delta(a_i,v)} | a_i \in A)$$
Where $\delta(a_i,v)$ is the minimum sum of edge weights between the ambulance $a_i$ and the vertex where the problem happened v (all of these factors will vary dependent on the particular situation in question).
AnswerKenntnis:
It seems your (mathematical) intuition is wrong, at least under the constraints you specified. Let's firm them up as follows:


The goal is to optimize the average time it takes to reach an incident. 
The starting locations of the ambulances are fixed. The question is what order to dispatch them in.
Once an ambulance is dispatched, it is permanently unavailable: It cannot serve other incidents during the same trip, or return to service before the end of the calculation. 


Note that after the second ambulance is dispatched, there is only one ambulance left, and it no longer matters where, timewise: There's a 50% chance that the third incident will be in the opposite side of the map. So, the question is: Starting with the 2 : 1 configuration you present, which dispatch strategy will result in the quickest response, on average, over the first two incidents? 

The result can be generalized to larger sizes, but the two-incident case is instructive. The answer will surprise you: The nearest-ambulance strategy is better!

A, B ----------------------'---------------------- C


Let's draw a line from A/B to C, and label it as the interval [0, 1]. An incident is a uniformly distributed random variable t in this interval. We can equate response time to distance: If there are ambulances on both sides, the response time to an incident at point t is min(t, 1-t). If ambulance A must be dispatched, the response time is simply t. 

The expected value of t, E(t), is 0.5. Obviously t is closer to the left if t < 0.5. It's easiest to consider scenarios by grouping incidents into two random events: Let's call an event L if t is in the left half of the range (t < 0.5), and R if it is in the right half. Then R and L occur with probability 0.5 each. 

There can be four two-incident patterns, occurring with equal probability (0.25): LL, LR, RL, RR. If you could always dispatch from the closest side, the expected travel is 0.25 per incident. You incur a cost when you have to dispatch from the wrong side of the map. The expected length of a "long" trip is 0.75.

So, the payoff matrix is:

incidents   dispatch closest   dispatch A
 L L            A, B             A, B
 L R            A, C             A, C
 R L            C, A             A*, B
 R R            C, A*            A*, C


The right column is your proposed strategy: dispatch A first, then whichever is closest. A star means that the ambulance had to make a long trip (from the wrong side of the map) to get there. Note that there are more stars (penalties) on the right column.

The fourth row in the table is the one you're worried about: What if there's another incident on the right side of the map, after you've dispatched C? The answer is, don't worry! The bottom row has exactly the same cost under the two strategies: When you dispatched A to the first incident, you already incurred the cost you were trying to avoid in the second incident.

But the third case is one you didn't factor in: What if you send A on a long trip, and then C is not needed after all? In this case, dispatch-A will take longer than the dispatch-closest algorithm. 

Since dispatch-A is not better under any scenario, dispatch-closest is superior on average.

Informal summary: If C is closer but you dispatch A, as you propose, you incur a penalty equal to the benefit you will reap if the next incident is nearer to C. So you would break even at best. But the next incident might be closer to A, and you'll never get to collect on your investment. Conclusion: Dispatching the closest ambulance is the better strategy. You can only do better by improving the distribution of ambulances before the second call comes in, as various others suggested. Once the phone rings, sending the closest car is in fact globally optimal.
AnswerKenntnis:
Do you have some legal obligations you must comply with? Some countries have laws that guarantee (to some degree of course) the citizens that ambulance arrives in some specified time frame after an incident has been reported. Which is (probably) actually more important than arriving as soon as possible, since there are some physiological processes that simply are time constrained and had help arrived later it would have just wasted resources.

In such a case you might want to take into account how big unserviceable area  would be created by sending C to 1 in the sense of the time constraint and compare it with the same area created by sending A there (because A is either not located at exactly the same place as B or the probability of an incident there is much higher). You "just" need to find the least wrong metric that would take into account at least the most important factors.

Of course - as already mentioned - real-life data will help you a lot. It can even show, that the current distribution of stations is suboptimal with respect to the long-term statistical distribution of incidents.
AnswerKenntnis:
I think @Gracchus has a great insight into this problem in proposing the Kelly Criterion as a way to attack it.  

The late Thomas Cover of Stanford and other information theorists, following Kelly and incorporating his ideas, have looked at similar problems.  They developed "universal" multivariate optimization approaches, that may very well give you a good way to approach and think about this problem.  

These universal approaches have applications in "Universal Data Compression", "Universal Portfolios", gambling, and a wide range of other areas.

Let me see if I can do them justice.

These approaches don't have parameters to fit.  They make no assumptions about the underlying probability distribution.  They make no attempt to predict the future.  Yet their performance can converge upon that of some most successful approach as if it had hindsight.   

In framing your problem universally, I think you can consider an infinite set of ambulance locations (@Gracchus already kind of thinks like this).  Consider each actual ambulance call an event.  After each event calculate the response time of every possible ambulance location.

Rank the response times and accumulate these rankings over all historical events.  Finally, find the location of the mean-historically-ranked location.       

This "mean ranked" or weighted location will drift over time as random clusters of event locations emerge and dissipate.  It won't necessarily stay at the center of your area.  

In use, I'd guess that you could use this universal locating algorithm in two steps.  Calculate the universal location after each event.  Send the ambulance closest to the universal location to the next call and until you have the next ranking, shift your staging of ambulances so that you have an ambulance heading for the location of the most recently calculated universal position.  When the most recently dispatched ambulance reaches its target, recalculate and reposition.

This doesn't "follow the leader" by assuming that the next call will come from the same place as the last.  I think it would place your ambulances at a kind of the center of gravity of an adaptive optimization.  

Such approaches have something in common with evolution.  Darwin said or implied that the strongest, fastest, or smartest, don't necessarily succeed in the next random events that face the next generation, but rather those whose genetic makeup have placed them in the best position to adapt to whatever really does come next.

Evolution doesn't speculate about the probability of future events.  It doesn't predict the future.  I think these universal approaches have some of the same properties.

The approach also has the interesting ability that you can easily adapt it to the actual times that it takes ambulances to respond, rather than just assuming distance as the measure.  Over time it would adapt to things like traffic, population density, accidents or events that affect more than one person.

Cover and others have proofs for these kinds of approaches.

These approaches have some limitations.  They like lots of events to process.  The larger the number of events the more closely they approach their optimum performance.

Still, it seems like something that might prove useful.
QuestionKenntnis:
The Mathematics of Tetris
qn_description:
I am a big fan of the oldschool games and I once noticed that there is a sort parity associated to one and only one Tetris piece, the $\color{purple}{\text{T}}$ piece.  This parity is found with no other piece in the game.

Background: The Tetris playing field has width $10$.  Rotation is allowed, so there are then exactly $7$ unique pieces, each of which is composed of $4$ blocks.

For convenience, we can name each piece by a letter.  See this Wikipedia page for the Image ($\color{cyan}{\text{I}}$ is for the stick piece, $\color{goldenrod}{\text{O}}$ for the square, and $\color{green}{\text{S}},\color{purple}{\text{T}},\color{red}{\text{Z}},\color{orange}{\text{L}},\color{blue}{\text{J}}$ are the others)

There are $2$ sets of $2$ pieces which are mirrors of each other, namely $\color{orange}{\text{L}}, \color{blue}{\text{J}}$ and $\color{green}{\text{S}},\color{red}{\text{Z}}$ whereas the other three are symmetric $\color{cyan}{\text{I}},\color{goldenrod}{\text{O}}, \color{purple}{\text{T}}$

Language: If a row is completely full, that row disappears.  We call it a perfect clear if no blocks remain in the playing field.  Since the blocks are size 4, and the playing field has width $10$, the number of blocks for a perfect clear must always be a multiple of $5$.

My Question:  I noticed while playing that the $\color{purple}{\text{T}}$ piece is particularly special.  It seems that it has some sort of parity which no other piece has.  Specifically:


  Conjecture:  If we have played some number of pieces, and we have a perfect clear, then the number of $\color{purple}{\text{T}}$ pieces used must be even.  Moreover, the $\color{purple}{\text{T}}$ piece is the only piece with this property.


I have verified the second part; all of the other pieces can give a perfect clear with either an odd or an even number used.  However, I am not sure how to prove the first part.  I think that assigning some kind of invariant to the pieces must be the right way to go, but I am not sure.

Thank you,
AnswersKenntnis
AnswerKenntnis:
My colleague, Ido Segev, pointed out that there is a problem with most of the elegant proofs here - Tetris is not just a problem of tiling a rectangle.

Below is his proof that the conjecture is, in fact, false.
AnswerKenntnis:
There is in fact a straightforward invariant that works in this circumstance - the 'classic' invariant for tiling problems.  Checkerboard-color the grid, and note that all other pieces (the $\color{cyan}{\text{I}}$, $\color{green}{\text{S}}$s, $\color{blue}{\text{J}}$s, and the square) take up an equal number of black and white squares in all orientations; by contrast, the $\color{purple}{\text{T}}$ always takes up three squares of one color and one square of the other.  This implies that for any number of rows (each of which have an equal number of squares of each color) to be perfectly filled, an even number of $\color{purple}{\text{T}}$ pieces must be used.

EDIT: As pointed out by Gilad, this approach only solves the 'static' issue of tiling a rectangle with tetrominoes including the $\color{purple}{\text{T}}$, not the 'dynamic' region-filling that Tetris provides for; see his excellent solution for why this matters if intermediate rows can be cleared and partial-pieces left behind.
AnswerKenntnis:
Does the usual checkerboard coloring resolve this? The $\color{purple}{\text{T}}$-shape covers $3$ squares of one color and one of the opposite. All the other shapes cover $2+2$.

Edit: Well, the same problem as with Steven's solution.
AnswerKenntnis:
Edited to add: The following is only correct if you build up your four lines from 0 (or if you only eliminate four rows at once) which is the way to get maximal points in Tetris. For a counterexample in the general case of clearing the screen in any way you like, see (and vote for) the answer by Gilad Naor 

My original answer:

Color the squares black and white in a chessboard fashion and regard the parity of black squares. This is your invariant.

(The $10\times 4$ rectangle has an even number of black squares, each $\color{purple}{\text{T}}$-piece has $3$ or $1$ black squares and all other pieces clearly have $2$ black squares, so not only do you have an even number of $\color{purple}{\text{T}}$s, you have the same number of predominantly black $\color{purple}{\text{T}}$s and predominantly white $\color{purple}{\text{T}}$s.)

There is a similar further relation for the combined number of $\color{orange}{\text{L}}$s and $\color{blue}{\text{J}}$s:

The number of $\color{orange}{\text{L}}$s, $\color{blue}{\text{J}}$s and $\color{purple}{\text{T}}$s with a horizontal line of three squares is even.

Instead of the checkboard colouring, you just look at the alternate coloring of whole rows and see that these pieces are exactly the ones that contribute an odd number of black squares.
QuestionKenntnis:
Multiple-choice question about the probability of a random answer to itself being correct
qn_description:
I found this math "problem" on the internet, and I'm wondering if it has an answer:


  Question: If you choose an answer to this question at random, what is the probability that you will be correct?
  
  a. 25%
  
  b. 50%
  
  c. 0%
  
  d. 25%


Does this question have a correct answer?
AnswersKenntnis
AnswerKenntnis:
No, it is not meaningful. 25% is correct iff 50% is correct, and 50% is correct iff 25% is correct, so it can be neither of those two (because if both are correct, the only correct answer could be 75% which is not even an option). But it cannot be 0% either, because then the correct answer would be 25%. So none of the answers are correct, so the answer must be 0%. But then it is 25%. And so forth.

It's a multiple-choice variant (with bells and whistles) of the classical liar paradox, which asks whether the statement


  This statement is false.


is true or false. There are various more or less contrived "philosophical" attempts to resolve it, but by far the most common resolution is to deny that the statement means anything in the first place; therefore it is also meaningless to ask for its truth value.



Edited much later to add: There's a variant of this puzzle that's very popular on the internet at the moment, in which answer option (c) is 60% rather than 0%. In this variant it is at least internally consistent to claim that all of the answers are wrong, and so the possibility of getting a right one by choosing randomly is 0%.

Whether this actually resolves the variant puzzle is more a matter of taste and temperament than an objective mathematical question. It is not in general true for self-referencing questions that simply being internally consistent is enough for an answer to be unambiguously right; otherwise the question


  Is the correct answer to this question "yes"?


would have two different "right" answers, because "yes" and "no" are both internally consistent. In the 60% variant of the puzzle it is happens that the only internally consistent answer is "0%", but even so one might, as a matter of caution, still deny that such reasoning by elimination is valid for self-referential statements at all. If one adopts this stance, one would still consider the 60% variant meaningless.

One rationale for taking this strict position would be that we don't want to accept reasoning by elimination on


  True or false?
  
  
  The Great Pumpkin exists.
  Both of these statements are false.
  


where the only internally consistent resolution is that the first statement is true and the second one is false. However, it appears to be unsound to conclude that the Great Pumpkin exists on the basis simply that the puzzle was posed.

On the other hand, it is difficult to argue that there is no possible principle that will cordon off the Great Pumpkin example as meaningless while still allowing the 60% variant to be meaningful.

In the end, though, these things are more matters of taste and philosophy than they are mathematics. In mathematics we generally prefer to play it safe and completely refuse to work with explicitly self-referential statements. This avoids the risk of paradox, and does not seem to hinder mathematical arguments about the things mathematicians are ordinarily interested in. So whatever one decides to do with the question-about-itself, what one does is not really mathematics.
AnswerKenntnis:
The question is underspecified since it doesn't say which distribution is used in choosing an answer at random. Any of the answers could be correct:

If I choose a. with probability 25% and b. with probability 75%, a and d are correct.

If I choose a. with probability 50% and b. with probability 50%, b is correct.

If I choose a. with probability 75% and b. with probability 25%, c is correct.

From the design of the question, it seems that whoever wrote it had in mind a uniform distribution over all four answers, but forgot to specify that. In that case Henning's answer applies.
AnswerKenntnis:
To offer up another perspective on Henning's answer, the question is essentially an elaboration of this (similar) multiple-choice question:


  What is the correct answer to this question?
  
  
  Answer (2)
  Answer (3)
  Answer (4)
  Answer (1)
  


Note that there are some fine puzzles built around variants of the 'self-referential test'; for instance, this simple example:


  Each of the following statements is either true or false.  Which of them are true and which are false?
  
  
  All of these sentences are false.
  Exactly 1 of these sentences is true.
  Exactly 2 of these sentences are true.
  Exactly 3 of these sentences are true.
  Exactly 4 of these sentences are true.
AnswerKenntnis:
If there is one right answer to the question, then you will answer this question statistically 25 percent of the time. If 25 percent is the "right" answer, then you actually have two options. 

If you have 2 options, then 50 percent is the statistical answer. And if since 50 percent is the only option place to mark down, that means that you will only get this answer right 25 percent of the time because you have a 1 in four chance. 

It is impossible without a miracle. Plus, if it is impossible then does that leave the option of 0 open because then there are no right answers? That is saying: "If there are no right answers, this is the right answer." What are you really saying there? Nothing. 

I think maybe you can't find out how many answers there are in the first place. There can't be only one. There can't be only two. There can't be three. There can't be four, and therefore one is the right answer? No. Because then you start back at the beginning.
AnswerKenntnis:
Well, I must be pretty insane if I start competing with these already heavily upvoted answers from high rep users. But although the following solution may sound a little creative or even frivolous, it could easily be the right one. You could say that this solution is reverse engineered, as follows:

The question instructs to only choose one single answer out of four. And assume a uniform distribution, since that is most likely intended, then each answer has a chance of 25% to become chosen.

So the correct answer should be: 25%.

This computes to answer A being correct, as well as answer D. Could that be? Yes, it can. The question does not reveal how many of the four given answers are correct, but since there is one to be picked, assume that at least one of the four answers is correct.

Let's call answer A + answer D the correct answer pair.

Now, there are two possible choices (A or D) that result in 50% of the correct answer (A and D). Secondly, there is 50% chance of picking one (A or D) of two (A and D) out of four (A to D). So whether answer A or answer D is chosen, in either case the probability of being correct (50% ├ù 50%) is 25%, which evaluates true.

Thus, yes, the question has 2 correct answers.

And now I realize that this post is the long version of the by joriki ages ago given comment. ;)



Ok, to be clear about what I mean, I believe the question is a special variant of the following trick question:


  What is the color of the car?
  
  
  Black
  Blue
  Gray
  Metallic
  


As owner of the car I know the correct answer is metallic black. But this would render the question unfair, because it is never possible to give this answer by only selecting one. The difference with the question in question is the equality of both answers to give, which makes it slightly more fair. But since you can select only half of the full solution, the probability is still 25%.
AnswerKenntnis:
See problem 2 here for a similar problem that can be solved.  

SPOILER: Solution here.  Don't look if you want to solve it yourself.



a) can't be the answer because it says b) is correct, but the statement of b) directly contradicts the statement of a)

c) can't be correct, because it means a) and b) are correct but they contradict each other

d) can't be correct.  If it were, it would imply a) or b) or c) to be correct.  The only possibility left is b), since I have already ruled out a) and c).  But, b) contradicts d).

b) canΓÇÖt be correct for the same reason, basically.  If it were true, since a) and c) canΓÇÖt be true, this would imply d) is correct.  But b) contradicts d).

f) can't be correct.  If it were, it would imply that e) is also correct, which would contradict the statement of f).

This leaves only e) and none of the statements contradict e) so e) must be the correct answer.
AnswerKenntnis:
Here is an explanation I came across today.
AnswerKenntnis:
Required probability=(1/4)(1/4)+(1/4)(1/2)+(1/4)(0)+(1/4)(1/4)=1/4.
AnswerKenntnis:
The correct answer is c. 0%. 

Either the conditions we are given are consistent or they are not.

If they are consistent, the way mathematicians solve these kinds of paradoxes is to say that none is provably correct in our formal system, however humans can use higher order reasoning to conclude therefore that c is correct.

If the conditions given are not consistent, then 1=2 and True=False, so c. is correct also in this case.

Conclusion: Only c. is always a correct answer
AnswerKenntnis:
The question starts:

"If you choose an answer to this question at random, "

However it does not then continue:

"what is the probability that the answer chosen will be the probability of choosing that answer?"

It instead says:

"what is the probability that you will be correct?"

And then dosn't define correct.

There are 7 possible answers to the question:

a, b, c, d, 25%, 50% and 0%

However, lets presume that one of the following answers can be chosen:

a, b, c or d

The probability of choosing each answer:

a - 25%
b - 25%
c - 25%
d - 25%
25% - 50%
50% - 25%
0% - 25%


Being correct for "what is the probability that you will be correct?" if there is one correct answer (although as covered above the question doesn't define correct or specify how many answers are correct). This produces the same answer as the question "is the answer you choose the probability of choosing that answer?":

a - yes
b - no
c - no
d - yes
25% - yes
50% - no
0% - no


Now to what I think could be the real question in the question. "what is the probability that the answer chosen will be the probability of choosing that answer?":

For me the answer to this must be 'b' (50%).
AnswerKenntnis:
It is a trick question. let me rephrase the question to keep the misleading elements out


  If you choose an answer to this question at random, what is the
  probability that you will be correct?
  
  
  A
  B
  C
  D
  


Provided that one of the four option is correct (assumption), the probability will be 25% that you are correct. Since you are picking up a random answer (don't bother about logic at all), the correct answer to the question "what is the probability that you will be correct" is 25%. Do not bother about the options, which is misleading.



Edit (Redoing and Correcting): I noticed there are two choices of 25% which is technically wrong because every choice must be different from the another. Lets redo the same example again.

Chances of each selection at random are 1/4 or 25%. That means 25% would select choice A at random, 25% choice B at random and so on. Since we know choice A and D are the correct answer (they are repeated which is wrong), that leads us to 50% correct answer if people make random choices.

So what is the probability that you will be correct is 50% :)
QuestionKenntnis:
Given an infinite number of monkeys and an infinite amount of time, would one of them write Hamlet?
qn_description:
Of course, we've all heard the colloquialism "If a bunch of monkeys pound on a typewriter, eventually one of them will write Hamlet."

I have a (not very mathematically intelligent) friend who presented it as if it were a mathematical fact.  Which got me thinking... Is this really true?  Of course, I've learned that dealing with infinity can be tricky, but my intuition says that time is countably infinite while the number of works the monkeys could produce is uncountably infinite.  Therefore, it isn't necessarily given that the monkeys would write Hamlet.

Could someone who's better at this kind of math than me tell me if this is correct?  Or is there more to it than I'm thinking?
AnswersKenntnis
AnswerKenntnis:
Some references (I am mildly surprised that no one has done this yet).  This is called the infinite monkey theorem in the literature.  It follows from the second Borel-Cantelli lemma and is related to Kolmogorov's zero-one law, which is the result that provides the intuition behind general statements like this.  (The zero-one law tells you that the probability of getting Hamlet is either zero or one, but doesn't tell you which.  This is usually the hard part of applying the zero-one law.)  Since others have addressed the practical side, I am telling you what the mathematical idealization looks like.


  my intuition says that time is countably infinite while the number of works the monkeys could produce is uncountably infinite.


This is a good idea!  Unfortunately, the number of finite strings from a finite alphabet is countable.  This is a good exercise and worth working out yourself.

Edit: also, regarding some ideas which have come up in the discussions on other answers, Jorge Luis Borges' short story The Library of Babel is an interesting read.
AnswerKenntnis:
I found online the claim (which we may as well accept for this purpose) that there are $32241$ words in Hamlet.  Figuring $5$ characters and one space per word, this is $193446$ characters.  If the character set is $60$ including capitals and punctuation, a random string of $193446$ characters has a chance of $1$ in $60^{193446}$ (roughly $1$ in $10^{344000}$) of being Hamlet.  While very small, this is greater than zero.  So if you try enough times, and infinity times is certainly enough, you will probably produce Hamlet.  But don't hold your breath.  It doesn't even take an infinite number of monkeys or an infinite number of tries.  Only a product of $10^{344001}$ makes it very likely.  True, this is a very large number, but most numbers are larger.
AnswerKenntnis:
[Note that in my answer I am actually assuming that there are only a finite number of monkeys.  I don't see what is gained by having both the number of monkeys and the time frame be infinite: mathematically speaking $\aleph_0 \times \aleph_0 = \aleph_0$, and it is somewhat confusing to contemplate infinitely many monkeys typing simultaneously: too much is happening at once.  In fact, there might as well be only one monkey, or at any rate only one typewriter.]

Let me take the unusual (for me) step of considering the practical aspects of this question as well.

As Ross Millikan has explained, there is a simple mathematical model of monkey keyboard pounding under which it is easy to see that the claim is true: the probability that at least one of the monkeys will type out Hamlet approaches $1$ as the time $n$ approaches infinity.  

However there is an assumption here: namely, that the pounding on the typewriter is random or sufficiently close to random.  One way to formalize this is to say that after typing any $n$ characters, the probability of hitting any given key as the $n+1$st character is at least $P$, where $P$ is positive and independent of $n$.  

The problem is that for actual typewriter banging, this is a very unlikely assumption.  The issue is similar here to what happens if you ask someone to produce a random sequence of digits, say from $0$ to $9$, or even a random sequence of $H$'s and $T$'s (for "heads" and "tails"). Just closing your eyes and banging away will produce something very far from being random.  

If the question is meant to apply to actual monkeys with their nonrandom motor behavior, then it is something else entirely.  I would be tempted to say that the probability of producing Hamlet does not approach $1$ as time approaches infinity, but I'm not sure off the top of my head how to justify this.
AnswerKenntnis:
If you have an infinite number of monkeys, then an infinite subset of them will just sit and type out Hamlet, letter-for-letter, straight away. So after a few hours you will have an infinite number of copies of Hamlet.

If you have a finite number of monkeys then you may have to wait. But given in infinite amount of time (and immortal monkeys, etc.), you'll get your Hamlet. Eventually.
AnswerKenntnis:
Hamlet was indeed written after a finite number of monkeys (Shakespeare was a a primate from the family Hominidae!)
AnswerKenntnis:
You donΓÇÖt even need an infinite number of monkeys!  For any $\epsilon > 0$ and $k \geq l(\text{Hamlet})$, there is some number $N$ such that $N$ monkeys at typewriters, each typing for $k$ keystrokes, will produce a copy of Hamlet with probability greater than $1-\epsilon$.  (This holds under some quite weak conditions on our model of monkey typing.)

This is an example of the general ΓÇ£soft analysis to hard analysisΓÇ¥ principle, championed by Terry Tao among others: most any proof in analysis may be transformed into a proof of a quantitative statement such as the one above.

This can be made precise in some generality using various rather beautiful proof-theoretic methods, such as variants of G├╢delΓÇÖs Dialectica translation; lovely results along these lines have been obtained by e.g. Avigad, Gerhardy and Towsner.  In this particular case, the bounds we get will of course depend on the model of monkey typing used.

For instance, if we assume that the keystrokes are independently uniformly distributed, if our Hamlet-recognition criterion is case-, punctuation- and whitespace-insensitive, then for the case $k = l(\text{Hamlet})$, 

$$N = \lceil \frac{\log \epsilon}{\log (1 - \frac{1}{26^{l(\text{Hamlet})}})}\rceil$$

will work.  (The proof is an exercise for the reader.)

Project GutenbergΓÇÖs copy of Hamlet (first folio) weighs in at 117,496 alphanumeric characters.  So if we want to produce Hamlet (first folio) with probability 1/2, in the minimal number of keystrokes, then by some quick slapdash estimating (rounding up a little to be on the safe side), something like $10^{170,000}$ monkeys should certainly suffice!

I guess empirical testing is out ΓÇö ethical controls are so tricky.  Anyone want to run some simulations?
AnswerKenntnis:
It would probably be faster to apply selective pressure to breed intelligent, literary monkeys.  Our common ancestor with chimps lived only 4 million years ago, and by design I'm sure we could make something similar happen faster starting with chimps, bonobos, or whatever.

We could probably get orcas and other whales up to speed very quickly, too!
AnswerKenntnis:
For some reason I want to attribute this reasoning to Douglas Hofstadter, though I couldn't tell you which of his books it's from. Here goes:

If you could get sufficient randomness from an infinite number of monkeys (this is trivial if you assume that by mere chance, a infinite subset will fit the bill ΓÇô or you could follow Arjang's approach and aggregate across monkeys for more entropy, which has the benefit of getting results much faster), you already have every variation of every story ever told. You'll even have every story that ever could be told. Just get an infinite number of monkeys (or a slightly smaller number of computers) and opening a publishing business. Make a million bucks and retire.

But this rings false, especially since modern computing power (relative to the difficulty of the task) is practically infinite, putting the practice of this philosophy within reach. Just imagine trying it yourself. It's not the monkeys or the computers or the printers doing all of the work. Suddenly, you are wading through millions of pages of gibberish text looking for the book that will make you rich. Good luck. (It is the fact that the filtering process is much slower than the production process that makes me say that computer power is practically infinite.)

It's not the characters on the page that make Hamlet. Hamlet is a synthesis of information, a composition that can only be guided by intelligence. In a sea of random characters, the sequence that maps isomorphically to Hamlet is just more noise.

This may sound like a qualified "yes" in response to the question, but in reality it is an empathic "no." It is not the act of producing the character sequence of Hamlet in a random string that writes Hamlet ΓÇô it is the act of finding Hamlet in a random string that writes Hamlet. The distinction may sound subtle, but the two tasks are profoundly different.
AnswerKenntnis:
The answer is yes, With infinite time and all of the infinite monkeys will produce hamlet and every other works infinitely many times. 

After the first keystroke of the infinitely many monkeys, there will be infinitely many hamlets if you just grabbed the first letter from each one of them.

Also at the first keystroke, infinitely of monkeys would have types the first letter of the entire hamlet already, this shows that if you have infinite number of monkeys you only each one of them to type just as many letters as the number of letters in hamlet to have already infinitely many copies of hamlet, so there is no need for infinite time to have one of them produced hamlet, infinitely many of the monkeys would produce infinitely many hamlets in finite amount of time as long as the finite amount of time is equal or greater than the time to type a single copy of hamlet. (this was already mentioned in Bennett McElwee's answer)

If you rephrase the question to : Would an infinite random sequence of letters in 2 dimensions contain at least one hamlet in every and each one of it's columns/rows? then the answer is yes, but there would be infinite number of hamlets contained in each row/column, As an infinite random sequence will contain all it's possible finite sub sequences, infinitely many times. ( Reference needed ).
AnswerKenntnis:
Let me be the one who says NO.
It is a bit hard to handle an infinite number of monkeys (because you will need an infinite number of bananas to feed them), but if you agree to have a finite number of monkeys and infinite time, I would guess that considering the time it should take for this to happen, it is likely that the universe would die before it actually does.

To quote a chat of one of my friends with my first year "intro to CS" professor:


  professor: "So there is no chance that a fair coin would fall with the head side up 50 times in a row."
  
  my friend: "No!, there is such a chance it's just very small...."
  
  professor: "Well yes, its like the chance for all the nitrogen molecules in the air to gather around your head and have you die from lack of oxygen."
AnswerKenntnis:
NOTE: By probability, I mean the chance of it happening per iteration, and starting with a new page each time.

Let's take a step back, shall we? (Not too many, because there's a cliff behind you.) Let's think of what the probability is of producing the following randomly:


  A


Assuming there are only 26 characters (A-Z, uppercase), the probability would be $\frac{1}{26}$.

What about this:


  AA


It'd be $(\frac{1}{26})^2$. This:


  AAA


It'd be $(\frac{1}{26})^3$. And this:


  XKCD


It'd be $(\frac{0}{26})^4$. [Just kidding, it's: $(\frac{1}{26})^4$].

So, for every character we add to the quote, it will be: $(1/26)^c)$, where $c$ represents the number of characters.

Basically, it would be a probability of $(\frac{1}{26*2+12})^c$ since the characters used could be: A-Z, a-z, .!?,;: "'/() Of course, there could be more characters, but that's just an example. :)
AnswerKenntnis:
Monkeys don't produce a proper random distribution on keystrokes. Not even a Markov-chain of keystrokes.

Given infinite time (and an undying support of monkeys) or just infinite monkeys, they will produce infinite text. But that does not need to imply that Hamlet will be part of this infinite long text.



[edit]

There is empirical evidence from such an experiment, reported by the BBC.

The actual text produced is obviously not that random at all.

(@Henry: Thx for these links.)

[/edit]
AnswerKenntnis:
Here's a rather interesting  article  discussing the probability of a monkey producing Shakespeare's works and uses a random letter generator to demonstrate some results.
AnswerKenntnis:
If there truly was an infinite amount of time and monkey, yes, it could happen. However, we know that time and monkeys are both limited. Let's say that the universe will be gone when there are no more neutrons. According to this article, that will be about 10^40 years. There are approximately 4*10^78 atoms. And let's just say that an atom monkey can type at 10^15 keys per second. Let's also assume that there are 40 keys on a typewritter (26 A-Z, numbers, period, comma, semicolon, and space). That'll give the following:

There will be 4e78*365*24*3600*1e15 key strokes per atom, giving a total of 1.26e101. There would then be 5.05e177 key strokes. 40^108=1.0531e+173. That means that there would be segments of around 108 characters of Hamlet around, but certainly not the whole work.
QuestionKenntnis:
A challenge by R. P. Feynman: give counter-intuitive theorems that can be translated into everyday language
qn_description:
The following is a quote from Surely you're joking, Mr. Feynman .  The question is: are there any interesting theorems that you think would be a good example to tell Richard Feynman, as an answer to his challenge?  Theorems should be totally counter-intuitive, and be easily translatable to everyday language.  (Apparently Banach-Tarski paradox was not a good example.)


  Then I got an idea.  I challenged
  them: "I bet there isn't a single
  theorem that you can tell me - what
  the assumptions are and what the
  theorem is in terms I can understand -
  where I can't tell you right away
  whether it's true or false."
  
  It often went like this: They would
  explain to me, "You've got an orange,
  OK? Now you cut the orange into a
  finite number of pieces, put it back
  together, and it's as big as the sun.
  True or false?"
  
  "No holes."
  
  "Impossible!
  
  "Ha! Everybody gather around! It's
  So-and-so's theorem of immeasurable
  measure!"
  
  Just when they think they've got
  me, I remind them, "But you said an
  orange! You can't cut the orange peel
  any thinner than the atoms."
  
  "But we have the condition of
  continuity: We can keep on cutting!"
  
  "No, you said an orange, so I
  assumed that you meant a real orange."
  
  So I always won. If I guessed it
  right, great. If I guessed it wrong,
  there was always something I could
  find in their simplification that they
  left out.
AnswersKenntnis
AnswerKenntnis:
Every simple closed curve that you can draw by hand will pass through the corners of some square.  The question was asked by Toeplitz in 1911, and has only been partially answered in 1989 by Stromquist.  As of now, the answer is only known to be positive, for the curves that can be drawn by hand. (i.e. the curves that are piecewise the graph of a continuous function) 

I find the result beyond my intuition. 



For details, see http://www.webpages.uidaho.edu/~markn/squares/  (the figure is also borrowed from this site)
AnswerKenntnis:
My favorite would probably be Goodstein's theorem:

Start with your favorite number (mine is $37$) and express it in hereditary base $2$ notation.  That is, write it as a power of $2$ with exponents powers of $2$, etc.

So, $37 = 2^{(2^2 + 1)} + 2^2 + 1$.  This is the first element of the sequence.

Next, change all the $2$'s to $3$'s, and subtract one from what's remaining and express in hereditary base $3$ notation.

We get $3^{(3^3 + 1)} + 3^3 + 1 - 1= 3^{(3^3 + 1)} + 3^3$ (which is roughly $2 \times 10^{13}$).  This is the second element of the sequence.

Next, change all $3$'s to $4$'s, subtract one, and express in hereditary base $4$ notation.

We get $4^{(4^4 + 1)} + 4^4 - 1 = 4^{(4^4 + 1)} + 3*4^3 + 3*4^2 + 3*4 + 3$ (which is roughly $5 \times 10^{154}$) .  This is the third element of the sequence.

Rinse, repeat:  at the $n^{th}$ stage, change all the "$n+1$" to "$n+2$", subtract $1$, and reexpress in hereditary base $n+2$ notation.

The theorem is: no matter which number you start with, eventually, your sequence hits 0, despite the fact that it grows VERY quickly at the start.

For example, if instead of starting with $37$, we started with $4$, then (according to the wikipedia page), it takes $3*2^{(402653211)} - 2$ steps ( VERY roughly $10^{(100,000,000)}$, or a $1$ followed by a hundred million $0$s).  $37$ takes vastly longer to drop to $0$.
AnswerKenntnis:
Suppose you have a large collection of books, all of the same size.  Balance one of them on the edge of a table so that one end of the book is as far from the table as possible.  Balance another book on top of that one, and again try to get as far from the table as possible.  Take $n$ of them and try to balance them on top of each other so that the top book is as far as possible away from the edge of the table horizontally.

Theorem:  With enough books, you can get arbitrarily far from the table.  If you are really careful.  This is a consequence of the divergence of the harmonic series.  I think if you haven't heard this one before it's very hard to tell whether it's true or false.
AnswerKenntnis:
The Monty Hall problem fits the bill pretty well. Almost everyone, including most mathematicians, answered it wrong on their first try, and some took a lot of convincing before they agreed with the correct answer.

It's also very easy to explain it to people.
AnswerKenntnis:
You have two identical pieces of paper with the same picture printed on them. You put one flat on a table and the other one you crumple up (without tearing it) and place it on top of the first one. Brouwer's fixed point theorem states that there is some point in the picture on the crumpled-up page that is directly above the same point on the bottom page. It doesn't matter how you place the pages, or how you deform the top one.
AnswerKenntnis:
My first thought is the ham sandwich theorem--given a sandwich formed by two pieces of bread and one piece of ham (these pieces can be of any reasonable/well-behaved shape) in any positions you choose, it is possible to cut this "sandwich" exactly in half, that is divide each of the three objects exactly in half by volume, with a single "cut" (meaning a single plane).
AnswerKenntnis:
Scott Aaronson once basically did this for a bunch of theorems in computer science here and here.  I particularly like this one:


  Suppose a baby is given some random examples of grammatical and ungrammatical sentences, and based on that, it wants to infer the general rule for whether or not a given sentence is grammatical. If the baby can do this with reasonable accuracy and in a reasonable amount of time, for any ΓÇ£regular grammarΓÇ¥ (the very simplest type of grammar studied by Noam Chomsky), then that baby can also break the RSA cryptosystem.
AnswerKenntnis:
You ask that the result be "counterintuitive", but Feynman doesn't insist on that.  He says that if you can phrase a true-or-false mathematical question in language that he can understand, he can immediately say what the right answer is, and that if he gets it wrong, it is because of something you did.

I think Feynman is being less than 100 percent serious.  Not that he didn't win every time he put this challenge to people--- but he probably only issued this challenge when he wanted to make a rhetorical point (about either the impracticality of a lot of mathematical investigation, or about the inability of mathematicians to faithfully translate their problems into normal language).

The Banach-Tarski result is obviously a terrible example, because the key to any paradoxical decomposition of a sphere, nonmeasurability, is almost impossible to convey in non-technical terms, and has no physical meaning.  And of course he would choose this example for his essay, if the only purpose of the challenge is to make the point illustrated marvelously by that particular response.

Here are some statements that might have given Feynman some pause.


The regular $n$-gon is constructible with an unmarked ruler and compass.  (Really a family of true-or-false statements, one for each $n \geq 3$.)

It takes some work to properly spell out what "constructible" means here, but it can be done in plain English.  It has been known since the 1800s (thanks to Gauss and Wantzel) that this statement is true if $n$ is the product of a nonnegative power of $2$ and any nonnegative number of distinct Fermat primes, and false otherwise.  

More concretely, the sequence of positive integers $n$ for which it is true is partially listed here.  Could Feynman have generated that sequence with his series of answers to true-or-false questions given by taking $n=3,4,5,\dots$?  I very much doubt it.
The Kelvin conjecture (roughly, "a certain arrangement of polyhedra partitions space into chunks of equal volume in a way that minimizes the surface area of the chunks"--- but you can be more precise without leaving plain English).  According to Wikipedia it was posed in 1887.  It was neither proved nor disproved until 1993, when it was disproved.

I find this example particularly compelling because Feynman presumably would not have caricatured Kelvin (something of a physicist himself) as a mathematician who only works on silly questions that nobody would ever ask.
Other geometrical optimization problems come to mind, e.g. the Kepler conjecture, the double bubble conjecture, and the four color conjecture (all theorems now, but let's pretend they're conjectures and ask Feynman).  My guess is that Feynman would have been right about the truth values of these statements.  But the mathematician's response is, of course, "OK.  Why are they true?"


This highlights a real difference between math and the physical sciences.  It is much more common in the sciences to be in a situation where knowing what happens in a given situation is useful, even if you don't know why it happens.  In math, this is comparatively rare: for example, the "yes or no" answers to the Clay Millennium problems are nowhere near as valuable as the arguments that would establish those answers.  Feynman almost certainly knew this, but pretended not to in order to make the rhetorical points mentioned above.
AnswerKenntnis:
There are true statements in arithmetic which are unprovable.  Even more remarkably there are explicit polynomial equations where it's unprovable whether or not they have integer solutions with ZFC! (We need ZFC + consistency of ZFC)
AnswerKenntnis:
It is possible for a group of people to hold a secret ballot election in which all communication is done publicly. This is one of the many surprising consequences of the existence of secure multiparty computation.

(Of course, the ballots are only "secret" under some reasonable cryptographic assumptions. I guess Feynman may have objected to this.)
AnswerKenntnis:
What is the smallest area of a parking lot in which a car (that is, a segment of) can perform a complete turn (that is, rotate 360 degrees)?

(This is obviously the Kakeya Needle Problem. Fairly easy to explain, models an almost reasonable real-life scenario, and has a very surprising answer as you probably know - the lot can have as small an area as you'd like).

Wikipedia entry: Kakeya Set.
AnswerKenntnis:
One that Feynman would have rejected: There are always two antipodal points on the Earth that are the same temperature. (This follows from the fact that a continuous scalar field on a circle has a diameter whose endpoints have the same value)

One that Feynman might have preferred:
Draw a triangle. Draw a circle through the midpoints of the triangle's sides. This circle also passes through the the foot of each altitude and the midpoint of the line segment from the orthcentre to each vertex. The nine point circle
AnswerKenntnis:
Similar to the Monty Hall problem, but trickier: at the latest Gathering 4 Gardner, Gary Foshee asked 


  I have two children. One is a boy born on a Tuesday. What is the probability I have two boys?


We are assuming that births are equally distributed during the week, that every child is a boy or girl with probability 1/2, and that there is no dependence relation between sex and day of birth.

His Answer: 13/27. This was in the news a lot recently, see for instance BBC News.  (Later analysis showed the answer depends on why the parent said that.)
AnswerKenntnis:
The Fold-and-Cut Theorem is pretty unintuitive. http://erikdemaine.org/foldcut/
AnswerKenntnis:
All of three dimensional space can be filled up with an infinite curve.
AnswerKenntnis:
Position-based Cryptography. This is a fun example since it seems very "out of left field".

The setup:
Three servers are positioned in known locations on the globe (their positions can be arbitrary, provided they aren't on top of each other).

A single computer wants to prove its location to the servers. In other words, if the computer is actually located where it claims, then the protocol will accept. However, if the computer is located anywhere else, then the protocol will reject, no matter how the computer cheats (it is even allowed to recruit friends to help it cheat).

All communication is subject to the laws of physics -- information travels at speed c, and quantum mechanics holds.

Theorem 1: This is impossible if all communication is classical. Cheating is always possible.

Theorem 2: This is possible if quantum communication is possible.
AnswerKenntnis:
Now that Wiles has done the job, I think that Fermat's Last Theorem may suffice. I find it a bit surprising still.
AnswerKenntnis:
For any five points on the globe, there is an angle in outer space from which you could see at least 4 of the 5 points (assuming the moon or anything isn't in the way).  The proof is pretty simple, too...
AnswerKenntnis:
Morely's trisection theorem -- not discovered until 1899.  http://www.mathpages.com/home/kmath376/kmath376.htm.

Trisect the three angles of a triangle. Take the intersection of each trisector with its nearest trisector of the nearest other vertex. These three points form an equilateral triangle!

With bisectors, they all meet in a point.  That trisectors should give an equilateral triangle is pretty surprising.
AnswerKenntnis:
The rational numbers are both a continuum (between any two rationals you can find another rational) and countable (they can be lined up in correspondence with the positive integers).

Mathematician missed it for hundreds (thousands?) of years, until Cantor.

Of course, the proof of that works both ways, and is equally surprising the other way -- there is a way to order the integers (or any countable set) that makes it into a continuum.
AnswerKenntnis:
"The natural numbers are as many as the even natural numbers".

This statement is trivial and not worth to be named "theorem", but it is rather counterintuitive if you don't know the meaning of "as many". At least, it was for Galileo :)
AnswerKenntnis:
A very counter intuitive result is "The Lever of Mahomet". I saw this somewhere in the 4 volume set,"The World of Mathematics" (ca. 1956). It works like this: Imagine a flatbed rail car with a lever attached by a hinge such that the lever swings 180 degrees in a vertical arc, parallel to the tracks. We assume the lever has no friction, and is only influenced by gravity, inertia, and the acceleration of the rail car. (assume other idealizations, like no wind). Now, the question is, given ANY predetermined motion of the railcar, both forward and backwards, however erratic (but continuous and physically realizable of finite duration), show there exists an initial position of the lever such that it will not strike the bed at either extreme of travel during the prescribed motion. The solution only invokes the assumption of continuity.
AnswerKenntnis:
Goldbach's Conjecture.

Granted this is open, so it may be cheating a bit. However, this seems like a very hard problem to intuit your way to the "conventional wisdom". By contrast, P != NP is "obviously" true. Indeed, Feynman had trouble believing P != NP was even open.
AnswerKenntnis:
Not exactly a theorem but nevertheless interesting.

(By an "interval" i will mean ratio between two sound frequencies) 

Ask Feynman: "I'm interested in a tuning system which has an exact octave and an identical interval between any two adjacent notes. How much steps should i use (in other words to how many equal intervals should i dissect the octave) to best approximate the first 4 harmonics?" 

(The first 4 harmonics of say C, are C, G, C, E. the famous major chord!)

Feynman will probably tell you to shut up and just use the regular 12-tone scale like everyone else. Unfortunately he will be right. 12 is a better a approximation then all it's predecessors (integers smaller then 12) .

Although If you will insist and ask: "What is the next best approximation?" 

Then you have a chance of tackling him. It turns out the next best approximation is 41!
AnswerKenntnis:
Every set can be well ordered, I once sat on the bar of my favourite place and ran into this girl I haven't seen for years. I explained a bit about AC, Zorn's Lemma and the Well-Ordering principle and that they are all equivalent.

(In another time, my friend told me that if every set can be well-ordered I should tell him the successor of 0 in the real numbers, I answered that 1 is. He then argued that he means the real numbers, and not the natural numbers. I told him that my well-order puts the natural numbers with the usual ordering first, then the rationals and then the irrationals. But I can shift a finite number of positions if he wants me to.)
AnswerKenntnis:
An infinite amount of coaches, each containing an infinite amount of people can be accommodated at Hilbert's Grand Hotel. Visual demonstration here.
AnswerKenntnis:
I should think the right phrasing of Arrow's impossibility theorem a reasonable candidate.
AnswerKenntnis:
What about the birthday problem?
AnswerKenntnis:
Here's my two cents worth. 

We have three sets: $\mathbb{R}$, $\{x \in \mathbb{R}:x \in [0,1]\}$, and the Cantor (ternary) set. They all have the same "size", the same number of elements (cardinality), which is uncountably infinite, but they have measure $\infty$, $1$ and $0$ respectively. That is, for any arbitrary length I can find an uncountably infinite set with that measure.

P.S. I'm surprised no one mentioned Russell's paradox.
AnswerKenntnis:
Theorem: Any predicate which can be evaluated in polynomial time on a nondeterministic turing machine can be evaluated in polynomial time on a deterministic turing machine.

Or is asking an open question cheating? :)
QuestionKenntnis:
Riddle: 1 question to know if the number is 1, 2 or 3
qn_description:
I've recently heard a riddle, which looks quite simple, but I can't solve it :/

The girl thinks of a number which is 1, 2, or 3

The boy then asks just 1 question about the number

The girl can only answer "Yes", "No", or "I don't know"

And after the girl answers it, he knows what the number is.

What is the question?

Note: girl is professional in maths and knows EVERYTHING about these three numbers

EDIT:

The person who told me this just said the correct answer is:


   "I'm also thinking of a number. It's either 1 or 2. Is my number less than yours?"
AnswersKenntnis
AnswerKenntnis:
"I am thinking of a number which is either 0 or 1. Is the sum of our numbers greater than 2?"
AnswerKenntnis:
"I'm also thinking of one of these numbers. Is your number, raised to my number, bigger than $2$?"

Let $n$ be the girl's number (unknown to me), and let $m$ be my number (unknown to her).


$n = 1 \implies $ NO: $1^m = 1 \not > 2$ for all $m \in \{1,2,3\}$.
$n = 3 \implies $ YES: $3^m \geq 3 > 2$ for all $m \in \{1,2,3\}$.
$n = 2 \implies $ I DON'T KNOW: Whether $2^m > 2$ depends on $m$.
AnswerKenntnis:
I just saw this question and signed up to math.stackexchange just because I felt like sharing my answer. I haven't read the other answers so pardon me if I am repeating anyone's answer.

Here's my thought process:

First of all I ruled out indirect ways of using reference to either of the numbers 1, 2 ,3 to frame a question, as I thought it's implicit in the question that it should challenge ur thinking, not ur cleverness.
If she answers I don't know, compared to yes or no, it is more likely that she is confused between two numbers, ruling out one possibility. 
If the boy thinks of a number, the most common way to link it up to 1, 2 ,3 will be by divisibility.
Also, I thought, out of 1, 2, 3, if I can rule out one number by the way I frame the question, I will be left with two options. The most common way of describing a number is whether it's odd or even.

So how about, I am thinking of an odd number. Is it perfectly divisible by your number?

If she says, no - clearly, the number is 2.
If she says, yes - the number is 1, because only with 1, you can be sure that any number is divisible by 1.
If she says, I don't know - the number is 3, because an odd number can or cannot be divisible by 3.

Solving this gave me some serious thought-boosting fun - like a sip of hot black coffee in the morning :)
AnswerKenntnis:
Let the boy ask the girl: 


  "Divide the number you have with the previous number. Is the result a fraction?"


If the girl replies:


"Yes" then the number is 3 because 3/2 is a fraction.
"No"  then the number is 2 because 2/1 is not a fraction.
"I don't know" then the number is 1 because 1/0 is undefined.
AnswerKenntnis:
Pick any bijective mapping from $\{1,2,3\}$ to $\{\text{Yes},\text{No},\text{I don't know}\}$ and then it is easy to contrive a question.

Here's an example question using this method.


  Let $f =\{(1,\text{Yes}),(2,\text{No}),(3,\text{I don't know})\}$ and let $x$ be the number that you are thinking of. What is $f(x)$?


This can be generalized to any set of possible numbers and set of possible responses with the same cardinality.
AnswerKenntnis:
"Among all prime numbers except 3, is there a positive and finite number of couples whose difference is the number you are thinking of?"

$N = 1 \implies$ no, since there are none ( $\{2, 3\}$ is disallowed).

$N = 2 \implies$  I don't know, at least until the Twin Primes conjecture is proved or disproved.

$N = 3 \implies$ yes, since there is only $\{2, 5\}$.
AnswerKenntnis:
The question doesn't state that the BOY is an expert in maths, so he'd probably go for:

Please say "no" if your number is 1, "don't know" if your number is 2, or "yes" if your number is 3.
AnswerKenntnis:
Question 1:

I'm thinking of a huge integer number with last digit $7$.

Is this ratio $~~\dfrac{\mbox{my number}}{\mbox{your number}}~~$ integer?


$1$ (yes)
$2$ (no)
$3$ (I don't know)




Question 2:

Consider series $\displaystyle\sum\limits_{n=1}^\infty a_n, \quad (a_n>0, ~~~ n \in \mathbb{N})$,
such that there exists limit (see Ratio test)
$$
L = \lim_{n\to \infty} \frac{a_{n+1}}{a_n}.
$$
If $L+1$ is equal to your number, is this series convergent?


$1$ ($L=0$, yes)
$2$ ($L=1$, I don't know)
$3$ ($L=2$, no)
AnswerKenntnis:
ΓÇÿIs there a perfect number $n$ such that $n+1$ is a multiple of your number?ΓÇÖ If her number is $1$, the answer is obviously yes; if her number is $2$, the answer is I donΓÇÖt know, since itΓÇÖs not known whether there are any odd perfect numbers; and if her number is $3$, the answer is no, because every even perfect number greater than $6$ is congruent to $1$ mod $3$.
AnswerKenntnis:
If $x$ is your number, is my brother's height in metres more than $10(x-2)+2$?
AnswerKenntnis:
This was suggested by a friend:


  If $k$ is your number, does $\mathbb{S}^{3k-2}$ have an exotic smooth structure?
AnswerKenntnis:
The girl take a number in {1, 2, 3}. I say to her: "Ok, now, imagine I know your number and pick one of the other, is your number greater than mine?"


If she has picked 1, she will answer "no" because 1 < 2 and 1 < 3.
If she has picked 2, she will answer "I don't know" because 2 > 1 but 2 < 3.
If she has picked 3, she will answer "yes" because 3 > 1 and 3 > 2.
AnswerKenntnis:
Is it correct that your number equals 1 or it equals 2 and {any question she don't know answer for}?

Yep, it's a boring answer, but it always works for such kind of problems.
AnswerKenntnis:
"If two less than your number is the second derivative of a function at a turning point, is that point a local minimum?"
AnswerKenntnis:
Here's my wife's solution:

The boy asks: "I have an equation of the form $ax^2+bx+c=0$ in my mind, in which $b^2-4ac \geq 0$. Is the number of its real roots less than your number?"


If the girl's number is 3, then her answer is "yes". 
If the girl's
number is 2, then her answer is "I don't know". 
If the girls' number
is 1, then her answer is "no".
AnswerKenntnis:
Let $n$ be the number you are thinking. And let $x$ and $y$ be positive integers I am thinking. Is there a positive integer solution $z$ for the following equation? 

$$
x^n+y^n=z^n
$$


Yes then $n=1$
I don't know then $n=2$
No then $n=3$ because of the following proven conjecture



  It is impossible to separate a cube into two cubes, or a fourth power into two fourth powers, or in general, any power higher than the second, into two like powers. I have discovered a truly marvelous proof of this, which your browser is too narrow to contain.
AnswerKenntnis:
I get the sense that there's a classic comedy routine in here somewhere.


  "You know, they give baseball players these days very peculiar names. [...] Well, now, let's see ... On our team we have: NO's on first, YES's on second, and I-DON'T-KNOW's on third ..."
AnswerKenntnis:
Does the girl know computing addition to math? Probably. 

"Here is an array of three character strings, indexed from [1]:

s[] = { "Yes", "No", "I don't know" }


what is the value of s[x] where x is the number you are thinking of?"

Basically, the space of three possible answers can be used as symbols to encode the information directly. 

Justification, in the light of comments:

The other answers differ in that they employ an arithmetic and logical coding trick: arithmetic is applied and then logic to produce an answer, whose truth value or in determinacy is then rendered to English "Yes", "No" or "I don't know".

It is just as valid and "mathematical" to simply obtain these symbols directly without using arithmetic coding.

Furthermore, it can still be regarded as arithmetic coding, because the answer strings are made of bits, and can therefore be coded as numbers: for instance, the bit patterns of the ASCII characters can be catenated together and treated as large integers. s is then effectively just a numeric table lookup which maps the indices 1 through 3 to integer symbols which denote text when broken into 8 bit chunks and mapped to ASCII characters.

A lookup table, though arbitrarily chosen, is a mathematical object: a function. 

Furthermore, the displacement calculation to do the array indexing is arithmetic; we are exploiting the fact that the information we are retrieving is numeric and can be used to index into a table. Otherwise we would have to specify an associative set relation instead of a function from the integer domain. ("Here is a mapping of your possible state values to the symbols I'd like you to use to send me the value.")

This answer reveals that the question is basically uninteresting. An entity holds some information that can be in one of three states, and there is to be a three-symbol protocol for querying that information. It boils down to, give me the symbol which corresponds to your state, according to this state->symbol mapping function. I would therefore argue that the convoluted arithmetic coding is the hack answer not this straightforward coding method. In computing, we sometimes resort to arithmetic encoding hacks when we have to use a language that isn't powerful enough to do some task directly, or simply when the resources (time, space) aren't there for the cleaner solution.
AnswerKenntnis:
I am thinking of a positive integer. Is your number, raised to my number and then increased in $1$, a prime number?

$$1^n+1=2\rightarrow \text{Yes}$$
$$2^n+1=\text{possible fermat number}\rightarrow \text{I don't know}$$
$$3^n+1=2k\rightarrow \text{No}$$
AnswerKenntnis:
$\frac12-it$ is a zero of the zeta function. Is $\frac{N-1}{2}\frac12+it$ also a zero of the zeta function?

$N = 1 \implies$ no, since $it$ is not on the critical strip.

$N = 2 \implies$ I don't know, since the Riemann hypothesis has not been proved. 

$N = 3 \implies$ yes, since the conjugate of a zero is another zero.
AnswerKenntnis:
Most of the answers seem to rely on relatively complex mathematics, that I couldn't easily do in my head. I'm hoping this is the simpliest answer out there, or at least, one of the simplest.

If I take your number, and subtract 2 from it, then take the reciprocal, is it positive? In other words: $\frac{1}{x-2}$


Yes- Number must have been 3
No- Number must have been 1.
I don't know- Is 1/0 positive or negative? It could be either, and thus I Don't Know is the appropriate answer.
AnswerKenntnis:
The boy gives the three numbers different names: "Yes", "No" and "I don't know". So the question is, "what is the name of your number?"
AnswerKenntnis:
How about this one:


  Let's say your number is $n$.
  For every even number $x$ ($x>2$) is that true that $x+n$ is representable as a sum of $n$ primes?
AnswerKenntnis:
Two silly, brute-force, examples, which (I hope) give two fairly extensible ways of constructing an answer to this problem.  $n$ refers throughout to the girl's number.

The unsolved problem in mathematics approach: (E.g., @alex's answer)



Is there a Moore graph of girth $5$ and degree $f(n)$?  Here, 

$$
f(n)=\begin{cases}2&n=1\\4&n=2\\57&n=3\end{cases}
$$



$2\mapsto$Yes (the Petersen graph)

$3\mapsto$No (A Moore graph of girth $5$ may only have degree $2,3,7$ or $57$)

$57\mapsto$I don't know (It is unknown whether a Moore graph of girth $5$ and degree $57$ exists).

The unconditional (on any unsolved result being unsolved!) probabilistic approach: (E.g., @Ben Millwood's answer)

Maybe the girl has constructed a Moore graph of girth $5$ and degree $57$ in her head, or read a recent paper exhibiting such a graph.  In that case, the following approach works.  



Let $G(n)$ be a random variable taking values in the set $\{1,2\}$.  The probability distribution is defined as follows: $G(1)$ is always $1$, $G(2)$ is always $2$ and $G(3)$ is $1$ with probability $0.5$ and $2$ with probability $0.5$.  

[Fix a point in the sample space.]  Is it the case that $G(n)=1$?
AnswerKenntnis:
The mathematician's answer: 

I am thinking of a function $f:\{1,2,3\}\to\{0,1\}$.  $f$ takes $1$ to $0$, $2$ to $1$ and $3$ either to $0$ or $1$, but I'm not telling you which.  

Let $n$ be your number.  Is $f(n)$ equal to $1$?
AnswerKenntnis:
For an unknown $x$, is your number 1 or (2 and $x$)?

YES means that the number is 1
NO means that the number is not 1 and not 2 -- so it's 3
I DON'T KNOW means that the number is 2 (since the (2 and $x$) clause will be true if $x=2$ and false otherwise)
AnswerKenntnis:
Without any math involved:

Boy: I'll map your numbers to your answers. 1 means "NO", 2 means "YES", 3 means "I don't know", the first word that comes out of your mouth, will you please say the phrase that is mapped to the number you are thinking of?

Girl: ahhhhhhhhhh
Boy: No, you have to say it


First dimension: 

Girl: NO
BOY: Then it's 1


Alternate dimension:

Girl: YES
BOY: Then it's 2


Altnerate dimension after that:

GIRL: I DON'T KNOW
BOY: Then it's 4, I mean 3
AnswerKenntnis:
If k is your number,
  does each continuous mass distribution ┬╡ in $\mathbb{R}^{3k-2}$  admit
  an equipartition by hyperplanes ?
AnswerKenntnis:
Here's one involving probabilistic trials.

If I were to choose a random variable $x$ distributed at $N(2, 0.01)$ but cut off at $[1.5, 2.5]$, would the number you're thinking of be higher than $x$?

If you're thinking of $1$, your answer is "no".

If you're thinking of $2$, your answer is "I don't know", since there's a 50-50 chance either way.

If you're thinking of $3$, your answer is "yes".
AnswerKenntnis:
Assume the girl's number is X.

The boy asks:


  Is half day before OP posted this question past October X?
QuestionKenntnis:
How many fours are needed to represent numbers up to $N$?
qn_description:
The goal of the four fours puzzle is to represent each natural number using four copies of the digit $4$ and common mathematical symbols.

For example, $165=(\sqrt{4} + \sqrt{\sqrt{{\sqrt{4^{4!}}}}}) \div .4$.


  If we remove the restriction on the number of fours, let $f(N)$ be the number of fours required to be able to represent all positive integers no greater than $N$. What is the asymptotic behaviour of $f(N)$? Can it be shown that $f(N) \sim r \log N$ for some $r$?


To be specific, letΓÇÖs restrict the operations to the following: 


addition: $x+y$
subtraction: $x-y$
multiplication: $x\times y$
division: $x\div y$
exponentiation: $y^x$
roots: $\sqrt[x]{y}$
square root: $\sqrt{x}$
factorial $n!$
decimal point: $.4$
recurring decimal: $. \overline 4$


It is easy to see that $f(N)$ is $O(\log N)$. For example, with four fours, numbers up to $102$ can be represented (see here for a tool for generating solutions), so, since $96 = 4\times4!$, we can use $6k-2$ fours in the form
$(\dots((a_1\times 96+a_2)\times 96+a_3)\dots)\times96+a_k$
to represent every number up to $96^k$.

On the other hand, we can try to count the number of distinct expressions that can be made with $k$ fours. For example, if we (arbitrarily) permit factorial only to be applied to the digit $4$, and allow no more than two successive applications of the square root operation, we get $\frac{216^k}{18}C_{k-1}$ distinct expressions where $C_k$ is the $k$th Catalan number. (Of course, many of these expressions wonΓÇÖt represent a positive integer, many different expressions will represent the same number, and the positive integers generated wonΓÇÖt consist of a contiguous range from $1$ to some $N$.) 

Using StirlingΓÇÖs formula, for large $k$, this is approximately $\frac{864^k}{72k\sqrt{\pi k}}$. So for $f(N)$ to grow slower than $r\log N$, weΓÇÖd need to remove the restrictions on the use of unary operations. (It is well-known that the use of logs enables any number to be represented with only four fours.)


  Can this approach be extended to show that $f(N)$ is $\Omega(\log N)$? Or does unrestricted use of factorial and square roots 
  mean that $f(N)$ is actually $o(\log N)$?
  Is the answer different if the use of $x\%$ (percentages) is also permitted?
AnswersKenntnis
AnswerKenntnis:
I'm one of the authors of the paper referenced by David Bevan in his comment. The four-fours was one inspiration for that problem, although others have thought about it also. The specific version of the problem there looks at the minimum number of 1s needed to represent n where one is allowed only addition and multiplication but any number of parentheses. Call this g(n). For example, g(6) <= 5, since 6=(1+1)(1+1+1), and it isn't hard to show that g(6)=5. Even in this limited version of the problem, the question is generally difficult even to get asymptotics. 

In some sense most natural questions of asymptotic growth are somewhat contained in this question, since one can write any given k as 1+1+1...+1 k times, and 1=k/k. Thus starting with some k other than 1 (such as k=4), the asymptotics stay bounded within a constant factor, assuming that addition and division are allowed.

However, actually calculating this sort of thing for any set of operations is generally difficult. In the case of integer complexity one has a straightforward way of doing so, since if one calculates g(i) for all i less than n, calculating g(n) is then doable. This doesn't apply when one has other operations generally, with division and substraction already making an algorithm difficult. In this case, one can make such an algorithm but exactly how to do so is more subtle. In fact, as long as one is restricted to binary operations this is doable (proof sketch: do what you did to look at all distinct expressions). 

Adding in non-binary operations makes everything even tougher. Adding in square roots won't make things that much harder, nor will adding factorial by itself. The pair of them together makes calculating specific values much more difficult. My guess would be that even with factorial, square root and the four binary operations there are numbers which require arbitrarily large numbers of 1s, but I also suspect that this would be extremely difficult to prove. Note that this is already substantially weaker than what you are asking- whether the order of growth is of log n. Here though square roots probably don't alter things at all; in order for it to matter one needs to have a lot numbers of the form n^2^k with surprisingly low complexity. This seems unlikely.
AnswerKenntnis:
You can get 103 with four 4s as (64 + 4 + sqrt(.4.))├╖sqrt(.4.)
where 64 = sqrt(sqrt(sqrt(4^4!))) and .4. = .4recurring = 4/9.

In fact, 113 is the first number I can't get with four 4s.

[Apologies: this is my first ever post: haven't figured out how to get the math notation.]
AnswerKenntnis:
It can't be $o(\log N)$ for any finite set of binary operations.  For a set of operations of size $k$, you can only have of order $k^N$ legal strings, so you can't represent more numbers than that.
QuestionKenntnis:
Is it faster to count to the infinite going one by one or two by two?
qn_description:
A young child asked me this question yesterday:


  Would it be faster to count to the infinite going one by one or two by two?


And I was split with these two answers:


In both case it'll take an infinite time...
Skipping half of the number should be really faster.


And it brings me this "paradox" :

Could an infinite be greater than another one?
AnswersKenntnis
AnswerKenntnis:
YES and NO.

Galileo made the "discovery", the so-called Galileo's paradox, that if you start with the succession of natural numbers:


  $1, 2, 3, ...$


and you map it into the succession of even numbers :


  $2, 4, 6, ...$


you may map (i.e.associate) every number into its double (today, we call it one-to-one mapping).

So, you have the same "number" of numbers and of even numbers.

Modern set theory (from Cantor on) solved the paradox extending the "counting" process to infinite sets, but proving that the euclidean common notion that "The whole is greater than the part" [see Euclid, The Elements, trans T.L.Heath, Dover, Common notions 5] will not hold for an infinite set.

According to modern set theory, the two above sets can be put in one-to-one correspondence, so they have the same cardinal number, and their "type" of infinity is called denumerable (a set is called denumerable exactly when it can be put in one-to-one correspondence with the set of natural numbers).

But, again by a result of Cantor, not all infinite sets can be put in one-to-one correspondence: there are infinite sets "more infinite" than another. A set of "a larger kind" of infinity is the set of real numbers; it is not denumerable, in the meaning defined above.

As for counting "faster": of course, if you count two by two, after a while you will be way "ahead" of your friend that is counting by one. The only problem is that you will not "end" before him, because there is no final goal to be reached!
AnswerKenntnis:
Fast or slow has to do with speed. So, if you properly define speed, and if you assume additional hypothesis, like "one count per second", then you can say that counting two by two is faster.

In fact, if you count one by one, then you will count one number per second. If you count two by two, it will be two counts per second. And since $2 > 1$, two by two is faster.

After you two agree that two by two is faster, the kid should be able to realize that this isn't exactly what s/he wanted to ask. As the kid rephrases the question, s/he should get closer and closer to being able to answer by perself. My conclusion is:

Two by two is faster, but it is kind of "useless", since you will not be able to finish anyway.

Asking questions is more important then answering them.
AnswerKenntnis:
Contrary to the common layman assumption, there is no unique context in which mathematics is being done. Words, especially coming from natural language, can be interpreted in different ways when changing the context.

In this case, the word "faster" can be interpreted in different ways, and it will affect the answer.


"Faster" as a real valued limit. We can think about this as two functions, $f(n)=n$ and $g(n)=2n$. These can be thought as sequences of real numbers, and we can ask whether or not one sequence dominates the other, and what is the limit of their ratios? $$\lim_{n\to\infty}\frac{f(n)}{g(n)}=\frac12$$ Since $\frac12<1$ we have that indeed $g$ is the faster sequence.
"Faster" as a computational process. This is similar to the above case, we define two sequences and calculate the limit of their ratios. However this time we say that if the ratio is a positive (but finite!) constant, then they are more or less the same speed. In this case both sequences have the same "speed".
"Faster" as a set theoretic process (cardinality). This is not similar to the two cases above, in this case we only measure the cardinality of the output of the sequence. We can ask whether or not the cardinality, which is the rawest notion of "size" for sets, of the two sets $\Bbb N$ and $\{2n\mid n\in\Bbb N\}$ are the same, despite one being a proper subset of the other.

The answer here is that the cardinality is the same, because there is a bijection between the two sets, indeed $g(n)=2n$ is this bijection. So the two methods of counting end up having the same "speed" again.


There are definitely more ways to define which sets go "faster" to infinity. And the result will definitely change from one context to another. The point is that there are different ways we can measure how fast a particular set of integers, or a sequence if you will, thins out as it grows, and it is useful to consider different ways in different contexts.

If you want to explain to a child about the importance of context in which a term is interpreted, ask them what it is easier to carry a $5\ \rm kg$ of iron cast into one block, or a balloon containing $1\ \rm kg$ of air which is huge ($0.85\rm m^3$ in volume). While the iron is definitely heavier, the balloon is definitely much larger and more difficult to handle.

So carrying it by hand makes the iron easier to carry. But if you have a cart on which you can put both objects, then the balloon is much easier to carry because you are pulling a lighter object and you have to put less effort into that.

Therefore there are two ways to interpret "easier to carry" and they depend on the the tools that you have, and so "faster" in mathematics depends on the context in which you are asking the question.
AnswerKenntnis:
Show your kid this table:
$$\begin{matrix}
1&2&3&4&5&6&7\\
\hline
2&4&6&8&10&12&14
\end{matrix}$$
Now let him decide which counting takes longer ...
AnswerKenntnis:
To answer this, lets try to think like a child and find:

Ironically, counting two by two should be actually slower!

If you count up to the $N$th element of the corresponding sequences ($\mathbb{N}$ and $2\mathbb{N}$), we observe the following pattern: the more digits the number has the longer it takes to spell it. 

Take for example $N=8$, the time you need to spell

"one, two, three, four, five, six, seven, eight"

is considerably shorter than the time you need to spell

"two, four, six, eight, ten, twelve, fourteen, sixteen".

One can imagine that  this holds true for "most" of the $N$, so skipping the odd numbers will be slower.

Of course, this is far away from a mathematical proof, but probably a child would like the way of thinking. One could bring up the whole Cantor/countability problem at a later point in time, for example after clarifying what we mean by "count".

I did not attempt to prove this "claim". :-) 
Maybe one can find a subsequence that, after fixing the counting times for the digits, has longer counting times in the first version, who knows...

EDIT: 
If we represent the numbers with their binary coefficients (for example $(0,1,0,\ldots)$ for 2) and if we assume that one neets equal amounts of time for each syllable we have that the time $\ell((0,1,0,\ldots))$ it needs spell the binary number is $3$: $1$ for "one" and $2$ for "ze-ro".
So if we spell $a_n = n$ in its binary representation it takes $\ell(a_n)$ time to do so. Since multiplication by two corresponds to a shift in binary space (add a zero) we have $\ell(b_n)=\ell(2a_n)=\ell(a_n)+2 > \ell(a_n)$. Therefore it always takes longer to spell the even sequence. Asymptotically, of course, the speed is the same: $\frac{\ell(b_n)}{\ell(a_n)}=1+\frac{2}{\ell(a_n)} \rightarrow 1$ as $n \rightarrow \infty.$ A fun fact is, that this is independent of the language. Just replace the number $2$ by the number of syllables used for $0$. :-)
AnswerKenntnis:
Counting by $2$s, you'll reach any finite number faster. But in either case you will never reach $\infty$. Putting it this way validates the feeling that counting by $2$s should be faster without violating the mathematics of the infinite.
AnswerKenntnis:
Hilbert's paradox of the Grand Hotel

This makes a nice puzzle for young people interested in infinity.


  Consider a hypothetical hotel with infinite rooms, all of them occupied.
  
  
  An extra guest arrives. Can you accomodate him?
  A neighboring, infinite hotel burned down. An infinite number of guests arrive. Can you accomodate all of them?
  Infinitely many buses with infinitely many guests arrive. Can you accomodate all of them?
  


The answer each time is yes, you can assign each existing guest and each new guest a unique room number. The existing guests have to move to a new room each, though.

All of these sets are countable infinite, aka $\aleph_0$, Aleph-naught.
See: Aleph number

Things get messy once you try to enumerate an infinite number of infinite subsets. As long as you have finite sets, you can encode each set using a $2^n$ binary number; which obviously is a unique mapping from integers to finite subsets. Once you want to be able to also accomodate any infinite subset in your enumeration - i.e. have a mapping from each infinite set to a finite number - things get, well, impossible. Roughly, by the same argument that the rational numbers are not equivalent to the irrational numbers. (You may want to read up on Cantor for this, around 1874). So in the end, it boils down to: why is pi not finite, e.g. the question: Pi might contain all finite sets, can it also contain infinite sets?

I.e. it's about rational vs. irrational numbers. Counting to infinity going by one or two just means counting in a different basis; but you will still miss $\pi$ and almost every other irrational number.
AnswerKenntnis:
It is the same question as "which set is bigger, the natural numbers or the even numbers?"

Two sets $A$ and $B$ have same number of elements if there exists reversible transformation between those sets. In this case this transformation is simple:

$$f(x) = 2x$$

Hence both sets have the same cardinality.
AnswerKenntnis:
The answer to the final question "can one infinite [quantity] be greater than another" is positive (there are many degrees of infinity in set theory), but that is not what the question is about. The question about going to infinity is similar to the question "would it be faster to travel to the moon on foot or by train?". The point is, although going by train is "faster" in terms of speed, it is not so in terms of reaching the goal: neither method will ever attain the goal that was set, so it is pointless to claim that one method gets there faster than the other. It is only a figment of our mental representation of infinity that we can approach infinity by going to ever larger numbers; doing so, we still remain infinitely distant from our target at all times.
AnswerKenntnis:
Feynman had a nice approach to this.  He bet a child of a friend of his that there were "twice as many numbers as there are numbers."  He told the kid to pick a number (young enough that only integers mattered). Kid says "six,"  Feynman says "twelve."  etc.  

In this case, the child was bright enough to come right back and say,  "Hey Mr. Feynman, I bet there are three times as many numbers as there are numbers."
AnswerKenntnis:
Is it faster to count to the infinite going one by one or two by two?


Since neither method will actually help you reach your destination, the question is meaningless. ΓÇ£To travel fasterΓÇ¥ and to ΓÇ£travel faster towards a specific destinationΓÇ¥ are two completely different things For instance, a man flying by plane travels faster than one going there by boat, but it's obvious that neither method of transportation will take either one of them faster to the Moon, for instance.
AnswerKenntnis:
Maybe the trouble is how we imagine infinity.  If you imagine it as say the vanishing point on the horizon (or a distant star etc, i.e. just a really big finite number), then skipping half is faster.  How about imagining it as a moving target?  I.e. a bit bigger than whatever number you like.  

E.g. you could say "to count to infinity we have to count to at least 10 more than we've already counted".  Then whether you skip half or not, your target still stretches out of reach just as quickly.
AnswerKenntnis:
You can't count to $\omega$, you can only count towards $\omega$.

(Here, I am using $\omega$ to refer to the smallest infinite ordinal number. Don't make the mistake of confusing it with the cardinal number $\aleph_0$ or the extended real number $\infty$!)

The two counting procedures you indicate never reach $\infty$. After one step, the first procedure has reached $1$, and the second has reached $2$. After a thousand steps, the first procedure has reached $1000$, and the second has reached $2000$. After a trillion steps, the first procedure has reached $1,000,000,000,000$ and the second has reached $2,000,000,000,000$.

The point is, each step in your counting procedure is a natural number of steps away from the starting point. As such, the number you have reached at any step cannot be $\omega$!

The problem is that when you define an algorithm of the sort


At each step, you do [something] to get to the next step


that can only get you as far as natural numbers. If you want to "count" further, or more generally talk about any other transfinite process, you need to include a second rule. A typical one is to have the steps of your transfinite process labelled by ordinal numbers, and then include a rule of the sort


To get to any step that doesn't have an immediate predecessor, do [something else]


For example, when counting by ones, [something else] might be "move onto the smallest ordinal you haven't reached or passed yet". In that case, at step $\omega$, you have counted to $\omega$. Then at step $\omega + 1$ you've counted to $\omega + 1$ and continue on.

But when counting by twos' you might use the same [something else]. Then at step $\omega$, you've still only reached $\omega$, since prior to $\omega$ -- i.e. at the finitely-numbered steps -- you've only reached natural numbers! But then you continue counting by $2$ and at step $\omega + 1$, you've reached $\omega + 2$, then $\omega + 4$, and so forth.

Actually, there's another gotcha: when you said you were counting by $1$'s, you thought you were counting natural numbers. But $\omega$ isn't a natural number: what does it mean to count by one or by two from $\omega$? It does make sense to continue on to the next ordinal number from there to count by ones (i.e. adding by one on the right: if you care to learn arithmetic of ordinals, note that $1 + \omega = \omega \neq \omega + 1$), and skipping every other successive ordinal to count by twos. I've assumed that's what you do in the above paragraphs.

Of course, don't try to do this in the "real world" in any fashion where you have to spend one unit of time per step -- there aren't enough units of time to reach $\omega$! Other fashions are possible, though: e.g. the description of events in Zeno's paradox can be continued by setting step $\omega$ to be where Achilles has actually reached the finish line.

Another common means of passing to the transfinite is taken in geometry / analysis, by adding points "at infinity". e.g. the numbers $+\infty$ and $-\infty$ that are the endpoints of the extended real line. When we have a function defined for real numbers like $\arctan x$ or $1/x$, and the function has limits at $+\infty$, it is customary to extended the function by continuity to have the limiting value. e.g. $\arctan(+\infty) = \pi/2$ or $1/(+\infty) = 0$. But this method is mostly unrelated to discrete processes like counting or executing algorithms one step at a time.
AnswerKenntnis:
The original question was turned into a definition of infinity by Dedekind.

In his Was sind und was sollen die Zahlen? of 1888, Dedekind defined infinite sets in paragraph 64:


  A set is said to be infinite when it is similar [in bijection with] to a proper subset
  of itself, otherwise it is said to be finite.


DedekindΓÇÖs footnote to this definition contains some important historical notes.


  In this form I submitted the definition of the infinite which forms
  the core of my whole investigation in September, 1882, to G. Cantor
  and several years earlier to Schwarz and Weber.   All other attempts
  that have come to my knowledge to distinguish the infinite from the
  finite seem to me to have met with so little success that I think I
  may be permitted to forego any criticism of them.


Thus, being able to count the even integers shows, according to Dedekind's definition, that the set of all integers is infinite.

Notes on Richard DedekindΓÇÖs
Was sind und was sollen die Zahlen?
AnswerKenntnis:
Maybe you can answer it by saying:


  Suppose you and I go to another planet and start walking around its equator. And keep walking forever. I have longer legs, so I will take steps twice as long as yours. So I will walk twice as fast as you. Which one of us will reach the end first?


This helps link the mysterious infinity with a more everyday concept.
AnswerKenntnis:
Yes, infinities come in different sizes (not exactly sizes), but...

No, counting by twos isn't faster: Comparing different methods of counting to infinity is like a race to an unreachable place. If you can't ever get there, it doesn't matter how fast you go.
AnswerKenntnis:
This answer is not meant to seriously attempt to solve the question, but to show that the question has plethora of answers because its (mathematical) context is ill-defined.



Assume that Alice and Bob walk on the road $\mathbb N = \{0,1,2,\dots\}$ : each second, Alice move from its place $a$ to $a+1$, while Bob moves from its place $b$ to $b+2$. Now, I will (arbitrary, but irrevocably) said that X moves faster than Y if, at the same second, the distance between $X$ and $0$ is greather than the distance between $Y$ and $0$. Seems legit.

But wait, what is the distance between one's place and $0$ ? Well, for the sake of my point (see the first sentence of the post) and because one always likes being the centre of everything, I decide to norm $\mathbb N$ by the $2$-adic distance : that is the distance between $n$ and $0$ is
$$ |n|_2 = 2^{-\nu_2(n)} $$
where $\nu_2(n)$ is the exponent of $2$ in the prime decomposition of $n$. (You can go ahead and verified that this respects what we want of a distance : the distance between $0$ and $0$ is $0$, the distance between $n + m$ and $0$ is less than the one between $0$ and $n$ added with the one between $0$ and $m$.)

So now, after $n$ seconds, Alice is in place $n$ while Bob is in place $2n$. I let you verify that $|2n|_2 = \frac 1 2 |n|_2$. So it seems that in those $n$ seconds, Alice made double the distance Bob did. Hence counting one by one is faster than $2$ by $2$.
AnswerKenntnis:
Infinity isn't a number. This is why there is so much confusion and "paradoxes" associated with it. It is treated as a number, yet it is NOT a number, but rather it is an indicator of an unending sequence of numbers (like the asterisk in "1/3 = 0.3*"). Counting to infinity is meaningless because it is akin to measuring the distance a javelin is thrown while it is still flying through the air. 

Doesn't matter whether you use centimeters or meters, you can't measure the distance because the total distance hasn't been traversed yet. Only once the javelin falls to the ground can you start measuring. But if it carries on flying infinitely, you might as well have a cup of tea.
AnswerKenntnis:
Since you never reach an end, speed is not of importance. You don't have strictly defined end point of what you are counting, so you won't be able to compare both approaches.

My answer is that it won't be faster, the counting will never end and you won't be able to decide.

The only thing that you may be sure (besides it will be a waste of time) is that, using the second method, at any given point you have skipped twice as many numbers.
AnswerKenntnis:
You can form a bijection from the set of all positive integers to a set of all even integers. If infinity were a quantity, then infinity would map to infinity. Mathematically then you'd reach infinity at the same time.
AnswerKenntnis:
Counting out all the numbers and counting out only the even numbers, gets you to infinity equally quickly, so says function growth analysis.

In big-O notation we have the following definition

$$ O(f) = \{ g \to \mathbb R \mid  \in \exists n > 0,\, k > 0 \;\forall n > n_0 \,.\, | g(n) | \le k| f(n)| \}$$

"Big-O of a function f is the set of all functions ($g$s), which f multiplied by a constant ($k$) will eventually ($n_0$) overtake in magnitude."

That is, if we compare $f(n) = n$ and $g(n) = 2n$, we see that $f \in O(g)$  because $ |g(1)| = 2 \le 3 = 3|f(1)| $ but also $ g \in O(f) $ becuase  $ |f(1)| = 1 \ge 2 = 1|g(1)|$.

Therefore the functions $f(n) = n$ and $g(n) = 2n$ grow equally fast.
AnswerKenntnis:
"Could an infinite be greater than another one?"

YES, and in more than one sense!

Many answers pointed out cardinality, i.e. a way to define size between sets, mathematical objects with no other structure than the relationship $x\in y$. This is defined by function injection. If you can map uniquely members of one set into another, the former is smaller than the latest. And if you can do it both ways, they are equal in size.

And one answer above brought another possible way to define bigger: ordinals. Ordinal size is different. $\omega$ is the ordinal corresponding to our intuitive notion of counting, one number after another; although it is defined by the concept of total ordering, and order where every subset has a least element. Here, you need little more structure, $x\in y$ and $x < y$ to workout this definition of size.

So, with ordinals you can have the full sequence of numbers 1, 2, 3, one after another, very well ordered; call it $\omega$. Now, and just because you like it, put the same sequence afterwards as if you were able to finish counting the first one (here the paradox of Achilles and the tortoise may help), then you start counting again. How fun is that?! And you have $\omega + \omega$, repeat this $\omega$ times and, yes, you got it $\omega * \omega$ = $\omega^2$, and repeat and repeat, $\omega^\omega$, $\omega^{\omega^\omega}$ and then you got all sort of infinities, one smaller than the other, without leaving the cardinality of $N$.

So, in mathematics one encounters infinity in different ways; counting as you said, and I already pointed out two possible ways to look at counting. But you have the infinity $\infty$ one see in calculus, which can be treated formally using, for example, non standard analysis which requires lot more structure to work through.

So, I know that this will be harder to explain to a little kid, but what's infinity depends on how you look and compare size; and different ways of looking gives you different infinities. Maths is fun!
AnswerKenntnis:
Counting by ones or by twos requires a visit to each element of the set, so if each visit happens at the same length of time, it really doesn't matter.

Humans can do the pairing in parallel to counting, so counts by two can proceed at the same concious rate as counts by ones.  Thus in any finite time, one can get to a higher number by pairs than individually.  Likewise, the grouping of numbers into cycles of 20 or so make counting faster too.

Infinity is generally considered a large number.  While Cantor's theory suggests that one can complete a count to infinity, in practice, there are numbers whose digits exceed any count (because the count itself spells out a number larger than that). 

Even if you seek your inspiration for infinity from other sources, the whole point of infinity is that fuzziness that comes from a vague equal sign comes to play, and this really can't happen if you're visiting every number.

On the other hand, infinity is a member of a groups of indefinites, some of which are abidingly finite.  For example, the instances of cases where a prime p divides its own period is necessarily unbounded, (it's related to $\sum_{1}^{\infty} \frac 1n$).  But both of these sums are of the form of $\log \log n$.   The known count for 10 is an indefinite number 3 or greater, for base 120, 4 are known.  

A two's count will get you out there faster, but there is plenty more road in front of you.
AnswerKenntnis:
Yes, an infinite can be bigger than another, BUT, the E set (the set composed by all the even numbers) is equal to the N set (the set composed by all the natural numbers.
There are 2 types of infinite:

1) numerable infinite: you can count it
examples. N , E ....

2) NON-numerable infinite: you can NOT count it
examples. all the real numbers

all the NON-numerable infinites > all the numerable infinite

all the NON-numerable infinites are equally infinite

all the numerable infinite are equally infinite.

To answer your question clearly, althought it may seem a non-sense N = E
QuestionKenntnis:
Nice examples of groups which are not obviously groups
qn_description:
I am searching for some groups, where it is not so obvious that they are groups.


In the lectures script there are only examples like $\mathbb{Z}$ under 
addition and other things like that. I don't think that these examples are helpful to unterstand the real properties of a group, when only looking to such trivial examples. I am searching for some more exotic examples, like the power set of a set together with the symmetric difference, or an elliptic curve with its group law.
AnswersKenntnis
AnswerKenntnis:
Homological algebra. Let $A,B$ be abelian groups (or more generally objects of an abelian category) and consider the set of isomorphism classes of abelian groups $C$ together with an exact sequence $0 \to B \to C \to A \to 0$ (extensions of $A$ by $B$). It turns out that this set has a canonical group structure (isn't that surprising?!), namely the Baer sum, and that this group is isomorphic to $\mathrm{Ext}^1(A,B)$. This is also quite helpful to classify extensions for specific $A$ and $B$, since $\mathrm{Ext}$ has two long exact sequences. For details, see Weibel's book on homological algebra, Chapter 3. Similarily many obstructions in deformation theories are encoded in certain abelian groups.

Combinatorial game theory. A two-person game is called combinatorial if no chance is involved and the ending condition holds, so that in each case one of the two players wins. Each player has a set of possible moves, each one resulting in a new game. There is a notion of equivalent combinatorial games. It turns out that the equivalence classes of combinatorial games can be made into a (large) group. The zero game $0$ is the game where no moves are available. A move in the sum $G+H$ of two games $G,H$ is just a move in exactly one of $G$ or $H$. The inverse $-G$ of a game $G$ is the one where the possibles moves for the two players are swapped. The equation $G+(-G)=0$ requires a proof. An important subgroup is the class of impartial games, where the same moves are available for both players (or equivalently $G=-G$). This extra structure already suffices to solve many basic combinatorial games, such as Nim. In fact, one the first results in combinatorial game theory is that the (large) group of impartial combinatorial games is isomorphic to the ordinal numbers $\mathbf{On}$ with a certain group law $\oplus$, called the Nim-sum (different from the usual ordinal addition). This identification is given by the nimber. This makes it possible to reduce complicated games to simpler ones, in fact in theory to a trivial one-pile Nim game. Even the restriction to finite ordinal numbers gives an interesting group law on the set of natural numbers $\mathbb{N}$ (see Jyrki's answer). All this can be found in the fantastic book Winning Ways ... by Conway, Berlekamp, Guy, and in Conway's On Numbers and Games. A more formal introduction can be found in this paper by Schleicher, Stoll. There you also learn that (certain) combinatorial games actually constitute a (large) totally ordered field, containing the real numbers as well as the ordinal numbers. You couldn't have guessed this rich structure from their definition, right?

Algebraic topology. If $X$ is a based space, the set of homotopy classes of pointed maps $S^n \to X$ has a group structure; this is the $n$th homotopy group $\pi_n(X)$ of $X$. For $n=1$ the group structure is quite obvious, since we can compose paths and go paths backwards. But at first sight it is not obvious that we can do something like that in higher dimensions. Essentially this comes down to the cogroup structure of $S^n$. There is a nice geometric proof that $\pi_n(X)$ is abelian for $n>1$.
AnswerKenntnis:
The group of exotic differentiable structures on the $n$-sphere in any given dimension is a group under the operation of connected sum, with the standard sphere being the identity element. Not at all obvious that this forms a group! For example, in dimension 7, this group is isomorphic to $\mathbf{Z}/28$.
AnswerKenntnis:
I was surprised to learn about the elliptic curve groups.  You fix constants $a$ and $b$ take the set $S$ of points on the Riemann sphere (that is, the complex plane plus a point at infinity) of the form $$y^2 = x^3 + ax + b.$$ Then define the sum two points $p_1, p_2$ on this curve by taking the straight line through $p_1$ and $p_2$ and finding the third point $p_3 = \langle x_3, y_3\rangle$ where the line intersects $S$. Then $p_3^{-1} = \langle x_3, -y_3\rangle$ is the group sum of $p_1$ and $p_2$.  It's not immediately clear that there is necessarily a point $p_3$, but there is, with suitable treatment of tangents and of the point at infinity. It's not immediately clear that the operation is associative, but it is. The point at infinity is the identity element, and the inverse of the point $\langle x, y\rangle$ is $\langle x, -y\rangle $.
AnswerKenntnis:
I was surprised the first time I saw the group of unit arithmetic functions under Dirichlet convolution.  Arithmetic functions are functions $f:\mathbb{N}\rightarrow F$, where $F$ can be any field (but usually $\mathbb{C}$).  The operation is $$(f\star g)(n)=\sum_{d\mid n}f(d)g\left(\frac{n}{d}\right).$$
So, here the identity is the function $$\varepsilon(n)=\left\{\begin{array}{lcl}1&:&n=1\\0&:&\text{otherwise}\end{array}\right.$$while inverses are defined recursively, as described here under "Dirichlet inverse."  Note that $1/f(1)$ appears in the definition of the inverses, so we must include only arithmetic functions for which $f(1)$ is invertible in $F$ (this is why we say unit arithmetic functions).
AnswerKenntnis:
The Brauer group of a field is not obviously a group in two ways: first it's not obvious that the group is closed under its group operation, and then it's still not obvious that inverses exist.
AnswerKenntnis:
1- Fourier analysis: the set of non-vanishing absolutely convergent Fourier series is a group under pointwise multiplication.

The neutral element is the constant function equal to $1$. And product stability follows from Cauchy product. These are straightforward. The existence of inverses is less obvious.


  Wiener's lemma: if $f(t)=\sum_{\mathbb{Z}}c_ne^{int}$ is absolutely convergent, i.e. $\sum_{\mathbb{Z}}|c_n|<\infty$, and does not vanish, then $\frac{1}{f(t)}$ is also the sum of an absolutely convergent Fourier series.


This is not that hard either. But it was, and remains, striking. You can find a proof here. Less elementary, but much more interesting, the proof given by Gelfand which raised the interest in Banach algebras. Indeed, the absolutely convergent Fourier series form a unital commutative Banach algebra  with spectrum $[0,2\pi]$. More precisely, the characters are the point evaluations $f\longmapsto f(t_0)$. The invertibility of non-vanishing elements is then obvious via Gelfand representation.

2- von Neumann algebras: for a type $\rm{II}_1$ factor von Neumann algebra $M$, i.e. an infinite-dimensional noncommutative probability space, we can make sense of $t\times t$ matrices over $M$ for every real $t>0$. This gives rise to another type $\rm{II}_1$ factor $M^t$. 


  In their seminal work dating back to the 1930's, Murray and von Neumann introduced the fundamental group of a $\rm{II}_1$ factor $M$
  $$
\mathcal{F}(M):=\{t>0\;;\;M^t\simeq M\}.
$$
  It is not hard, but not obvious per se, to see that this is a subgroup of $(\mathbb{R}^+,\;\cdot\;)$.


One of their striking classification results says that, up to isomorphism, there exists a unique approximately finite-dimensional type $\rm{II}_1$ factor $R$. As a consequence, it follows that
$$
\mathcal{F}(R)=\mathbb{R}^+.
$$
By Connes' groundbreaking work (1976), any amenable type $\rm{II}_1$ factor is isomorphic to $R$. So these also have fundamental group equal to $\mathbb{R}^+$. This includes the group von Neumann algebra $L(\Gamma)$ of any countable amenable group $\Gamma$ with infinite conjugacy classes. 

On the other hand, Connes proved in 1980 that the fundamental group of $L(\Gamma)$ is countable when $\Gamma$ has Kazhdan's property (T). But it remained open for some time whether the fundamental group of a $\rm{II}_1$ factor could be trivial. 

In a more recent breakthrough, Popa exhibited in 2001 such examples. In particular, he showed that
$$
\mathcal{F}(L(\mathbb{Z}^2\rtimes \rm{SL}(2,\mathbb{Z})))=\{1\}.
$$
On the opposite side, he also proved in 2003 that any countable subgroup of $\mathbb{R}^+$ arises as the fundamental group of some type $\rm{II}_1$ factor. For a larger class of such groups and open questions, see these slides by Vaes, another important contributor to the theory.

Finally, note that Voiculescu's free probability theory allowed Radulescu to prove that
$$
\mathcal{F}(L(F_\infty))=\mathbb{R}^+
$$
for the free group on a countably infinite number of generators $F_\infty$. Unfortunately, these techniques have not permitted to compute the fundamental group of $L(F_n)$ for the free group on $2\leq n<\infty$ generators. Note that the following puzzling long-standing question remains open:
$$
L(F_2)\simeq L(F_3)\;?
$$
AnswerKenntnis:
May be the groups of nimbers would fit the bill? The underlying set is that of non-negative integers $\mathbb{N}$. The group operation (denoted by $+$) is defined recursively as follows
$$
a+b=\operatorname{mex}\left(\{a'+b\mid a'<a\}\cup \{a+b'\mid b'<b\}\right).
$$
Here $\operatorname{mex}(S)$ is defined for all proper subsets of $\mathbb{N}$ and means the smallest non-negative integer not in the set $S$ (=Minimum EXcluded number). So $0+0=0$ simply because both sets on the r.h.s. are empty. But then $0+1=\operatorname{mex}(\{0\})=1=1+0$, $1+1=\operatorname{mex}(\{1\})=0$,
$0+2=\operatorname{mex}(\{0,1\})=2=2+0$, $1+2=3$, $2+2=0$ et cetera.
The operation is well defined, because the sets on the r.h.s. are obviously finite, and hence proper subsets of $\mathbb{N}$, for all $a,b\in\mathbb{N}$.

Now, it turns out that this operation is just the NIM-sum (addition in base two without carry). That is not entirely obvious even though it isn't exceedingly hard to see either.

It turns out that the sets of the form $S_n:=\{x\in\mathbb{N}\mid x<2^n\}$ are subgroups. Furthermore, if $n$ is a power of two, this set also has a multiplication that turns it into a field. The construction is due to Conway. See this wikipage for more.
AnswerKenntnis:
Here are some examples:


The ideal class group of a number field $K$. It is not obvious that this is a group, because for example to be able to invert an ideal requires the definition of an invertible ideal and showing that $\mathfrak{p}\mathfrak{p}^{-1} = \mathcal{O}$. This last part is not trivial and if memory serves me right you need to invoke the Nakayama Lemma.
The fundamental group of a topological space $X$ - not trivial to show that the operation of taking products of loops is associative. When I took such a class my lecturer drew some pretty pictures to show homotopies between $f \ast (g \ast h)$ and $ (f \ast g) \ast h$, but I was not entirely convinced.
AnswerKenntnis:
After some study, it might become clear that the following is a group. But it seemed nonobvious the first time I saw it: the collection of all fractional linear transformations from $\mathbb{C}\cup\{\infty\}$ to itself, with formulas $$z\mapsto\frac{az+b}{cz+d}$$ such that $ad-bc\neq 0$ (in order to guarantee that you don't have a constant map), using composition as the group operation. Firstly, it takes at least a full second to believe that the composition of two such things is another such thing. Secondly, at some point you realize that any one fractional linear transformation has infinitely many representations: $z\mapsto\frac{kaz+kb}{kcz+kd}$. So a lot of your early thoughts on the topic are not 100% correct. Thirdly, associativity is no fun to confirm directly. (Again, it's not immediately obvious, but eventually you can see that this is a factor group of the $2\times 2$ general linear matrix group.)
AnswerKenntnis:
It's not obvious that the collection of integers mod $p$, excluding the coset of $0$, form a group under multiplication. In particular, it's not obvious that inverses exist. You typically use the Euclidean algorithm for that.
AnswerKenntnis:
Here is an example that is a bit different, namely one that appears as a subgroup of another group, but where it is not obvious that it is a subgroup.

Let $G$ be a finite group with a proper non-trivial subgroup $H$ such that for all $g\in G\setminus H$ we have $H\cap H^g = \{1\}$ (such an $H$ is called a Frobenius complement in $G$ and if $G$ has a Frobenius complement it is called a Frobenius group).

Define $$N = \left(G\setminus\bigcup_{g\in G}H^g\right)\cup\{1\}$$

Then $N$ is a subgroup of $G$, but I am not aware of a proof of this that does not involve character theory (for a proof see for example Theorem 7.2 in Isaacs' Character Theory of Finite Groups).
($N$ is called the Frobenius kernel of $G$ and it is in fact a normal complement of $H$).
AnswerKenntnis:
What about the set of line bundles over a manifold? This forms a group, whether your line bundles are real or complex.  The difference between them is also very interesting, as one is 2-torsion, and the other can be torsion-free!

Here the group operation is tensor product: showing it is a closed associative operation is fairly easy.  The trivial bundle is the identity.  Ah, but what are the inverses?
AnswerKenntnis:
Another example is mentionned here:


  Let $G$ be a finite group of order $n$ and $S \subset G$ be any subset. Then $$S^n = \{s_1s_2 \cdots s_n \mid s_1, s_2, \dots, s_n \in S\}$$ is a subgroup of $G$.
AnswerKenntnis:
I always found the fact that braid groups are groups at all quite interesting. The elements of the group are all the different braids you can make with, say, $n$ strings.  The group operation is concatenation.  The identity is the untangled braid.  But the fact that inverses exist is not obvious.
AnswerKenntnis:
Exotic example can be rubik's cube group with cube moves.
AnswerKenntnis:
It is not obvious from their definition that KK-groups actually have inverses.
AnswerKenntnis:
If $G$ is a Lie group, with multiplication operator $m:G\times G\rightarrow G$ and inverse $i:G\rightarrow G$, then $TG$ is also a Lie group, with multiplication operator $Tm:TG\times TG\rightarrow TG$ and inverse $Ti:TG\rightarrow TG$. To see this, use the obvious notation that for $v_g\in T_g G$ and $h\in G$, $v_g\cdot h = T_g R_h(v_g)$, where $R_h:G\rightarrow G$ is right multiplication by $h$, and similarly for $h\cdot v_g$ (these operations are easily shown to be associative). Then for $g,h\in G$ and $\xi,\zeta\in \mathfrak{g}$, the Lie algebra of $G$,
$$T_{(g,\,h)}m(\xi\cdot g,\,\zeta\cdot h) = \xi\cdot g\cdot h + g\cdot\zeta\cdot h = (\xi + \mathrm{Ad}_g\zeta)\cdot gh,$$
and so under the bijection between $\mathfrak{g}\times G$ and $TG$ given by $(\xi,\, g)\mapsto \xi\cdot g$, $TG$ is just $\mathfrak{g}\rtimes_{\mathrm{Ad}}G$, the semidirect product of $\mathfrak{g}$ and $G$ with respect to the adjoint action $\mathrm{Ad}$.
AnswerKenntnis:
Well if you want to get more visual, you can go with symmetry groups and wallpaper groups.
AnswerKenntnis:
Similar to how we turn the natural numbers into the additive group of integers, and the group of integers to the multiplicative group of the rationals, let $A$ be a set with an abelian operation and an identity (abelian monoid). For $A \times A$, declare $(a_1, b_1) \tilde{} (a_2, b_2)$ iff there is a $c \in A$ such that $a_1 + b_2 +c = a_2 + b_1 + c$.
AnswerKenntnis:
Two examples:

The set of algebraic numbers is a field and it isn't trivial to prove that their sum and multiplication comply  to give two groups, in one had. In the other, consider the Grothendieck group's construction.
AnswerKenntnis:
Let $k$ be a field, and let $A$ be a finite type $k$-algebra.

Consider the isomorphism classes of dualizing complexes over $A$.

Given two dualizing complexes $R$ and $S$, define their "product" to be the isomorphism class of the Hochschild cohomology complex of their tensor product over $k$:

$R\cdot S := RHom_{A\otimes_k A}(A,R\otimes_{k} S)$.

Then it is not clear that:


The result is a dualizing complex.
That this operation is associative.
That this operation has an inverse.


Yet, all these turn out to be true. See Section 4 of http://arxiv.org/abs/1401.6678
QuestionKenntnis:
Too old to start math
qn_description:
I'm sorry if this question goes against the meta for posting questions - I attached all the "beware, this is a soft-question" tags I could.

This is a question I've been asking myself now for some time. In most areas, there's a "cut off age" to be good at something. For example, you're not going to make the NHL if you start playing hockey at 20. It just won't happen.

So my question then, how late is too late to start studying math and make a career out of it? By "start studying math" I mean, to really try to understand and comprehend the material (as opposed to just being able to do well in a formal, intuitional environment). 

I don't mean this from a "do what you love, its not too late" motivational perspective. I mean this from a purely biological perspective; at approximately what age has your brain's capacity to learn effectively and be influenced by your learning stop? When does the biological clock for learning new math run out?

My reasoning for asking this question is (for those who care): I love math. Really I do. But , having spent the first 21 years of my life in sports/video games/obtaining a degree in a scientific field which I care nothing of/ect, despite all my best attempts at trying to learn math, am I just too late starting to ever actually be good enough at it to make it a career? I've almost completed my second degree (in Math), but find that in many cases, despite how I look at a problem, I lack the intuition to comprehend it. I'm going to single him out (sorry), only as an example, but Qiaochu Yuan is my age. 

Note 1: If this question isn't a suitable post, I won't be offended at all if you vote to close - I know this question borders what's acceptable to ask.

Note 2: Thanks to everyone for reading and taking the time for the great responses. Really appreciate it!
AnswersKenntnis
AnswerKenntnis:
Karl Weierstrass was in his 40's when he got his PHD. There are a dozen other counterexamples, a number fairly recent. A good set of examples can be found in the thread on MO here: http://mathoverflow.net/questions/3591/mathematicians-who-were-late-learners 

This myth of "science is a game for the young" is one of the falsest and most destructive canards in modern society. Don't listen to it. You only get one life and when it's over,that's it. When you're dead a hundred million years,you'll be dead the tiniest most infinitesimal fraction of all the time you'll ever be dead. So stop listening to career advice from teenagers,grab a calculus book and get to work. That's my advice.
AnswerKenntnis:
21 is not old at all. I personally know heaps of people my age (32) who started out at 18 as salesclarks/BA or BCom majors/lawyers/bookeepers etc and ended up having a PhD degree in some advanced math areas and landed a job in academia or industry.

My personal case: I got a lousy BCom degree with little math at 22 and then worked in a primitive banking job. After a few years I realized I was growing stupid, so decided to do what I secretly always liked but never really had the balls to do: math and stats. 

So I moved to another country, did a Masters degree in Computational Statistics, (2nd level honours) then started on PhD in Computer Science (mathematical modeling of AI). After 6.5 years of math I'm, like $n^n$ times smarter than I was at 22, I got a postdoc job in my area and got awarded a Doctoral degree this morning.
AnswerKenntnis:
In Israel kids are expected to serve in the army when they are 18, and they serve for three years (men do, women serve two years). After this period it is common to find yourself questioning what you should do with yourself and not many people have answers. Therefore it is common to take another two years to work and travel the world before settling down and starting your academic education.

This means that most students in Israel begin their undergrad studies around the age of 23-24.

That been said there are considerably less mathematics students, and many of them start sooner. I started at 22, but I studied both with kids that didn't serve in the army and were 19-20 and people who took longer to settle for math and were 25.

So if you are just 21 and you want to start with mathematics, you're still younger than the average Israeli freshman.
AnswerKenntnis:
Of course you can make a career out of it! When I started reading your question I though you were around 50, but 22 is not old at all to go after a career in anything but sports. This kind of time don't affect your brains ability to think at all. The only thing is, if you have great ambitions, you are probably not gonna be able to win the fields medal because it has an age limit, but apart from that there is nothing that can stop you from following a career in math and be great at it.
AnswerKenntnis:
I'm not sure my personal experiences will be very helpful to a mere kid of 22, but here goes ...

I made a complete mess of being an undergraduate when I was 18 (until 21), and followed a career for some decades before I finally got round to seeing if I was actually capable of doing maths at a more advanced level.

I was almost 50 by the time I had published some research and gained a PhD in pure maths, so the effort could be considered a total waste of effort in terms of "my career", but it was hugely rewarding to me personally to have discovered that I was capable of finding out things in maths that professionals were interesting in reading - even if they were not in the same league as the millenium problems.

So - "go for it!" - you are never too old!
AnswerKenntnis:
Oh my! $22$ years old? 

You are still very young, and certainly not too old to pursue any passion, math or otherwise! 

I've taken many (lengthy) breaks from math. But each time I've returned to serious and dedicated mathematical work (be it studying math, teaching math, or pursuing research), I've come at it from a fresh perspective. 

Sure, when I've resumed mathematical work after taking "time off" from studying math, I've been a bit rusty at first, and have needed a bit of time to clear cobwebs from my brain. But that happens when taking time off from anything! So yes, "picking it up again" can feel discouraging at first, even perhaps overwhelming. But it's worth it; sometimes revisiting material you've encountered a few years back actually leads to a deeper and more comprehensive understanding of the material. 

With respect to your impression that you "lack the intuition" to fully comprehend some of the problems you encounter, I doubt that intuition is "something you either have or don't have"; I'm convinced that mathematical intuition is something one can acquire/develop and honed over time, with practice and perseverance.  

Take heart. Pursue your passions; with patience and persistence, the "cobwebs" will clear, and in no time at all, you'll feel very much at home in the mathematical world.

On a different note: I do think there is a myth floating around that you need to be a prodigy to excel in math, and there does seem to be a bias held by many academics that only the best and brightest among young students are worth investing in, in terms of mentoring, and/or admission into graduate programs. But perhaps the best way to defy such bias is by setting out to prove them wrong!



Added $(1)$: Your question reminded me of the article Is math a young man's game?. (Of course, I'd prefer it was entitled: *Is math a young person's game?* - but that's another matter altogether!)



Added $(2)$: On a light note, see xkcd for Too old for....
AnswerKenntnis:
If your career means Fields medal, you're probably too old. But 21 is not too old for studying math and be successful, in the sense that you still have a great chance to become a professor in a descent university after say 15 years, 36 is not old at all, I saw lots of people got their Ph.D around 30. But I am sure you will fell frustrated sometime but if you can hold on to it, you will make it.
AnswerKenntnis:
OK, I understand nothing, but here's my opinion: 


To be a star you should have already started as a child, out of your own accord, and should have found yourself devoting all of your time to profession of choice - be that a star video game player, a star lawyer, a star anything.
At the age of 21, after having completed a degree in a scientific field (for which you should have learned some math, regardless of caring for it or not) AND having almost completed your second degree in math, you are obviously qualified to make a career out of Math. Especially since you love it.


It might interest you to know that most (secular, non Arab) Israelis serve in the army till the age of 21-22, then usually take a one year vacation (backpacking around the world) and only then start their higher education. Didn't hurt us any.

As an obese person at the age of (OMG almost) 53 trying to survive Ninjutsu classes, I feel your pain :). I know I'll never be Sensei Hatsumi but I'm quite sure that had I decided to make a career out of it, I'd be able to reach instructor level.
AnswerKenntnis:
Maths is life, when you start doing maths your age will be 0. Don't worry about age. Maths is life, live life as life whether its 10 days or 100 years.

All the best. I too started Maths very late :-), and after that only I rediscovered myself.
As far as I remember, most of Euler's work done after he became blind (around 59 years ).
AnswerKenntnis:
I am a couple of months away from being your age and I, as well, just started doing math. I also wasted a good amount of time playing games, sports, etc. I was a psychology major but changed my major a year ago to math -- not that I hate psychology, I still love it. Of course I struggle understanding some of the concepts in math but that alone won't deter me from accomplishing the goals I want. To be honest, I really don't care if it takes me 50 years to completely understand math. My advice will be work as hard as you can and don't look back.
AnswerKenntnis:
It depends on you! 

I can take myself as an example, I started studying college math when I was 15 years old, I was sick of math when I was 19, so many things to study, I didn't have the maturity to study such a serious subject, now I'm 29 and I'm doing my master's degree in math after two bachelor's degrees: psychology (duration 6 years) and math (duration 4 years). I feel like when I was 15, the same difficulties, in fact, I think I am better now than I was 15, really. And now I feel like I can study anything I want, my brain is really fresh and new.

However, I have friends who are old inside, what do I mean? I mean they don't like thinking, don't like to discover new things, they only live to work hard and take care of their family, very difficult to teach something new to them.

So forget research which says your brain power becomes less as you age. The tests are correct in some sense, but we have to ask ourselves why a person with older age makes less points in tests than younger people, this happens because when they become older, they stop to study to work hard, have children and so on.

So what you have to have in mind is not to lose your interest to study new things and don't be contaminated by people who have lost their will of life and curiosity. If you do so, you NEVER lose your capacity to study new things.

I really don't know why mathematicians have this kind of prejudice. I've never seen this in any other areas of science.

So remember, your problem is not biological, your problem is social, the social can influence our brains.
AnswerKenntnis:
I am in graduate school now. Plenty of my classmates are aged over 30 and they performed very well. My mother went to college at 24 due to political reasons. She is a successful medical professor closing to retire now. I do not see any reason age should be an obstacle for your pursuit if you have passion, courage and following the right guidance.
AnswerKenntnis:
We can be good at anything we set our minds to.  If we make excuses, though, those become brick walls which hold us back from achieving greatness.  In other words, if you approach math in the way that you'll be one of the best, and age won't matter at all.  Plus, as someone who's researched mental decay, it tends to happen to people who let themselves mentally go, meaning that doing math or something mentally straining as you get older is great for your mind.
AnswerKenntnis:
It's easy to find any excuse to give up, but it's hard to slog it out and learn something in depth. 

I'm almost 50, have never done physics before, but I'm slowly but surely getting my way through Special relativity, which is meant to be easy. After that I'll go through General relativity. 

Years ago at uni, we had a guy who was 8o years old in his first year, he went on to do his masters and Phd in the German language, by that time he was 91.
AnswerKenntnis:
The bigger problem for mathematicians is not age, but running out of ideas. There is a historic trend that the best work has been done my mathematicians while they were relatively young, and after that they just kind of floundered through the rest of their careers, riding on their past glory.

If you start late, you may still have a chance to go through the same thing, at a later age. The excitement of exploring something unfamiliar may be there for you, in contrast to others who have long burned out already.

This window of creativity may have nothing to do with age; it may just have to do with an individual's capacity, which is "emptied out" like a vessel, earlier or later.

Sometimes, the more you know, the more excuses you have to reject some idea or not to pursue some avenue of exploration. It's the young academics who make the advancements because it's a time for them where they don't have the breadth to get in the way of digging deeply in some direction.
AnswerKenntnis:
Pierre de Fermat was a French lawyer and amateur mathematician. I think he only started doing math in his late 20s. He is most famous for Fermat's Last Theorem, conjectured in 1637 and solved in 1994 by Andrew Wiles.
AnswerKenntnis:
You're never too old to learn anything.
You're only 22 -- These are the years you're supposed to be deciding what to do with your life, so if you're interested in mathematics, do it! 


This is a similar situation to my own. I'm going for it, you should too!
AnswerKenntnis:
Apart from age, this makes me think about this basic fear that if you're not enormously brilliant at doing logic and math puzzles, you're not going to make anything in maths, hard sciences or even applied sciences.

It's true that if you are not sure of being a crack, you are probably not one of them. But I see many people doing well in applied maths that are really not "cracks" (and I'm sure there are also some in very scientific fields).

Also, I usually hear about the major "super brains" in maths that they used help from fellow researchers on writing down theories, etc. (I was thinking about A. Grothendieck, sure you can find some examples).

So I think there is a place for "less genius brains" in science and maths.
And if you're thinking about applied maths, there is place to make money with maths today more than ever.
If you love maths, go for it (there are too few people like you!).
AnswerKenntnis:
Knowledge is provided for whoever want it. Like a Chinese quote,'Live and learn until you become old or even death'. Somebody believe in IQ or gifted or talented. But i believe the quality of hardworking and never give up is the true path to success. If you know something is right, just do it.
AnswerKenntnis:
When I started my undergrad degree, the head of the physics department was a guest speaker in another class I was taking.  He told us that physicists don't come up with any ideas that are groundbreaking after age 40.  So, even if a physicist were to publish a ground breaking paper at age 60, it is most likely based on ideas they first came up with when they were younger.  I think this probably is true for the most part.

However, there are many things here to consider.


This statement isn't absolute.  There are counterexamples.  And, it is based on his observations and not on a statistical experiment that is well controlled and well documented.
You are still much younger than 40 and even after you get a PhD, I think you still will be, though I'm not sure about your age.
This is probably the most important one.  Most PhDs in any field don't do anything that is groundbreaking at any age.


So, what is your goal?  Do you want to be a world famous mathematician?  If so, if you are a genius then it might not matter when you start (i.e., even if you do start late, your genius can make up for it).  And, if you are not a genius, then it might not matter when you start (i.e., even if you started young you still probably won't do anything world famous).

Otherwise, if your goal is to be a professor and do research that is fun to you (but not groundbreaking or world famous) and teach other students, then you're definitely not too old for that.  Where I go to grad school, half the students are 30+ when they graduate.  And, most of the people I know in pure math in my department go on to jobs where they are required to do no research or are required to do limited research.  This is something you could achieve.  Is this what you want to do?

If you want to do more research, you could do it on your own, in your own free time.  If you want your job to be doing research, then it's possible but not likely no matter when you start.  Most of the professors where I am getting my PhD got theirs at schools like Berkeley, Penn State, Yale, Harvard, Illinois Urbana Champagne, Wisconsin-Madison, etc.  They now work here, a research university, and a large portion of their job is research.  Can you get a PhD from a top school?  That can't be answered here.  We don't know enough about you.
AnswerKenntnis:
I don't think that age is an issue with you. This lack of "epiphany" and "intuition" you are having is not because of age. It is because of inexperience. You just have been out of touch with math for too long. Or maybe you were never exposed to enough mathematical thinking to begin with. Thinking logically is hard. And it can take a lifetime to get there.

So its not that your brain is incapable of being good at math. Its just that you need to spend some time in math mode. I have been buried in math consistently and constantly for the past 9 years and still at this point even if I just step away for one summer I start losing some of it. For me its exposure. If I see a problem, usually something in the past that I have seen helps me. Rarely I think of something truly original. So what I do is just expose myself as much as possible so my arsenal keeps getting bigger and bigger.

Very few people (like Gauss and Mozart) are truly gifted and rock the world as soon as they are born. The rest of us just learned and refused to give up. I think the only thing which you have no control over is creativity. Good GOOD mathematicians always had a lot of creativity and that is something you can't get with age or experience. That's the only thing you need to be born with.

Just keep at it and you will get better, guaranteed. Humans (including our brains) are remarkable at adapting.
AnswerKenntnis:
If, on the other hand, if this being really good requires a tenure stream academic career, I believe you need to think about how most hiring committees would view someone starting out at the age you have completed your Phd. 

Mine was planned for age 50 but delayed due to revisions for three years and I discovered that 53 was too late. Onetime I actually found out the committee decided they would prefer the younger candidate (no I did not sue) and the one position I was hired for, it was pointed out that I starting rather late for academe. It was a very good Department, but I chose to leave after the first year rather than relocate my kids just before they finished high school. 

You should be done well before that, I wish someone had pointed this out to me.
AnswerKenntnis:
I started working on my bachelor's in Computer Science at 24 at UCSD, and I came in with almost no knowledge of programming, and the highest level of math I had accomplished at that point was Pre-Calculus. So in addition to taking the entire CS curriculum, I had to take all 5 engineering calculus courses as well. I just tackled everything I needed to do, and with the help of good people around me, I finished with pretty good grades.

So, no. You're not too old.
AnswerKenntnis:
This popped as a newsletter question, and it seems appropriate to share personal experience.

It is true that most significant math research seems to be done before 30. I remember Hirzebruch from my Alma Mater who had published 50% of his research by 25 - or at least that was what people said. At the same school, my Algebra professor, Jens Franke, was a year or two younger than me (see below), having already spent time at Princeton and Moscow before this. One of my teachers in grad school (economics) had 4 seminal papers in 4 different areas by 25 (and more or less retired after).

In my first semester of college, I was 25. In my first semester of math, I was 26. Being surrounded by people 7 to 8 years younger than me wasn't very encouraging - in particular the regrettable attitude of many math students to (falsely) claim that they solved an exercise you agonized over with no problem at all, and to spend 1/2 their time shortening and obscuring their arguments, probably because of a misunderstood understanding of what is elegant and cool. My first homework buddy told me what I never forgot, and have found quite true:

"If someone has a better solution than you, just assume he copied it from a better book than you had access to."

Given that my high school math education wasn't very good, for faults of my own and my teacher's, and I averaged I'd say a B+ (below my general average), with a glorious F in my final oral exam (my only F ever), I felt both inferior, and did objectively struggle at the beginning. Add to this that in informal rankings (there are no official ones in Germany) my school, Bonn, was considered one of the two best for math, and so attracted many former math Olympics participants (the most accomplished one had participated in grades 10-13, winning 2 silver and 2 gold medals). Before meeting them, I didn't even know there were math Olympics...

I worked very hard, and I think for most this is simply necessary in math. As a result, within about a year, in a crowd of about 200,  I started being considered pretty good - certainly behind the math Olympics guys, but probably around there. I went on being admitted to a top 3 grad school in the U.S. - not for math as I still lacked the confidence, but with a goal to study the most theoretical part of economics (decision, game theory and such), which boils down to applying algebraic topology and other fairly hardcore math disciplines. My course work consisted mostly of taking the theoretical stats grad level classes of the first two years (in stats, my school was - then - traditionally considered as competing with Berkeley to be the top-ranked stats school), scoring consistently A's with the rare A-, and I did very well (ranked 'outstanding' and 'excellent' by my school the first two years).  Being a rather troubled human being, I proceeded to boycott my own future as an academic (which is a different story not belonging here), but still my  main thesis paper was 3rd rounded by Mathematics of Operations Research (with feedback "Clearly worthy of publication", asking to tie up details), before I stopped pursuing it, having gone to industry, not academia.

I'm now in my 40s, and am just done auditing algebraic topology at Columbia. 22 is certainly in itself not too old. While you say that you don't want a "do what you like!" pat on the back, I can't help giving you one. Just expect it to be tough originally, to have to work very hard (making it your life for a while), and to pretty much keep feeling that you should see things faster than you do. That's the doing math experience: every new problem is a true challenge.
AnswerKenntnis:
While I think you are never too old to start anything, I really think Math sports needs to be learned and cultivated from a young age to be truly effective.
AnswerKenntnis:
I have looked through the answers so far, and don't see one from anyone really old. I am 82 and still learning maths, and lots of other stuff, as part of a hobby that includes electronics and amateur radio. I help with on-line tutoring on a UK course for those taking their exam for a Full amateur radio licence, and I have no trouble sorting out the answers to the problems students have. So age is not a hindrance.

From boredom and ill health, I just scraped though a Pass degree in Maths and Physics when I was 21. After ten years as an engineer I studied for a Teaching Certificate, and at the same time became interested (1964) in computing. I got a Master's degree in Technology (computer Science) at age 43, and thereafter taught computing at a Polytechnic that became a University (and a very good one) a few years before I retired.

My advice is to attempt what you fancy, age mostly brings maturity that makes it easier to study.
AnswerKenntnis:
When I was 21 I entered college not even knowing how to solve a quadratic equation, as I was a high-school dropout (I eventually got a GED). Ten years later I had a Ph.D in math.
QuestionKenntnis:
Can you answer my son's fourth-grade homework question: Which numbers are prime, have digits adding to ten and have a three in the tens place?
qn_description:
My son Horatio (nine years old, fourth grade) came home with some fun math homework exercises today. One of his problems was the following little question: 


  I am thinking of a number...
  
  
  It is prime.
  The digits add up to 10. 
  It has a 3 in the tens place.
  
  
  What is my number? 


Let us assume that the problem refers to digits in decimal notation. Horatio came up with 37, of course, and asked me whether there might be larger solutions with more digits. We observed together that 433 is another solution, and also 631 and 1531. But also notice that 10333 solves the problem, based on the list of the first 10000 primes, and also $100333$, and presumably many others. 

My question is: How many solutions does the problem have? In particular, are there infinitely many solutions? 

How could one prove or refute such a thing? I could imagine that there are very large prime numbers of the decimal form $10000000000000\cdots00000333$, but don't know how to prove or refute this.

Can you provide a satisfactory answer this fourth-grade homework question?
AnswersKenntnis
AnswerKenntnis:
As requested I'm posting this an answer. I wrote a short sage script to check the primality of numbers of the form $10^n+333$ where $n$ is in the range $[4,2000]$. I found that the following values of $n$ give rise to prime numbers:

$$4,5,6,12,53,222,231,416.$$

Edit 3: I stopped my laptop's search between 2000 and 3000, since it hadn't found anything in 20 minutes. I wrote a quick program to check numbers of the form $10^n+3*10^i+33$. Here are a couple 


100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000030000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000033
100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000300033
100000000000000000000000000000000000000000000000000000300000000000000000000000000000000000000033
100000000000000000000000000000000000000000000000030000000000000000000000000000000000000000000033
100000000000000000000000000000000000000000000030000000000000000000000000000000000000000000000033
10000000000000000000000000000000003000000033
10000000000000000000000000000030000000000033
10000000000000000000000030000000000000000033
10000000003000000000000000000000000000000033


There seemed to be plenty of numbers of this form and presumably I could find more if I checked some of the other possible forms as outlined by dr jimbob. 

Note: I revised the post a bit after jimbob pointed out I was actually looking for primes that didn't quite fit the requirements. 

Edit 4: As requested here are the sage scripts I used. 
To check if $10^n+333$ was prime:

for n in range(0,500):
  k=10^n+333
  if(is_prime(k)):
    print n


And to check for numbers of the form $10^n+3*10^i+33$:

for n in range(0,500):
  k=10^n+33
  for i in range(2,n):
    l=k+3*10^i
    if(is_prime(l)):
      print l
AnswerKenntnis:
From Srivatsan Narayanan's comment: there are on the order of $n^7$ numbers satisfying the digit constraint, with $n$ digits. The probability that a random $n$-digit number is prime is of order $1/n$. So naively there are on the order of $n^6$ $n$-digit numbers satisfying all the conditions.  The sum of sixth powers diverges (quite strongly!) and I suspect the answer is infinitely many and would be quite surprised to learn otherwise. In particular the number of such integers with $n$ digits or less "ought to be" on the order of $1^6 + 2^6 + \cdots + n^6$, or on the order of $n^7$; the number of such integers less than or equal to $x$, then, is on the order of $\log_{10} (Cx^7)$ for some constant $C$, or about $7 \log_{10} x$.
AnswerKenntnis:
37
433
631
1531
3331
4231
10333
10531
13033
15031
20233
20431
23131
30133
31033
31231
40231
41131
50131
51031
100333
103231
105031
110233
110431
113131
114031
120331
122131
123031
202231
211231
212131
231031
300331
310231
312031
321031
400033
411031
501031
510031
1000333
1001431
1010431
1011331
1030033
1050031
1110133
1110331
1112131
1130131
1311031
1320031
1400131
1401031
2001331
2011033
2020231
2110033
2130031
2300131
2301031
2400031
3000133
3000331
3011131
3030031
3100231
4010131
4020031
10002133
10002331
10010431
10012033
10014031
10020133
10020331
10023031
10112131
10121131
10201231
10203031
10210033
10220131
10500031
11040031
11101033
11101231
11102131
11111131
11201131
12000133
12020131
15000031
AnswerKenntnis:
Not an answer as such but primes that satisfy criteria 2 & 3 have the form:

$$\begin{cases}
37\\
31+6\times10^a\\
31+5\times10^a+10^b\\
31+4\times10^a+2\times10^b\\
31+4\times10^a+10^b+10^c\\
31+3\times10^a+2\times10^b+10^c\\
31+3\times10^a+10^b+10^c+10^d\\
31+2\times10^a+10^b+10^c+10^d+10^e\\
31+10^a+10^b+10^c+10^d+10^e+10^f\\
33+4\times10^a\\
33+3\times10^a+10^b\\
33+2\times10^a+2\times10^b\\
33+2\times10^a+10^b+10^c\\
33+10^a+10^b+10^c+10^e\\
\end{cases}$$

where $a,b,c,d,e,f\in\mathbb N$, are distinct and $\gt1$.

Taking any one of these forms, can anyone prove that there are infinitely many primes in the sequence? I would guess that $33+4\times10^a$ would be the easiest to try.

I will also say that given that many other sequences that are not as restrictive as this (e.g. Goldbach's conjecture, twin prime, Proth, Mersine) cannot be proved to have infinitely many primes this could well be a hiding to nothing.
AnswerKenntnis:
I wrote some Perl code for this. There are 125 such primes other than 37 up to 100000000. There are 99 that end with 31. And 26 that end in 33 :). I believe this is exhaustive list. Getting numbers for higher limit is just matter of compute time.

433 631 1531 3331 4231 10333 10531 13033 15031 20233 20431 23131 30133
31033 31231 40231 41131 50131 51031 100333 103231 105031 110233 110431
113131 114031 120331 122131 123031 202231 211231 212131 231031 300331 310231
312031 321031 400033 411031 501031 510031 1000333 1001431 1010431 1011331
1030033 1050031 1110133 1110331 1112131 1130131 1311031 1320031 1400131
1401031 2001331 2011033 2020231 2110033 2130031 2300131 2301031 2400031
3000133 3000331 3011131 3030031 3100231 4010131 4020031 10002133 10002331
10010431 10012033 10014031 10020133 10020331 10023031 10112131 10121131
10201231 10203031 10210033 10220131 10500031 11040031 11101033 11101231
11102131 11111131 11201131 12000133 12020131 15000031 20003131 20004031
20013031 20110231 20112031 20202031 20210131 20211031 20400031 21001033
21100033 21100231 21201031 22002031 22100131 22110031 23100031 30000133
30000331 30010033 30030031 30102031 31110031 32100031 33000031 40000033
40000231 40011031 40101031 50000131 50010031


Code:

#!/usr/local/bin/perl

use strict;
use POSIX qw(ceil);

my $limit = $ARGV[0];
my $cnt=0;
    my $cnt31=0;
my $cnt33=0;
    my @sieve = set_sieve($limit);
chk_special($limit*$limit, $limit);
    print "Special primes: $cnt, Ending with 31: $cnt31, Ending with 33: $cnt33\n";

sub set_sieve {
    my $limit = $_[0];
    my $i=5;
        my $incr = 2;
    my @sieve = [];
    $sieve[0] = 2;
        $sieve[1] = 3;
    while ($i < $limit) {
    my $j = 0;
    	my $found = 1;
    while (($sieve[$j]*$sieve[$j]) <= $i) {
    	    $j++;
    	    if (($i % $sieve[$j]) == 0) {
    		$found = 0;
    		last;
    	    }
    	}
    	if ($found == 1) {
        push(@sieve, $i);
    	    sp_prime($i);
    }
    $i = $i + $incr;
    	if ($incr == 2) {
        $incr = 4;
    	} else {
    	    $incr = 2;
    	}
        }
        my $total = $#sieve+1;
    return @sieve;
}

sub chk_special {
    my $limit = $_[0];
    my $start = $_[1];
    my $i=$start-($start%6)+7;
        my $cutoff = power10(length($i)-1)*6;
        my $incr = 4;
    while ($i < $limit) {
    my $j = 0;
    	my $found = 1;
    if (sp_num($i)==1) {
    	    while (($sieve[$j]*$sieve[$j]) <= $i) {
    		$j++;
    		if (($i % $sieve[$j]) == 0) {
    		    $found = 0;
    		    last;
    		}
    	    }
    	    if ($found == 1) {
    		print "$i\n";
    		my $mod = $i%100;
    		if ($mod == 31) {
    		    $cnt31++;
    		}
    		if ($mod == 33) {
    		    $cnt33++;
    		}
    		$cnt++;
    	    }
    	}
    	$i = $i + $incr;
    if ($incr == 2) {
    	    $incr = 4;
    	} else {
    	    $incr = 2;
    	}
    	if ($i > $cutoff) {
    	    my $new_start = power10(length($cutoff)-1)*10;
    	    $i = $new_start - ($new_start%6) + 7; 
    	    $incr = 4;
    	    $cutoff = power10(length($i)-1)*6;
    	    #print "New_start: $new_start Cutoff:$cutoff\n";

    }
    }
}

sub sp_prime {
    my $prime = $_[0];
    my $mod_100 = $prime%100;
    if (($mod_100 == 33) || ($mod_100 == 31)) {
    my $sum;
    	$sum += eval join '+', split(//, $prime);
    	#print "$prime:$mod_100:$sum\n";
    if ($sum == 10) {
    	    print "$prime\n";
    	    my $mod = $prime%100;
    	    if ($mod == 31) {
    		$cnt31++;
    	    }
    	    if ($mod == 33) {
    		$cnt33++;
    	    }
    	    $cnt++;
    }
    }
}

sub power10 {
    my $exp = $_[0];
    my $power = 1;
        foreach my $n (1..$exp) {
    	$power *= 10;
        }
        return $power;
}


sub sp_num {
    my $num = $_[0];
    my $mod_100 = $num%100;
    if (($mod_100 == 33) || ($mod_100 == 31)) {
    my $sum;
    	$sum += eval join '+', split(//, $num);
    	if ($sum == 10) {
        return 1;
    } else {
        return 0;
    }
    } else {
    return 0;
    }
}


EDIT:
Another curious fact is as sum of digits is 10, all numbers are of the form 1 (mod 3) or 6n+1 type....
QuestionKenntnis:
Can't argue with success? Looking for "bad math" that "gets away with it"
qn_description:
I'm looking for cases of invalid math operations producing (in spite of it all) correct results (aka "every math teacher's nightmare").

One example would be "cancelling" the 6s in

$$\frac{64}{16}.$$

Another one would be something like

$$\frac{9}{2} - \frac{25}{10} = \frac{9 - 25}{2 - 10} = \frac{-16}{-8} = 2 \;\;.$$

Yet another one would be

$$x^1 - 1^0 = (x - 1)^{(1 - 0)} = x - 1\;\;.$$

Note that I am specifically not interested in mathematical fallacies (aka spurious proofs).  Such fallacies produce shockingly wrong ends by (seemingly) valid means, whereas what I am looking for are cases where one arrives at valid ends by (shockingly) wrong means.

Edit: fixed typo in last example.
AnswersKenntnis
AnswerKenntnis:
I was quite amused when a student produced the following when cancelling a fraction:

$$\frac{x^2-y^2}{x-y}$$

He began by "cancelling" the $x$ and the $y$ on top and bottom, to get:

$$\frac{x-y}{-}$$

and then concluded that "two negatives make a positive", so the final answer has to be $x+y$.
AnswerKenntnis:
Here's a pretty funny one from xkcd.
AnswerKenntnis:
A student in a test was asked to give an example of two irational numbers whose sum is irational.

He choose $x = \sqrt{2}$, and $y=\sqrt{3}$, and computed the sum $x+y$ using a calculator. Unfortunetly, he only took two digits, which led to the following:

$x = 1.41$, and $y = 1.73$, which implies that $x+y = 3.14$. 

The student concluded that $\sqrt{2}+\sqrt{3}=\pi$
AnswerKenntnis:
From MathWorld / Printer's Errors:


  Typesetting "errors" in which exponents or multiplication signs are omitted but the resulting expression is equivalent to the original one. Examples include
  $$\begin{align} 2^5 9^2 &= 2592, \\ 3^4 425 &= 34425, \\ 31^2 325 &= 312325,\end{align}$$
  and
  $$2^5 \cdot \frac{25}{31} = 25 \ \frac{25}{31},$$
  where a whole number followed by a fraction is interpreted as a mixed fraction (e.g., $1 \frac{1}{2} = 1 + \frac{1}{2} = \frac{3}{2}$).


That page also contains a link to your first example of "cancelling" 6s, denoted "Anomalous Cancellation", and containing three other examples with both numerator and denominator less than $100$: $$\frac{98}{49} = \frac{8}{4} = 2, \qquad \qquad \frac{95}{19} = \frac{5}{1} = 5, \qquad \qquad \frac{65}{26} = \frac{5}{2}.$$
AnswerKenntnis:
Here's another classical freshman calculus example: 

Find $\frac{d}{dx}x^x$. 

Alice says "this is like  $\frac{d}{dx}x^n = nx^{n-1}$, so the answer is $x x^{x-1} = x^x$."
Bob says "no, this is like  $\frac{d}{dx}a^x = \log a \cdot a^x$, so the answer is $\log x \cdot x^x$." 
Charlie says "if you're not sure, just add the two terms, so you'll get partial credit".

The answer  $\frac{d}{dx}x^x = (1 + \log x)x^x $ turns out to be correct.
AnswerKenntnis:
This one is from Mathematical Fallacies, Flaws, and Flimflam - Edward J. Barbeau. 

A student on a quiz was asked to integrate $\displaystyle \int \frac{1}{1+x}\;{dx}$. His/her answer was as follows: 

$$ \displaystyle \begin{aligned} \int \frac{1}{1+x}\;{dx} &= \int \bigg(\frac{1}{x}+\frac{1}{1}\bigg)\;{dx}  \\& = \int \frac{1}{x}\;{dx}+\int\frac{1}{1}\;{dx} \\&= \log(x)+\log(1) \\&= \log(x+1)+C. \end{aligned}$$
AnswerKenntnis:
I was once writing something where for stylistic reasons it made sense to change the way I wrote a vector of non-negative integers by writing $(a_1,\dotsc,a_n)$ as $1^{a_1}\dotsm n^{a_n}$, like a product, and omitting $i$ from the string if $a_i=0$, so for example $(1,0,0,3,0,0,0,1)$ would be $14^38$ (all the vectors in the actual problem had a large number of zeros, one of the reasons to change to this more concise notation). Most of the time all of the non-zero numbers were $1$s, so they all ended up looking like integers.

Naturally the first time I actually did a calculation in this notation, I wanted to remind anybody reading that the numbers had to be read back as these vectors, not as integers. Unfortunately, the first line was:

$$(0,0,0,1,1,1,0,0,0)+(1,0,0,0,1,0,0,0,1)-(1,0,0,0,1,1,0,0,0)=(0,0,0,1,1,0,0,0,1)$$

or in my notation:

$$456+159-156=459$$

Amusing, but fairly unhelpful!
AnswerKenntnis:
I dont't know if this counts. But I really like it. 
Let $A$ be a square matrix over a field $K$ and $$ \chi = \det(X \cdot \operatorname{Id} - A) \in K[X] $$ the characteristic polynomial of $A$.
Then $\chi(A) = 0$, because "it's just plugging in".
AnswerKenntnis:
$\sin(x) = 0$

Thus we have either $x = 0$ or $\sin = 0$. A function cannot be equal to a number, therefore we must have x = 0.

I knew someone who once got as far as the first step, although in their defense I think it was just a temporary brain fart. The conclusion is correct if you're working with a restriction of the sine function to, say, $(-\pi, \pi)$.
AnswerKenntnis:
Here is my example:
$$
\lim_{n\to\infty}\frac{1+2^2+3^3+\ldots+n^n}{n^n}=\lim_{n\to\infty}\left(\frac{1}{n^n}+\frac{2^2}{n^n}+\ldots+\frac{n^{n}}{n^n}\right)=0+0+\ldots+ 1=1.
$$
AnswerKenntnis:
Old John's example is gorgeous, but consider famous freshman's dream
$$ (a+b)^p = a^p + b^p \pmod p . $$

Various things which are true because of complex numbers, could be derived incorrect way in reals, e.g. using symbols like $\sqrt{-2}$, etc.

In probability theory there are lot of issues with dependent random variables, which can still yield correct results.

Also, check out this:
\begin{align}
S(a,b) &= \sum_{k=a}^{b} 2^k\\
T(a) &= \sum_{k=a}^{\infty} 2^k = 2^a + 2\sum_{k={a+1}}^{\infty} 2^{k-1} = 2^a + 2T(a)\\
T(a) &= \frac{2^a}{1-2} = -2^a \quad(\text{sum of positive elements is negative!})\\
S(a,b) &= T(a) - T(b+1) = -2^a - (-2^{b+1}) = 2^{b+1}-2^a
\end{align}
and this:

\begin{align}
\sum_{k=0}^{n} 2^k &= \frac{2^{n+1}-1}{1-2} \\
\frac{d}{d2}\sum_{k=0}^{n} 2^k &= \frac{d}{d2}\frac{2^{n+1}-1}{1-2}\quad(\text{differentiate over two!})\\
\sum_{k=0}^{n} k2^{k-1} &= \frac{1-(n+1)2^n+n2^{n+1}}{(1-2)^2}
\end{align}

Cheers!
AnswerKenntnis:
If $G$ is a group and $K,N$ are normal in $G$ with $K \subseteq N$  then $$G/N \cong (G/K)\large/\normalsize(N/K)$$ which is obviously true by just cancelling the terms on the rhs.
AnswerKenntnis:
Earlier, I asked my friend to simplify $\dfrac{\cos^2 (73) + \cos^2(17)}{\cos^2(63) + \cos^2(27)}$. Here is his work:


  $$\frac{\cos^2(73) + \cos^2(17)}{\cos^2(63) + \cos^2(27)} = \frac{\cos^2(73 + 17)}{\cos^2(63 + 27)} = \frac{\cos^2{(90)}}{\cos^2(90)} = \frac{\cos^2}{\cos^2} = 1$$
AnswerKenntnis:
Kepler's second law famously states that the radius vector from the sun to a planet will sweep out equal areas under equal times. His proof of this law included the following errors:

(1) He assumed that the velocity of the planet, as the planet traversed its orbit, was inversely proportional to the distance from the sun.

(2) Let $P_1P_2\dots P_{n+1}$ be points on an arc of the orbit of the planet, and such that the distances $|P_{i+1}-P_i|$ for $i=1,\dots,n$ are all equal to some small $\Delta s$. Let $S$ be the position of the sun, and let $r_i = |P_i -S|$ be the radial distance between the sun and the planet's position at $P_i$. Kepler then assumed that the area swept out by the radius vector from $S$, as the planet moved from $P_1$ to $P_n$, was proportional to the sum $(r_1+r_2\dots+r_n)\Delta s$. 

Both these assumptions are wrong, but fortunately the effects of these errors cancel each other, and so Kepler was able to state his correct second law of planetary motion.
AnswerKenntnis:
Slightly contrived:

Given $n = \frac{2}{15}$ and $x=\arccos(\frac{3}{5})$, find $\frac{\sin(x)}{n}$.

$$
\frac{\sin(x)}{n} =  \mathrm{si}(x) = \mathrm{si}x = \boxed{6}
$$
AnswerKenntnis:
A classical example due to Euler, I believe:

Notice that the roots of $\sin(x)$ are precisely the numbers $k \pi$ where $k$ is any integer.  But the same is true of the product

$$x \left(1 - \frac{x^2}{\pi^2 1^2}\right) \left(1 - \frac{x^2}{\pi^2 2^2}\right)\ldots$$

so the two must be equal.  The coefficient of $x^3$ in the product is $-\frac{1}{\pi^2} \sum_{n=1}^\infty \frac{1}{n^2}$, and the coefficient of $x^3$ in the Taylor series of $\sin(x)$ is simply $-\frac{1}{6}$.  Therefore,

$$\sum_{n=1}^\infty \frac{1}{n^2} = \frac{\pi^2}{6}$$

If part of your brain is tempting you to think that this argument might be right after all, note that if you apply exactly the same reasoning to the function $\sin(\pi x)$ then you get the value $\frac{\pi^3}{6}$.  Nevertheless, this is so eerie that I can't help but wonder if there's something to it...
AnswerKenntnis:
My "favorite" error is 
$$
\frac{i}{i}=\frac{\sqrt[2\,\,]{-1}}{\sqrt[2]{-1}}=\sqrt[2\,\,]{\frac{-1}{-1}}=\sqrt[2\,\,]{1}=1.
$$
AnswerKenntnis:
One example from me:

$$ \sqrt{5 \frac{5}{24}} = 5 \sqrt{\frac{5}{24}}
$$
$$ \sqrt{12 \frac{12}{143}} = 12 \sqrt{\frac{12}{143}} $$
AnswerKenntnis:
When I asked my student to get rid of irrationality in the denominator of fraction
$$
\frac{1}{\sqrt[3]{3}+\sqrt[3]{5}}
$$
He gave an immediate solution
$$
\frac{1}{3^{1/3}+5^{1/3}}
$$
What can I say, no roots no irrationalities :-) 

I must confess, this example doesn't fit in the original citeria.
AnswerKenntnis:
You all probably, no doubt, have seen the proof to the question: Is Hell Endo or Exothermic. 

This one always makes me laugh...



Dr. Schambaugh, of the University of Oklahoma School of Chemical Engineering, Final Exam question for May of 1997. Dr. Schambaugh is known for asking questions such as, "why do airplanes fly?" on his final exams. His one and only final exam question in May 1997 for his Momentum, Heat and Mass Transfer II class was: "Is hell exothermic or endothermic? Support your answer with proof."

Most of the students wrote proofs of their beliefs using Boyle's Law or some variant. One student, however, wrote the following:

"First, We postulate that if souls exist, then they must have some mass. If they do, then a mole of souls can also have a mass. So, at what rate are souls moving into hell and at what rate are souls leaving? I think we can safely assume that once a soul gets to hell, it will not leave.

Therefore, no souls are leaving. As for souls entering hell, let's look at the different religions that exist in the world today. Some of these religions state that if you are not a member of their religion, then you will go to hell. Since there are more than one of these religions and people do not belong to more than one religion, we can project that all people and souls go to hell. With birth and death rates as they are, we can expect the number of souls in hell to increase exponentially.

Now, we look at the rate of change in volume in hell. Boyle's Law states that in order for the temperature and pressure in hell to stay the same, the ratio of the mass of souls and volume needs to stay constant. Two options exist:

If hell is expanding at a slower rate than the rate at which souls enter hell, then the temperature and pressure in hell will increase until all hell breaks loose.
If hell is expanding at a rate faster than the increase of souls in hell, then the temperature and pressure will drop until hell freezes over.
So which is it? If we accept the quote given to me by Theresa Manyan during Freshman year, "that it will be a cold night in hell before I sleep with you" and take into account the fact that I still have NOT succeeded in having sexual relations with her, then Option 2 cannot be true...Thus, hell is exothermic."

The student, Tim Graham, got the only A.
AnswerKenntnis:
A very common mistake in analysis.


  Exercise: Let's $K\subset\mathbb{R}^{n}$compact and a function $f:K\to \mathbb{R}$ locally Lipschitz, i.e. for all $x$ in the compact $K$ there is an open $V_x$ containing $x$ and a constant $L_x$ such that
  $$
|f(u)-f(v)|<L_x \|u-v\|, \quad \forall u,v\in V_x
$$
  Proof that $f$ is too Lipschitz in all $K$. 


"Proof:"
Let $\{V_x\}_{x\in K}$ the open cover of $K$ where each $V_x$ is as in the hipotesis of exercise. As $K$ is compact there is a finite  $\{V_{x_1},\dots, V_{x_N}\}$. Then for all $u,v\in K$ we have 
$$
|f(u)-f(v)|<\max\{L_{x_1},\dots,L_{x_N}\} \|u-v\|, \quad \forall u,v\in K. 
$$

So just $L=\max\{L_{x_1},\dots,L_{x_N}\}$ to a constant that is valid for all $K$. Then $f$ is too Lipschitz in all $K$.
AnswerKenntnis:
There is a lot of treatment with little rigor around the first infinitesimal calculations. For example consider a circle of radius $r$, we can approximate it's area by filling it with equal triangles.



The area of ΓÇïΓÇïeach triangle is given(approximately) by $lr/2$, where $l$ is the base of the triangle.
If we have $n$ triangles, the sum of their areas is given by $nlr/2$. By increasing
the number of triangles to infinity, the sum of the bases of the triangles
approximates the length of the circumference, i.e, if $n\rightarrow\infty$ then $nl\rightarrow2\pi r$. Thus, the sum of the areas of the triangles
tends to $2\pi r^2/2 = \pi r^2$, which is the area of the circle.

The result is correct but we calculates $\infty\cdot 0$ with almost no rigor at all.
AnswerKenntnis:
Another one I came across was a function composition problem.

Let $g(x)=x^2.$  Find $(g\circ g)(x)$.

Well it should be $$(g\circ g)(x)=g(g(x))=g(x^2)=(x^2)^2=x^{2\cdot{2}}=x^4$$
But of course I should have caught that my students would do the "natural thing" and say
$$(g\circ g)(x)=g(x)\cdot g(x)=x^2\cdot x^2=x^{2+2}=x^4$$

I blame myself for not catching this one, but.....
AnswerKenntnis:
This happened to me last week with a quiz I gave to my Algebra 2 class doing radical equations.

Solve $\sqrt{-5x+35}+7=x$

WRONG
$$\sqrt{-5x+35}=x-7$$
$$-5x+35=x^2-49$$
$$0=x^2+5x-84=0$$
$$0=(x+12)(x-7)$$
Thus $x=-12, 7$.  Checking for extraneous solutions yields the only solution as $x=7$

RIGHT
$$\sqrt{-5x+35}=x-7$$
$$-5x+35=x^2-14x+49$$
$$0=x^2-9x+14$$
$$0=(x-2)(x-7)$$
Thus $x=2,7$.  Checking for extraneous solutions yields the only solution as $x=7$

I assumed most of them were cheating.... I was wrong!
AnswerKenntnis:
Does this count? It can be shown that following the steps will give the correct answer, but the steps themselves are sometimes questionable. 
Let $y=(x-1)^3(x-2)^5(x-3)^7$. Find $\dfrac{dy}{dx}$.

Take the log of both sides. We get
$$\log y=3\log(x-1)+5\log(x-2)+7\log(x-3).$$
Thus 
$$\frac{1}{y}\frac{dy}{dx}=\frac{3}{x-1}+\frac{5}{x-2}+\frac{7}{x-3},$$
and therefore 
$$\frac{dy}{dx}=3(x-1)^2(x-2)^5(x-3)^7 + 5(x-1)^3(x-2)^4(x-3)^7+7(x-1)^3(x-2)^5(x-3)^6.$$
Simple, generalizes, true for all $x$, including many $x$ at which log is not defined. 

Remark: One can find many examples in Euler: formal manipulations that lead to the correct answer through in principle unjustified steps. About this, Euler wrote something like "Sometimes my pencil is more clever than I am."
AnswerKenntnis:
Recently seen:

Given $\gcd(a, b) = c$ we have $c\mid a$ and $c \mid b$, so $$(c\mid a) \cdot (c \mid b) = (c \cdot c) \mid (a \cdot b) = c^2 \mid ab,$$
hence $c^2 \mid ab$.
AnswerKenntnis:
Question is : Find $\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{\ln(x)}\right)$

My answer is : 
Divide and rule!! 

$\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{ln(x)}\right) = \lim_{x \to 1}\left(\frac{x}{x-1}\right)-\lim_{x \to 1}\left(\frac{1}{ln(x)}\right)$

Now using L'Hospital rule!

$\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{ln(x)}\right) = \lim_{x \to 1}\left(\frac{x}{x-1}\right)-\lim_{x \to 1}\left(\frac{1}{ln(x)}\right)=\frac{1}{1}-0=1$
AnswerKenntnis:
Well, using $\frac{dy}{dx}$ as a ratio is also one such example. It carries no meaning at all to use  $\frac{dy}{dx}$ as ratio but it works each time to get you to the right result instead of appreciating the limit process behind it.
I think it is as much abuse of notation as is eliminating 6's from a fraction, it is just that in this case the notation is designed such that each time you abuse it, you will get the right answer but you won't know actually why if you just rely on the notation. For example:
$\frac{dy}{dx}=\frac{dy}{dt} \frac{dt}{dx}$ due to chain rule and not due to treating $\frac{dy}{dx}$ as a fraction just like $\frac{x^2-y^2}{x-y}=x+y$ by algebra and not by 

$$\frac{x^2-y^2}{x-y}$$

"cancelling" the $x$ and the $y$ on top and bottom, to get:

$$\frac{x-y}{-}$$

and then conclude that "two negatives make a positive", so the final answer is be $x+y$.

Now if you see a student prove $\frac{5^2-3^2}{5-3}=8$ by the wrong method, will he be correct as this method of proof will hold for all $x,y \in R$ until $x \neq y$.

Also in three dimensions you have stuff like $ \frac{\partial x}{\partial y}\cdot\frac{\partial y}{\partial z}\cdot\frac{\partial z}{\partial x}=-1. $

Also, $dy$ isn't even defined , let alone be manipulated like a real number.
AnswerKenntnis:
$\newcommand{\+}{^{\dagger}}
 \newcommand{\angles}[1]{\left\langle\, #1 \,\right\rangle}
 \newcommand{\braces}[1]{\left\lbrace\, #1 \,\right\rbrace}
 \newcommand{\bracks}[1]{\left\lbrack\, #1 \,\right\rbrack}
 \newcommand{\ceil}[1]{\,\left\lceil\, #1 \,\right\rceil\,}
 \newcommand{\dd}{{\rm d}}
 \newcommand{\down}{\downarrow}
 \newcommand{\ds}[1]{\displaystyle{#1}}
 \newcommand{\expo}[1]{\,{\rm e}^{#1}\,}
 \newcommand{\fermi}{\,{\rm f}}
 \newcommand{\floor}[1]{\,\left\lfloor #1 \right\rfloor\,}
 \newcommand{\half}{{1 \over 2}}
 \newcommand{\ic}{{\rm i}}
 \newcommand{\iff}{\Longleftrightarrow}
 \newcommand{\imp}{\Longrightarrow}
 \newcommand{\isdiv}{\,\left.\right\vert\,}
 \newcommand{\ket}[1]{\left\vert #1\right\rangle}
 \newcommand{\ol}[1]{\overline{#1}}
 \newcommand{\pars}[1]{\left(\, #1 \,\right)}
 \newcommand{\partiald}[3][]{\frac{\partial^{#1} #2}{\partial #3^{#1}}}
 \newcommand{\pp}{{\cal P}}
 \newcommand{\root}[2][]{\,\sqrt[#1]{\vphantom{\large A}\,#2\,}\,}
 \newcommand{\sech}{\,{\rm sech}}
 \newcommand{\sgn}{\,{\rm sgn}}
 \newcommand{\totald}[3][]{\frac{{\rm d}^{#1} #2}{{\rm d} #3^{#1}}}
 \newcommand{\ul}[1]{\underline{#1}}
 \newcommand{\verts}[1]{\left\vert\, #1 \,\right\vert}
 \newcommand{\wt}[1]{\widetilde{#1}}$
$$\large
\lim_{x \to 0^{+}}{8 \over x} = \infty\quad\imp\quad\lim_{x \to 0^{+}}{3 \over x} =\omega
$$
AnswerKenntnis:
Some disagree with Laplace's socalled "Rule of succession".

See : http://en.wikipedia.org/wiki/Rule_of_succession

Not sure if this is what you wanted. But some say he is " getting away with it " (or was).

In fact it is said that he gets away with it because he did other good math.
Some people use his rule and others sometimes argue it should not be used in THAT CASE for which he just did.

As for " when to use the rule " there is also no consensus. Although the extreme opponents never use it ofcourse.

I came up with this so fast because my mentor is an opponent of this.

To justify his opinion somewhat here is one of his more or less formal arguments :

(quote)
Tommy1729 : 

Suppose a 6sided dice gets an equal amount of 1,2,3,4,5,6 after 60 spins.
So 10 times 1. 10 times 2. etc.

1) By the rule of succession the probability for (1 or 2) is 21/62.

2) By the rule of succession for the probability of (3 or 4) we have 21/62.

3) By the rule of succession for the probability of (5 or 6) we have 21/62.

So the total probability for (1 or 2 or 3 or 4  or 5 or 6 ) is 21/62 + 21/62 + 21/62 = 63/62.

63/62 ?? That is not 1.

Of course one can argue that the addition for independant probabilities A and B is no longer A + B. But that is just silly.

Notice that if we used to sum all the probabilities for each value of 1,2,... then we got 66/62 ; yet another number !

However that means we used Probability(1 or 2) = Probability(1) + Probability(2) = 11/62 + 11/62 = 22/62.

That is inconsistant with the successes of (1 or 2) +1 !

Another often defense is that the Rule of succession ONLY applies to TWO possible outcomes.

However 2 is a divisor of 6.

In other words the researcher could not know that the " success " is composed of little " successes ".

So if succes is defined as (1,2,3) and failure as (4,5,6) then it seems logical to assume that TWO possible outcomes are actually collections of Higher possible outcomes.

SO the rule P(A+B) = P(A)+P(B) should apply.  Thus follows from S = succes is defined as 

S = s1+s2+s3.

In other words the successes and their probabilities follow the rule S = s1 + s2 + s3 <=> P(A+B+C)= P(A)+P(B)+P(C) seems almost trivially true.

Resume : If a success depends on other success factors ( as often in statistics ! ) then using the rule of succession is disagreeing with P(A+B) = P(A)+P(B) for independant probabilities !!

Saying the rule of succession only works for binary possibilities is thus only consistant if you say " only P(A+B) exists " and thus not P(A) or P(B) ... Unless P(B) = 1 - P(A).

The rule of succession has thus issues with the rule of addition for independant probabilities , the possibility of subsuccesses or successfactors , the rule of total probability = 1.

The logic is quite funny :

suppose we have a coin 

we get 10 heads and 10 tails.

now succession gives 11/22. Whereas ordinary gives 10/20 or 1/2.

They are equal but 11/22 just looks silly.

Suppose we get 5 heads and 15 tails.

succession gives

heads : 6/22 , tails : 16/22

and then someone mentions the probability of heads is 1/4. And then he justifies this 6/22 by saying that if we take more coin tosses with prob 1/4 for heads our 6/22 finally becomes 1/4 in the limit.

LOL so you have to admit 6/22 is wrong to finally arrive at a justification for it ??
Did we admit 6/22 is wrong ? Yes because you assumed 1/4 ! AND your limits gives 1/4.

Why did you not take 1/4 then from the beginning ???

I call the rule of succession : " Orwellian statistics "

For those who are stubborn I continue

Let P mean probability and S succes.

a dice has 6 sides.

but we have P(1) and P(NOT 1).
P(NOT 1) = P(2)+P(3)+P(4)+P(5)+P(6) and/or S(NOT 1) = S(2)+S(3)+S(4)+S(5)+S(6).
( P and S are independant(!) probabilities and successes ! )

If you agree with any of those 2 you get the paradoxes from above.

If you disagree with both , you will have a hard time doing statistics !

One more time, a dice has 6 possibilities.

but 1 or not 1 is a binary choice.

So in fact the rule of succession for binary possibilities does apply afterall !

similarly "2" or "not 2" is a binary choice. Notice "not 2" CONTAINS 1. So we need 

P(1) = 11/62. P(NOT 1) = 51/62

P(NOT 1) = 51/62 = P(2)+P(3)+P(4)+P(5)+P(6)

Now by symmetry we know P(2)=(P(2)+P(3)+P(4)+P(5)+P(6))/5 = 51/310.
But also by symmetry P(1) = P(2).  But 51/310 =/= 11/62 !

So the rule of succession is not consistant with 

1) the rule of addition for independant probabilities
2) the possibility of subsuccesses or successfactors
3) the rule of total probability = 1.
4) symmetry for equal probabilities.

QED ?

regards

tommy1729

(end quote)

Note the quote is the way I remember it. Not an actual quote. I believe it was posted on sci.math. see also http://en.wikipedia.org/wiki/Orwellian

http://en.wikipedia.org/wiki/George_Orwell
QuestionKenntnis:
Is mathematics one big tautology?
qn_description:
Is mathematics one big tautology? Let me put the question in clearer terms:

Mathematics is a deductive system: it works by starting with arbitrary axioms, and deriving therefrom "new" properties through the process of deduction. As such, it would seem that we are simply creating a string of equivalences; each property can be traced back logically to the axioms. It must be that way, that's how deductive systems work!

If that be the case, then in what sense are we introducing novel or new ideas? It would seem that everything is simply equivalent to the fundamental set of axioms that we choose to start with. Is there a precise step in mathematical derivation that we can isolate as going beyond pure logic? If so, then how does this fit in with the fact that mathematics is deductive? Must we change our view of mathematics as purely deductive? And if not, then is there a way to reconcile the feeling of creativity in mathematics with the fact that it boils down to pure logic?

I'm trying to figure out the true nature of what's going on here.
AnswersKenntnis
AnswerKenntnis:
Disclaimer: different people view this differently. I side with Lakatos: Logic is a tool. Proofs are a way to verify one's intuition (and in many cases to improve one's intuition) and it is a tool to check the consistency of theories in a process of refining the axioms. The fact that every proof boils down to a tautology is true but irrelevant to mathematics. 

Here is an isomorphic question to the question you posed: A painting is just blobs of paint of different colour on canvas. So, are we to deduce from this fact that the art of painting is reduced to just placing paint on canvas? Technically, the answer is yes. But the painter does much more than that. In fact, it is clear that while the painter must possess quite a large amount of skill in placing paint on canvas, this skill is the least relevant (while absolutely necessary) for the creative process of painting.

So it is with mathematics. Being able to prove is essential, but is the least relevant skill for doing mathematics. In mathematics we don't deduce things from axioms. Rather we try to capture a certain idea by introducing axioms, check which theorems follow from the axioms and compare these results against the idea we are trying to capture. If the results agree we are happy. If the results disagree, we change the axioms. The ideas we try to capture transcend the deductive system. The deductive system is there to help us find consequences from the axioms, but it does not tell us how to gauge the validity of results against the idea we try to capture, nor how to adjust the axioms. 

This is my personal point of view of what mathematics is (or at least what a sizable portion of it is). It is very close to what physics is. Physics is not just some theories about matter and its interactions with stuff. Rather it is trying to model reality. So does mathematics, it's just not entirely clear which reality it is trying to model.
AnswerKenntnis:
It doesn't matter whether every provable theorem is, logically, a tautology. That's just a slightly provocative restatement of the definition of provable.

What matters is via which means such proofs are found. This is where the novel ideas are introduced - in, for example, an ingenious construction, or some clever definition. Or often by going off seemingly on a tangent, proving a few lemmata which at first glance seems to have nothing to do with the theorem in question, only to turn around later, combing the lemmata, and voila, there the theorem.

Note that you can, in some formal systems, actually remove such detours from proofs. That property is called cutfree-ness, and basically states that every proof can be brought into a form where it doesn't take any detours and doesn't proof anything that isn't strictly necessary (that's a very rough description, I know). For such systems, you could argue that it's indeed hard to find creative value in a proof, if the same fact can also be proved in a straight-forward (and boring) way. Luckily for us, it turns out that the property of being cut-free itself has to be something that is very hard to proof. One can show that being cut-free automatically makes a deduction system consistent. Thus, from G├╢dels theorem, it follows that actually proving cutfree-ness of something like PA has to use methods which themselves go beyond PA's capabilities. Which of course makes cutfree-ness not applicable to the proof of cutfree-ness itself, and this thus always leaves some room for creativity. On just has to pick a strong enough formal system.
AnswerKenntnis:
Your statement that "Mathematics is a deductive system: it works by starting with arbitrary axioms, and deriving therefrom "new" properties through the process of deduction" is one that many mathematicians (though I presume not all) would disagree with; I am one of them.  There is a famous "chairs, tables, and beer-mugs" remark attributed to Hilbert that encourages this point-of-view, but my own view is that the very formal attitude to mathematics that this remark suggests is reflective more of a particular period in mathematics (one when foundational issues were at the forefront, for various reasons) than of the essence of mathematics.

I share the veiw of Ittay Weiss, namely that the ideas come first, and the axioms are just a way to model them.   Reasoning, too, often proceeds by working with the ideas first; as the argument develops, eventually it will be molded into something more formal, but (in my experience) this is not how arguments begin their lives.
AnswerKenntnis:
Tautology is a term used in logic to denote a statement that is true regardless of the values assigned to its variables, or its interpretation.

Mathematical statements aren't statements of logic (at last not the ones that consist of stuff other than logic, when we consider logic to be a branch of mathematics).  Logic is used to connect statements in mathematics.

An algebraic equation E1, for instance, is connected to logic insofar as that equation is either true or false.  We can derive another true equation E2 based on E1, but that is derivation and not logical deduction.

And so then we can look at this and make a logical statement such as "if E1, then E2".

But this statement is not a tautology. It is false whenever E1 is true and E2 is false.

Of course, it is not the case that E1 is true and E2 is false because we have established E1, and then mathematically derived E2 from it.  But all that has to do with the interpretation that we impose upon "if E1, then E2" and not with its logical form.

But these are interpretations which are not the consequence of the logical form of "if E1 then E2". That form itself isn't, well, tautological.

Secondly, tautology is not a pejorative term in logic. The word is used pejoratively in the sense of rhetoric tautology: some kind of obviously true statement that doesn't advance a discourse.

Logical tautologies are darn useful. Take, for instance, De Morgan's laws.  The field of logic probably has tautologies that are large, complicated and surprising.
AnswerKenntnis:
You've found a property of mathematics that might be philosophically interesting, but has very little to do with math itself. You're right, but that doesn't add any interesting knowledge.

The interesting part of mathematics is which deductions you make, and how science applies these deducted theorems in understanding reality. Even if it cannot be proven that they are true in an absolute sense.

You can be aware that it is impossible to know anything for sure, and yet live a happy life of learning.


  To know that you do not know is the best.
  To pretend to know when you do not know is a disease. 
  
  Lao Tsu
AnswerKenntnis:
I think you'll find Chapter 1 (in particular) of Bertrand Russell's Principles of Mathematics a delightful read. I'm positive that Russell's work will help you "figure out the true nature" of what's going on. Forgive me for not giving an explanation in my own words, but I firmly believe that I could not put it any better than Russell himself.
AnswerKenntnis:
One could extend this argument ad absurdam: English, as a language, consists of words whose meanings are defined in a dictionary; one could read a dictionary and know the meanings of all the words there are. Having done so, what need would there be to read anything else? Poetry, literature, discourse; it all just consists of the same words in varying order.

The same is true of many things - modern engineers construct new devices out of gears, cams, rods and parts that would be familiar to a Victorian engineer; computers are powered by logic gates, resistors, capacitors and components that have been around for decades, and so on.

A mathematical proof is something of a gestalt; as a whole it can explain things that go beyond the immediate implications of its constituent parts. Admittedly, it was just as true before anyone discovered it as after, but there is still great skill in producing it. Atoms existed in medieval times as they do today, but that doesn't take anything away from the achievement of the physicists who proved their existence and determined their structure. Foreign continents like America or Australia had been sitting beyond the horizon for thousands of years before sailors got there, but we still remember the names of the ships that made the first crossings. Likewise, every mathematical proof that humanity will ever produce is already true, but proving so is still worthwhile. The ideas may not be new in a fundamental sense, but they are new to us.
AnswerKenntnis:
Mathematics is one big tautology -- there's no escaping that.  If you imagine MATH as a person, and you were to state any theorem to MATH, MATH would say "well obviously."

But humans don't work like math.  If you axiomatize HUMAN as a belief/logical system, we lack several properties that MATH enjoys.  Just because we believe {A_i} doesn't mean we necessarily believe anything that can be derived from {A_i}.  Just because we believe A doesn't mean we don't believe !A.

Any theorem that we prove is completely trivial to MATH, but often non-trivial and novel to HUMAN.
AnswerKenntnis:
In a way, yes it is.  In fact, although I rarely bother, I find pleasure in reducing proofs to more and more fundamental terms.  

But I think, as Ittay Wiess says, mathematics is more than that.  It is a picture, a painting.

If we were beings of infinite intelligence, then perhaps mathematics would be a much less prominent field because all of the paths from the axioms would be trivially obvious.  If we were simply vastly more intelligent, then, it could be used for communication, but like casual language, would be a much more "mundane" experience - perhaps the objectivity would allow us to engulf ourselves in the intangible aspects of the experience even less.  It would be a mere descriptor.

For example imagine if we as human being, had flawless memory.  There would be no reason to paint a landscape.  It is possible one might paint to convey an experience, but what meaningfulness would this have to someone with an infinite memory? Someone with flawless memory could simply relive the experience of seeing the picture; why paint it?  It would knock the hec out of certain aspects of art, perhaps (not that it would annihilate it for sure; I'm not sure what infinite memory would do to our immediate sense of aesthetics!  Perhaps our sense of aesthetics evolved as a 'shortcut' way of encouraging us to modify our environment.  But that's another question...)

And that is where the human element really comes in.  We must perceive what we do (I hope.)  As a discipline, mathematics, input into a willing and receptive mind, forms a way of thinking about things, of subdividing problems, in a way that is reflective of reality.  It can complement our minds in much the same way our complex use of words in thought might give us a richer intellectual experience than our nearest evolutionary cousin's, though few have been the subject of a difference so prominent.

Think of it as a medium of thought, (for more on that term try the book "Rise of the image, fall of the word," by Mitchell Stephens.)  It gives us a way of perceiving things; the logic is an art unto itself, and one that some of us have been so blessed as to be able to see the beauty of.

Also, in say, a different universe, there might be different fundamental axioms, of a kind we cannot even conceive of - this would lead to completely different mathematics!
AnswerKenntnis:
This reminds me of a story told by Gelfand at his seminar: a drill sergeant at the ROTC training for math students used to tell them: "this is not algebra, here you have to actually think!"
According to Gelfand, the phrase was true: algebra is trivial because the LHS is always the same as the RHS, while analysis is non-trivial because it deals with inequalities and estimates.

Tautology or not, mathematics is useful for expressing and gaining knowledge about the world we live in.

Moreover, saying that it is a tautology is like saying that since the all fish consists of cells, ichthyology can be reduced to cytology, which, in turn, can be reduced to chemistry.

PS. Philosophy of science is as useful to scientists as ornithology is to birds. (attributed to Feynman).
AnswerKenntnis:
This question has been accurately explained in Wittgensteins' Tractatus. In ┬º6.1 he said: "The propositions of logic are tautologies." Later: "It is clear that one could achieve the same purpose by using contradictions instead of tautologies."

Mathematics seem to be a way of thinking and talking; of building propositions and sentences. Moreover we're fascinated by the idea that the universe actually adheres to  our thinking. That we've found "the basic language of the nature".

Here are two practical ideas why mathematics are (maybe) not just a big tautology:


still under development;
an extremely valuable system for individuals and cultures.


Mathematics is a part of our culture, and developed further with each new generation. For example, the Romans yet had no zero and hence no higher mathematics. Although logic has no intrinsic value, other than more logic, it has a meaning (for us) which transcends itself.
AnswerKenntnis:
The answer to this question requires that to be correct does not contain any mathematical tool: no theorem, no logical proposition, no axiom, and no structure isomorphic.

G├╢del would be happy to show you this grand illusion.
AnswerKenntnis:
Edit: expanded

The purely formal process of combining axioms with laws of deduction to move from one "truth" to another "truth" is tautological.

But the meaning which we assign to mathematical statements exists outside of this formal system.

To illustrate the difference, consider the following thought experiment. Suppose there existed an oracle that told us which statements are true (say, in ZFC). Then our job as mathematicians would be made easier in some sense, but still it would by no means be rendered obsolete.

First of all, mathematics is not just the quest for all truths. Rather, mathematicians work within a dynamic field of meaning, a constantly evolving language consisting of concepts that they find useful. An oracle, on the other hand, would produce statements in a fixed language, and without regard for their "meaning".

Secondly, mathematicians want to know why things are true. And they are not content with just any proof -- they want, if possible, a proof that illuminates, that has a potential for shedding insight, or for being generalizable or for embodying a technique that can be used in other problems. If we liken mathematics to a novel, then we are not content with just a list of facts or of minute details of cause-and-effect -- we are interested in a larger insight into the relationships between the characters.

Finally, as has been commented upon, a large part of mathematics is in finding the "right" questions to ask -- the ones which we find interesting and which could lead to further insight.

I hope this illustrates some of the differences between the "meaningless" nature of a truth-producing oracle and the meaningful, or meaning-seeking, nature of mathematics
AnswerKenntnis:
First of all, I want to thank everyone for their contributions and comments, there's some really great stuff here, and I've (and I feel anyone who has viewed this question would agree) definitely gained a lot from all that has been said. I've given my question a lot of thought, and I feel compelled to give an answer that encompasses some of the more elegant ideas expressed by other users. Here goes:

Mathematics, in its most essential form, is simply a set of ideas about quantity. These ideas are ways to view the world through the lens of measurement and of dimension. They have a unique "flavor", and in an exactly analogous manner, every other science (or field of study) is a group of ideas that help us view the world in a "flavored" way. Mathematicians discover these ideas, invent them, use them to find other ideas, clarify them and bring them to precise formulation, work with them, and this list may go on. We have a body of knowledge, and that is the key.

Thus far I've said nothing of deduction and for good reason: Deduction is the tool we use in order to ground our ideas in a firm, unshakable system. We strive to find axioms that will properly serve as the "seeds" for all of the mathematical ideas we'd like to have in our system. We wish to build up a logical fortress of implications and equivalences that will house our mathematical ideas. The deductive system is the means to derive and discuss the ideas of mathematics. Let me put this in different words: In order to further our quantitative knowledge, it becomes necessary to clearly define our abstract structures; it also becomes necessary to clearly perceive the properties of these structures, to manipulate them, and ultimately use them to arrive at other structures. This is the nature of the mathematical-deductive system, and the benefit is twofold: Firstly, we have a precise and logical way to house our intuitive quantitative ideas which form the main body of math. Secondly, once the dust has settled and we have worked out our precise deductive system to the last jot and tittle, it becomes possible to create new ideas, to reach novelties! That is the magic of the deductive system; the precision is a way to formalize our intuition, and the new-found rigor may even result in new ideas hitherto unsuspected. Once you have a logical system, novelties might be reached by utilizing the system, playing by its logic rules of derivation. So the true mathematics is a combination of both intuition and rigor.

It doesn't matter that, in some technical sense, everything might be traced back to axiomatic roots. That is just how deduction works, you can't fault a logical system for being logical. But at each derivative step, we have a new idea, that is the essential point! Even in an equality which seems to be the biggest triviality, the LHS and the RHS represent two different ideas, and their being equal a third. To reiterate, the deduction is a rigorous, "tautological" (not in the strict sense) system; but in each each step that we take, that brings us further and further away from the axioms, a new idea is birthed or represented. It is the concepts contained in each theorem or identity that are at the heart of math, and not the logical steps between them. Those logical steps are just due to the nature of deduction, and are of necessity if we are to employ the tool of deduction. 

I hope I have added something new to this (in my opinion) intriguing discussion, or at least synthesized what's already here. Thanks for reading.
AnswerKenntnis:
There are a few things to mention here; without checking what others have already said, I'll quickly sum them up.

First, there are more than only one set of axioms in Mathematics. Indeed, the beauty, and diversity, of mathematics arises from the diversity, and beauty, of the different axiomatic systems that have been introduced thus far. Certainly, it is not a novel act to introduce such a system, but it is so if the system is itself novel or interesting. Since, axioms are supposed to be, by definition "fundamental," introducing two sets of logically equivalent axioms (which differ, in the end, only in presentation) will not result in two (wholly, perhaps I should clarify this more) distinct theories. On a related note, it may very well be difficult to establish the logical equivalence of two sets of axioms. For more on the discussion of axiomatic systems, I recommend you study the development of and current set theory and formal logic.

Secondly, you must understand the difference between logical equivalence and identity. For example, the statement $P \implies Q$ is logically equivalent to $ \neg  P \lor Q$, however, they are not the same statement. Indeed, both statements say the same thing, but they differ, as mentioned prior, in presentation; you may use one over the other, however, you may not be able to derive the same conclusions depending on your choice. For more on the difference between the two, see this and this.

Thirdly, and perhaps the most obvious to mention here, there are certain propositions in Mathematics that can neither be proved nor disproved. Indeed, this is Godel's theorem.

To answer your question about the "creation" of new and novel truths, theorems can simply be interpreted as new ways of looking at combinations of axioms. For example, $${12 \over \pi^2}\sum_{k = 1}^\infty {1\over{k^2}} = 2 \tag{1}$$ is just another way (I would say new, but that is not really the case) of saying $$2 = 2 \tag{2}.$$ And, certainly, there is nothing novel about saying $(1)$ in this light. But! The point of the exercise is to draw relations that are not immediately obvious, and relations such as they may be useful in drawing other relations and equivalences. It is after all, as you said, a matter of drawing a string of equivalences, but again, keep in mind we are not limited to one set of axioms.
AnswerKenntnis:
I would simply say that the space of axiomatic systems and theorems deduceable from those systems is definitely infinite. All those axiomatic systems and theorems /exists/ already in a sense. And they are tautologic.

The creative process is finding a way through that system. And not an arbitrary way of random theorems, but a way with lot of connections to other such paths, and with connections to the art of thinking or to common mathematical problems or to beauty or to practical usability.

And as coffee_table says, often a mathematician has an idea of what he hopes to find.
AnswerKenntnis:
Usually it is. That's what makes it useful. I could say: "I have 5 gallons of gasoline so I can go to Mars." and mathematics can tell you whether you are right or wrong and help you avoid embarking on the journey if you are wrong.

But not all statements can be decided to be true or false. That's what makes it interesting. The search in math is to identify which useful statements are provably true, which are provably false, and most interestingly those to which we must say "I don't know."

The "I don't know" bit makes it not a tautology; not one big "duh!". It also makes it a human artistic effort because the box of "I don't knows" includes both those that are genuinely unprovable and those that we do not have the skill to prove yet.
AnswerKenntnis:
This is a great question that I have pondered in my own way many times.

When I was in Real Analysis, I proposed to my teacher that truth could be defined as the largest set of all statements which can coexist without contradicting one another.

As we all know, when one lies, one cannot go on forever without reaching a contradiction. But the truth can go on forever, or at least we can postulate that it can, without ever reaching a contradiction. Hence, any set of lies would have to be smaller than the set containing all true things. And all those sets of lies would in a sense be embedded within the set of truth because the true version of each lie is the very fact that the lie is a lie.

My teacher responded that this was far too philosophical and had no place in a math class. But I still wonder if that would be a workable definition for truth.
AnswerKenntnis:
It is technically true that every theorem is equivalent to the axioms; that is the point, or else the theorem would be wrong. But that doesn't mean the axioms and the theorems are the same.

I quite like the term Douglas Hofstadter uses: implicit truths and explicit truths. While all the theorems are truths which are implicit in the axioms, it is the job of mathematics to make them explicit. You might enjoy reading the book Godel, Escher, Bach by Douglas Hoftsadter.
AnswerKenntnis:
I think the answer you might be looking for is that truth within a mathematical model is an axiom or combination of axioms, augmented with a number of definitions. There can be no other truths. Whether math represents truth in general is discussed in 

http://www.ocf.berkeley.edu/~wwu/cgi-bin/yabb/YaBB.cgi?board=truth;action=display;num=1268924603;start=
AnswerKenntnis:
Yes and no. ${}{}{}{}{}{}{}{}{}{}$
QuestionKenntnis:
Proving you *can't* make $2011$ out of $1,2,3,4$: nice twist on the usual
qn_description:
An undergraduate was telling me about a puzzle he'd found: the idea was to make $2011$ out of the numbers $1, 2, 3, 4, \ldots, n$ with the following rules/constraints: the numbers must stay in order, and you can only use $+$, $-$, $*$, $/$, ^ and $!$. In words, "plus minus times divide, exponentiation and factorial". The game was to construct $2011$ with $n$ as small as possible.

To my amazement, he had managed to do $n=5$: indeed

$$((1+2)!)!+(3!)^4-5=2011.$$

He now wanted to solve the puzzle completely by proving that $n=1,2,3,4$ are impossible.

So there's where it gets interesting. My first thought was "computer search -- done". But it's not as easy as that, because factorial is only a unary operator. For example one has to rule out any possible amazing cancellations between very large numbers, e.g. one has to check

$$(1+2)!!!!!!!!!!!!!-3^{(4!!!!!!!!!!!)} \neq  2011.$$

This one in particular is not hard to rule out, because, for example, the left hand side is a multiple of $3$ and the right hand side isn't. In general, this approach can perhaps be used to bound the number of factorials that can occur in any presentation of $2011$ using $1, 2, 3, 4$ only -- but making this rigorous seemed a bit delicate and I wondered if I was missing something. Anyone any ideas?

EDIT: Ron Maimon's heroic attempt to deal with the problem by brute force has led him to the interesting case of $2011=(1+2)!!!...!!!/(3!!!...!!!/4!!!!...!!!)$, which seems to be tougher to rule out than the others: the game here is to prove that $2011$ cannot be written as $3!!!...!!!*4!!!!...!!!/3!!!!...!!!$ for any choices of numbers of factorials.

EDIT: Size considerations seem to deal with the above case. Ultimately it seems that the question I asked can be answered using a rather lengthy, but finite(!), procedure. Thanks Ron for your efforts.
AnswersKenntnis
AnswerKenntnis:
This is simple enough to do by hand, although there are many cases. First, dispose of the case n=1, since 1 is a fixed point for factorials. The case n=2, is similarly trivial, since 2 is also a fixed point for factorials and 2011 is not a factorial.

I will come back to n=3 later, first I will discuss the problem of n=4.

Binary operations make a parse-tree, so that the binary operations you perform give a skeleton upon which you can add factorials. There are exactly five binary trees on 4 nodes, which I list below:


pairing: ((12)(34))
forward: (((12)3)4)
backward: (1(2(34)))
center-left: ((1(23))4)
center-right: (1((23)4))


These five parenthizations define the five ways to apply binary operations to the leaves 1,2,3,4. The factorials can come on the three leaf, producing 6,720,etc, on the four leaf, producing 24, etc, or on one of the three parenthesized intermediate quantities.

There can be no factorial applied to the top node, since 2011 is not a factorial. For each case, there are exactly four nodes on each tree where you can apply factorial--- on 3, on 4, and on the two intermediate nodes.

Three quantities cannot do it

In order to deal with n=4, one has to methodically deal with n=3. In this case, there are only 2 different parenthizations


left: (1(23))
right: ((12)3)


Factorial is only allowed on 3, and on the value of the inner parenthesis. The outer quantity can't get a factorial, since 2011 is not a factorial.

Now notice: the operation involving 1 is either +,-,*,/,^. The last operation produces 1, reducing the problem size to binary, the divide operation produces nonsense, and the * operator just removes the 1 node. So the only possibility is +/- (EDIT: if you expand the domain to rational numbers, so that you can make 1/(2*3!!!) in intermediate stages, there are many new cases)

This means that, the answer 2011 is either produced from left, in which case 2010 is written using (23), or right, in which case 2011 is written using (33). Both of these are binary and trivially impossible.

This disposes of n=3

Four quantities mostly reduce to three

Again, four quantities reduce to 3 when you consider the binary operation involving 1. If this operation is not + or -, it must kill the node (EDIT: excluding rational number operations), thereby reducing the tree to 3,2, or 1 objects.

The remaining possiblity is that 1 adds to a quantity. This produces the following three-quantity problems:


((3 3) 4) make 2011
(3(3 4)) make 2011
(2(3 4)) make 2010 or 2011
((2 3) 4) make 2010 or 2011


and exactly one true four-quantity problem
* ((1 + (23)) 4)

The true four-quantity problem has 15 possible operation combinations and 4 places to put factorials. I will first dispense with the three-quantity cases.

2 3 4 or 3 3 4 don't make 2011

The top node making 2011 can't be ^, because 2011 is not a power. It can't be * because 2011 is prime. This leaves +,-,/. I will call A_n the n-fold factorial iteration:


(3_n + 3_m)_k + 4_l
(3_m - 3_n)_k + 4_l
(3_m * 3_n)_k + 4_l
(3_m / 3_n)_k + 4_l
(3_m ^ 3_n)_k + 4_l
(3_n + 3_m)_k - 4_l
(3_m - 3_n)_k - 4_l
(3_m * 3_n)_k - 4_l
(3_m / 3_n)_k - 4_l
(3_m ^ 3_n)_k - 4_l


For k>0, these cannot be 2011 for parity reasons. For k=0, the products/quotients are excluded for parity reasons (since 3_m and 3_n are never different by 1, their quotient is always even or equal to 1--- 1 is excluded because 2010 is not an iterated factorial of 4, exponentiation case is excluded by divisibility by 3 for l>0 and by the fact that 2015 and 2007 are not powers for l=0). This leaves


3_n + 3_m - 4_l
3_n - 3_m + 4_l
3_n - 3_m - 4_l


(the all plus case is excluded by size bounds and a finite search). It is impossible for both n,m to be bigger than 1, or else the sum is even. So exactly one of n or m is 1. Then reducing modulo 6 gives 3 for l>1 n>1 and 2011 is 1 modulo 6.

The case where the first 3 is replaced by 2 is handled exactly the same.


(3_n + 3_m)_k / 4_l
(3_m - 3_n)_k / 4_l
(3_m * 3_n)_k / 4_l
(3_m / 3_n)_k / 4_l
(3_m ^ 3_n)_k / 4_l


This cannot be 2011 for k>0 for primeness reasons (2011 is not the ratio of two factorials other than 2011!/2010! and (33) does not make 8044).  This leaves the k=0 cases:

EDIT: I skipped these nontrivial cases too.


(3_n + 3_m) = 2011 4_l
(3_m - 3_n) = 2011 4_l 
(3_m * 3_n) = 2011 4_l : UNRESOLVED
3_m = 2011 4_l 3_l
(3_m ^ 3_n) = 2011 4_l


The case A!= 2011 B! C! is resolved in the next section, and this takes care of 3_m = 2011 4_l 3_l. The case 3_m^3^n is resolved by noting that the right side factorial must be sufficiently bigger than the left side factorial to include a new prime. A! + B! = 2011 C! requires A>C and B>C and WLOG A>B, so that, dividing, you get C(C+1)...(C+(A-C)) + C(C+1)..(C+(B-C)) = 2011, which requires by primeness C=B or C=B-1 but 3_k and 4_m can never be exactly equal by one-oneness of factorial, and they can't differ by 1, except at m=0 k=0, because they are always both even.

The case 3_m * 3_n = 2011 4_l is unresolved, and is similar to the other unresolved case below.

next there is (3(34)). In this case, the top node again cannot be * or ^ because 2011 is not a power or a product.

EDIT: MORE (3(34))

So there are another 15 cases (before, I wrote them down, but didn't work them out.)


3_l + (3_m + 4_n)_p :


The inside of the paren is at least 7, 7! is 5040, too big, so p=0. The quantities 3_l+3_m is even unless exactly one of l or m is zero, so you have 3 +3_m + 4_n , which is a finite search to pass through 2011.


3_l + (3_m - 4_n)_p


The inside of the paren cannot be negative, and if it is positive, m must be at least 1, so that the second term is even. This means the first term must be odd, so l=0. This makes 3 + (3_m - 4_n)_p = 2011, and 2008 is not a factorial, so p=0. So you want the difference of 3_m and 4_n to be 2008, which is impossible if n>0 because 2008 isn't 0 mod 3. So 2004 must be 3_m, which is impossible. 


3_l + (3_m * 4_n)_p


2011 is 1 mod 3, and this is zero mod 3.


3_l + (3_m / 4_n)_p


The question of how to interpret quotients arises here--- I will interpret it as the integer part. So the inner argument of the paren can be 0 or 1 (3/4 and 6/4), making 3_l 2010 or 2011, impossible. So the inner part of the paren is not 0 or 1. The ratio of two factorials which is bigger than 2 is itself an integer, so you get the sum of two factorials, which is even unless l=0 or p=0.

If l=0, you have a factorial which gives 2008, which, since 2008 is not factorial, gives p=0, and 2008 is a ratio of factorials which is impossible, because it doesn't factor into the product of consecutive numbers.

This leaves p=0, l nonzero. (3_l - 2011) * 4_n + 3_m = 0, which by signs requires that 3_l<2011, so that l is 1,2,3. and this is the two cases:


(6 - 2011) * 4_n + 3_m = 0
(720 - 2011) * 4_n + 3_m = 0


Both these equations are impossible because the nontrivial coefficient, 2005 and 291, cannot be the ration of two factorials, since neither is a product of consecutive numbers.


3_l + (3_m ^ 4_n)_p


This is zero mod 3, and 2011 is not.


3_l - (3_m + 4_n)_p


This is zero mod 3 unless n=0 and p=0. 3_l - 3_m + 4 = 2011, meaning that the difference of 2 iterated factorials of 3 needs to be 2007, which is odd, so this is impossible.


3_l - (3_m - 4_n)_p


This is zero mod 3 unless n=0 and p=0, 3_l - 3_m - 4 = 2011 so that the difference of 2 iterated factorials of 3 needs to be 2015, which is not zero mod 3, so done.


3_l - (3_m * 4_n)_p


This quantity is zero mod 3, unlike 2011.


3_l - (3_m / 4_n)_p


These two quantities will both be even unless p=0, l=0, or the quantity in the parentheses is 1. l=0 is excluded since the result is less than 3, and if the quantity in parens is 1, then 3_l must be 2010, not possible. So this requires p=0, and this becomes the diophantine equations


3_m = (3_l- 2011)4_n


In this case, 3_l must be bigger than 2011, so that l>2. 3_m/4_n is a ratio of two factorials, so it becomes

(A!/(B!(A-B)!))*(A-B)! = (3_l - 2011)

The left side is even in any nontrivial case, and the right side is odd, ruling this out by parity.


3_l - (3_m ^ 4^n)_p


This is zero mod 3, so not 2011.


3_l / (3_m + 4_n)_p 
3_l / (3_m - 4_n)_p
3_l / (3_m * 4_n)_p
3_l / (3_m / 4_n)_p
3_l / (3_m ^ 4_n)_p


The quotient of two nontrivial factorials is always a product of consecutive numbers, so it cannot be 2011 unless the top is 2011! and the bottom is 2010!. 3_l is never 2011. You can conclude that either l=0 or p=0. l=0 is impossible, since the result would be smaller than 3, so p=0 for all the above. This gives the following 4 diophantine equations


3_l = 2011*(3_m + 4_n)
3_l = 2011*(3_m - 4_n)
3_l = 2011*(3_m * 4_n)
3_l = 2011*(3_m ^ 4_n)
3_l = 2011*(3_m / 4_n)


For the first four cases, l must be bigger than 3 because 3!!!=720! which does not have a factor of 2011. So these are all big nontrivial factorials.

Consider a more general form of the sum equation, the first case equation above:


A! = 2011 (B!+C!)


Without loss of generality A>B>C, so dividing by C! gives A!/C! = 2011(B!/C!+1) where the quantities A!/C! and B!/C! are products of consecutive integers, at least one of which is even, because A is not equal to B, and both are even unless B=C+1. So B=C+1, and you get A!/C! = 2011(C+1), or A!=2011(C+1)! which is impossible because 2011 is not a product of consecutive integers. The same thing rules out the minus sign case.


A! = 2011 B! C!


Again, WLOG, B>C, this can be rewritten:


(A!/B!(A-B)!) ( (A-B)!/C!(A-B-C)!) (A-B-C)! = 2011


where everything is expressed in terms of the multiplicatively more fundamental binomial coefficients. This requires that each factor is either 1 or 2011, which requires either A=B+C or A=B+C+1, since the last factor can't equal 2011 under any circumstances. In both cases, the two combinatorial coefficients become one, and the result is that C=1 or 0 and B=2010 while A=2011, giving the two trivial solutions 2011! = 2011 * 2010! 1! and 2011! = 2011 2010! 0!, and no others (these trivial solutions don't work, they don't have C>4 for one). Done.


A! = 2011 B!^C!


Where C>4. Since C>4, and for B bigger than 2, (B!)^4> (2B)! (easy to prove using Stirling's formula), you can conclude that A>2B, so that there is a new prime between B and 2B which is contained in A! which is not contained on the right side, done. This also works when C is 3, so it resolves the parallel case for (33)4 above.

The final case to consider is the quotient of the quotient, which rearranges into


3_l * 4_n = 2011 * 3_m


here, either l is bigger than 3, or else n is bigger than 2, in order for one of the two objects on the left to have a factor of 2011, so these are big factorials again. The general form


A! B! = 2011 C!


for large A, B, and C, WLOG A


2011 ((A+B)!/A!B!) = (A+B)(A+B-1)..(A+B-y+1)


In this formula, A and C are both factorial iterates of 3, while B is a factorial iterate of 4. This means that C is either equal to A (which doesn't work) or enormously bigger than A, being at least A!. To make the size of the right and left hand side equal, B must be about the same size as C.

The LHS is B^A/A!, while the right hand side is B^y, so to match, A and y have to be of the same order.

Now the right hand side is divisible by y!, while the left hand side cannot be divisible by something as big as A!. This is a property of Pascal's triangle, that ((A+B)!/A!B!) is not divisible again by A!. The reason is a simple prime counting:

The number of powers of 2 in N! is N/2 + N/4 + N/8 + N/16... + N/(2^(log_2(N))) where division means floor division. This is asymptotic to N, and this means that the number of powers of 2 just cancel between numerator and denominator when A+B=C. If you want y! to factor into the resulting element of Pascal's triangle, you need extra powers of 2 in C!, an amount about equal to 2A+B. There shouldn't be this many powers of 2 in (C!). The same holds for powers of 3, or of any other prime less than A.

So it should be impossible to satisfy the equation based just on prime-power counting, but this argument doesn't prove it, because B is so enormous compared to A, the error in the power of two estimate for ((A+B)!) is naively bigger than A. But there are odd entries in Pascal's triangle arbitrarily far out, especially near the left edge, so there must be better bounds on the prime powers occuring in Pascal's triangle than what I gave. I am sure that y! can't go into the Pascal triangle entry for large y, but I can't give a solid argument. So I will leave it as unresolved for now.

I am surprised that this case is so much more difficult than the other cases, because it is relatively obvious that purely multiplicative stuff cannot work, that you need additive stuff.

anyway: UNRESOLVED. But the above sketch might resolve it if made precise.

EDIT (2 (3 4)) doesn't make 2011 (for completeness sake)

I neglected to work out the 2(34) cases to make 2011. The top node cannot be * or ^, since 2011 is not prime or a power, and it can't be - or /, because 2011 is bigger than 2.


2 + (3_m + 4_n)_p
2 + (3_m - 4_n)_p
2 + (3_m * 4_n)_p
2 + (3_m / 4_n)_p
2 + (3_m ^ 4_n)_p


p>0 is excluded because 2009 is not a factorial. 3_m + 4_n, 3_m - 4_n  doesn't work for m>0 because of parity, so m=0, and so done. The power case 3_m^4_n is excluded because 2009 is not a power. (3_m *4_n) is zero mod 3, and 2009 is not, so the only case is 3_m=2009 4_m, which is of the form


A! = 2009 B!


or (A!/B!(A-B)!)(A-B)! = 2009 which is excluded by parity unless A=B+1, when you get the trivial solution 2009! = 2009*2008!, which doesn't match iterated factorials of 3 and 4.

For the sake of allowing fractions, I will consider the only reasonable division process


2/(3_m/4_m) = 2*4_m/3_m = 2011


this is an even integer when the numerator is bigger than the denominator, namely 2( A!/(B!(A-B)!))(A-B)!, so excluded.

2 3 4 doesn't make 2010

Now 2010 = 2 * 3 * 5 * 67. The decomposition into ((23)4) can only get factorials on 3 and 4.


(2+3_m)_n +4_p
(2-3_m)_n +4_p
(2*3_m)_n +4_p
(2/3_m)_n +4_p
(2^3_m)_n +4_p
(2+3_m)_n -4_p
(2-3_m)_n -4_p
(2*3_m)_n -4_p
(2/3_m)_n -4_p
(2^3_m)_n -4_p


for these cases, it is enough to note that 2010 is not divisible by 4, so that n=0 or n=1, or the argument of the factorial is 1, and a tedious enumeration exhausts these.


(2+3_m)_n *4_p
(2-3_m)_n *4_p
(2*3_m)_n *4_p
(2/3_m)_n *4_p
(2^3_m)_n *4_p


2010 is not divisible by 4, so these are ruled out.


(2+3_m)_n /4_p
(2-3_m)_n /4_p
(2*3_m)_n /4_p
(2/3_m)_n /4_p
(2^3_m)_n /4_p


These give the relation 2010 4^p = (2*3_n)_m. Looking at it modulo 7 and 67 forbids this equation from holding for any m,n.


(2+3_m)_n ^4_p
(2-3_m)_n ^4_p
(2*3_m)_n ^4_p
(2/3_m)_n ^4_p
(2^3_m)_n ^4_p


2010 is not a power.

((1+(23))4) doesn't make 2011

There are 15 cases, since the top node cannot be * by primeness, and cannot be ^ since 2011 is not a power:


(1+(2+3_l)_m)_n + 4_p
(1+(2-3_l)_m)_n + 4_p
(1+(2*3_l)_m)_n + 4_p
(1+(2/3_l)_m)_n + 4_p
(1+(2^3_l)_m)_n + 4_p
(1+(2+3_l)_m)_n - 4_p
(1+(2-3_l)_m)_n - 4_p
(1+(2*3_l)_m)_n - 4_p
(1+(2/3_l)_m)_n - 4_p
(1+(2^3_l)_m)_n - 4_p


n=0 by parity. This reduces the problem by associativity into 2,3,4 making 2010.


(1+(2+3_l)_m)_n / 4_p
(1+(2-3_l)_m)_n / 4_p
(1+(2*3_l)_m)_n / 4_p
(1+(2/3_l)_m)_n / 4_p
(1+(2^3_l)_m)_n / 4_p


These are the only truly new cases. In this case, you get 2011*4_p = (1 + (something))_n which is forbidden by looking modulo 2011.

It is very likely that your friend did a search of this sort for the case n=5 to find the special solution.
AnswerKenntnis:
If square roots and percentages (and unary minus) are permitted, then there are a number of solutions, the simplest probably being

$$2011 = (-1 + (2 + 3!)!\%) \div \sqrt{4\%}$$

Many years ago, I wrote a simple Windows program called $200$ Up (scroll to the end to download from the link) for solving problems like these:

$\hspace{1.75in}$ 

The domain of calculation is $\mathbb{Z}/d$ for some specified denominator $d\in\mathbb{N}$ (and with limits on the magnitude of the numerator).

Note that, in the image above, the solution for 2018 is

$$
\large 2018 \;\;=\;\; \big( \sqrt[\sqrt{\cdot \dot{1}}]{\Large 2} \; + \; 3!!\%\% \big) \; \div \; \cdot 4\%.
$$
QuestionKenntnis:
Funny identities
qn_description:
Here is a funny exercise 
$$\sin(x - y) \sin(x + y) = (\sin x - \sin y)(\sin x + \sin y).$$
(If you prove it don't publish it here please).
Do you have similar examples?
AnswersKenntnis
AnswerKenntnis:
$$\int_0^1\frac{\mathrm{d}x}{x^x}=\sum_{k=1}^\infty \frac1{k^k}$$
AnswerKenntnis:
$$\left(\sum\limits_{k=1}^n k\right)^2=\sum\limits_{k=1}^nk^3 .$$
AnswerKenntnis:
$$ \infty! = \sqrt{2 \pi} $$

It comes from the zeta function.
AnswerKenntnis:
Ah, this is one identity which comes into use for proving the Euler's Partition Theorem. The identity is as follows: $$ (1+x)(1+x^{2})(1+x^{3}) \cdots  = \frac{1}{(1-x)(1-x^{3})(1-x^{5}) \cdots}$$
AnswerKenntnis:
The Frobenius automorphism

$$(x + y)^p = x^p + y^p$$
AnswerKenntnis:
$$\frac{1}{\sin(2\pi/7)} + \frac{1}{\sin(3\pi/7)} = \frac{1}{\sin(\pi/7)}$$
AnswerKenntnis:
\begin{eqnarray}
1^{3} + 2^{3} + 2^{3} + 2^{3} + 4^{3} + 4^{3} + 4^{3} + 8^{3} = (1 + 2 + 2 + 2 + 4 + 4 + 4 + 8)^{2}
\end{eqnarray}
More generally, let $D_{k} = ${ $d$ } be the set of unitary divisors of a positive integer $k$, and let $\mathsf{d}^{*} \colon \mathbb{N} \to \mathbb{N}$ denote the number-of-unitary-divisors (arithmetic) function. Then 
\begin{eqnarray}
\sum_{d \in D} \mathsf{d}^{*}(d)^{3} = \left( \sum_{d \in D} \mathsf{d}^{*}(d) \right)^{2}
\end{eqnarray}

Note that $\mathsf{d}^{*}(k) = 2^{\omega(k)}$, where $\omega(k)$ is the number distinct prime divisors of $k$.
AnswerKenntnis:
Machin's Formula:
\begin{eqnarray}
\frac{\pi}{4} = 4 \arctan \frac{1}{5} - \arctan \frac{1}{239}.
\end{eqnarray}
AnswerKenntnis:
$$\large{1,741,725 = 1^7 + 7^7 + 4^7 + 1^7 + 7^7 + 2^7 + 5^7}$$

and

$$\large{111,111,111 \times 111,111,111 = 12,345,678,987,654,321}$$
AnswerKenntnis:
Well, i don't know whether to classify this as funny or surprising,  but ok it's worth posting.


Let $(X,\tau)$ be a topological space and let $A \subset X$ . By iteratively applying operations of closure and complemention, one can produce at most 14 distinct sets. It's called as the Kuratowski's Closure complement problem.
AnswerKenntnis:
$\displaystyle\big(a^2+b^2\big)\cdot\big(c^2+d^2\big)=\big(ac \mp bd\big)^2+\big(ad \pm bc\big)^2$
AnswerKenntnis:
\[\sqrt{n^{\log n}}=n^{\log \sqrt{n}}\]
AnswerKenntnis:
$$\sec^2(x)+\csc^2(x)=\sec^2(x)\csc^2(x)$$
AnswerKenntnis:
$$ \sum\limits_{n=1}^{\infty} n =  1 + 2 +3 + \cdots \text{ad inf.} = - \frac{1}{12}$$

Now doesn't this sound funny. You can also see many more on http://terrytao.wordpress.com/2010/04/10/the-euler-maclaurin-formula-bernoulli-numbers-the-zeta-function-and-real-variable-analytic-continuation/
AnswerKenntnis:
Facts about $\pi$ are always fun!

\begin{equation}
\frac{\pi}{2} = \frac{2}{1}\cdot\frac{2}{3}\cdot\frac{4}{3}\cdot\frac{4}{5}\cdot\frac{6}{5}\cdot\frac{6}{7}\cdot\frac{8}{7}\cdot\ldots\\
\end{equation}
\begin{equation}
\frac{\pi}{4} = 1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\frac{1}{9}+\ldots\\
\end{equation}
\begin{equation}
\frac{\pi^2}{6} = 1+\frac{1}{2^2}+\frac{1}{3^2}+\frac{1}{4^2}+\frac{1}{5^2}+\ldots\\
\end{equation}
\begin{equation}
\frac{\pi^3}{32} = 1-\frac{1}{3^3}+\frac{1}{5^3}-\frac{1}{7^3}+\frac{1}{9^3}+\ldots\\
\end{equation}
\begin{equation}
\frac{\pi^4}{90} = 1+\frac{1}{2^4}+\frac{1}{3^4}+\frac{1}{4^4}+\frac{1}{5^4}+\ldots\\
\end{equation}
\begin{equation}
\frac{2}{\pi} = \frac{\sqrt{2}}{2}\cdot\frac{\sqrt{2+\sqrt{2}}}{2}\cdot\frac{\sqrt{2+\sqrt{2+\sqrt{2}}}}{2}\cdot\ldots\\ 
\end{equation}
\begin{equation}
\pi = \cfrac{4}{1+\cfrac{1^2}{3+\cfrac{2^2}{5+\cfrac{3^2}{7+\cfrac{4^2}{9+\ldots}}}}}\\
\end{equation}
AnswerKenntnis:
The following number is prime


  $p = 785963102379428822376694789446897396207498568951$


and $p$ in base 16 is


  $89ABCDEF012345672718281831415926141424F7$


which includes counting in hexadecimal, and digits of $e$, $\pi$, and $\sqrt{2}$.

Do you think this's surprising or not?

$$11 \times 11 = 121$$
$$111 \times 111 = 12321$$
$$1111 \times 1111 = 1234321$$
$$11111 \times 11111 = 123454321$$
$$\vdots$$
AnswerKenntnis:
\begin{eqnarray}
\sum_{i_1 = 0}^{n-k} \, \sum_{i_2 = 0}^{n-k-i_1} \cdots \sum_{i_k = 0}^{n-k-i_1 - \cdots - i_{k-1}} 1 = \binom{n}{k}
\end{eqnarray}
AnswerKenntnis:
$$
\frac{e}{2} = \left(\frac{2}{1}\right)^{1/2}\left(\frac{2\cdot 4}{3\cdot 3}\right)^{1/4}\left(\frac{4\cdot 6\cdot 6\cdot 8}{5\cdot 5\cdot 7\cdot 7}\right)^{1/8}\left(\frac{8\cdot 10\cdot 10\cdot 12\cdot 12\cdot 14\cdot 14\cdot 16}{9\cdot 9\cdot 11\cdot 11\cdot 13\cdot 13\cdot 15\cdot 15}\right)^{1/16}\cdots
$$
[Nick Pippenger, Amer. Math. Monthly, 87 (1980)]. Set all the exponents to 1 and you get the Wallis formula for $\pi/2$.
AnswerKenntnis:
Two related integrals:

$$\int_0^\infty\sin\;x\quad\mathrm{d}x=1$$

$$\int_0^\infty\ln\;x\;\sin\;x\quad \mathrm{d}x=-\gamma$$
AnswerKenntnis:
M.V Subbarao's identity: an integer n>22 is a prime number iff it satisfies,

$$n\sigma(n)\equiv 2 \pmod {\phi(n)}$$
AnswerKenntnis:
$$\left|z+z'\right|^{2}+\left|z-z'\right|^{2}=2\times\left(\left|z\right|^{2}+\left|z'\right|^{2}\right)$$


  The sum of the squares of the sides
  equals the sum of the squares of the
  diagonals.
AnswerKenntnis:
By excluding the first two primes, Euler's Prime Product becomes a square:

$$\prod _{n=3}^{\infty } \frac{1}{1-\frac{1}{(p_n)^{2}}}=\frac{\pi ^2}{9}$$

By using multiples of the product of the first two primes, we get the square root:

$$\prod _{n=1}^{\infty } \frac{1}{1-\frac{1}{(n p_1 p_2)^{2}}}=\frac{\pi }{3}$$
AnswerKenntnis:
Considering the main branches

$$i^i = \exp\left(-\frac{\pi}{2}\right)$$

$$\root i \of i  = \exp\left(\frac{\pi}{2}\right) $$

And 
$$ \frac{4}{\pi } = \displaystyle 1 + \frac{1}{{3 +\displaystyle \frac{{{2^2}}}{{5 +  \displaystyle\frac{{{3^2}}}{{7 +\displaystyle \frac{{{4^2}}}{{9 +\displaystyle \frac{{{n^2}}}{{\left( {2n + 1} \right) +  \cdots }}}}}}}}}} $$
AnswerKenntnis:
\begin{eqnarray}
\zeta(0) = \sum_{n \geq 1} 1 = -\frac{1}{2}
\end{eqnarray}
AnswerKenntnis:
What is 42?

$$
6 \times 9 = 42 \text{ base } 13
$$
I always knew that there is something wrong with this universe.
AnswerKenntnis:
$$ 10^2+11^2+12^2=13^2+14^2 $$

There's a funny Abstruse Goose comic about this, which I can't seem to find at the moment.
AnswerKenntnis:
Let $f$ be a symbol with the property that $f^n = n!$. Consider $d_n$, the number of ways of putting $n$ letters in $n$ envelopes so that no letter gets to the right person (aka derangements). Many people initially think that $d_n = (n-1)! = f^{n-1}$ (the first object has $n-1$ legal locations, the second $n-2$, ...). The correct answer isn't that different actually:

$d_n = (f-1)^n$.
AnswerKenntnis:
The product of any four consecutive integers is one less than a perfect square.

To phrase it more like an identity:

For every integer $n$, there exists an integer $k$ such that
$$n(n+1)(n+2)(n+3) = k^2 - 1.$$
AnswerKenntnis:
$32768=(3-2+7)^6 / 8$

Just a funny coincidence.
AnswerKenntnis:
I actually think currying is really cool:

$$(A \times B) \to C \; \simeq \; A \to (B \to C)$$

Though not strictly an identity, but an isomorphism.

When I met it for the first time it seemed to be a bit odd but it is so convenient and neat. At least in programming.
QuestionKenntnis:
Can every proof by contradiction also be shown without contradiction?
qn_description:
Are there some proofs that can only be shown by contradiction or can everything that can be shown by contradiction also be shown without contradiction? What are the advantage/disadvantages of proving by contradiction?

As an aside, how is proving by contradiction viewed in general by 'advanced' mathematicians, is it a bit of an 'easy way out' when it comes to trying to show something or is it perfectly fine? I ask because one of our tutors said something to that effect and said that he isn't fond of proof by contradiction.
AnswersKenntnis
AnswerKenntnis:
To determine what can and cannot be proved by contradiction, we have to formalize a notion of proof.  As a piece of notation, we let $\bot$ represent an identically false proposition. Then $\lnot A$, the negation of $A$, is equivalent to $A \to \bot$, and we take the latter to be the definition of the former in terms of $\bot$. 

There are two key logical principles that express different parts of what we call "proof by contradiction":


The principle of explosion: for any statement $A$, we can take "$\bot$ implies $A$" as an axiom.  This is also called ex falso quodlibet.  
The law of the excluded middle: for any statement $A$, we can take "$A$ or $\lnot A$" as an axiom. 


In proof theory, there are three well known systems:


Minimal logic has neither of the two principles above, but it has basic proof rules for manipulating logical connectives (other than negation) and quantifiers. This system corresponds most closely to "direct proof", because it does not let us leverage a negation for any purpose. 
Intuitionistic logic includes minimal logic and the principle of explosion
Classical logic includes intuitionistic logic and the law of the excluded middle


It is known that there are statements that are provable in intuitionistic logic but not in minimal logic, and there are statements that are provable in classical logic that are not provable in intuitionistic logic. In this sense, the principle of explosion allows us to prove things that would not be provable without it, and the law of the excluded middle allows us to prove things we could not prove even with the principle of explosion.  So there are statements that are provable by contradiction that are not provable directly. 

The scheme "If $A$ implies a contradiction, then $\lnot A$ must hold" is true even in intuitionistic logic, because $\lnot A$ is just an abbreviation for $A \to \bot$, and so that scheme just says "if $A \to \bot$ then $A \to \bot$". But in intuitionistic logic, if we prove $\lnot A \to \bot$, this only shows that $\lnot \lnot A$ holds. The extra strength in classical logic is that the law of the excluded middle shows that $\lnot \lnot A$ implies $A$, which means that in classical logic if we can prove $\lnot A$ implies a contradiction then we know that $A$ holds. In other words: even in intuitionistic logic, if a statement implies a contradiction then the negation of the statement is true, but in classical logic we also have that if the negation of a statement implies a contradiction then the original statement is true, and the latter is not provable in intuitionistic logic, and in particular is not provable directly.
AnswerKenntnis:
If a statements says "not $X$" then it is perfectly fine to assume $X$, arrive at a contradiction and conclude "not $X$".  However, in many occasions a proof by contradiction is presented while it is really not used (let alone necessary).  The reasoning then goes as follows:


  Proof of $X$:  Suppose not $X$.  Then ... complete proof of $X$ follows here... This is a contradiction and therefore $X$.


A famous example is Euclid's proof of the infinitude of primes.  It is often stated as follows (not by Euclid by the way):


  Suppose there is only a finite number of primes.  Then ... construction of new prime follows ... This is a contradiction so there are infinitely many primes.


Without the contradiction part, you'd be left with a perfectly fine argument.  Namely, given a finite set of primes, a new prime can be constructed.

This kind of presentation is really something that you should learn to avoid.  Once you're aware of this pattern its amazing how often you'll encounter it, including here on math.se.
AnswerKenntnis:
It somewhat depends on whether you are intuitionist or not (or both? or neither? Who knows without the law of excluded middle). According to the Wikipedia article even intuitionists accept some versions of what one could call indirect proof, but reject most. In that sense, a direct proof would be preferable (and is often even a bit more elegant).



An example:

Theorem. There exist irrational numbers $a,b$ such that $a^b$ is rational.

Proof: Assume that $a,b\notin \mathbb Q$ always implies $a^b\notin \mathbb Q$. Then $u:=\sqrt 2^{\sqrt 2}\notin \mathbb Q$ and $u^\sqrt 2=\sqrt 2^{\sqrt 2\cdot\sqrt 2}=\sqrt 2^2=2\notin \mathbb Q$ - contradiction!

Indeed, an intuitionist would complain that we do not exhibit a pair $(a,b)$ with $a,b\notin \mathbb Q$ and $a^b\in \mathbb Q$. Instead, we only show that either $(\sqrt 2,\sqrt 2)$ or $(u,\sqrt 2)$ is such a pair.
Converting the proof given above to a direct and constructive proof would in fact require you to actually prove one of the two possible options $u\in \mathbb Q$ or $u\notin\mathbb Q$.
AnswerKenntnis:
See this post: Are proofs by contradiction weaker than other proofs?. There are some wonderful answers related to your question - and addresses, directly, your "aside": See, in particular, what JDH writes.



One of the advantageous to constructing direct proofs of propositions, when this is feasible, is that one can discover other useful propositions in the process. That is, direct proofs help clarify the necessary and sufficient conditions that make a theorem true, and provide a structure demonstrating how these conditions relate, and how the chain of implications imply the conclusion.

Indirect proofs, on the other hand (aka "proofs by contradiction") only tell us that supposing a proposition to be otherwise leads to a contradiction at some point. But such a proof doesn't really provide the sort of insight that can be gained from direct proofs. 

That is not to say that indirect proofs don't have their place (e.g., they come in handy when asked to prove propositions during a time-limited exam!). They often help "rule out" certain propositions on the basis that they contradict well established axioms or theorems. Also, indirect proofs are sometimes more intuitive than direct proofs. For example, proving that $\sqrt{2}$ is not rational using a proof by contradiction is clean, and intuitive. 

Sometimes an indirect proof will emerge first, after which one can seek to proceed with trying to construct a direct proof to prove the same proposition. That is, providing an indirect proof of a proposition often motivates the construction of direct proofs.



Edit:

I found this blog entry (Gowers's Weblog) When is a proof by contradiction necessary.
from which I'll quote an introductory remark:


  It seems to be possible to classify theorems into three types: ones where it would be ridiculous to use contradiction, ones where there are equally sensible proofs using contradiction or not using contradiction, and ones where contradiction seems forced. But what is it that puts a theorem into one of these three categories?


The post follows immediately with a nice reply from Terence Tao.
AnswerKenntnis:
A few points from my (limited) experience:


I love proof by contradiction and I have used it in graduate level classes and no one seemed to mind so long as the logic was infallible. 
For me, it's much easier to think about a proposition in terms of "What if this wasn't true?". That is usually my first instinct, this makes proof by contradiction the natural first choice. For instance, if I were to be asked to prove something like "Prove that a non-singular matrix has a unique inverse". My first instinct would be "What if a non-singular matrix had 2 inverses?" and from then on, the proof follows cleanly.
Sometimes, however, contradictions don't come cleanly and proof by simple logical deductions would probably take 5 lines whereas contradiction will take millions. I could point you to specific proofs but I'll have to do some digging. Further, if you look at every proof and try using Proof by Contradiction, another problem you will face is that sometimes, you will state your intended contradiction but never use it. In other words, solve using direct proof.
Another aspect about Proof by Contradiction (IMHO) is that you really must know all definitions and their equivalent statements fairly well to come up with a nice contradiction. Else, you will end up proving several lemmas on the way which looks clean in a direct proof but not so much in a Proof by Contradiction, but again, this might be a personal choice. 


In summary, if you find it easier to think in terms of "What if not" then go ahead, use it but make sure your proof skills using other strategies are as good because $\exists$ nail that you cannot hit with the PbC hammer that you'll carry.
AnswerKenntnis:
What is a proof by contradiction? This is actually quite difficult to answer in a satisfactory way, but usually what people mean is something like this: given a statement $\phi$, a proof of $\phi$ by contradiction is a derivation of a contradiction from the assumption $\lnot \phi$. In order to analyse this, it is very important to distinguish between the statement $\phi$ and the statement $\lnot \lnot \phi$; the two statements are formally distinct (as obvious from the fact that their written forms are different!) even though they always have the same truth value in classical logic. 

Let $\bot$ denote contradiction. When we show a contradiction assuming $\lnot \phi$, what we have is a conditional proof of $\bot$ from $\lnot \phi$. This can then be transformed into a proof of the statement $\lnot \phi \to \bot$, which is the long form of $\lnot \lnot \phi$ ΓÇô in other words, we have a proof that "it is not the case that $\lnot \phi$". This, strictly speaking, is not a complete proof of $\phi$: we must still write down the last step deducing $\phi$ from $\lnot \lnot \phi$. This is the point of contention between constructivists and non-constructivists: in the constructive interpretation of logic, $\lnot \lnot \phi$ is not only formally distinct from $\phi$ but also semantically distinct; in particular, constructivists reject the principle that $\phi$ can be deduced from $\lnot \lnot \phi$ (though they may accept some limited instances of this rule). 

There is one case where proof by contradiction is always acceptable to constructivists (or at least intuitionists): this is when the statement $\phi$ to be proven is itself of the form $\lnot \psi$. This is because it is a theorem of intuitionistic logic that $\lnot \lnot \lnot \psi$ holds if and only if $\lnot \psi$. On the other hand, it is also in principle possible to give a "direct" proof of $\lnot \psi$ in the following sense: we simply have to derive a contradiction by assuming $\psi$. Any proof of $\lnot \psi$ by contradiction can thus be transformed into a "direct" proof because one can always derive $\lnot \lnot \psi$ from $\psi$; so if we can obtain a contradiction by assuming $\lnot \lnot \psi$, we can certainly derive a contradiction by assuming $\psi$. 

Ultimately, both of the above methods involve making a counterfactual assumption and deriving a contradiction. However, it is sometimes possible to "push" the negation inward and even eliminate it. For example, if $\phi$ is the statement "there exists an $x$ such that $\theta (x)$ holds", then $\lnot \phi$ can be deduced from the statement "$\theta (x)$ does not hold for any $x$". In particular, if $\theta (x)$ is itself a negative statement, say $\lnot \sigma (x)$, then $\lnot \phi$ can be deduced from the statement "$\sigma (x)$ holds for all $x$". Thus, proving "there does not exist an $x$ such that $\sigma (x)$ does not hold" by showing "$\sigma (x)$ holds for all $x$" might be considered a more "direct" proof than either of the two previously-mentioned approaches. 

Can all proofs by contradiction be transformed into direct proofs? In some sense the answer has to be no: intuitionistic logic is known to be weaker than classical logic, i.e. there are statements have proofs in classical logic but not intuitionistic logic. The only difference between classical logic and intuitionistic logic is the principle that $\phi$ is deducible from $\lnot \lnot \phi$, so this (in some sense) implies that there are theorems that can only be proven by contradiction. 

So what are the advantages of proof by contradiction? Well, it makes proofs easier. So much so that one algorithm for automatically proving theorems in propositional logic is based on it. But it also has its disadvantages: a proof by contradiction can be more confusing (because it has counterfactual assumptions floating around!), and in a precise technical sense it is less satisfactory because it generally cannot be (re)used in constructive contexts. But most mathematicians don't worry about the latter problem.
AnswerKenntnis:
As "Inquest"'s answer mentions, it's often easier to find a proof by contradiction than a direct proof.  But after you do that, you can often make the proof simpler by rearranging it into a direct proof.  It is not good to make a proof appear more complicated than it really is.

To see another disadvantage of some proofs by contradiction, consider this:

Proof: To prove $A$, assume not $A$. [insert 50 pages of argument here] We have reached a contradiction.  Therefore $A$. End of proof

Now ask yourself: Which of the propositions proved in those 50 pages are erroneous and could be proved only because one relied on the false assumption that not $A$, and which are validly proved, and which are true but not validly proved because the assumption that not $A$ was relied on?  It's not so easy to tell without a lot more work.  And if you remember a proof of one of those propositions, you might just mistakenly think that it's been proved and is therefore known to be true.  So it might be far better to limit the use of proof by contradiction to some portions of those 50 pages where no other method works.

Perhaps proofs of non-existence can be done only by contradiction.  Here I might offer as an example the various proofs of the irrationality of $\sqrt{2}$, but for the fact that I've seen it asserted that if $m$, $n$ are integers, than $m/n$ differs from $\sqrt{2}$ by at least an amount that depends on $n$ --- I think it might have been $1/(3n^2)$.  Here's another example: How would one prove the non-existence of a non-trivial (i.e. $>1$) common divisor of $n$ and $n+1$?

I've seen a book on logic asserting that a proof by contradiction of a non-existence assertion does not constitute an "indirect proof", since the assertion is inherently negative.  I don't know how conventional that is.
AnswerKenntnis:
Another example of a contradiction proof that provides no idea on a constructive proof is the strategy-stealing argument.  For certain symmetric games, the second player cannot have a winning strategy.  If he did, the first player could "pretend" to be the second player and steal his winning strategy, stealing it from him, a contradiction. 

An interesting example is the game Hex.  It is easy to show that Hex cannot end in a tie, and the strategy-stealing argument does apply to it. Therefore, it is a first player win.  But for symmetric $n$ x $n$, the actual winning strategy is still not known.  Thus, this is an example of something that has been proven using contradiction and not constructively (yet).
AnswerKenntnis:
There is nothing wrong with proof by contradiction. You can show that they work using a truth table. In the end, that's all that really matters, right?

As far as I know, you can't know for certain that something is not provable by a direct proof. However, a proof by contradiction might be an easier way to prove some things, like the irrationality of certain numbers. For example, I have never seen a direct proof of the irrationality of $\sqrt{2}$.

EDIT: As Carl Mummert said in his answer, the above part in italics is not true. There are propositions which are only provable by contradiction.

A proof by contradiction can be also be formulated as a proof by contrapositive. If we know $Q$ is false, if we can show $P\Rightarrow Q$ then we have proved that $P$ is false. Whether you view this as "proof without contradiction" or not is up to you. In any case, they are logically equivalent.
AnswerKenntnis:
My non-mathematical response.

A == B equals !(A != B)

You always end up with a binary decision, is or is not. And in any language is = !(is not).

But I guess it is too simple to be ok.
AnswerKenntnis:
Whether a proof is "by contradiction" really just depends on the statement you started with. If your inital statement is $P \rightarrow Q$, then showing the equivalent $\neg Q \rightarrow \neg P$ is "proof by contradiction". But in reality, the "direct" proof for $ P \rightarrow Q$ is just a proof "by contradiction" for $\neg Q \rightarrow \neg P$. The only reason why we started with $P \rightarrow Q$ instead of $\neg Q \rightarrow \neg P$ is our intuition.

This is just my opinion, but also remember that sometimes, it is also very valuable to know what holds if $Q$ does not hold.
AnswerKenntnis:
I do believe there are some proofs that are only demonstrable through contradiction, and I'm going to attempt to describe them logically:

Let X be a logical statement such that: X $\rightarrow$ y, where y is a known contradiction (such as 2+2=5 in the normal arithmetic structure). Without knowing anything else of X, $\neg$X implies nothing and nothing implies $\neg$X (and hence is not provable). But, of course, assuming X implies a contradiction, and thus, $\neg$X.

This form of statement X is isolated, in that it only relates to itself and the contradiction. I do believe they can be constructed though, for it seems it they can be described.

With that said, in real math and logic, or in general real world scenarios, I don't believe any statements of this form exist, except possibly ones that are constructed to meet this criteria and otherwise meaningless. The proof of the primes was eventually proved without contradiction, to my understanding; until math had been more developed, I think that the statement "the number of primes is $\infty$" was basically an isolated logical statement at Euclid's time and for many years after probably, in that there were no other things known to imply it and it didn't imply anything else useful towards its proof.
AnswerKenntnis:
First of all, this is not an answer to the title but to the aside question and is just an example of why you would prefer a constructive proof to a proof by contradiction. Consider the example below,

Prove that $x^2 = 1$ has a root.

Proof by contradiction: Assume that $x^2 = 1$ has no root. Let $f(x) = x^2 - 1 $ then $x^2 = 1$ has a root if and only if $f(x_0) = 0$ for some $x_0$. By assumption $x^2 =1$ has no root and thus, $f(x) \neq 0$ for every $x$. Note that $f$ is continuous and $f(0) = -1$ and $f(2) = 3$. Hence, by the intermediate value theorem, $\exists x_0$ such that $f(x_0) = 0$ which is a contradiction. Therefore, $x^2=1$ has a root.

Constructive proof: For $x^2=1$ if and only if $x^2-1=0$ iff $(x-1)(x+1)=0$. Hence, for $x=\pm 1$ the equation is satisfied, namely the roots are $-1$ and $1$.

The difference is not about the length of the proofs but the information you have. In constructive proof, you know what the roots are but not in the proof by contradiction. Of course, in proof by contradiction, you could have said "let $x_0 = 1$, then $x_0^2=1$ which is a contradiction since $1$ is a root." but then, it is not a clear distinction between the two types of proofs.
QuestionKenntnis:
Is $7$ the only prime followed by a cube?
qn_description:
I discovered this site which claims that "$7$ is the only prime followed by a cube".  I find this statement rather surprising.  Is this true?  Where might I find a proof that shows this?

In my searching, I found this question which is similar but the answers seem focused on squares next to cubes.

Any ideas?
AnswersKenntnis
AnswerKenntnis:
This is certainly true. Suppose $n^3 - 1$ is prime, for some $n$. We get that $n^3-1 = (n-1)(n^2 + n + 1)$ and so we have that $n-1$ divides $n^3 - 1$. If $n-1>1$ then we're done, as we have a contradiction to $n^3 - 1$ being prime.
AnswerKenntnis:
$$
x^3 - 1 = \underbrace{(x-1)(x^2+x+1)}.
$$
Being a product of two numbers, the expression over the $\underbrace{\text{underbrace}}$ is composite UNLESS $(x-1)=1$.  That happens only if $x=2$, so $x^3=8$.
AnswerKenntnis:
Key Idea $\ $ Composite polynomials take composite values (except for finitely many values)

Indeeed, suppose that $\ f(x)\color{#c00}{\ne 0}\ $ is a composite polynomial: $\, f(x) = g(x)h(x)\,$ with $\ g,\,h\color{#c00}{\ne \pm1}.\,$ Then $\, f(n) = g(n)h(n)\, $ is a composite integer if $\,g(n),\,h(n)\,\neq\,  0,\,\pm1.\,$ The possible exceptions to this are $ $ finite $ $ in number: $ $ when $\,n\,$ is a root of $\ g,\, h,\, g\pm1,\,$ or $\, h\pm1, \, $ all of which are $\color{#c00}{nonzero}$ polynomials, hence have finite sets of roots. $\ $ QED

Remark $\ $ For a specific composite polynomial $\,f = gh\,$ this yields a simple algorithm to enumerate its finitely many prime values: test if $\,f(n)\,$ is prime as $\,n\,$ ranges over the roots  of $\,g\pm1\,$ or $\,h\pm1.\,$  Applying this to $\, f = x^3-1 = (x-1)(x^2\!+x+1)\,$ quickly yields the sought result.

Hence the method used in the other answers is a special case of a method that works generally. Furthermore, this is an instance of a general philosophy relating the factorizations of polynomials to the factorizations of their values (see said answer for much more on this viewpoint).
AnswerKenntnis:
You want to know when $x^3-1$ is prime. This expression can be written as $(x-1)(x^2+x+1)$, So it is always divisible by $(x-1)$. If a prime is divided by $(x-1)$, so $x-1=1$ or $x=2$ and $x^3-1=7$.
AnswerKenntnis:
Wouldn't $-2$ also be a prime followed by $-1$ which is a cube of $-1$.
As $x^2 + x +1$ will also equal one for $x=-2$.
QuestionKenntnis:
Why do mathematicians use single-letter variables?
qn_description:
I have much more experience programming than I do with advanced mathematics, so perhaps this is just a comfort thing with me, but I often get frustrated trying to follow mathematical notation. Specifically, I get frustrated trying to keep track of what each variable signifies.

As a programmer, this would be completely unacceptable no matter how many comments you added explaining it:

float A(float P, float r, float n, float t) {
  return P * pow(1 + r / n, n * t);
}


Yet a mathematician would have no problem with this:


  $A = P\ \left(1+\dfrac{r}{n}\right)^{nt}$
  
  where
  $A$ = final amount
  $P$ = principal amount (initial investment)
  $r$ = annual nominal interest rate (as a decimal)
  $n$ = number of times the interest is compounded per year
  $t$ = number of years


So why don't I ever see the following?

$\text{final_amount} = \text{principal}\; \left(1+\dfrac{\text{interest_rate}}{\text{periods_per_yr}}\right)^{\text{periods_per_yr}\cdot\text{years}}$
AnswersKenntnis
AnswerKenntnis:
I think one reason is that often one does not want to remember what the variable names really represent. 

As an example, when we choose to talk about the matrix $(a_{ij})$ instead of the matrix $(\mathrm{TransitionProbability}_{ij})$, this expresses the important fact that once we have formulated our problem in terms of matrices, it is perfectly safe to forget where the problem came from originally -- in fact, remembering what the matrix "really" describes might only be unnecessary psychological baggage that prevents us from applying all linear-algebraic tools at our disposal. 

(As an aside, have you ever seen code written by a mathematician? It very often looks exactly like your first example.)
AnswerKenntnis:
We are very, very lazy. I am very, very serious about this.

NB1: The history is told in Florian Cajori's book on the history of notation. In very old times, there were no variables (and no formulas, really) and everything was incredibly verbose. Cajori's book beautifully shows the very long and tortuous way from that to modern day notation for variables; there are several sections regarding the notation of unknowns and of their powers.

NB2: Additionally, we usually deal with very complicated expressions, so using verbose names for variables you render things almost impossible. Writing down the formula for Gaussian curvature in terms of $E$, $F$, $G$ and the Christoffel symbols if we wrote $\mathsf{Christoffel}^i_{jk}$ instead of $\Gamma^{i}_{jk}$ would turn differential geometry into a dead subject very soon :P
AnswerKenntnis:
Perhaps the most compelling reason for using single character variables is that it enables the usual convention of omitting the multiplication sign in products. This enables great conciseness in notating polynomials - which is important since polynomials are ubiquitous in mathematics, so any convention that simplifies their notation, comprehension, etc is surely worthwhile. Thus we can write $\rm\ xyz\ $ to mean $\rm\ x\cdot y\cdot z\ $ without any worry that it will be mistaken for a variable name. 

While having to insert the multiplication signs doesn't reduce conciseness much for a monomial, it can greatly increase complexity for a polynomial of many terms. For it may cause equations to overflow the line/page length, etc, greatly hindering comprehension. Moreover, as many cognitive studies show, humans read read words by their shape (e.g. cover up the top/bottom half of a line of text and note how you can still easily read it), so any convention that alters shapes (or increases their visual complexity) may inhibit visual parsing, pattern-matching, and global inference of key structural characteristics.
AnswerKenntnis:
My linear algebra professor (J. Komlos) said something that has always stuck with me: we should always use the same letters to denote certain variables, and different letters for different (math) subjects. In this way, our brains are able to build mental pathways so that when we see certain letters we can remember lots of other things we know about that subject because we associate those letters with certain facts, theorems, etc.

I actually think it's mostly a cultural phenomenon, comp-sci people like to use acronyms in part because it's more clear to program with an acronym than a single letter. But similarly, chemists like to use Latin words, physicists make up descriptive names for things, and mathematicians make up new words no one has ever heard of before.
AnswerKenntnis:
A few thoughts:


It is not true that one does not see formulae as you wrote in the very last line, something like $$ \mathrm{velocity} = \frac{\mathrm{displacement}}{\mathrm{time}} $$ In fact, I was taught algebra that way: start with word problems and write down mathematical expressions with words and labels, instead of numbers. I believe this kind of notation is also often used in textbooks. 
Like Mariano and Templar said in their answers, one of the main advantage of the short single letter notation is ease of copying. For computations it is much easier to write (by hand) single letters than whole strings. 
Another issue similar to the above is that it is easier to visually recognize identical terms when you use single letters. Take the expression for the "final amount" you wrote down. I happen to think that using the string "periods_per_yr" makes it harder to notice that the same term appear both in the denominator inside the brackets and in the exponent outside. Algebraically it is perhaps easier to keep track of structures using single letters. 
Also, what about when performing abstract arguments where the variables do not refer to anything specific and concrete? Is the phrase "take three points in the plane, point_one, point_two, and point_three..." more easily to understand than "take three points $P,Q,R$ in the plane..."? 
Lastly, in my PhD dissertation I have several computations involving expressions that span close to half a page when printed. I shudder to think what would happen if I use verbose names for all the terms: is it worth it to make individual variables more "legible" at the expense of making each equation span 3 pages? Does that actually improve overall legibility?
AnswerKenntnis:
I can't imagine writing full words when solving equation and rewriting it 10 times, when programming you usually don't write it so much, you can use functions, classes, copy/paste, programs which automatically insert variables etc.
AnswerKenntnis:
A number of excellent explanations have been given, ranging from laziness of mathematicians to convention. I'd like to add one more that may be slightly more debatable than others.

I dare to say I experience some sort of freedom when assigning variable names. This freedom is very typical to math: ideas are not bound by physical reality, the only constraints are your own imagination and the consistency of your thoughts. This freedom suffers if you're thinking about your math too concretely. 

Here are a few remarks to explain my point of view:


Somewhere in the 15th century ($\pm$ a few centuries) people realised they didn't have to discribe their equations in words, they could just assign letters to their quantities and let the formulae speak for themselves. Suddenly people realised it was not necessary for algebraic equations to have a direct geometric meaning. If people had kept writing $\rm area = length\cdot width$ until the end of days, this might never have happened.
Let's say we were thinking about distance. We might write
$$ \rm distance = \sqrt{horizontal\ displacement^2 + vertical\ displacement^2}.$$ However, would you ever dare to write $\rm distance = |horizontal\ displacement| + |vertical\ displacement|$? Maybe you would, but write this on the blackboard of an average high-school physics teacher (no offence meant) and they might try to hit you with something. This is because they're thinking about the physical reality, not about the abstract properties of such a formula or it's consequences in a more abstract setting. Therefore if you ever want to define the concept of a metric space and study it's properties in full generality, it's probably safer to denote distance simply by "d". (Choosing 'd' as a small mnemonic to where it all started.)
Let's say we're thinking about a curve this time. At some point you may come to realise there's actually an interesting group structure on your curve. If you're refering to your curve simply as "curve" everywhere, it's probably a giant leap to suddenly rebaptize your curve into "curve that is actually a group as well". You'll probably still call your curve "curve" all the time and you may unconsciously make it harder for yourself to realise the importance and usefullness of it's group structure.


In conclusion: math is an abstract science, assigning the name all to concrete names to objects will constrain your imagination, which is always a bad thing in math.
AnswerKenntnis:
You're sort of comparing apples and oranges.

Mathematical papers are written in verbose, descriptive language (e.g. English); equations and such are introduced to introduce precision and brevity when needed.

A computer program, however, is written in a very precise language. The role of some coding style guidelines (e.g. long identifier names) are to introduce the verbose, descriptive language where needed.

Also, mathematics is "executed" -- humans have to manipulate them.

Computer programs, however are almost never executed. Even in an interpreted language, your program will get tokenized and parsed, and the interpreter will operate on the result.
AnswerKenntnis:
Actually, I think the reason why single letter identifiers are popular in math, and not so popular in programming is Intelisense. Today, every profesional developer would flinch if shown something like return P * pow(1 + r / n, n * t), but we have been spoiled by the ease of use of automatic filling of long names.

As I remember, 10-15 years ago it was more common to use single or double letter names for any local variable, because the developer would have to write each character himself, by hand. Right now, I just press a few keys, and the IDE does the rest.

BTW, the name of the function used in the example (pow for Power) fits nicely with the explanation.
AnswerKenntnis:
It's a convention like any other; never underestimate the power of historical inertia! Different disciplines have different conventions. 

I would also guess (and I have no evidence to support this) that a big reason it is currently still around is that typesetting equations was expensive and time-consuming before the rise of modern typesetting (e.g. TeX) and writers of textbooks were probably encouraged to keep their notation as concise as possible. This would explain the disparity between mathematicians and programmers since the latter, after all, have the benefit of a history of using computers.
AnswerKenntnis:
Because a variable is just a number and they all behave equally, different variables dont have any different meaning or interpretation in math, you dont gain any additional information by writing "final_amount" instead of x. Its only confusing and unproffesional. Even if you try to follow this path, there can be intermediate steps in solving an equation in which these words can not be interpreted in any sensible physical or informal way. For instance it can be convenient to introduce imaginary numbers even when solving equations with real solutions.
AnswerKenntnis:
When doing algebra by hand with pencil and paper, it's a lot easier - and a lot faster - to work with something like 

PV=nRT

instead of 

(pressure)(volume) = (number of moles of gas) (gas constant) (temperature).

And this matters a lot when you're doing a timed exam.
AnswerKenntnis:
Because the intellisense & autocompletion on my piece of paper is turned off. :) 

(So is the context sensitive color highlighting.)

Holy cow, imagine a sheaf cohomology commutative diagram chase with camel casing and vaguely Java like method syntax for all operations. Or even just the chain rule:

derivative(firstSmoothFunction.composedWith(secondSmoothFunction)) = derivative(firstSmoothFunction).composedWith(secondSmoothFunction) * derivative(secondSmoothFunction)

In many cases the more concise notation may make it harder to remember what stands for what, but well chosen notation makes the relations between things much more apparent.
AnswerKenntnis:
I don't think that substituting single-letter variables with more letters would do much positive in most mathematics, because most theorems (and such) are short enough so that remembering a few variables isn't a problem. And if you forget, it is just to look at the start of the theorem. Also, there is conventions for what variable-letters to use in different circumstances. And last, it is a way to make it easier to separate words from variables.

In programming, the ability to have more letters for one variable, is a huge advantage because a program often consists of thousands of lines, and hundreds of variables.
AnswerKenntnis:
Its quite self explanatory if you read of how Cardan wrote polynomials:

Instead of 

$$x^4+6x^2+36 = 60x$$

He'd write

$$1\overline{q}d\overline{q}d. p: 6\overline{q}d. p:36 \text{ aequalia. } 60 pos.$$

or to write

$$x^4+(2y+12)x^2 +y^2+12y+36 = (2y+6)x^3+60x+y^2+12y$$

He'd put

$$1\overline{q}d\overline{q}d. p:2 pos.p:12 \overline{q}d \text{ R }p:1\overline{q}d.p:1 pos. \text{ additi numeri } p:36 \text{ aequalia. } $$
$$2 pos.6\overline{q}drator\overline{u},p:60 pos.p:1 \overline{q}d. p:12 pos. \text{ numeri additi }$$
AnswerKenntnis:
I think mathematicians continue to use such terse notation because they don't have to maintain their creations under time pressure.  Mathematics is essentially a write-once language and it only runs inside another mathematician's very forgiving brain.  You can spend an hour rereading the same paragraph in a math paper until you understand it, taking time to absorb and reabsorb the sundry meanings of the Greek and Roman characters arrayed before you, and nothing bad will happen in the meantime.  In an IT operating environment, we don't have that luxury.  If I were ever rolled out of bed at 0300 to deal with a computer system problem and I had to deal with scripts/logs written anything like a typical math theorem, the person/idiot responsible for those scripts/logs would be strangled/fired before sunup.
AnswerKenntnis:
I am a retired software engineer and a math person. I am going to answer your question based on my own personal experience and observation.

The coding style in your first example is unacceptable today but was common in old days. The FORTRAN programs written in 60's and 70's are like that.

The programmers deal with real life problems. The reasons programmers use long variable names are mostly for readability and easy to debug. Programmers are asked to use long names because they were having difficulty understanding code written by others and debugging code written in short names. I was once shown a piece of code written by myself and could not figure out what I was doing.

On the other hand, mathematicians mostly deal with abstractions. The formula in your example generally will be present with the explanation you provided. Later on in the literature,
the author can use t, which is the number of years, wherever it is needed without repeated explanations. Most mathematicians follow certain conventions, say they usually use x for an unknown, c for a constant without explanation. This sometimes will give the readers some trouble understanding the text if unusual conventions were used. Also, the reader will have to get used to the notation the author adopts. Sometimes it's a pain.

In either case, there is a compiler there. In the programming case, you have a compiler to help generating machine code for the computer to understand. In the math case, your brain is the compiler to generate the knowledge.
AnswerKenntnis:
I'm a programmer as well. Note that your initial phrasing would be better as "As an imperative programmer, ..."

If you look at functional programming languages like F# or Lisp, the single letter variable paradigm is quite common for many of the reasons mentioned in the other answers. Take the functions:

let square x = x * x;;
let power x y = x ^ y;;


These are common and accepted ways to write your functional functions. This is mostly due to stateless/immutability differences in variables, but if we can skip the why explanations I'll just assert that the functional programming style parallels mathematical thinking far better than imperative.

Now imperative programming (by far the majority of programming) is more like a list of instructions, what I would compare in mathematics to a proof. If you remember back to 'doing proofs,' you state your reason for making each step along the way; in some cases rather verbosely.
AnswerKenntnis:
I write: Solutions of quadratic equation $ax^2 + bx + c=0$ are $(-b\pm\sqrt{b^2-4ac})/(2a)$.  I would not want to write this with time in place of $x$ and acceleration_of_gravity in place of $a$ and so on!
AnswerKenntnis:
If we saw something like the above, then the alphabet implicitly used in mathematics would consist of words.  So, then the individual letters of that alphabet basically require another language to get understood in the first place.  In other words if you have something like "velocity=distance/time" then you have "velocity", "distance", and "time" at least as implied as existing in some language as part of its alphabet.  But, of course, you're wanting those symbols also to represent English words which have meaning also.  Thus, you need two alphabets working together at once, as well as two languages working together at once, and it's not at all clear that you'll avoid ambiguity in principle when you do this.  You will have character strings which consist of a word in one language and a letter of the alphabet in the other language at the same time.

On the other hand the more common way just requires one alphabet and one language.  In principle, one doesn't need any understanding of any natural languages to have v=(d/t) mathematically speaking.  You just need "v", "d" and "t" as variables in your alphabet... and to perhaps make this clearer you could write the same formula mathematically as 6=(7/8) given 6, 7, and 8 as variables in your alphabet for some language.  But, then we wouldn't seek to use "6", "7", and "8" to denote numbers, because then we would have two languages working simultaneously.

Basically, it comes as simpler to have v=(d/t) than to have velocity=(distance/time).
AnswerKenntnis:
The point is that we usually want to be as concise as possible, in other words, we want to be capable of being understood and on the same time do not need to write lots of things. In truth, you'll never see in the middle of a serious text of math some equations with letters appearing from nowhere without explanations: we always have the definitions first. The point is that there are some conventions that we follow: things that always have the same name, and that our audience is supposed to know about. But if we do not assume even those basic things from our audience, we define them as well.

Now, I'll give you an example that you'll agree that writting everything like you say will make us even unable to proceed with the theory (only a masochist would proceed with something like that). This is an equation from differential geometry:

$$\sum_{r=1}^ng_{lr}(\gamma(t)) \frac{d^2\gamma^r}{dt^2}+\sum_{i,j=1}^n[ij,l](\gamma(t))\frac{d\gamma^i}{dt}\frac{d\gamma^j}{dt}=0$$

Now, that $[ij,l]$ expands also into another kind of big expression. Now imagine if for each of the letters we write the word it means. An equation like this one, that after making the definitions is at same time compact and understandable, would become a real mess and people would get lazzy to write down equations like that writing every word. So, we do use letters because we gain compactness, we gain simplicity and we do not waste too much time writing, but the benefits of that are only achievable if we combine with clear definitions and organized line of thought. If so, when someone reaches an equation like that will look at it and say: "well, that's easy to read, the author defined all those terms properly!" and although in the paper will appear only letters, for one who knows the definitions the entire words will "be there" but without making a real mess with the text.
AnswerKenntnis:
First of all, if mathematicians used more-than-one-letter variables, they might confuse them for multiplication. Second, mathematicians like to be as accurate in as little words as possible. And finally, there are 26 letters in the alphabet. It's not like one equation will use them all, anyways.
QuestionKenntnis:
The Integral that Stumped Feynman?
qn_description:
In "Surely You're Joking, Mr. Feynman!," Nobel-prize winning Physicist Richard Feynman said that he challenged his colleagues to give him an integral that they could evaluate with only complex methods that he could not do with real methods:


  One┬átime┬áI boasted, "I can do by other┬ámethods any integral anybody else┬áneeds contour integration to do."
  
  So┬áPaul [Olum] puts up┬áthis tremendous damn integral he┬áhad┬áobtained┬áby starting┬áout┬áwith a┬ácomplex function that he┬áknew┬áthe┬áanswer┬áto, taking┬áout the┬áreal part of it and┬áleaving┬áonly the┬ácomplex part. He┬áhad┬áunwrapped┬áit so it was only possible┬áby contour integration! He was always deflating┬áme┬álike┬áthat. He┬áwas a┬ávery smart fellow.


Does anyone happen to know what this integral was?
AnswersKenntnis
AnswerKenntnis:
I doubt that we will ever know the exact integral that vexed Feynman.
Here is something similar to what he describes.

Suppose $f(z)$ is an analytic function on the unit disk.
Then, by Cauchy's integral formula,
$$\oint_\gamma \frac{f(z)}{z}dz = 2\pi i f(0),$$
where $\gamma$ traces out the unit circle in a counterclockwise manner.
Let $z=e^{i\phi}$.
Then
$\int_0^{2\pi}f(e^{i\phi}) d\phi = 2\pi f(0).$
Taking the real part of each side we find 
$$\begin{equation*}
\int_0^{2\pi} \mathrm{Re}(f(e^{i\phi}))d\phi = 2\pi \mathrm{Re}(f(0)).\tag{1}
\end{equation*}$$
(We could just as well take the imaginary part.)
Clearly we can build some terrible integrals by choosing $f$ appropriately.

For example, let $\displaystyle f(z) = \exp\frac{2+z}{3+z}$.
This is a mild choice compared to what could be done ...
In any case, $f$ is analytic on the disk.
Applying (1), and after some manipulations of the integrand, we find
$$\int_0^{2\pi}
\exp\left(\frac{7+5 \cos\phi}{10+6\cos\phi}\right)
\cos \left(
\frac{\sin\phi}{10+6 \cos\phi}
\right)
d\phi = 2\pi e^{2/3}.$$
AnswerKenntnis:
Coincidentally, I just happened to be reading "Genius: The Life and Science of Richard Feynman" a few weeks ago. On page 178, James Gleick writes:


  At lunch one day, feeling even more ebullient than usual, he
  challenged the table to a competition. He bet that he could solve any
  problem within sixty seconds, to within ten percent accuracy, that
  could be stated in ten seconds. Ten percent was a broad margin, and
  choosing a suitable problem was hard. Under pressure, his friends
  found themselves unable to stump him. The most challenging problem
  anyone could produce was: Find the tenth binomial coefficient in the
  expansion of $(1 + x)^{20}$. Feynman solved that just before the clock
  ran out. Then Paul Olum spoke up. He had jousted with Feynman before,
  and this time he was ready. The demanded the tangent of ten to the
  hundredth. The competition was over. Feynman would essentially have
  had to divide one by $\pi$ and throw out the first one hundred digits of
  the results - which would mean knowing the one-hundredth decimal digit
  of $\pi$. Even Feynman could not produce that on short notice.
AnswerKenntnis:
The Question was regarding Differentiation under the integral Rule.

The direct quotation from "Surely You're Joking, Mr. Feynman!" regarding the method of differentiation under the integral sign is as follows:


  One thing I never did learn was contour integration. I had learned to do integrals by various methods shown in a book that my high school physics teacher Mr. Bader had given me. One day he told me to stay after class. "Feynman," he said, "you talk too much and you make too much noise. I know why. You're bored. So I'm going to give you a book. You go up there in the back, in the corner, and study this book, and when you know everything that's in this book, you can talk again." So every physics class, I paid no attention to what was going on with Pascal's Law, or whatever they were doing. I was up in the back with this book: Advanced Calculus, by Woods. Bader knew I had studied Calculus for the Practical Man a little bit, so he gave me the real worksΓÇöit was for a junior or senior course in college. 
  
  It had Fourier series, Bessel functions, determinants, elliptic functionsΓÇöall kinds of wonderful stuff that I didn't know anything about. That book also showed how to differentiate parameters under the integral signΓÇöit's a certain operation. It turns out that's not taught very much in the universities; they don't emphasize it. 
  
  But I caught on how to use that method, and I used that one damn tool again and again. So because I was self-taught using that book, I had peculiar methods of doing integrals. The result was, when guys at MIT or Princeton had trouble doing a certain integral, it was because they couldn't do it with the standard methods they had learned in school. If it was contour integration, they would have found it; if it was a simple series expansion, they would have found it. Then I come along and try differentiating under the integral sign, and often it worked. So I got a great reputation for doing integrals, only because my box of tools was different from everybody else's, and they had tried all their tools on it before giving the problem to me.
AnswerKenntnis:
It was something related to calculating a definite integral that required Feynman to calculate some digits of $\pi$ after the decimal point. An exact reference to this integral would be very difficult to find if it exists in literature.
QuestionKenntnis:
'Obvious' theorems that are actually false
qn_description:
It's one of my real analysis professor's favourite sayings that "being obvious does not imply that it's true".

Now, I know a fair few examples of things that are obviously true and that can be proved to be true (like the Jordan curve theorem).

But what are some theorems (preferably short ones) which, when put into layman's terms, the average person would claim to be true, but, which, actually, are false
(i.e. counter-intuitively-false theorems)?

The only ones that spring to my mind are the Monty Hall problem and the divergence of $\sum\limits_{n=1}^{\infty}\frac{1}{n}$ (counter-intuitive for me, at least, since $\frac{1}{n} \to 0$
).

I suppose, also, that $$\lim\limits_{n \to \infty}\left(1+\frac{1}{n}\right)^n = e=\sum\limits_{n=0}^{\infty}\frac{1}{n!}$$ is not obvious, since one 'expects' that $\left(1+\frac{1}{n}\right)^n \to (1+0)^n=1$.

I'm looking just for theorems and not their (dis)proof -- I'm happy to research that myself.

Thanks!
AnswersKenntnis
AnswerKenntnis:
Theorem (false):


  One can rearrange the terms in a convergent series, and the resulting series will converge to the same sum as the original series.
AnswerKenntnis:
A shape with finite volume must have finite surface area.
AnswerKenntnis:
I keep harping on this, because I think it's a spectacular example of something that can be demonstrated to be completely obvious (not only because it seems so, but because it was so widely believed for so long) and yet is completely wrong:


  Suppose $\Phi$ is a property that might or might not hold of some object.  Then there is a collection $S_\Phi$ of all objects with property $\Phi$.


Many serious and even famous mathematicians went ahead with this intuitively obvious  but utterly false principle, whose demolition shook mathematics to its foundations and marks the beginning of modern logic and set theory.

(There are many counterexamples, of which the most well known is $\Phi(x) = $ ΓÇ£$x$ is not a member of collection $x$ΓÇ¥.)
AnswerKenntnis:
I wish I'd thought of this yesterday, when the question was fresh, because it's astounding.  Suppose $A$ and $B$ are playing the following game: $A$ chooses two different numbers, via some method not known to $B$, writes them on slips of paper, and puts the slips in a hat.

$B$ draws one of the slips at random and examines its number.  She then predicts whether it is the larger of the two numbers.

If $B$ simply flips a coin to decide her prediction, she will be correct half the time.  


  Obviously, there is no method that can do better than the coin flip.


But there is such a method, described in Thomas M. Cover ΓÇ£Pick the largest numberΓÇ¥Open Problems in Communication and Computation Springer-Verlag, 1987, p152.

which I described briefly here, and in detail here.
AnswerKenntnis:
In a related mathOverflow thread, Gowers pointed out the following obvious but false claim:


  Let $I_1, I_2, \ldots$ be subintervals of $[0,1]$ whose total length is strictly less than 1.   Then the union of the $I_i$ cannot contain $\Bbb Q\cap [0,1]$.


(Note that if $\Bbb Q$ is replaced with $\Bbb R$, the claim is true.)

I find the fact that all of $\Bbb Q$ can be covered by an arbitrarily small family of intervals to be one of the most bizarrely counterintuitive in all of mathematics.
AnswerKenntnis:
This is elementary compared to most of the other examples, but how about


  There are more rational numbers than there are integers (natural numbers).


?
AnswerKenntnis:
The falseness of


  Let $S$ be an infinite family of strictly positive numbers.  Then $\sum S = \infty$


has been boggling people for thousands of years.  It is the basis for Zeno's paradox, but if you think Zeno's paradox is old and tired, consider that it is  also the basis for the Gabriel's Horn paradox (also mentioned in this thread), which still puzzles people.
AnswerKenntnis:
If a function $f(x)$ has an horizontal asymptote, then $\lim f'(x) = 0$
AnswerKenntnis:
$
0.\overline{9} < 1
$

Probably the most famous of the "obvious" but false.
AnswerKenntnis:
This part is true (Jordan-Brouwer separation theorem):


  (a) Any imbedding of the $2$-sphere into $3$-dimensional Euclidean space
  separates the space into two disjoint regions.


But this part, which would seem to be a natural generalization of the Jordan-Sch├╢nflies Curve Theorem, is not true:


  (b) The regions are homeomorphic to the inside and outside of the unit sphere.
AnswerKenntnis:
Keller's conjecture is obviously true:


  Let $\Bbb R^n$ be completely covered with identical, non-overlapping $n$-cubes.  There  must be two cubes that share a face.


(For example, when $n=2$ we cover the plane with little square tiles, and the conjecture states that there must be two tiles that share an edge. This is true.)

However, the conjecture is false for all $n>7$.
AnswerKenntnis:
$i^i$ is imaginary.$\ \ \ \ \ \ $
AnswerKenntnis:
Every chain of subsets of $\mathbb N$ is countable.
AnswerKenntnis:
The real numbers/Cantor set are countable.

There are several false "obvious" proofs:


"Proof". Consider the tree $\{0,\ldots,9\}^\Bbb N$, then every real number corresponds to a node in the tree. Since there are only countably many levels and each is finite, it follows that the real numbers are finite.

Why does it fail? This set is actually not a tree. You can order it so it looks like a tree, but in fact the tree would be composed of initial segments of each functions ordered by continuation. This tree, then, would have a last level (namely a level that no point there has a successor), and it would be exactly the level of the functions themselves (the previous levels would be proper initial segments of the functions).

If we remove that last level, then the tree is indeed countable, but now each real number corresponds to a branch in the tree rather than a node. (It's the unique branch whose limit equals to the function, which previously appeared on that final level.)
"Proof". The rational numbers are countable, and between every two real numbers there is a rational number. Therefore this defines a bijection between pairs of real numbers and the rational numbers.

Why does it fail? Because there are many, many, many pairs being mapped to the same rational number, this is not actually a bijection.
"Proof". The Cantor set is closed, its complement is open, so it is a countable union of intervals, so the Cantor set is countable.

Why does it fail? Because not every point in the Cantor set is an endpoint of such interval. For example $\frac14$. It is true that the endpoints of these intervals form a countable dense subset, though.
BONUS!, $\mathcal P(\Bbb N)$ is countable.

"Proof". For every finite $n$, $\mathcal P(n)$ is finite, and $\mathcal P(\Bbb N)=\mathcal P(\bigcup n)=\bigcup\mathcal P(n)$, is a countable union of finite sets, which is countable.

Why does it fail? Because the union only includes finite subsets of $\Bbb N$, but none of its infinite subsets.
AnswerKenntnis:
Theorems that are intuitively true,  but actually flawed:


There is no continuous, nowhere-differentiable real function. 
There is no real function that is differentiable and not monotonic on any non-trivial interval. 
If a real function satisfies $\forall x, y,  f(x+y) =f(x) +f(y) $, it is of the form $x\to ax$. 
Infinite sums and integrals can be swapped anytime. 
A connected metric space is path-connected.
AnswerKenntnis:
I really like "wrong proofs" as typically the insight why the proof is wrong gives you some understanding of the topic. One very simple version is this one, which I threw at my first semesters when I was a tutor:


  Each binary relation which is symmetric and transitive is also reflexive and therefor an equivalence relation.


"Proof":


  Let $\sim$ denote a symmetric and transitive relation and let $x$, $y$ be two elements with $x \sim y$. As $\sim$ is symmetric, it holds that $y \sim x$. Since $x \sim y$ and $y\sim x$ it follows by the transitivity of $\sim$ that $x \sim x$, which is the definition of reflexivity.


Edit: Since I was asked, here's why the proof is wrong (move your mouse there to show):


   Take a look at the empty relation on a non-empty set $S$, so that there are no $x, y \in S$ so that $x \sim y$. This relation is symmetric and transitive, but it is not reflexive. Reflexivity needs $x \sim x$ to hold for all $x$. The proof assumes that there is a y so that x ~ y, which isn't necessarily the case for all $x$.
AnswerKenntnis:
The probability that you hit any single point on a dart board is $0$ but the probability that you hit the dart board is $1$ (as long as you're not as bad as I am at throwing darts ;D).

EDIT:

As @JpM pointed out I didn't follow the format of these posts albeit the idea can (easily in my opinion) be understood from what I've said above.


  Pseudo-Claim: The probability of hitting a single point on a dart board is greater than $0$ since the probability of hitting it at all (assuming that you will hit the dart board) is $1$.


Seems obvious in the sense that a bunch of $0$ can't add up to be $1$ so each point must have some probability. Actually false because of some properties of measures.
AnswerKenntnis:
If $U$ is an open subset of $\mathbb{R}^n$ that is homeomorphic to $\mathbb{R}^n$, one might think it "obvious" that it's in fact diffeomorphic to $\mathbb{R}^n$ (perhaps thinking something like "topologically it looks like $\mathbb{R}^n$, and differentiably it's locally trivial").  In fact, this is true (but by no means obvious!) for $n\neq 4$.  But for $n=4$ it is false: there exist exotic $\mathbb{R}^4$'s (differentiable manifolds that are homeomorphic, but not diffeomorphic, to $\mathbb{R}^4$), including "small" ones which are diffeomorphic to an open subset of $\mathbb{R}^4$.
Much less profound, but still fun: it's "obvious" that the sum of two convex open sets in the plane whose border is $C^\infty$ also has a $C^\infty$ border (perhaps thinking something like "the border of the sum is parametrized by a smooth function of the borders of the summands").  But this is false: in fact, the border of the sum is always $C^{20/3}$ (meaning six times differentiable and with a sixth derivative which is appropriately H├╢lder) and no more in general.  A simple counterexample is given by the epigraphs of $x^4/4$ and $x^6/6$.  For details, see Kiselman, "Smoothness of Vector Sums of Plane Convex Sets", Math. Scand. 60 (1987), 239ΓÇô252.
AnswerKenntnis:
There are a good number of counterintuitive probability situations out there. One of my favorites is nontransitive dice:

There are 3 dice, A, B and C. The dice have numbers from 1-9 on their sides (repeats possible). If die B beats (higher number) die A more than half the time and die C beats die B more than half the time, then die C will beat die A more than half the time.

This is not necessarily a true statement. Dice can be designed such that the "x beats y" property is not transitive. A beats B, which beats C, which beats A.
AnswerKenntnis:
I'm surprised noone gave this answer already, so here it is:


  There are more integers than there are natural numbers.


It's obvious, isn't it?
AnswerKenntnis:
In my opinion, the most interesting (but also sometimes not intuitive) results in mathematics are those that state a theorem that ends up being false because it actually holds in many cases, except for very few or very strange cases. In other words, the most "obvious" false theorems to me are those that have very difficult counterexamples.

Some examples:


Banach-Tarski: There exists a strict subset $A$ of the Euclidean $n$-ball $B$ such that one can partition $A$ and $B$ into an equal number of further subsets that can be mapped to each other by isometries. This shows that not all sets are measurable, and that it's possible to perform partitions that do not preserve measure.
Non-finiteness of differentiable structures: For $\mathbb{R}^n$ with $n = 4$, there are an uncountable number of distinct differentiable structures.
Divergence of Fourier series: There exists an integrable function on $[-\pi, \pi]$ whose Fourier series diverges everywhere. This is extremely unusual because for any typical function we might write down, usually its Fourier series might diverge at one or a finite number of points, but will probably converge everywhere else.
AnswerKenntnis:
Hypothesis: Every infinitely-differentiable function is real-analytic somewhere.

This is false, as shown by (for example) the Fabius function.
AnswerKenntnis:
Consider a function $f:(0, \infty) \rightarrow \mathbb{R}$ that is $\mathcal{C}^\infty$ on that interval.  At first glance, one might think that, if $\lim(f) = 0$ as $x \rightarrow \infty$, then $\lim(f') = 0$ as $x \rightarrow \infty$.  However, this is false.  Here is but one counterexample:

$$f(x) = \frac{1}{x}\sin(x^2)$$

Further, if we add the stipulation that $f$ also be monotonic, counterexamples can still be found (though they are quite pathological).
AnswerKenntnis:
The Hauptvermutung states that there is essentially only one PL structure on a manifold. More precisely, it states that any two triangulations have a common subdivision. The reason why this seems "obviously true" is that you can take both triangulations and superimpose them one on top of the other, subdividing the manifold into a bunch of cells, and then taking the barycentric subdivision to get a triangulation. It turns out that this is false and one needs some pretty subtle invariants to detect it. The problem with the argument that I gave is that one triangulation could be very wild with respect to the other (fractally wiggly) so that their union does not subdivide the manifold into a nice collection of cells.
AnswerKenntnis:
The following statement I once believed to be "obvious":


  If $f:\mathbb{R} \rightarrow [0,\infty)$ continuous is such that $\int_{-\infty }^{\infty }f(x)\text{d}x<{\infty } $, then $\lim \limits_{x \to \pm\infty} f(x) = 0$


which is actually false. 

(Note: It is true if $f$ is uniformly continuous!)
AnswerKenntnis:
Theorem: Let $f_1(x,y)$ and $f_2(x,y)$ be two joint probability densities, each having its $x,y$ components positively correlated ($Cov_1(x,y)>0$, $Cov_2(x,y)>0$). Let $f_3=\alpha f_1 + (1-\alpha) f_2$ be the mixing density, for some $0\le \alpha\le 1$. Then $Cov_3(x,y)>0$.

In words: mixing populations preserves the correlation sign. In other words: if the average MSE male user is brighter than  the mean, and if the average MSE female user is brighter than the mean, then the average MSE user is brigther than the mean. Obviously true.

False. See Simpson's paradox.
AnswerKenntnis:
Here's one of my favorites: Let's assume playing with a fair coin.


  Theorem (false)
  In a long coin-tossing game each player will be on the winning side for about half the time, and the lead will pass not infrequently from one player to the other.


The following is from the classic of Chung & Feller Introduction to Probability Theory and It's Applications, Vol 1:


  According to widespread beliefs a so-called law of averages should ensure the Theorem above. But, in fact this theorem is wrong and contrary to the usual belief the following holds:
  
  With probability $\frac{1}{2}$ no equalization occurred in the second half of the game regardless of the length of the game. Furthermore, the probabilities near the end point are greatest.


In fact this leads to the Arc sine law for last visits (see e.g. Vol 1, ch.3, section 4, Theorem 1).

Note: Please note their remarkable statements cited from Chapter III: Fluctuations in Coin Tossing and Random Walks:


  (Chung & Feller): For example, in various applications it is assumed, that observations on an individual coin-tossing game during a long time interval will yield the same statistical characteristics as the observation of the results of a huge number of independent games at one given instant. This is not so.


and later on:


  (Chung & Feller): Anyhow, it stands to reason that if even the simple coin-tossing game leads to paradoxical results that contradict our intuition, the latter cannot serve as a reliable guide in more complicated situations.
AnswerKenntnis:
A simple arc (homeomorphic image of the closed unit interval) in the plane has $2$-dimensional Lebesgue measure zero.
AnswerKenntnis:
Something I used to be seduced by in my mathematical immaturity (which is sadly still existing): 


  Suppose that $P_n$ are a family of statements indexed by $n\in\mathbb{N}$ and we can assign meaning to $P_{\infty}$.
  Then if $P_n$ is true for all $n\in\mathbb{N}$, then $P_{\infty}$ is true also.
AnswerKenntnis:
Here are some of the false statements popping into my mind that made me raise at least one eyebrow when I first realized they were not true.



Every linear function between two vector spaces is continuous.

True only as long as the domain is finite-dimensional. If it is not, then there exists a linear function that is not continuousΓÇöat any point!



The set of real numbers can in no way be (totally) ordered in such a way that every non-empty set in it has a least element.

False if choice is assumed, by the well-ordering theorem.



$\mathbb Q$ is not countable.

I am still tempted to believe it sometimes...



If the derivative of a continuous real-to-real function exists almost everywhere and (wherever it exists) vanishes almost everywhere, then the function must be constant.

False. In fact, there exists a function that satisfies the premise and it is strictly [sic!] increasing!



Any compact set is closed.

The name ΓÇ£compactΓÇ¥ would suggest this, but this can be guaranteed only in Hausdorff spaces.



A set is compact if and only if every sequence in it contains a convergent subsequence.

While true in metric spaces, not only is it false in some more general topological spaces, but also neither condition implies the other!
QuestionKenntnis:
In the history of mathematics, has there ever been a mistake?
qn_description:
I was just wondering whether or not there have been mistakes in mathematics. Not a conjecture that ended up being false, but a theorem which had a proof that was accepted for a nontrivial amount of time and then someone found a hole in the argument. Does this happen anymore now that we have computers? I imagine not. But it seems totally possible that this could have happened back in the Enlightenment heyday. 

Feel free to interpret this how you wish!
AnswersKenntnis
AnswerKenntnis:
[I posted this recently in another thread, but it works much better here, so I've deleted it from there. I spent some time a couple of years ago trying to track down unequivocally incorrect claims of false results, and this was the most remarkable one I found. ]

In 1933, Kurt G├╢del showed that the class called $\lbrack\exists^*\forall^2\exists^*, {\mathrm{all}}, (0)\rbrack$ was decidable.  These are the formulas that begin with $\exists a\exists b\ldots \exists m\forall n\forall p\exists q\ldots\exists z$, with exactly two $\forall$ quantifiers, with no intervening $\exists$s. These formulas may contain arbitrary relations amongst the variables, but no functions or constants, and no equality symbol. G├╢del showed that there is a method which takes any formula in this form and decides whether it is satisfiable. (If there are three $\forall$s in a row, or an $\exists$ between the $\forall$s, there is no such method.)

In the final sentence of the same paper, G├╢del added:


  In conclusion, I would still like to remark that Theorem I can also be proved, by the same method, for formulas that contain the identity sign.


Mathematicians took G├╢del's word for it, and proved results derived from this one, until the mid-1960s, when St├Ñl Aanderaa  realized that G├╢del had been mistaken, and the argument G├╢del used would not work.  In 1983, Warren Goldfarb showed that not only was G├╢del's argument invalid, but his claimed result was actually false, and the larger class was not decidable.

G├╢del's original 1933 paper is Zum Entscheidungsproblem des logischen Funktionenkalk├╝ls (On the decision problem for the functional calculus of logic) which can be found on pages 306ΓÇô327 of volume I of his Collected Works. (Oxford University Press, 1986.) There is an introductory note by Goldfarb on pages 226ΓÇô231, of which pages 229ΓÇô231 address G├╢del's error specifically.
AnswerKenntnis:
When trying to enumerate mathematical objects, it's notoriously easy to inadvertently assume that some condition must be true and conclude that all the examples have been found, without recognizing the implicit assumption.  A classic example of this is in tilings of the plane by pentagons: for the longest time everyone 'knew' that there were five kinds of pentagons that could tile the planes.  Then Richard Kershner found three more, and everyone knew that there were eight; Martin Gardner wrote about the 'complete list' in a 1975 Scientific American column, only to be corrected by a reader who had found a ninth - and then after reporting on that discovery, by Marjorie Rice, a housewife who devoted her free time to finding tessellations and found several more in the process.  These days, she has a web page devoted to the subject, including a short history, at https://sites.google.com/site/intriguingtessellations/home
AnswerKenntnis:
Several examples come to my mind: 


Hilbert's "proof" of the continuum hypothesis, in which an error was discovered by Olga Taussky when she was editing his collected works. This was shown to be undecidable by Paul Cohen later.
Cauchy's proof (published as lecture notes in his collected papers) of the fact that the pointwise limit of continuous functions is continuous. At the time, there was a poor understanding of the concept of continuity, until Weierstrass came along.
Lam├⌐'s proof of Fermat's last theorem, erroneous in that it was supposing unique factorization in rings of algebraic integers, which spurred the invention of ideals by Kummer.
AnswerKenntnis:
One of the classic examples surely is the Perko pair of knots. For 75 years people thought that these two knots were distinct, even though they had found no invariants to distinguish between them. Then in 1974 Kenneth Perko (a lawyer!) discovered that they were actually the same knot. Even Conway, apparently, in compiling his table, had missed this. 

It is not by any means a significant error, but it is an intriguing one nonetheless.
AnswerKenntnis:
In 2003 a startling breakthrough was made (Review text only available to MathSciNet subscribers) in the theory of combinatorial differential manifolds. This theory was started by Gel'fand and MacPherson as a new combinatorial approach to topology, and one of the objects of its study is the matroid bundle. Much effort was spent in clarifying the relationship between real vector bundles and matroid bundles. From various previous results, the relationship is expected to be "complicated". 

The Annals of Mathematics published in 2003 an article by Daniel Biss whose main theorem essentially showed that the opposite is true: that morally speaking there is no difference between studying real vector bundles and matroid bundles. This came as quite a shock to the field. (For an expert's account of the importance of this result, one should read the above-linked MathSciNet review.) 

Unfortunately the article was retracted in 2009 after a flaw was found by (among others) Mnev. The story was popularised by Szpiro in his book of essays.  

From Wikipedia one also finds the following account of the incident by someone familiar with the details and has expertise in the field, which contradicts some of the assertions/descriptions in Szpiro's essay. According to the various accounts, "experts" may have known about the error in the proof as early as 2005. But in the "recorded history" the first public announcement was not until 2007, and the erratum only published in 2009. So depending on your point of view, this may or may not count as a theorem accepted for some "nontrivial" amount of time.
AnswerKenntnis:
A fairly recent example that I know of is a paper by the name of "A counterexample to a 1961 'theorem' in homological algebra" by Amnon Neeman (2002). It was a fairly big deal for some people when they realized the 'theorem' was false. I don't know enough about the specifics to discuss it in depth, since it's not terribly close to what I work on, so here is the abstract of Neeman's paper in lieu of any discussion:


  In 1961, Jan-Erik Roos published a ΓÇ£theoremΓÇ¥, which says that in an $[AB4 * ]$ abelian category, $\lim^1$ vanishes on MittagΓÇôLeffler sequences. See Propositions 1 and 5 in [4]. This is a ΓÇ£theoremΓÇ¥ that many people since have known and used. In this article, we outline a counterexample. We construct some strange abelian categories, which are perhaps of some independent interest.These abelian categories come up naturally in the study of triangulated categories. A much fuller discussion may be found in [3]. Here we provide a brief, self contained, nonΓÇôtechnical account. The idea is to make the counterexample easy to read for all the people who have used the result in their work.In the appendix, Deligne gives another way to look at the counterexample.
AnswerKenntnis:
The "telescope conjecture" of chromatic homotopy theory is an interesting example.

In 1984, Ravenel published a seminar paper called "Localization with respect to certain periodic homology theories" where he made a series of 7 or 8 important conjectures about the global structure of the ($p$-local) stable homotopy category of finite spaces.  Four years later, Devinatz-Hopkins-Smith published "Nilpotence I" (while Hopkins was still a grad student!!), which along with the follow-up paper "Nilpotence II" proved all but one of Ravenel's conjectures, the telescope conjecture.  Then in 1990, Ravenel published a disproof of this conjecture, and went so far as to write a paper entitled "Life after the telescope conjecture" in 1992 that detailed a new way forward.  But then it turned out that his disproof had a flaw in it too!  The telescope conjecture remains open to this day, although I think most experts believe that it is false.
AnswerKenntnis:
A famous example of this involves Vandiver's 1934 "proof" of one of the two steps in a line of attack on (an important case of) Fermat's Last Theorem.  In algebraic number theory, there arise important positive integers called class numbers.  In particular, for each prime p, a certain class number $h_p^+$ can be defined that is intimately connected with Fermat's Last Theorem.  

Kummer proposed that (an important case of) Fermat's Last Theorem could be proved by

i)  Proving that $h_p^+$ is not divisible by p

ii)  Proving that $h_p^+$ not being divisible by p implies the "first case" of Fermat's Last Theorem.

In 1934, Vandiver published a proof of ii).  In the introduction to "Cyclotomic Fields I and II", Serge Lang stated:

"...many years ago, Feit was unable to understand a step in Vandiver's 'proof' that $p$ not dividing $h_p^+$ implies the first case of Fermat's Last Theorem, and stimulated by this, Iwasawa found a precise gap which is such that there is no proof."  

(In fact, Vandiver passed away believing that his proof was correct.)

I would like to know more about this history of this myself, and would gladly edit this post with more reliable information.  For instance, 

http://gow.epsrc.ac.uk/NGBOViewGrant.aspx?GrantRef=EP/C549074/1

says that Feit's observation occurred "around" 1980, which suggests that it was never published.
AnswerKenntnis:
Some technical results in the disintegration theory of von Neumann algebras (roughly speaking, results expressing an algebraic object as a "direct integral" of "simpler" algebraic objects) stated by Minoru Tomita in the 1950s turned out to not be OK.  There was an entire chapter following Tomita's approach in Naimark's book Normed Rings that vanished from later editions when the errors came to light.

I am not clear on the details of exactly how Tomita's stuff was wrong.  (This happened before I was born, and I am not that interested in the history of mathematics, so I only know what I have heard about this from people who were there when it happened.)  I have heard one person say that Tomita made use of certain technical results that only held under certain "nice" hypotheses that were not met at the level of generality at which he was working.  Another person said that Tomita's arguments simply weren't clear enough to admit close analysis of how he went wrong, but that flaws were evident once people produced counterexamples to statements of the results.  I don't personally know which of these stories is closer to the truth.

I am not sure to what extent this work was "accepted for a nontrivial amount of time."  The person who told me most of what I know about this conveyed to me that at the time, there was a sense in the air that there was something "fishy" about some of the theorems, and that counterexamples were circulated among people working in the area long before it all worked itself out in print.
AnswerKenntnis:
This seems to be related enough to deserve to be in an answer:

The April 2013 issue of the Notices of the AMS features a long article Errors and Corrections in Mathematics Literature written by Joseph F. Grcar.

Not a specific mistake, rather an analysis of how mathematics journals and mathematicians deal with mistakes in general, compared to other sciences.
AnswerKenntnis:
I don't know how long some of his proofs standed, but Legendre is infamous for his repeated attempts at proving the parallel postulate.
AnswerKenntnis:
Not sure if the following fits the criterion for constraint, but Hans Rademacher incident comes to mind (page 82, The Riemann Hypothesis:
For the aficionado and virtuoso alike):


  8.2 Hans Rademacher and False Hopes
  
  In 1945, Time Magazine reported that Hans Rademacher had submitted a
  flawed proof of the Riemann Hypothesis to the journal Transactions of the
  American Mathematical Society. The text of the article follows:
  A sure way for any mathematician to achieve immortal fame would
  be to prove or disprove the Riemann hypothesis. This baffling theory,
  which deals with prime numbers, is usually stated in RiemannΓÇÖs symbolism
  as follows: ΓÇ£All the nontrivial zeros of the zeta function of s,
  a complex variable, lie on the line where sigma is 1/2 (sigma being
  the real part of s).ΓÇ¥ The theory was propounded in 1859 by Georg
  Friedrich Bernhard Riemann (who revolutionized geometry and laid
  the foundations for EinsteinΓÇÖs theory of relativity). No layman has ever
  been able to understand it and no mathematician has ever proved it.
  One day last month electrifying news arrived at the University of
  Chicago office of Dr. Adrian A. Albert, editor of the Transactions of
  the American Mathematical Society. A wire from the societyΓÇÖs secretary,
  University of Pennsylvania Professor John R. Kline, asked Editor
  Albert to stop the presses: a paper disproving the Riemann hypothesis
  was on the way. Its author: Professor Hans Adolf Rademacher, a
  refugee German mathematician now at Penn. 
  On the heels of the telegram came a letter from Professor Rademacher
  himself, reporting that his calculations had been checked and confirmed
  by famed Mathematician Carl Siegel of PrincetonΓÇÖs Institute
  for Advanced Study. Editor Albert got ready to publish the historic
  paper in the May issue. U.S. mathematicians, hearing the wildfire rumor,
  held their breath. Alas for drama, last week the issue went to
  press without the Rademacher article. At the last moment the professor
  wired meekly that it was all a mistake; on rechecking. Mathematician
  Siegel had discovered a flaw (undisclosed) in the Rademacher
  reasoning. U.S. mathematicians felt much like the morning after a
  phony armistice celebration. Sighed Editor Albert: ΓÇ£The whole thing
  certainly raised a lot of false hopes.ΓÇ¥ [142]


Edit: This link has further (dis)proofs of RH including de Branges saga.
AnswerKenntnis:
A plentiful source of examples of "theorems" that were "proved" is supplied by the Italian school of algebraic geometry.

The Italians, most prominently Guido Castelnuovo, Federigo Enriques and Francesco Severi, derived some remarkable results on classification algebraic surfaces, relying strongly on geometical insight. The problem was, their reliance on intuition ultimately led them astray, to the point where some of things that were intuitively obvious to Severi were plain wrong. For an extreme example, Severi claimed to show a degree 6 surface in a 3 dimensional projective space has at most 52 nodes, while Mumford exhibited such surface that in fact had 65 nodes. Wikipedia provides a short but informative discussion. There is also a great thread on Mathoverflow.
AnswerKenntnis:
Has there ever been a mistake? LOL! Yeah, just a few. ;-)

OK, so that isn't exactly what you asked...

Well, there have been plenty of conjectures which everybody thought were correct, which in fact were not. The one that springs to mind is the Over-estimated Primes Conjecture. I can't seem to find a URL, but essentially there was a formula for estimating the number of primes less than $N$. Thing is, the formula always slightly over-estimates how many primes there really are... or so everybody thought. It turns out that if you make $N$ absurdly large, then the formula starts to under-estimate! Nobody expected that one. (The "absurdly large number" was something like $10^{10^{10^{10}}}$ or something silly like that.)

Fermat claimed to have had a proof for his infamous "last theorem". But given that the eventual proof is a triumph of modern mathematics running to over 200 pages and understood by only a handful of mathematicians world wide, this cannot be the proof that Fermat had 300 years ago. Therefore, either 300 years of mathematicians have overlooked something really obvious, or Fermat was mistaken. (Since he never write down his proof, we can't claim that "other people believed it before it was proven false" though.)

Speaking of which, I'm told that Gauss or Cauchy [I forget which] published a proof for a special case of Fermat's last theorem - and then discovered that, no, he was wrong. (I don't recall how long it took or how many people believed it.)
QuestionKenntnis:
Fun but serious mathematics books to gift advanced undergraduates.
qn_description:
I am looking for fun, interesting mathematics textbooks which would make good studious holiday gifts for advanced mathematics undergraduates or beginning graduate students.  They should be serious but also readable.

In particular, I am looking for readable books on more obscure topics not covered in a standard undergraduate curriculum which students may not have previously heard of or thought to study.

Some examples of suggestions I've liked so far:


On Numbers and Games, by John Conway.
Groups, Graphs and Trees: An Introduction to the Geometry of Infinite Groups, by John Meier.
Ramsey Theory on the Integers, by Bruce Landman.


I am not looking for pop math books, Godel, Escher, Bach, or anything of that nature.

I am also not looking for books on 'core' subjects unless the content is restricted to a subdiscipline which is not commonly studied by undergrads.  (E.g. Finite Group Theory by Isaacs would be good, but Abstract Algebra by Dummit and Foote would not.)
AnswersKenntnis
AnswerKenntnis:
Check into Generatingfunctionology by Herbert Wilf. From the linked (author's) site, the second edition is available for downloading as a pdf. There is also a link to the third edition, available for purchase. It's a very helpful, useful, readable, fun, (and short!) book that a student could conceivably cover over winter break.





Another promising book by John Conway (et. al.) is The Symmetries of Things, which may very well be of interest to students.





One additional suggestion, as it is a classic well worth being placed on any serious student's bookshelf: How to Solve It by Georg Polya.
AnswerKenntnis:
For a fun read, which has the additional advantage of dividing into independent chapters which can be consumed in bite-sized chunks over the holiday season, how about


  Proofs from The Book, by Martin Aigner and G├╝nter Ziegler


And +1 to the OP's initial suggestion of Conway's On Numbers and Games.
AnswerKenntnis:
I would gift "Visual Complex Analysis" by Needham. It is a very beautiful book with a deep geometric intuition about complex numbers that is not typically covered in an undergraduate complex analysis course.
I would also gift Stillwell's "Roads to Infinity: The Mathematics of Truth and Proof", one of the most beautiful treatment of the infinity concept that I encountered and that does not stay at the undergraduate level.
AnswerKenntnis:
Julian HavilΓÇÖs Gamma: Exploring EulerΓÇÖs Constant is a very readable introduction to a number of topics tied together by connections with the Euler-Mascheroni constant $\gamma$, topics that in my experience seldom get more than a mention in an undergraduate curriculum. ItΓÇÖs not a textbook, but itΓÇÖs not a popularization in the usual sense; call it a popularization for younger mathematicians.

Graham, Knuth, & Patashnik, Concrete Mathematics, is one of the most readable textbooks IΓÇÖve seen; some of the material in it may be covered in undergraduate courses in combinatorics or probability, but much of it will be unfamiliar.
AnswerKenntnis:
I just got a hold on the book Primes of the Form $p=x^2+ny^2$ by David A. Cox and I think it has the required features. 

In this book the author manages to present advanced algebraic number theory via historical point of view. He starts with the works of Fermat, Euler, and Gauss, and finishes with class field theory and complex multiplication. 

I would certainly recommend this book as a fun and interesting book for an advance undergrad or beginning grad student (actually to anyone who likes number theory).
AnswerKenntnis:
This is a great book on the art of inequalities. Lots of problems inside as well:
Cauchy-Schwarz Inequality

Also available online in PDF form here:

Cauchy-Schwarz PDF
AnswerKenntnis:
The Sensual (Quadratic) Form, by John Conway.

I confess that I've only read the first chapter, but what I've read seems to fit the bill perfectly: Easily readable essays on an interesting topic that students don't normally see. Each chapter is independent from the others, and even many number theorists I know haven't heard of "topographs," the unique approach to visualizing quadratic forms that Conway develops in the first chapter.

EDIT: I want to add Proofs that Really Count by Art Benjamin and Jenny Quinn. Again, haven't read it myself, but I've met both the authors and seen them give (excellent) talks, and I've never heard anything but praise for this book.
AnswerKenntnis:
Surreal Numbers by Knuth.
A Novel which turns into pure mathematics.
AnswerKenntnis:
Here are some fun books on geometric topology:


The Shape of Space by Jeff Weeks
The Knot Book by Colin Adams
The Wild World of 4-Manifolds by Alexandru Scorpan


Scorpan's book is much more difficult than the first two, but it's still suitable for many beginning graduate students.

Disclaimer: While I'm currently reading Scorpan's book, I haven't actually read either Weeks' or Adams' book.  These are titles that I know from reputation and would eventually like to read myself.
AnswerKenntnis:
Two of my favorites are written by John Derbyshire. They both combine a historical narrative with mathematical discourse with plenty of charts and illustrations to help visualize concepts:


Prime Obsession: Bernhard Riemann and the Greatest Unsolved Problem in Mathematics (Plume Books, 2003) ISBN 0-452-28525-9
Unknown Quantity: A Real And Imaginary History of Algebra (Joseph Henry Press, 2006) ISBN 0-309-09657-X
AnswerKenntnis:
I propose Counterexamples in Topology and Visual Group Theory.

Les nombres remarquables by Fran├ºois le Lionnais is also interesting, but it is written in French; I do not know if there is an equivalent in English, maybe The Penguin Dictionary of Curious and Interesting Numbers.
AnswerKenntnis:
I would highly suggest Matrix Groups for Undergraduates by Kristopher Tapp. This is extremely readable--you feel like you are doing little more than reviewing some linear algebra and analysis, but BAM you realize that you've just had an extremely gentle, but useful introduction to the basics of Lie groups.
AnswerKenntnis:
Look at Numbers, by Ebbinghaus and 7 co-authors. It has nice discussions about the real and complex numbers (aimed at mathematicians, not neophytes), and also the  quaternions, octonions, p-adic numbers, and infinitesimals.
AnswerKenntnis:
I suggest Information Theory, Inference and Learning Algorithms by David MacKay. It is a book about Information Theory and codes, topics of great practical importance which aren't well covered in undergraduate courses. It has many exercises, some of which are very challenging. Opening it at random is bound to reveal something interesting, such as how the Bletchley Park codebreakers worked, what's the difference between British and American crosswords, and why we don't reproduce asexually. It requires a minimum of prior knowledge and is also a great introduction to probability and Bayesian statistics.
AnswerKenntnis:
I recommend Paul Halmos' Automathography for an account of an extremely interesting life in mathematics. It's a joy to read!
AnswerKenntnis:
I've not read it myself, but a friend told me he really enjoyed Robertson and Webb's Cake-Cutting Algorithms: Be Fair If You Can, which seems to be both mathematically serious and readable, and moreover is on a topic not usually covered in the undergraduate curriculum.
AnswerKenntnis:
Here are some of my favorite books in this category.

Real Infinite Series

A Radical Approach to Real Analysis

Counterexamples in Analysis

Galois Theory for Beginners

All of these are great for pedagogical purposes. They are all well written and accessible to any undergrad. The first one, even calculus students can appreciate. The next two teach and supplement any analysis course. The fourth one gives an excellent history and an introduction to Galois theory, how/why it began, why the quintic is impossible to solve in radicals, how Gauss made an algebraic connection to geometry and provided a construction of a regular 17-gon, and how three of the ancient geometric problems (doubling a cube, squaring a circle, and trisecting an angle) were proved impossible once and for all.
AnswerKenntnis:
Ronald Brown's Topology And Groupoids gives a highly original and unusual first course in topology through basic category theory and the fundamental groupoid instead of the fundamental group. This allows Brown to present homotopy constructions in a very geometric way and to exclude homology altogether.
AnswerKenntnis:
Imre Lakatos, Proofs and refutations: The logic of mathematical  discovery

It's a joy to read and everybody will  learn something new from it, even your math professor (if he didn't already read it).
AnswerKenntnis:
In addition to the other choices, maybe you want to think about some other types of books.

You might want to check out many of the books by Clifford Pickover.

Additionally, you might want to go through this large list of fascinating mathematical fiction books and titles and you might find interesting choices.

Have fun!
AnswerKenntnis:
Modern Graph theory by Bela Bollobas counts as fun if they're interested in doing exercises which can be approached by clever intuitive arguments; it's packed full of them.
AnswerKenntnis:
Euler's Gem is a great book, you should check it out!
AnswerKenntnis:
Fifty challenging problems in probability. Here is a larger list. Hope it helps
AnswerKenntnis:
I would suggest Graphs and their uses by Oystein Ore.

One can find there some game theory, shortest route problems, coloring maps on surfaces, etc. It is very pleasant to read.
AnswerKenntnis:
I personally did not read this, but a friend of mine read A History of Abstract Algebra by Israel Kleiner for a term paper he was writing.  It was real good, especially the parts about Noether and Dedekind. From what I gather all the information came from this book.  I plan to buy it soon myself.
AnswerKenntnis:
I should like to add In Pursuit of the Traveling Salesman by William Cook.
AnswerKenntnis:
Saunders MacLane, Mathematics Form and Function. I'm reading it right now. It gives a wonderful birds eye view of (undergraduate) mathematics. The book is mostly self-contained for undergraduates and upwards, but it certainly helps to know a lot of math already.
AnswerKenntnis:
Off the top, no particular order:


Conceptual Mathematics - Lawvere and Schanuel
Sets for Mathematics - Lawvere and Rosebrugh
A Walk Through Combinatorics - Bona
Combinatorial Species and Tree-Like Structures - Bergeron, Labelle & Leroux
Ordinary Differential Equations - Arnold
What Are and What's the Purpose of Numbers - Dedekind 
Collected Works of Karl Menger - Menger  
Algebraic Number Theory and Fermat's Last Theorem - Stewart


Just a couple if you're interested in applied areas:


Theory of Gambling and Statistical Logic - Epstein
Theoretical Introduction to Programming - Mills
Elements of Statistical Learning - Hastie, Tibshirani & Friedman
AnswerKenntnis:
Here are several books that I have looked at frequently. 

Proofs and Confirmations, David Bressoud

Winning Ways For your Mathematical Plays Vols. 1 to 4, Berlekamp, Conway, Guy

Integer Partitions, Andrews and Eriksson

Number Theory in Science and Communication, Schroeder

Fractals, Chaos, and Power Laws, Schroeder

The first part of The Road to Reality, Penrose contains a primer on the math required in modern physics.
AnswerKenntnis:
The Cartoon Guide to Calculus is an amazing book for calculus beginners and does satisfy all of the OP's needs.
QuestionKenntnis:
Surprising identities / equations
qn_description:
What are some surprising equations / identities that you have seen, which you would not have expected?

This could be complex numbers, trigonometric identities, combinatorial results, algebraic results, etc.

I'd request to avoid 'standard' / well-known results like $ e^{i \pi} + 1 = 0$.

Please write a single identity (or group of identities) in each answer.

I found this list of Funny identities, in which there is some overlap.
AnswersKenntnis
AnswerKenntnis:
This one by Ramanujan gives me the goosebumps:

$$
\frac{2\sqrt{2}}{9801} \sum_{k=0}^\infty \frac{ (4k)! (1103+26390k) }{ (k!)^4 396^{4k} } = \frac1{\pi}.
$$
AnswerKenntnis:
$\mathrm{GCD}(F_{n},F_{m}) = F_{\mathrm{GCD}(n,m)}$ where $F_n$ is the $n$th Fibonacci number.
AnswerKenntnis:
${1\over 2} < \left\lfloor \mathrm{mod}\left(\left\lfloor {y \over 17} \right\rfloor 2^{-17 \lfloor x \rfloor - \mathrm{mod}(\lfloor y\rfloor, 17)},2\right)\right\rfloor$

The above is the most interesting inequality in mathematics.  If you plot it so that areas satisfying the inequality are shaded, this is what you get:



This is known as Tupper's self referential formula.
AnswerKenntnis:
$$10^2+11^2+12^2=13^2+14^2$$ I found that one stunning.

P.S. In general, for $n>0$, the sum of $n+1$ consecutive squares starting with $x_1 = 2n^2+n$ is equal to $n$ consecutive squares starting with $y_1 = x_1+(n+1)$. Hence,

$$3^2+4^2 = 5^2$$

$$10^2+11^2+12^2=13^2+14^2$$

$$21^2+22^2+23^2+24^2 = 25^2+26^2+27^2$$

and so on.
AnswerKenntnis:
$3^3 + 4^3 + 5^3 = 6^3$.

Also,

$1/89 = 0.01 + 0.001 + 0.0002 + 0.00003 + 0.000005 + 0.0000008 + 0.00000013 + \cdots$.



Let $S = \sum \frac{F_n} {k^n}$. Then $S + kS =  1 + \sum \frac{ F_{n} + F_{n-1} } {k^n} = 1 + \sum \frac {F_{n+1}}{k^n} = 1 + k^2S -1 - k$

In particular, for $k=10$, we get $ S = \frac{10}{89}$. Divide by 10 to get the second equation.
AnswerKenntnis:
$$\sum_{n=1}^\infty \frac{1}{n^2}=\frac{\pi^2}{6}$$

was surprising to me when I saw it for the first time.
AnswerKenntnis:
This is slightly contrived, but consider a situation where you have two balls, of mass $M$ and $m$, where $M=16\times100^N\times m$ for some integer $N$.  The balls are placed against a wall as shown: 



We push the heavy ball towards the lighter one and the wall.  The balls are assumed to collide elastically with the wall and with each other.  The smaller ball bounces off the larger ball, hits the wall and bounces back.  At this point there are two possible solutions: the balls collide with each other infinitely many times until the larger ball reaches the wall (assume they have no size), or the collisions from the smaller ball eventually cause the larger ball to turn around and start heading in the other direction - away from the wall.  

In fact, it is the second scenario which occurs: the larger ball eventually heads away from the wall.  Denote by $p(N)$ the number of collisions between the two balls before the larger one changes direction, and gaze in astonishment at the values of $p(N)$ for various $N$: 

\begin{align}
p(0)&=3\\
p(1)&=31\\
p(2)&=314\\
p(3)&=3141\\
p(4)&=31415\\
p(5)&=314159\\
\end{align}

and so on.  $p(N)$ is the first $N+1$ digits of $\pi$!  

This can be made to work in other bases in the obvious way.  

See 'Playing Pool with $\pi$' by Gregory Galperin.
AnswerKenntnis:
Taken from the first question I posed upon joining M.SE:

Define a function $f(\alpha, \beta)$, $\alpha \in (-1,1)$, $\beta \in (-1,1)$ as

$$ f(\alpha, \beta) = \int_0^{\infty} dx \: \frac{x^{\alpha}}{1+2 x \cos{(\pi \beta)} + x^2}$$

You can use, for example, the Residue Theorem to show that

$$ f(\alpha, \beta) = \frac{\pi \sin{\pi \alpha \beta}}{ \sin{\pi \alpha}  \sin{\pi \beta}} $$

Clearly, from this latter expression, $f(\alpha, \beta) = f(\beta, \alpha)$.  But from where does such a symmetric result come?  The integral itself does not lend itself to predicting any such symmetry so far as I (and many others so far) can see.
AnswerKenntnis:
Where $\varphi = \frac{1 + \sqrt{5}}{2}$ a golden ratio, $$\int_0^\infty\frac{1}{(1+x^\varphi)^\varphi}\mathrm dx = 1.$$

The proof for this goes as follows (with $B$ being the beta function):
$$\begin{align}
\int_0^\infty\frac{1}{(1+x^\varphi)^\varphi}\mathrm dx
&= \varphi^{-1}\int_0^\infty\frac{y^{\varphi^{-1} - 1}}{(1+y)^\varphi}\mathrm dy \\
&= \varphi^{-1}\int_0^\infty\frac{y^{\varphi - 2}}{(1+y)^\varphi}\mathrm dy \\
&= \varphi^{-1} B\bigl(\varphi - 1, 1\bigr) \\
&= \varphi^{-1} \frac{\Gamma(\varphi-1)\ \Gamma(1)}{\Gamma(\varphi)} \\
&= \varphi^{-1} \frac{1}{\varphi - 1} = 1.
\end{align}$$

One more thing with golden ratio : by Ramanujan, 
$$r=\dfrac{e^{-2\pi/5}}{1 + \dfrac{e^{-2\pi}}{ 1 + \dfrac{e^{-4\pi}}{1 + \cdots}}} =  \sqrt{ \sqrt{5}\varphi} - \varphi$$

and even more bizarrely (found based on the work of Vidunas), the hypergeometric function $N=\,_2F_1\big(\tfrac{19}{60},\tfrac{-1}{60},\tfrac{4}{5},1\big)$ is a deg-80 algebraic number given by,

$$N=\frac{1}{(r^{20}-228r^{15}+494r^{10}+228r^5+1)^{1/20}}$$
AnswerKenntnis:
By far my favorite identity: $\displaystyle\int_{-\infty}^{\infty} \frac{\sin \left( x\right )}{x} \mathrm{d}x = \int_{-\infty}^{\infty} \frac{\sin ^ 2\left( x\right )}{x^2} \mathrm{d}x$

The fun part about this one (for me) is that it looks absolutely false at first glance.  They both evaluate to $\pi$.
AnswerKenntnis:
When I began my serious encounter with number theory and looked at properties of prominent combinatorical matrices I found this identity. This impressed me so much (even a bit philosophically) that I wanted to printed it on a t-shirt (but the white-on-black printing was then too expensive). The german phrase means "the exponential of the counting is the binomial"     

Here is, how it looked asymptotically:
AnswerKenntnis:
Easy geometric series but I found this one charming when I found out:

1/7 = 0,142857...
    = 0,14 +
      0,0028 +
      0,000056 +
      0,00000112 +
      0,0000000224 + ... (double the value and shift it by two spaces)
AnswerKenntnis:
If $A+B+C=180^\circ$ then
$$\tan(A)+\tan(B)+\tan(C)=\tan(A)\tan(B)\tan(C)$$
AnswerKenntnis:
$$\frac{\Gamma\left(\frac15\right)\Gamma\left(\frac4{15}\right)}{\Gamma\left(\frac13\right)\Gamma\left(\frac2{15}\right)}=\frac{\sqrt2\,\sqrt[20]3}{\sqrt[6]5\sqrt[4]{5-\frac{7}{\sqrt{5}}+\sqrt{6-\frac{6}{\sqrt{5}}}}}\,$$
AnswerKenntnis:
$\displaystyle\sum_{k=1}^{24} k^2=70^2$ is novel.
AnswerKenntnis:
$ \tan 10^\circ  = \tan 20^\circ \times \tan 30^\circ \times \tan 40^\circ $.
$\tan 80^\circ = \tan 70^\circ \times \tan 60^\circ \times \tan 50^\circ $.
AnswerKenntnis:
Do logic answers count?  I like the Drinker Paradox, which isn't really a paradox but actually a theorem of logic:

$\exists x.\ [D(x) \rightarrow \forall y.\ D(y)]$

For every bar there is a person for whom, if that person is drinking, then everyone is drinking.
AnswerKenntnis:
Here is a mathematical scherzo.

$$\left(\sum_{k=1}^n k\right)^2 = \sum_{k=1}^n k^3.$$
AnswerKenntnis:
$$\sum_{k=1}^{\infty}k^{-k}=\int_0^1x^{-x}\mbox{ d}x=\mathrm{Sophomore's}\mbox{ }  \mathrm{dream}$$
AnswerKenntnis:
$$\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}dx=\dfrac{\pi e}{4!}$$
AnswerKenntnis:
$$
\int_0^1 \frac{\ln(1+t^{4+\sqrt{15}})}{1+t}dt= -\frac{\pi^2}{12}(\sqrt{15}-2)+\ln 2\cdot \ln(\sqrt{3}+\sqrt{5})+\ln\frac{1+\sqrt{5}}{2}\cdot \ln(2+\sqrt{3}) 
$$

For references, see http://ega-math.narod.ru/Chowla/index.htm (there is a scan of a paper of Herglotz where it is proved).
AnswerKenntnis:
The square root of 2 is also the only real number other than 1 whose infinite tetrate is equal to its square...
AnswerKenntnis:
$$
{a \over b} = {c \over d}
\quad\Longrightarrow\quad 
{a + b\over a - b} = {c + d \over c - d}
$$
AnswerKenntnis:
$$ \begin{align}\frac{\pi}{4} = 4 \arctan \frac{1}{5} - \arctan \frac{1}{239}   \\\,\\\,\\
 \frac{\pi}{4} = 5 \arctan \frac{1}{7} + 2 \arctan \frac{3}{79}\end{align}$$

Both can be shown easily using polar form, complex multiplication.
AnswerKenntnis:
I find this identity due to Euler particularly striking (and not obvious at all):
$$\prod_{n=1}^\infty (1-x^n) = \sum_{k=-\infty}^\infty (-1)^k\,x^{p(k)}$$

where the $p(k) = \dfrac{k(3k-1)}{2}$ are the generalized pentagonal numbers. This is what these numbers look like us  for $1 \leq k \leq 5$,


[image created by Aldoaldoz]
AnswerKenntnis:
Some zeta-identies have been much surprising to me.       

Let's denote the value $\zeta(s)-1$ as $\zeta_1(s)$ then
$$ \small \begin{array} {}
1 \zeta_1(2) &+&1 \zeta_1(3)&+&1 \zeta_1(4)&+&1 \zeta_1(5)&+&  ... &=&1\\
1 \zeta_1(2) &+&2 \zeta_1(3)&+&3 \zeta_1(4)&+&4 \zeta_1(5)&+&  ... &=&\zeta(2)\\
             & &1 \zeta_1(3)&+&3 \zeta_1(4)&+&6 \zeta_1(5)&+&  ... &=&\zeta(3)\\ 
             & &            & &1 \zeta_1(4)&+&4 \zeta_1(5)&+&  ... &=&\zeta(4)\\ 
             & &            & &            & &1 \zeta_1(5)&+&  ... &=&\zeta(5)\\ 
 ...         & & & & & & & &... &= &  ...
\end{array}
$$
There are very similar stunning alternating-series relations:

$$ \small \begin{array} {}
1 \zeta_1(2) &-&1 \zeta_1(3)&+&1 \zeta_1(4)&-&1 \zeta_1(5)&+&  ... &=&1/2\\
             & &2 \zeta_1(3)&-&3 \zeta_1(4)&+&4 \zeta_1(5)&-&  ... &=&1/4\\
             & &            & &3 \zeta_1(4)&-&6 \zeta_1(5)&+&  ... &=&1/8\\ 
             & &            & &            & &4 \zeta_1(5)&-&  ... &=&1/16\\ 
 ...         & & & & & & & &... &= &  ...
\end{array}
$$
AnswerKenntnis:
$3^3 + 4^4 + 3^3 + 5^5 = 3435$

$1^1=1$ is the only other such number.
AnswerKenntnis:
$$\sum_{n=1}^\infty(n\,\operatorname{arccot}n-1)=\frac12+\frac{17\,\pi}{24}-\ln\sqrt{e^{2\pi}-1}+\frac1{4\pi}\operatorname{Li}_2\frac1{e^{2\pi}},$$
where $\operatorname{Li}_2$ is the dilogarithm.
AnswerKenntnis:
Ramanujan stated this radical in his lost notebook:

$$\sqrt{5+\sqrt{5+\sqrt{5-\sqrt{5+\sqrt{5+\sqrt{5+\sqrt{5-\dots}}}}}}} = \frac{2+\sqrt 5 +\sqrt{15-6\sqrt 5}}{2}$$

I still don't have any idea on this one.
AnswerKenntnis:
Pfister's 16-Square Identity:

$$(x_1^2+x_2^2+x_3^2+\dots+x_{16}^2)(y_1^2+y_2^2+y_3^2+\dots+y_{16}^2) = z_1^2+z_2^2+z_3^2+\dots+z_{16}^2$$

where the $z_i$ are rational functions of the $x_i, y_i$. One would have thought that $n$ square identities are only for $n = 1,2,4,8$, but non-bilinear ones in fact are for all $n = 2^m$.
